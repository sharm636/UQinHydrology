{"cells":[{"cell_type":"markdown","metadata":{"id":"Avdd-HgKVhZD"},"source":["# IMPORT LIBRARIES"]},{"cell_type":"markdown","metadata":{"id":"ErxoKhyiVhZF"},"source":["# LOAD DATA"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GDIEeBFXVhZF"},"outputs":[],"source":["import sys\n","sys.path.append(\"../\")\n","import config\n","import EALSTM\n","import os\n","import random\n","import math\n","import time\n","import numpy as np\n","import pandas as pd\n","import torch\n","import matplotlib.pyplot as plt\n","from collections import Counter\n","from sklearn.cluster import KMeans\n","from sklearn.manifold import TSNE\n","\n","# CHANNELS INFO\n","channels = config.channels\n","input_channels = config.weather_channels+config.sf_channels\n","sf_channels = config.sf_channels\n","static_channels = config.static_channels\n","\n","# TIME SERIES INFO\n","window = config.window\n","\n","# TRAIN INFO\n","device = config.device\n","code_dim = config.code_dim\n","n_clusters = config.n_clusters\n","epochs = 200#config.epochs\n","batch_size = config.batch_size\n","learning_rate = 0.003 #config.learning_rate\n","alpha = config.alpha\n","\n","# MODEL INFO\n","recon_weight = 1#config.recon_weight\n","static_weight = 1#config.static_weight\n","triplet_weight = 1# config.triplet_weight\n","sum_weight = recon_weight+static_weight+triplet_weight \n","architecture = \"ATT_NL\"\n","# architecture = \"LAST\"\n","run = 1# int(sys.argv[1])\n","temp = 1#float(sys.argv[2])\n","num_hidden =0\n","num_layer =1\n","Hidden=\"Hidden_{}_Serial_contrastive_extend\".format(num_hidden)\n","\n","# MODEL NAME\n","model_name = \"{}_{}_{}_{}_{}_{}_{}_{}_{}_{}_{}_{}\".format(\"ALL\", architecture, code_dim, len(static_channels), run,batch_size,\"{}_NL\".format(num_layer),Hidden,recon_weight,static_weight,triplet_weight,temp)\n","pretrain = None\n","\n","print(\"{} Hyperparameters\".format(model_name))\n","print(\"Channels : {}\".format(channels))\n","print(\"Input Channels : {}\".format(input_channels))\n","print(\"Static Channels : {}\".format(static_channels))\n","print(\"Code dim : {}\".format(code_dim))\n","print(\"Epochs : {}\".format(epochs))\n","print(\"Batch Size : {}\".format(batch_size))\n","print(\"Learning rate : {}\".format(learning_rate))\n","print(\"Reconstruction Weight : {}\".format(recon_weight))\n","print(\"Static Weight : {}\".format(static_weight))\n","print(\"Triplet Weight : {}\".format(triplet_weight))\n","print(\"Temperature : {}\".format(temp))\n","print(\"Pretrain : {}\".format(pretrain))\n","\n","if not os.path.exists(os.path.join(config.MODEL_DIR)):\n","    os.makedirs(os.path.join(config.MODEL_DIR))\n","if not os.path.exists(os.path.join(config.RESULT_DIR)):\n","    os.makedirs(os.path.join(config.RESULT_DIR))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yb-LeVPqVhZH"},"outputs":[],"source":["train_data = np.load(os.path.join(config.NUMPY_DIR, \"train_data_basin_ealstm.npy\"))[:,:,:,:-1]\n","validation_data = np.load(os.path.join(config.NUMPY_DIR, \"validation_data_basin_ealstm.npy\"))[:,:,:,:-1]\n","test_data = np.load(os.path.join(config.NUMPY_DIR, \"test_data_basin_ealstm.npy\"))[:,:,:,:-1]\n","\n","print(\"Train Data:{}\\tValidation Data:{}\\tTest Data:{}\".format(train_data.shape, validation_data.shape, test_data.shape))\n","\n","feature_names = np.load(os.path.join(config.DATA_DIR, \"RAW_DATA\", \"feature_names.npy\"), allow_pickle=True)\n","print(\"Static features:{}\".format(feature_names[config.static_channels]))\n","print(\"Weather features:{}\".format(feature_names[config.weather_channels]))\n","print(\"SF features:{}\".format(feature_names[config.sf_channels]))"]},{"cell_type":"markdown","metadata":{"id":"gbk_VTY1VhZH"},"source":["# BUILD MODEL"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zOeNG78FVhZH"},"outputs":[],"source":["class SimCLR_Loss(torch.nn.Module):\n","    def __init__(self, temperature):\n","        super(SimCLR_Loss, self).__init__()\n","        self.temperature = temperature\n","        self.criterion = torch.nn.CrossEntropyLoss(reduction=\"sum\")\n","        self.similarity = torch.nn.CosineSimilarity(dim=2)\n","\n","    def mask_correlated_samples(self, batch_size):\n","        N = 2 * batch_size\n","        mask = torch.ones((N, N), dtype=bool)\n","        mask = mask.fill_diagonal_(0)\n","        \n","        for i in range(batch_size):\n","            mask[i, batch_size + i] = 0\n","            mask[batch_size + i, i] = 0\n","        return mask\n","\n","    def forward(self, z):\n","        \n","        N = z.shape[0]\n","        batch_size = N//2\n","\n","        sim = self.similarity(z.unsqueeze(1), z.unsqueeze(0)) / self.temperature\n","\n","        sim_i_j = torch.diag(sim, batch_size)\n","        sim_j_i = torch.diag(sim, -batch_size)\n","        \n","        positive_samples = torch.cat((sim_i_j, sim_j_i), dim=0).reshape(N, 1)\n","        mask = self.mask_correlated_samples(batch_size)\n","        negative_samples = sim[mask].reshape(N, -1)\n","        \n","        #SIMCLR\n","        labels = torch.from_numpy(np.array([0]*N)).reshape(-1).to(positive_samples.device).long()\n","        \n","        logits = torch.cat((positive_samples, negative_samples), dim=1)\n","        loss = self.criterion(logits, labels)\n","        loss /= N\n","        \n","        return loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l6zyw5-LVhZI"},"outputs":[],"source":["class ATT_NL(torch.nn.Module):\n","    def __init__(self, in_channels, stat_channels, code_dim, device):\n","        super(ATT_NL,self).__init__()\n","        \n","        self.code_dim = code_dim\n","        self.device = device\n","        self.encoder = torch.nn.GRU(in_channels, code_dim,num_layers=num_layer, batch_first=True, bidirectional=True)\n","        self.att = torch.nn.Linear(code_dim, 1)\n","        self.decoder = torch.nn.GRU(in_channels, code_dim, batch_first=True)\n","        self.out = torch.nn.Linear(code_dim, in_channels)\n","        self.linear_1 = torch.nn.Linear(code_dim,code_dim)\n","        #self.linear_2 = torch.nn.Linear(code_dim,code_dim)\n","        self.static_out = torch.nn.Linear(code_dim, stat_channels)\n","        self.relu = torch.nn.ReLU()\n","\n","        for m in self.modules():\n","            if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Linear):\n","                torch.nn.init.xavier_uniform_(m.weight)\n","    \n","    def forward(self, x):\n","        batch, seq_len, in_channels = x.shape\n","        \n","        code_vec, _ = self.encoder(x)\n","        code_vec = torch.add(code_vec[:,:,:self.code_dim], code_vec[:,:,self.code_dim:])\n","        att_weights = torch.unsqueeze(torch.nn.functional.softmax(self.att(code_vec).squeeze(), dim=1), dim=-1)\n","        code_vec = att_weights*code_vec\n","        code_vec = torch.unsqueeze(torch.sum(code_vec, dim=1), dim=0)\n","        static_out = self.relu(self.linear_1(code_vec.squeeze()))\n","        #static_out = self.relu(self.linear_2(static_out))\n","        static_out = self.static_out(static_out)\n","\n","        out = torch.zeros(batch, seq_len, in_channels).to(self.device)\n","        h = code_vec\n","        input = torch.zeros((batch, 1, in_channels)).to(self.device)\n","        for step in range(seq_len):\n","            input, h = self.decoder(input, h)\n","            output = self.out(torch.mul(input.squeeze(), code_vec.squeeze()))\n","            out[:,step] = output\n","            input = output.unsqueeze(1)\n","        \n","        out = out.view(batch, seq_len, in_channels)\n","        return code_vec.squeeze().view(batch, -1), out, static_out     \n","\n","    \n","class LAST(torch.nn.Module):\n","    def __init__(self, in_channels, stat_channels, code_dim, device):\n","        super(LAST,self).__init__()\n","        \n","        self.code_dim = code_dim\n","        self.device = device\n","        self.encoder = torch.nn.GRU(in_channels, code_dim, batch_first=True, bidirectional=True)\n","        self.decoder = torch.nn.GRU(in_channels, code_dim, batch_first=True)\n","        self.out = torch.nn.Linear(code_dim, in_channels)\n","        self.static_out = torch.nn.Linear(code_dim, stat_channels)\n","\n","        self.encoder = torch.nn.GRU(in_channels, code_dim, batch_first=True, bidirectional=True)\n","        self.decoder = torch.nn.GRU(in_channels, code_dim, batch_first=True)\n","        self.out = torch.nn.Linear(code_dim, in_channels)\n","\n","        for m in self.modules():\n","            if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Linear):\n","                torch.nn.init.xavier_uniform_(m.weight)\n","    \n","    def forward(self, x):\n","        batch, seq_len, in_channels = x.shape\n","        \n","        _, code_vec = self.encoder(x)\n","        code_vec = torch.unsqueeze(torch.sum(code_vec, dim=0), dim=0)\n","        static_out = self.static_out(code_vec.squeeze())\n","\n","        out = torch.zeros(batch, seq_len, in_channels).to(self.device)\n","        h = code_vec\n","        input = torch.zeros((batch, 1, in_channels)).to(self.device)\n","        for step in range(seq_len):\n","            input, h = self.decoder(input, h)\n","            output = self.out(torch.mul(input.squeeze(), code_vec.squeeze()))\n","            out[:,step] = output\n","            input = output.unsqueeze(1)\n","        \n","        out = out.view(batch, seq_len, in_channels)\n","        return code_vec.squeeze().view(batch, -1), out, static_out\n","\n","model = globals()[architecture](in_channels=len(input_channels), stat_channels=len(static_channels), code_dim=code_dim, device=device)\n","model = model.to(device)\n","criterion = torch.nn.MSELoss(reduction=\"none\")\n","contrastive_criterion = SimCLR_Loss(temperature=temp)\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","print(\"Total trainable parameters:{}\".format(pytorch_total_params))"]},{"cell_type":"markdown","metadata":{"id":"3oPPzjuyVhZI"},"source":["# LOAD PRETRAINED MODEL"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I-x3f9WEVhZI"},"outputs":[],"source":["if pretrain:\n","    model.load_state_dict(torch.load(os.path.join(config.MODEL_DIR, \"{}_{}.pt\".format(pretrain, code_dim))), strict=False)\n","    model.eval()"]},{"cell_type":"markdown","metadata":{"id":"vepueszrVhZJ"},"source":["# TRAIN MODEL"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-U2p5M6AVhZJ"},"outputs":[],"source":["train_loss = []\n","validation_loss = []\n","min_val = 10000\n","nan_batch =[]\n","for epoch in range(epochs):\n","    start = time.time()\n","    \n","    model.train()\n","\n","    #############################################################\n","    # RUN ON TRAIN DATA\n","    dataset = train_data\n","    basins = dataset.shape[0]\n","    years = dataset.shape[1]\n","    window = dataset.shape[2]\n","    channels = dataset.shape[3]\n","    \"\"\"Generate random years\"\"\"\n","    random_years_1 = np.zeros((basins, years))\n","    for node in range(basins):\n","        random_years_1[node] = random.sample(range(years), years)\n","    random_years_1 = random_years_1.astype(np.int64)\n","    random_years_2 = np.zeros((basins, years))\n","    for node in range(basins):\n","        random_years_2[node] = random.sample(range(years), years)\n","    random_years_2 = random_years_2.astype(np.int64)\n","\n","    total_loss = 0\n","    total_recon_loss = 0\n","    total_contrastive_loss = 0\n","    total_static_loss = 0\n","    flag =1\n","    for year in range(years):\n","        anchor_data = dataset[np.arange(dataset.shape[0]), random_years_1[:, year]]\n","        positive_data = dataset[np.arange(dataset.shape[0]), random_years_2[:, year]]\n","\n","        # Remove pairs where (anchor,positive) years are same\n","        keep_idx = random_years_1[:, year] != random_years_2[:, year]\n","        anchor_data = anchor_data[keep_idx]\n","        positive_data = positive_data[keep_idx]\n","\n","        # Remove pairs where (anchor,positive) basins have unknown in streamflow\n","        keep_idx = np.zeros((anchor_data.shape[0], 2)).astype(bool)\n","        keep_idx[:,0] = (anchor_data[:,:,-1]!=config.unknown).all(axis=1)\n","        keep_idx[:,1] = (positive_data[:,:,-1]!=config.unknown).all(axis=1)\n","        keep_idx = keep_idx.all(axis=1)\n","        anchor_data = anchor_data[keep_idx]\n","        positive_data = positive_data[keep_idx]    \n","        random_batches = random.sample(range(anchor_data.shape[0]),anchor_data.shape[0])\n","        for batch in range(math.ceil(anchor_data.shape[0]/batch_size)):\n","            optimizer.zero_grad()\n","            \n","            random_batch = random_batches[batch*batch_size:(batch+1)*batch_size]\n","            batch_anchor_data = torch.from_numpy(anchor_data[random_batch]).to(device)\n","            batch_positive_data = torch.from_numpy(positive_data[random_batch]).to(device)\n","\n","            batch_anchor_data_input = batch_anchor_data[:,:,input_channels]\n","            batch_positive_data_input = batch_positive_data[:,:,input_channels]\n","            \n","            batch_anchor_data_static = batch_anchor_data[:,0,static_channels]\n","            batch_positive_data_static = batch_positive_data[:,0,static_channels]\n","\n","            input_data = torch.cat((batch_anchor_data_input, batch_positive_data_input), dim=0)\n","            static_data = torch.cat((batch_anchor_data_static, batch_positive_data_static), axis=0)\n","            if(input_data.isnan().any()):\n","                print(\"True\")\n","                print(torch.isnan(input_data))\n","            code, reconstruction, static_reconstruction = model(input_data.to(device))\n","\n","            if(code.isnan().any()):\n","                flag=0\n","                #print(input_data)\n","                print(\"NAN_TEST_CODE\",code)\n","                print(\"NAN_TEST_RECONSTRUCTION\",reconstruction.isnan().any())\n","                print(\"NAN_TEST_STATIC_RECON\",static_reconstruction.isnan().any())\n","                break    \n","            # Calculate reconstruction loss\n","            recon_loss = torch.sum(criterion(reconstruction, input_data), axis=2)\n","            recon_loss = torch.masked_select(recon_loss, (input_data[:,:,-1]!=config.unknown))\n","            recon_loss = torch.mean(recon_loss)\n","\n","            # Calculate NT-Xent loss\n","            filtered_code = code[~torch.any(code.isnan(),dim=1)]\n","            contrastive_loss = contrastive_criterion(filtered_code)\n","\n","            # Calculate static loss\n","            static_loss = torch.mean(criterion(static_reconstruction, static_data), axis=1)\n","            static_loss = torch.mean(static_loss)\n","\n","            # Calculate total loss\n","            loss = (recon_weight*recon_loss + triplet_weight*contrastive_loss + static_weight*static_loss)/sum_weight\n","            total_loss += loss.item()\n","            total_recon_loss += recon_loss.item()\n","            total_contrastive_loss += contrastive_loss.item()\n","            total_static_loss += static_loss.item()\n","\n","            # Backpropogate loss\n","            loss.backward()\n","            optimizer.step()\n","#         if(flag==0):\n","#             break\n","    print('Epoch:{}\\tTrain Loss:{:.4f}\\tRecon Loss:{:.4f}\\tTriplet Loss:{:.4f}\\tStatic Loss:{:.4f}'.format(epoch, total_loss/((batch+1)*(year+1)), total_recon_loss/((batch+1)*(year+1)), total_contrastive_loss/((batch+1)*(year+1)), total_static_loss/((batch+1)*(year+1))), end=\"\\t\")\n","    train_loss.append(total_loss/((batch+1)*(year+1)))\n","    model.eval()\n","        #############################################################\n","    # RUN ON validation DATA\n","    dataset = validation_data\n","    basins = dataset.shape[0]\n","    years = dataset.shape[1]\n","    window = dataset.shape[2]\n","    channels = dataset.shape[3]\n","    \"\"\"Generate random years\"\"\"\n","    random_years_1 = np.zeros((basins, years))\n","    for node in range(basins):\n","        random_years_1[node] = random.sample(range(years), years)\n","    random_years_1 = random_years_1.astype(np.int64)\n","    random_years_2 = np.zeros((basins, years))\n","    for node in range(basins):\n","        random_years_2[node] = random.sample(range(years), years)\n","    random_years_2 = random_years_2.astype(np.int64)\n","\n","    total_loss = 0\n","    total_recon_loss = 0\n","    total_contrastive_loss = 0\n","    total_static_loss = 0\n","    for year in range(years):\n","        anchor_data = dataset[np.arange(dataset.shape[0]), random_years_1[:, year]]\n","        positive_data = dataset[np.arange(dataset.shape[0]), random_years_2[:, year]]\n","\n","        # Remove pairs where (anchor,positive) years are same\n","        keep_idx = random_years_1[:, year] != random_years_2[:, year]\n","        anchor_data = anchor_data[keep_idx]\n","        positive_data = positive_data[keep_idx]\n","\n","        # Remove pairs where (anchor,positive) basins have unknown in streamflow\n","        keep_idx = np.zeros((anchor_data.shape[0], 2)).astype(bool)\n","        keep_idx[:,0] = (anchor_data[:,:,-1]!=config.unknown).all(axis=1)\n","        keep_idx[:,1] = (positive_data[:,:,-1]!=config.unknown).all(axis=1)\n","        keep_idx = keep_idx.all(axis=1)\n","        anchor_data = anchor_data[keep_idx]\n","        positive_data = positive_data[keep_idx]    \n","        random_batches = random.sample(range(anchor_data.shape[0]),anchor_data.shape[0])\n","        for batch in range(math.ceil(anchor_data.shape[0]/batch_size)):\n","            optimizer.zero_grad()\n","            \n","            random_batch = random_batches[batch*batch_size:(batch+1)*batch_size]\n","            batch_anchor_data = torch.from_numpy(anchor_data[random_batch]).to(device)\n","            batch_positive_data = torch.from_numpy(positive_data[random_batch]).to(device)\n","\n","            batch_anchor_data_input = batch_anchor_data[:,:,input_channels]\n","            batch_positive_data_input = batch_positive_data[:,:,input_channels]\n","            \n","            batch_anchor_data_static = batch_anchor_data[:,0,static_channels]\n","            batch_positive_data_static = batch_positive_data[:,0,static_channels]\n","\n","            input_data = torch.cat((batch_anchor_data_input, batch_positive_data_input), dim=0)\n","            static_data = torch.cat((batch_anchor_data_static, batch_positive_data_static), axis=0)\n","            code, reconstruction, static_reconstruction = model(input_data.to(device))\n","\n","#             if(code.isnan().any()):\n","#                 flag=0\n","#                 #print(input_data)\n","#                 #print(\"NAN_TEST\",code.isnan().any())\n","#                 break\n","            # Calculate reconstruction loss\n","            recon_loss = torch.sum(criterion(reconstruction, input_data), axis=2)\n","            recon_loss = torch.masked_select(recon_loss, (input_data[:,:,-1]!=config.unknown))\n","            recon_loss = torch.mean(recon_loss)\n","\n","            # Calculate NT-Xent loss\n","            contrastive_loss = contrastive_criterion(code)\n","\n","            # Calculate static loss\n","            static_loss = torch.mean(criterion(static_reconstruction, static_data), axis=1)\n","            static_loss = torch.mean(static_loss)\n","\n","            # Calculate total loss\n","            loss = (recon_weight*recon_loss + triplet_weight*contrastive_loss + static_weight*static_loss)/sum_weight\n","            total_loss += loss.item()\n","            total_recon_loss += recon_loss.item()\n","            total_contrastive_loss += contrastive_loss.item()\n","            total_static_loss += static_loss.item()\n","    print('Val Loss:{:.4f}\\tRecon Loss:{:.4f}\\tTriplet Loss:{:.4f}\\tStatic Loss:{:.4f}'.format(total_loss/((batch+1)*(year+1)), total_recon_loss/((batch+1)*(year+1)), total_contrastive_loss/((batch+1)*(year+1)), total_static_loss/((batch+1)*(year+1))), end=\"\\t\")\n","    validation_loss.append(total_loss/((batch+1)*(year+1)))\n","    if min_val>validation_loss[-1] and validation_loss[-1]>0:\n","        min_val = validation_loss[-1]\n","        torch.save(model.state_dict(), os.path.join(config.MODEL_DIR, \"{}.pt\".format(model_name)))\n","    \n","    end = time.time()\n","    print(\"Time:{:.4f}\".format(end-start))\n","    \n","plt.figure(figsize=(10,10))\n","plt.xlabel(\"#Epoch\", fontsize=50)\n","plt.plot(train_loss, linewidth=4)\n","plt.plot(validation_loss, linewidth=4)\n","plt.tight_layout(pad=0.0,h_pad=0.0,w_pad=0.0)\n","plt.savefig(os.path.join(config.RESULT_DIR, \"{}_LOSS.png\".format(model_name)), format = \"png\")\n","plt.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HLv_X9e7VhZK"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"main","language":"python","name":"main"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"colab":{"name":"MODEL_Impute_k.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}