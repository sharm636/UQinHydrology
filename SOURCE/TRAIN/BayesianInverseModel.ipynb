{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL_ATT_NL_32_27_3_200_1_NL_Hidden_0_Serial_reconstruction_loss+triplet_loss_withoutSF Hyperparameters\n",
      "Channels : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n",
      "Input Channels : [27, 28, 29, 30, 31]\n",
      "Static Channels : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26]\n",
      "Code dim : 32\n",
      "Epochs : 200\n",
      "Batch Size : 200\n",
      "Learning rate : 0.005\n",
      "Reconstruction Weight : 0.1\n",
      "Static Weight : 10\n",
      "Triplet Weight : 1\n",
      "Pretrain : None\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import config\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from blitz.modules import BayesianGRU\n",
    "from blitz.utils import variational_estimator\n",
    "\n",
    "\n",
    "# CHANNELS INFO\n",
    "channels = config.channels\n",
    "input_channels = config.weather_channels#+config.sf_channels\n",
    "static_channels = config.static_channels\n",
    "\n",
    "DIR = 'DATA_DIR/'\n",
    "\n",
    "\n",
    "# TIME SERIES INFO\n",
    "window = config.window\n",
    "\n",
    "# TRAIN INFO\n",
    "device = config.device\n",
    "code_dim = config.code_dim\n",
    "n_clusters = config.n_clusters\n",
    "epochs = 200\n",
    "batch_size = config.batch_size\n",
    "learning_rate = config.learning_rate\n",
    "alpha = 2\n",
    "\n",
    "# MODEL INFO\n",
    "recon_weight = 0.1#config.recon_weight\n",
    "static_weight = 10#config.static_weight\n",
    "triplet_weight = 1#config.triplet_weight\n",
    "sum_weight = recon_weight+static_weight+triplet_weight\n",
    "\n",
    "#BIM : ATT_NL_3\n",
    "# IM+VAE: VAE\n",
    "# IM+CD : ATT_NL_CD\n",
    "# Other Bayesian baselines are also given in this notebook\n",
    "architecture = \"ATT_NL_3\"\n",
    "# Forward Models : LSTM , EALSTM\n",
    "\n",
    "run = int(len(sys.argv))\n",
    "Hidden=\"Hidden_0_Serial_reconstruction_loss+triplet_loss_withoutSF\"\n",
    "num_hidden = 0\n",
    "model_name = \"{}_{}_{}_{}_{}_{}_{}_{}\".format(\"ALL\", architecture, code_dim, len(static_channels), run,batch_size,\"1_NL\",Hidden)\n",
    "\n",
    "pretrain = None\n",
    "\n",
    "print(\"{} Hyperparameters\".format(model_name))\n",
    "print(\"Channels : {}\".format(channels))\n",
    "print(\"Input Channels : {}\".format(input_channels))\n",
    "print(\"Static Channels : {}\".format(static_channels))\n",
    "print(\"Code dim : {}\".format(code_dim))\n",
    "print(\"Epochs : {}\".format(epochs))\n",
    "print(\"Batch Size : {}\".format(batch_size))\n",
    "print(\"Learning rate : {}\".format(learning_rate))\n",
    "print(\"Reconstruction Weight : {}\".format(recon_weight))\n",
    "print(\"Static Weight : {}\".format(static_weight))\n",
    "print(\"Triplet Weight : {}\".format(triplet_weight))\n",
    "print(\"Pretrain : {}\".format(pretrain))\n",
    "\n",
    "\n",
    "DATA_DIR = os.path.join(\"DATA\")\n",
    "NUMPY_DIR = os.path.join(DATA_DIR, \"NUMPY\")\n",
    "RESULT_DIR = os.path.join(DATA_DIR, \"RESULT\")\n",
    "MODEL_DIR = os.path.join(DATA_DIR, \"MODEL\")\n",
    "\n",
    "if not os.path.exists(os.path.join(MODEL_DIR)):\n",
    "    os.makedirs(os.path.join(MODEL_DIR))\n",
    "if not os.path.exists(os.path.join(RESULT_DIR)):\n",
    "    os.makedirs(os.path.join(RESULT_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:(531, 39, 365, 33)\tValidation Data:(531, 9, 365, 33)\tTest Data:(531, 19, 365, 33)\tHidden Train Data:(531, 39, 365, 33)\n",
      "Static features:['p_mean' 'pet_mean' 'p_seasonality' 'frac_snow' 'aridity'\n",
      " 'high_prec_freq' 'high_prec_dur' 'low_prec_freq' 'low_prec_dur'\n",
      " 'carbonate_rocks_frac' 'geol_permeability' 'soil_depth_pelletier'\n",
      " 'soil_depth_statsgo' 'soil_porosity' 'soil_conductivity'\n",
      " 'max_water_content' 'sand_frac' 'silt_frac' 'clay_frac' 'elev_mean'\n",
      " 'slope_mean' 'area_gages2' 'frac_forest' 'lai_max' 'lai_diff' 'gvf_max'\n",
      " 'gvf_diff']\n",
      "Weather features:['PRCP(mm/day)' 'SRAD(W/m2)' 'Tmax(C)' 'Tmin(C)' 'Vp(Pa)']\n",
      "SF features:['SF']\n"
     ]
    }
   ],
   "source": [
    "train_data = np.load(os.path.join(DIR, 'NUMPY', \"train_data_basin.npy\"))[:,:,:,:-1]\n",
    "validation_data = np.load(os.path.join(DIR, 'NUMPY', \"validation_data_basin.npy\"))[:,:,:,:-1]\n",
    "test_data = np.load(os.path.join(DIR, 'NUMPY', \"test_data_basin.npy\"))[-num_hidden:,:,:,:-1]\n",
    "hidden_train_data = np.load(os.path.join(DIR, 'NUMPY', \"train_hidden_data_basin.npy\"))[:,:,:,:-1]\n",
    "print(\"Train Data:{}\\tValidation Data:{}\\tTest Data:{}\\tHidden Train Data:{}\".format(train_data.shape, validation_data.shape, test_data.shape,hidden_train_data.shape))\n",
    "\n",
    "feature_names = np.load(os.path.join(DIR, \"RAW_DATA\", \"feature_names.npy\"), allow_pickle=True)\n",
    "print(\"Static features:{}\".format(feature_names[config.static_channels]))\n",
    "print(\"Weather features:{}\".format(feature_names[config.weather_channels]))\n",
    "print(\"SF features:{}\".format(feature_names[config.sf_channels]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bayesian GRU\n",
    "#Import libraries\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from blitz.modules.base_bayesian_module import BayesianModule, BayesianRNN\n",
    "from blitz.modules.weight_sampler import TrainableRandomDistribution, PriorWeightDistribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianGRU(BayesianRNN):\n",
    "    \"\"\"\n",
    "    Bayesian GRU layer, implements the linear layer proposed on Weight Uncertainity on Neural Networks\n",
    "    (Bayes by Backprop paper).\n",
    "    Its objective is be interactable with torch nn.Module API, being able even to be chained in nn.Sequential models with other non-this-lib layers\n",
    "    \n",
    "    parameters:\n",
    "        in_fetaures: int -> incoming features for the layer\n",
    "        out_features: int -> output features for the layer\n",
    "        bias: bool -> whether the bias will exist (True) or set to zero (False)\n",
    "        prior_sigma_1: float -> prior sigma on the mixture prior distribution 1\n",
    "        prior_sigma_2: float -> prior sigma on the mixture prior distribution 2\n",
    "        prior_pi: float -> pi on the scaled mixture prior\n",
    "        posterior_mu_init float -> posterior mean for the weight mu init\n",
    "        posterior_rho_init float -> posterior mean for the weight rho init\n",
    "        freeze: bool -> wheter the model will start with frozen(deterministic) weights, or not\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_features,\n",
    "                 out_features,\n",
    "                 bias = True,\n",
    "                 prior_sigma_1 = 0.1,\n",
    "                 prior_sigma_2 = 0.002,\n",
    "                 prior_pi = 1,\n",
    "                 posterior_mu_init = 0,\n",
    "                 posterior_rho_init = -6.0,\n",
    "                 freeze = False,\n",
    "                 prior_dist = None,\n",
    "                 **kwargs):\n",
    "        \n",
    "        super().__init__(**kwargs)\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.use_bias = bias\n",
    "        self.freeze = freeze\n",
    "        \n",
    "        self.posterior_mu_init = posterior_mu_init\n",
    "        self.posterior_rho_init = posterior_rho_init\n",
    "        \n",
    "        self.prior_sigma_1 = prior_sigma_1\n",
    "        self.prior_sigma_2 = prior_sigma_2\n",
    "        self.prior_pi = prior_pi\n",
    "        self.prior_dist = prior_dist\n",
    "        \n",
    "        # Variational weight parameters and sample for weight ih\n",
    "        self.weight_ih_mu = nn.Parameter(torch.Tensor(in_features, out_features * 4).normal_(posterior_mu_init, 0.1))\n",
    "        self.weight_ih_rho = nn.Parameter(torch.Tensor(in_features, out_features * 4).normal_(posterior_rho_init, 0.1))\n",
    "        self.weight_ih_sampler = TrainableRandomDistribution(self.weight_ih_mu, self.weight_ih_rho)\n",
    "        self.weight_ih = None\n",
    "        \n",
    "        # Variational weight parameters and sample for weight hh\n",
    "        self.weight_hh_mu = nn.Parameter(torch.Tensor(out_features, out_features * 4).normal_(posterior_mu_init, 0.1))\n",
    "        self.weight_hh_rho = nn.Parameter(torch.Tensor(out_features, out_features * 4).normal_(posterior_rho_init, 0.1))\n",
    "        self.weight_hh_sampler = TrainableRandomDistribution(self.weight_hh_mu, self.weight_hh_rho)\n",
    "        self.weight_hh = None\n",
    "        \n",
    "        # Variational weight parameters and sample for bias\n",
    "        self.bias_mu = nn.Parameter(torch.Tensor(out_features * 4).normal_(posterior_mu_init, 0.1))\n",
    "        self.bias_rho = nn.Parameter(torch.Tensor(out_features * 4).normal_(posterior_rho_init, 0.1))\n",
    "        self.bias_sampler = TrainableRandomDistribution(self.bias_mu, self.bias_rho)\n",
    "        self.bias=None\n",
    "        \n",
    "        #our prior distributions\n",
    "        self.weight_ih_prior_dist = PriorWeightDistribution(self.prior_pi, self.prior_sigma_1, self.prior_sigma_2, dist = self.prior_dist)\n",
    "        self.weight_hh_prior_dist = PriorWeightDistribution(self.prior_pi, self.prior_sigma_1, self.prior_sigma_2, dist = self.prior_dist)\n",
    "        self.bias_prior_dist = PriorWeightDistribution(self.prior_pi, self.prior_sigma_1, self.prior_sigma_2, dist = self.prior_dist)\n",
    "        \n",
    "        self.init_sharpen_parameters()\n",
    "        \n",
    "        self.log_prior = 0\n",
    "        self.log_variational_posterior = 0\n",
    "    \n",
    "    def sample_weights(self):\n",
    "        #sample weights\n",
    "        weight_ih = self.weight_ih_sampler.sample()\n",
    "        weight_hh = self.weight_hh_sampler.sample()\n",
    "        \n",
    "        #if use bias, we sample it, otherwise, we are using zeros\n",
    "        if self.use_bias:\n",
    "            b = self.bias_sampler.sample()\n",
    "            b_log_posterior = self.bias_sampler.log_posterior()\n",
    "            b_log_prior = self.bias_prior_dist.log_prior(b)\n",
    "            \n",
    "        else:\n",
    "            b = 0\n",
    "            b_log_posterior = 0\n",
    "            b_log_prior = 0\n",
    "            \n",
    "        bias = b\n",
    "        \n",
    "        #gather weights variational posterior and prior likelihoods\n",
    "        self.log_variational_posterior = self.weight_hh_sampler.log_posterior() + b_log_posterior + self.weight_ih_sampler.log_posterior()\n",
    "        \n",
    "        self.log_prior = self.weight_ih_prior_dist.log_prior(weight_ih) + b_log_prior + self.weight_hh_prior_dist.log_prior(weight_hh)\n",
    "        \n",
    "        self.ff_parameters = [weight_ih, weight_hh, bias]\n",
    "        return weight_ih, weight_hh, bias\n",
    "        \n",
    "    def get_frozen_weights(self):\n",
    "        \n",
    "        #get all deterministic weights\n",
    "        weight_ih = self.weight_ih_mu\n",
    "        weight_hh = self.weight_hh_mu\n",
    "        if self.use_bias:\n",
    "            bias = self.bias_mu\n",
    "        else:\n",
    "            bias = 0\n",
    "\n",
    "        return weight_ih, weight_hh, bias\n",
    "\n",
    "    \n",
    "    def forward_(self,\n",
    "                 x,\n",
    "                 hidden_states,\n",
    "                 sharpen_loss):\n",
    "        \n",
    "        if self.loss_to_sharpen is not None:\n",
    "            sharpen_loss = self.loss_to_sharpen\n",
    "            weight_ih, weight_hh, bias = self.sharpen_posterior(loss=sharpen_loss, input_shape=x.shape)\n",
    "        elif (sharpen_loss is not None):\n",
    "            sharpen_loss = sharpen_loss\n",
    "            weight_ih, weight_hh, bias = self.sharpen_posterior(loss=sharpen_loss, input_shape=x.shape)\n",
    "        \n",
    "        else:\n",
    "            weight_ih, weight_hh, bias = self.sample_weights()\n",
    "\n",
    "        #Assumes x is of shape (batch, sequence, feature)\n",
    "        bs, seq_sz, _ = x.size()\n",
    "        hidden_seq = []\n",
    "        \n",
    "        #if no hidden state, we are using zeros\n",
    "        if hidden_states is None:\n",
    "            \n",
    "            h_t = torch.zeros(bs, self.out_features).to(x.device)\n",
    "        else:\n",
    "            h_t = hidden_states\n",
    "        \n",
    "        #simplifying our out features, and hidden seq list\n",
    "        HS = self.out_features\n",
    "        hidden_seq = []\n",
    "        \n",
    "        for t in range(seq_sz):\n",
    "            x_t = x[:, t, :]\n",
    "            # batch the computations into a single matrix multiplication\n",
    "            \n",
    "            A_t = x_t @ weight_ih[:, :HS*2] + h_t[:,t,:] @ weight_hh[:, :HS*2] + bias[:HS*2]\n",
    "\n",
    "            r_t, z_t = (\n",
    "                torch.sigmoid(A_t[:, :HS]),\n",
    "                torch.sigmoid(A_t[:, HS:HS*2])\n",
    "            )\n",
    "            n_t = torch.tanh(x_t @ weight_ih[:, HS*2:HS*3] + bias[HS*2:HS*3] + r_t * (h_t[:,t,:] @ weight_hh[:, HS*3:HS*4] + bias[HS*3:HS*4]))\n",
    "            h_t = (1 - z_t) * n_t + z_t * h_t\n",
    "\n",
    "            hidden_seq.append(h_t.unsqueeze(0))\n",
    "            \n",
    "        hidden_seq = torch.cat(hidden_seq, dim=0)\n",
    "        # reshape from shape (sequence, batch, feature) to (batch, sequence, feature)\n",
    "        hidden_seq = hidden_seq.transpose(0, 1).contiguous()\n",
    "        \n",
    "        return hidden_seq, h_t\n",
    "\n",
    "    def forward_frozen(self,\n",
    "                       x,\n",
    "                       hidden_states):\n",
    "\n",
    "        weight_ih, weight_hh, bias = self.get_frozen_weights()\n",
    "\n",
    "        #Assumes x is of shape (batch, sequence, feature)\n",
    "        bs, seq_sz, _ = x.size()\n",
    "        hidden_seq = []\n",
    "        \n",
    "        #if no hidden state, we are using zeros\n",
    "        if hidden_states is None:\n",
    "            h_t = torch.zeros(bs, self.out_features).to(x.device)\n",
    "        else:\n",
    "            h_t = hidden_states\n",
    "        \n",
    "        #simplifying our out features, and hidden seq list\n",
    "        HS = self.out_features\n",
    "        hidden_seq = []\n",
    "        \n",
    "        for t in range(seq_sz):\n",
    "            x_t = x[:, t, :]\n",
    "            # batch the computations into a single matrix multiplication\n",
    "            A_t = x_t @ weight_ih[:, :HS*2] + h_t @ weight_hh[:, :HS*2] + bias[:HS*2]\n",
    "\n",
    "            r_t, z_t = (\n",
    "                torch.sigmoid(A_t[:,:HS]),\n",
    "                torch.sigmoid(A_t[:, HS:HS*2])\n",
    "            )\n",
    "\n",
    "            n_t = torch.tanh(x_t @ weight_ih[:, HS*2:HS*3] + bias[HS*2:HS*3] + r_t * (h_t @ weight_hh[:, HS*3:HS*4] + bias[HS*3:HS*4]))\n",
    "            h_t = (1 - z_t) * n_t + z_t * h_t\n",
    "\n",
    "            hidden_seq.append(h_t.unsqueeze(0))\n",
    "            \n",
    "        hidden_seq = torch.cat(hidden_seq, dim=0)\n",
    "        # reshape from shape (sequence, batch, feature) to (batch, sequence, feature)\n",
    "        hidden_seq = hidden_seq.transpose(0, 1).contiguous()\n",
    "        \n",
    "        return hidden_seq, h_t         \n",
    "\n",
    "    def forward(self,\n",
    "                x,\n",
    "                hidden_states=None,\n",
    "                sharpen_loss=None):\n",
    "\n",
    "        if self.freeze:\n",
    "            return self.forward_frozen(x, hidden_states)\n",
    "        \n",
    "        if not self.sharpen:\n",
    "            sharpen_loss = None\n",
    "            \n",
    "        return self.forward_(x, hidden_states, sharpen_loss)    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters:29089\n"
     ]
    }
   ],
   "source": [
    "from blitz.modules import BayesianLinear\n",
    "\n",
    "class ATT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, stat_channels, code_dim, device):\n",
    "        super(ATT,self).__init__()\n",
    "        \n",
    "        self.code_dim = code_dim\n",
    "        self.device = device\n",
    "        self.encoder = torch.nn.GRU(in_channels, code_dim, batch_first=True, bidirectional=True)\n",
    "        self.att = torch.nn.Linear(code_dim, 1)\n",
    "        self.decoder = torch.nn.GRU(in_channels, code_dim, batch_first=True)\n",
    "        self.out = torch.nn.Linear(code_dim, in_channels)\n",
    "        self.static_out = torch.nn.Linear(code_dim, stat_channels)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch, seq_len, in_channels = x.shape\n",
    "        \n",
    "        code_vec, _ = self.encoder(x)\n",
    "\n",
    "        code_vec = torch.add(code_vec[:,:,:self.code_dim], code_vec[:,:,self.code_dim:])\n",
    "        att_weights = torch.unsqueeze(torch.nn.functional.softmax(self.att(code_vec).squeeze(), dim=1), dim=-1)\n",
    "        code_vec = att_weights*code_vec\n",
    "        code_vec = torch.unsqueeze(torch.sum(code_vec, dim=1), dim=0)\n",
    "        static_out = self.static_out(code_vec.squeeze())\n",
    "\n",
    "        out = torch.zeros(batch, seq_len, in_channels).to(self.device)\n",
    "        h = code_vec\n",
    "        input = torch.zeros((batch, 1, in_channels)).to(self.device)\n",
    "        \n",
    "        for step in range(seq_len):\n",
    "            input, h = self.decoder(input, h)\n",
    "            output = self.out(torch.mul(input.squeeze(), code_vec.squeeze()))\n",
    "            out[:,step] = output\n",
    "            input = output.unsqueeze(1)\n",
    "        \n",
    "        out = out.view(batch, seq_len, in_channels)\n",
    "        return code_vec.squeeze().view(batch, -1), out, static_out\n",
    "\n",
    "@variational_estimator\n",
    "class ATT_NL(torch.nn.Module):\n",
    "    def __init__(self, in_channels, stat_channels, code_dim, device):\n",
    "        super(ATT_NL,self).__init__()\n",
    "        \n",
    "        self.code_dim = code_dim\n",
    "        self.device = device\n",
    "        self.encoder = torch.nn.GRU(in_channels, code_dim, batch_first=True, bidirectional=True)\n",
    "        self.att = torch.nn.Linear(code_dim, 1)\n",
    "#         self.decoder = torch.nn.GRU(in_channels, code_dim, batch_first=True)\n",
    "        self.decoder = BayesianGRU(in_channels, code_dim)#, batch_first=True)\n",
    "        self.out = torch.nn.Linear(code_dim, in_channels)\n",
    "        self.linear_1 = torch.nn.Linear(code_dim,code_dim)\n",
    "        #self.linear_2 = torch.nn.Linear(code_dim,code_dim)\n",
    "        self.static_out = torch.nn.Linear(code_dim, stat_channels)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch, seq_len, in_channels = x.shape\n",
    "        \n",
    "        code_vec, _ = self.encoder(x)\n",
    "        code_vec = torch.add(code_vec[:,:,:self.code_dim], code_vec[:,:,self.code_dim:])\n",
    "        att_weights = torch.unsqueeze(torch.nn.functional.softmax(self.att(code_vec).squeeze(), dim=1), dim=-1)\n",
    "        code_vec = att_weights*code_vec\n",
    "\n",
    "\n",
    "        code_vec = torch.unsqueeze(torch.sum(code_vec, dim=1), dim=0)\n",
    "        static_out = self.relu(self.linear_1(code_vec.squeeze()))\n",
    "        #static_out = self.relu(self.linear_2(static_out))\n",
    "        static_out = self.static_out(static_out)\n",
    "\n",
    "        out = torch.zeros(batch, seq_len, in_channels).to(self.device)\n",
    "        h = code_vec\n",
    "        input = torch.zeros((batch, 1, in_channels)).to(self.device)\n",
    "#         print(h.size())\n",
    "        for step in range(seq_len):\n",
    "            input, h = self.decoder(input, h)\n",
    "            output = self.out(torch.mul(input.squeeze(), code_vec.squeeze()))\n",
    "            out[:,step] = output\n",
    "            input = output.unsqueeze(1)\n",
    "        \n",
    "        out = out.view(batch, seq_len, in_channels)\n",
    "        return code_vec.squeeze().view(batch, -1), out, static_out    \n",
    "\n",
    "class ATT_NL_0(torch.nn.Module):\n",
    "    def __init__(self, in_channels, stat_channels, code_dim, device):\n",
    "        super(ATT_NL_0,self).__init__()\n",
    "        \n",
    "        self.code_dim = code_dim\n",
    "        self.device = device\n",
    "        self.encoder = torch.nn.GRU(in_channels, code_dim, batch_first=True, bidirectional=True)\n",
    "        self.att = torch.nn.Linear(code_dim, 1)\n",
    "        self.decoder = torch.nn.GRU(in_channels, code_dim, batch_first=True)\n",
    "#         self.decoder = BayesianGRU(in_channels, code_dim)#, batch_first=True)\n",
    "        self.out = torch.nn.Linear(code_dim, in_channels)\n",
    "        self.linear_1 = torch.nn.Linear(code_dim,code_dim)\n",
    "        #self.linear_2 = torch.nn.Linear(code_dim,code_dim)\n",
    "        self.static_out = torch.nn.Linear(code_dim, stat_channels)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch, seq_len, in_channels = x.shape\n",
    "        \n",
    "        code_vec, _ = self.encoder(x)\n",
    "        code_vec = torch.add(code_vec[:,:,:self.code_dim], code_vec[:,:,self.code_dim:])\n",
    "        att_weights = torch.unsqueeze(torch.nn.functional.softmax(self.att(code_vec).squeeze(), dim=1), dim=-1)\n",
    "        code_vec = att_weights*code_vec\n",
    "\n",
    "\n",
    "        code_vec = torch.unsqueeze(torch.sum(code_vec, dim=1), dim=0)\n",
    "        static_out = self.relu(self.linear_1(code_vec.squeeze()))\n",
    "        #static_out = self.relu(self.linear_2(static_out))\n",
    "        static_out = self.static_out(static_out)\n",
    "\n",
    "        out = torch.zeros(batch, seq_len, in_channels).to(self.device)\n",
    "        h = code_vec\n",
    "        input = torch.zeros((batch, 1, in_channels)).to(self.device)\n",
    "#         print(h.size())\n",
    "        for step in range(seq_len):\n",
    "            input, h = self.decoder(input, h)\n",
    "            output = self.out(torch.mul(input.squeeze(), code_vec.squeeze()))\n",
    "            out[:,step] = output\n",
    "            input = output.unsqueeze(1)\n",
    "        \n",
    "        out = out.view(batch, seq_len, in_channels)\n",
    "        return code_vec.squeeze().view(batch, -1), out, static_out    \n",
    "\n",
    "    \n",
    "@variational_estimator\n",
    "class ATT_NL_1(torch.nn.Module):\n",
    "    def __init__(self, in_channels, stat_channels, code_dim, device):\n",
    "        super(ATT_NL_1,self).__init__()\n",
    "        \n",
    "        self.code_dim = code_dim\n",
    "        self.device = device\n",
    "#         self.encoder = torch.nn.GRU(in_channels, code_dim, batch_first=True, bidirectional=True)\n",
    "        self.encoder = BayesianGRU(in_channels, code_dim)#, batch_first=True, bidirectional=True)\n",
    "        self.att = torch.nn.Linear(code_dim, 1)\n",
    "        self.decoder = torch.nn.GRU(in_channels, code_dim, batch_first=True)\n",
    "#         self.decoder = BayesianGRU(in_channels, code_dim)#, batch_first=True)\n",
    "        self.out = torch.nn.Linear(code_dim, in_channels)\n",
    "        self.linear_1 = torch.nn.Linear(code_dim,code_dim)\n",
    "        #self.linear_2 = torch.nn.Linear(code_dim,code_dim)\n",
    "        self.static_out = torch.nn.Linear(code_dim, stat_channels)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch, seq_len, in_channels = x.shape\n",
    "        \n",
    "        code_vec, _ = self.encoder(x)\n",
    "        code_vec = torch.add(code_vec[:,:,:self.code_dim], code_vec[:,:,self.code_dim:])\n",
    "        att_weights = torch.unsqueeze(torch.nn.functional.softmax(self.att(code_vec).squeeze(), dim=1), dim=-1)\n",
    "        code_vec = att_weights*code_vec\n",
    "\n",
    "\n",
    "        code_vec = torch.unsqueeze(torch.sum(code_vec, dim=1), dim=0)\n",
    "        static_out = self.relu(self.linear_1(code_vec.squeeze()))\n",
    "        #static_out = self.relu(self.linear_2(static_out))\n",
    "        static_out = self.static_out(static_out)\n",
    "\n",
    "        out = torch.zeros(batch, seq_len, in_channels).to(self.device)\n",
    "        h = code_vec\n",
    "        input = torch.zeros((batch, 1, in_channels)).to(self.device)\n",
    "#         print(h.size())\n",
    "        for step in range(seq_len):\n",
    "            input, h = self.decoder(input, h)\n",
    "            output = self.out(torch.mul(input.squeeze(), code_vec.squeeze()))\n",
    "            out[:,step] = output\n",
    "            input = output.unsqueeze(1)\n",
    "        \n",
    "        out = out.view(batch, seq_len, in_channels)\n",
    "        return code_vec.squeeze().view(batch, -1), out, static_out    \n",
    "\n",
    "    \n",
    "@variational_estimator\n",
    "class ATT_NL_3(torch.nn.Module):\n",
    "    def __init__(self, in_channels, stat_channels, code_dim, device):\n",
    "        super(ATT_NL_3,self).__init__()\n",
    "        \n",
    "        self.code_dim = code_dim\n",
    "        self.device = device\n",
    "        self.encoder = torch.nn.GRU(in_channels, code_dim, batch_first=True, bidirectional=True)\n",
    "#         self.att = torch.nn.Linear(code_dim, 1)\n",
    "        self.att = BayesianLinear(code_dim, 1)\n",
    "        self.decoder = torch.nn.GRU(in_channels, code_dim, batch_first=True)\n",
    "#         self.decoder = BayesianGRU(in_channels, code_dim)#, batch_first=True)\n",
    "        self.out = torch.nn.Linear(code_dim, in_channels)\n",
    "        self.linear_1 = torch.nn.Linear(code_dim,code_dim)\n",
    "        #self.linear_2 = torch.nn.Linear(code_dim,code_dim)\n",
    "        self.static_out = torch.nn.Linear(code_dim, stat_channels)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch, seq_len, in_channels = x.shape\n",
    "        \n",
    "        code_vec, _ = self.encoder(x)\n",
    "        code_vec = torch.add(code_vec[:,:,:self.code_dim], code_vec[:,:,self.code_dim:])\n",
    "        att_weights = torch.unsqueeze(torch.nn.functional.softmax(self.att(code_vec).squeeze(), dim=1), dim=-1)\n",
    "        code_vec = att_weights*code_vec\n",
    "\n",
    "\n",
    "        code_vec = torch.unsqueeze(torch.sum(code_vec, dim=1), dim=0)\n",
    "        static_out = self.relu(self.linear_1(code_vec.squeeze()))\n",
    "        #static_out = self.relu(self.linear_2(static_out))\n",
    "        static_out = self.static_out(static_out)\n",
    "\n",
    "        out = torch.zeros(batch, seq_len, in_channels).to(self.device)\n",
    "        h = code_vec\n",
    "        input = torch.zeros((batch, 1, in_channels)).to(self.device)\n",
    "#         print(h.size())\n",
    "        for step in range(seq_len):\n",
    "            input, h = self.decoder(input, h)\n",
    "            output = self.out(torch.mul(input.squeeze(), code_vec.squeeze()))\n",
    "            out[:,step] = output\n",
    "            input = output.unsqueeze(1)\n",
    "        \n",
    "        out = out.view(batch, seq_len, in_channels)\n",
    "        return code_vec.squeeze().view(batch, -1), out, static_out    \n",
    "\n",
    "\n",
    "\n",
    "@variational_estimator\n",
    "class ATT_NL_4(torch.nn.Module):\n",
    "    def __init__(self, in_channels, stat_channels, code_dim, device):\n",
    "        super(ATT_NL_4,self).__init__()\n",
    "        \n",
    "        self.code_dim = code_dim\n",
    "        self.device = device\n",
    "        self.encoder = torch.nn.GRU(in_channels, code_dim, batch_first=True, bidirectional=True)\n",
    "        self.att = torch.nn.Linear(code_dim, 1)\n",
    "        self.decoder = torch.nn.GRU(in_channels, code_dim, batch_first=True)\n",
    "#         self.decoder = BayesianGRU(in_channels, code_dim)#, batch_first=True)\n",
    "#         self.out = torch.nn.Linear(code_dim, in_channels)\n",
    "        self.out = BayesianLinear(code_dim, in_channels)\n",
    "        self.linear_1 = torch.nn.Linear(code_dim,code_dim)\n",
    "        #self.linear_2 = torch.nn.Linear(code_dim,code_dim)\n",
    "        self.static_out = torch.nn.Linear(code_dim, stat_channels)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch, seq_len, in_channels = x.shape\n",
    "        \n",
    "        code_vec, _ = self.encoder(x)\n",
    "        code_vec = torch.add(code_vec[:,:,:self.code_dim], code_vec[:,:,self.code_dim:])\n",
    "        att_weights = torch.unsqueeze(torch.nn.functional.softmax(self.att(code_vec).squeeze(), dim=1), dim=-1)\n",
    "        code_vec = att_weights*code_vec\n",
    "\n",
    "\n",
    "        code_vec = torch.unsqueeze(torch.sum(code_vec, dim=1), dim=0)\n",
    "        static_out = self.relu(self.linear_1(code_vec.squeeze()))\n",
    "        #static_out = self.relu(self.linear_2(static_out))\n",
    "        static_out = self.static_out(static_out)\n",
    "\n",
    "        out = torch.zeros(batch, seq_len, in_channels).to(self.device)\n",
    "        h = code_vec\n",
    "        input = torch.zeros((batch, 1, in_channels)).to(self.device)\n",
    "#         print(h.size())\n",
    "        for step in range(seq_len):\n",
    "            input, h = self.decoder(input, h)\n",
    "            output = self.out(torch.mul(input.squeeze(), code_vec.squeeze()))\n",
    "            out[:,step] = output\n",
    "            input = output.unsqueeze(1)\n",
    "        \n",
    "        out = out.view(batch, seq_len, in_channels)\n",
    "        return code_vec.squeeze().view(batch, -1), out, static_out    \n",
    "    \n",
    "\n",
    "@variational_estimator\n",
    "class ATT_NL_5(torch.nn.Module):\n",
    "    def __init__(self, in_channels, stat_channels, code_dim, device):\n",
    "        super(ATT_NL_5,self).__init__()\n",
    "        \n",
    "        self.code_dim = code_dim\n",
    "        self.device = device\n",
    "        self.encoder = torch.nn.GRU(in_channels, code_dim, batch_first=True, bidirectional=True)\n",
    "        self.att = torch.nn.Linear(code_dim, 1)\n",
    "        self.decoder = torch.nn.GRU(in_channels, code_dim, batch_first=True)\n",
    "#         self.decoder = BayesianGRU(in_channels, code_dim)#, batch_first=True)\n",
    "        self.out = torch.nn.Linear(code_dim, in_channels)\n",
    "#         self.linear_1 = torch.nn.Linear(code_dim,code_dim)\n",
    "        self.linear_1 = BayesianLinear(code_dim,code_dim)\n",
    "        #self.linear_2 = torch.nn.Linear(code_dim,code_dim)\n",
    "        self.static_out = torch.nn.Linear(code_dim, stat_channels)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch, seq_len, in_channels = x.shape\n",
    "        \n",
    "        code_vec, _ = self.encoder(x)\n",
    "        code_vec = torch.add(code_vec[:,:,:self.code_dim], code_vec[:,:,self.code_dim:])\n",
    "        att_weights = torch.unsqueeze(torch.nn.functional.softmax(self.att(code_vec).squeeze(), dim=1), dim=-1)\n",
    "        code_vec = att_weights*code_vec\n",
    "\n",
    "\n",
    "        code_vec = torch.unsqueeze(torch.sum(code_vec, dim=1), dim=0)\n",
    "        static_out = self.relu(self.linear_1(code_vec.squeeze()))\n",
    "        #static_out = self.relu(self.linear_2(static_out))\n",
    "        static_out = self.static_out(static_out)\n",
    "\n",
    "        out = torch.zeros(batch, seq_len, in_channels).to(self.device)\n",
    "        h = code_vec\n",
    "        input = torch.zeros((batch, 1, in_channels)).to(self.device)\n",
    "#         print(h.size())\n",
    "        for step in range(seq_len):\n",
    "            input, h = self.decoder(input, h)\n",
    "            output = self.out(torch.mul(input.squeeze(), code_vec.squeeze()))\n",
    "            out[:,step] = output\n",
    "            input = output.unsqueeze(1)\n",
    "        \n",
    "        out = out.view(batch, seq_len, in_channels)\n",
    "        return code_vec.squeeze().view(batch, -1), out, static_out    \n",
    "    \n",
    "\n",
    "    \n",
    "@variational_estimator\n",
    "class ATT_NL_6(torch.nn.Module):\n",
    "    def __init__(self, in_channels, stat_channels, code_dim, device):\n",
    "        super(ATT_NL_6,self).__init__()\n",
    "        \n",
    "        self.code_dim = code_dim\n",
    "        self.device = device\n",
    "        self.encoder = torch.nn.GRU(in_channels, code_dim, batch_first=True, bidirectional=True)\n",
    "        self.att = torch.nn.Linear(code_dim, 1)\n",
    "        self.decoder = torch.nn.GRU(in_channels, code_dim, batch_first=True)\n",
    "#         self.decoder = BayesianGRU(in_channels, code_dim)#, batch_first=True)\n",
    "        self.out = torch.nn.Linear(code_dim, in_channels)\n",
    "        self.linear_1 = torch.nn.Linear(code_dim,code_dim)\n",
    "        #self.linear_2 = torch.nn.Linear(code_dim,code_dim)\n",
    "#         self.static_out = torch.nn.Linear(code_dim, stat_channels)\n",
    "        self.static_out = BayesianLinear(code_dim, stat_channels)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch, seq_len, in_channels = x.shape\n",
    "        \n",
    "        code_vec, _ = self.encoder(x)\n",
    "        code_vec = torch.add(code_vec[:,:,:self.code_dim], code_vec[:,:,self.code_dim:])\n",
    "        att_weights = torch.unsqueeze(torch.nn.functional.softmax(self.att(code_vec).squeeze(), dim=1), dim=-1)\n",
    "        code_vec = att_weights*code_vec\n",
    "\n",
    "\n",
    "        code_vec = torch.unsqueeze(torch.sum(code_vec, dim=1), dim=0)\n",
    "        static_out = self.relu(self.linear_1(code_vec.squeeze()))\n",
    "        #static_out = self.relu(self.linear_2(static_out))\n",
    "        static_out = self.static_out(static_out)\n",
    "\n",
    "        out = torch.zeros(batch, seq_len, in_channels).to(self.device)\n",
    "        h = code_vec\n",
    "        input = torch.zeros((batch, 1, in_channels)).to(self.device)\n",
    "#         print(h.size())\n",
    "        for step in range(seq_len):\n",
    "            input, h = self.decoder(input, h)\n",
    "            output = self.out(torch.mul(input.squeeze(), code_vec.squeeze()))\n",
    "            out[:,step] = output\n",
    "            input = output.unsqueeze(1)\n",
    "        \n",
    "        out = out.view(batch, seq_len, in_channels)\n",
    "        return code_vec.squeeze().view(batch, -1), out, static_out    \n",
    "    \n",
    "\n",
    "    \n",
    "class LAST(torch.nn.Module):\n",
    "    def __init__(self, in_channels, stat_channels, code_dim, device):\n",
    "        super(LAST,self).__init__()\n",
    "        \n",
    "        self.code_dim = code_dim\n",
    "        self.device = device\n",
    "        self.encoder = torch.nn.GRU(in_channels, code_dim, batch_first=True, bidirectional=True)\n",
    "        self.decoder = torch.nn.GRU(in_channels, code_dim, batch_first=True)\n",
    "        self.out = torch.nn.Linear(code_dim, in_channels)\n",
    "        self.static_out = torch.nn.Linear(code_dim, stat_channels)\n",
    "\n",
    "        self.encoder = torch.nn.GRU(in_channels, code_dim, batch_first=True, bidirectional=True)\n",
    "        self.decoder = torch.nn.GRU(in_channels, code_dim, batch_first=True)\n",
    "        self.out = torch.nn.Linear(code_dim, in_channels)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch, seq_len, in_channels = x.shape\n",
    "        \n",
    "        _, code_vec = self.encoder(x)\n",
    "        code_vec = torch.unsqueeze(torch.sum(code_vec, dim=0), dim=0)\n",
    "        static_out = self.static_out(code_vec.squeeze())\n",
    "\n",
    "        out = torch.zeros(batch, seq_len, in_channels).to(self.device)\n",
    "        h = code_vec\n",
    "        input = torch.zeros((batch, 1, in_channels)).to(self.device)\n",
    "        for step in range(seq_len):\n",
    "            input, h = self.decoder(input, h)\n",
    "            output = self.out(torch.mul(input.squeeze(), code_vec.squeeze()))\n",
    "            out[:,step] = output\n",
    "            input = output.unsqueeze(1)\n",
    "        \n",
    "        out = out.view(batch, seq_len, in_channels)\n",
    "        return code_vec.squeeze().view(batch, -1), out, static_out\n",
    "\n",
    "\n",
    "@variational_estimator\n",
    "class ATT_NL_CD(torch.nn.Module):\n",
    "    def __init__(self, in_channels, stat_channels, code_dim, device):\n",
    "        super(ATT_NL_CD,self).__init__()\n",
    "        \n",
    "        self.code_dim = code_dim\n",
    "        self.device = device\n",
    "        self.encoder = torch.nn.GRU(in_channels, code_dim, batch_first=True, bidirectional=True)\n",
    "        self.att = torch.nn.Linear(code_dim, 1)\n",
    "#         self.att = BayesianLinear(code_dim, 1)\n",
    "        self.cd = CD(\n",
    "            weight_regulariser=1e-6,\n",
    "            dropout_regulariser=1e-3\n",
    "                    )\n",
    "        self.cd_layer = torch.nn.Linear(code_dim,code_dim)\n",
    "        self.decoder = torch.nn.GRU(in_channels, code_dim, batch_first=True)\n",
    "#         self.decoder = BayesianGRU(in_channels, code_dim)#, batch_first=True)\n",
    "        self.out = torch.nn.Linear(code_dim, in_channels)\n",
    "        self.linear_1 = torch.nn.Linear(code_dim,code_dim)\n",
    "        #self.linear_2 = torch.nn.Linear(code_dim,code_dim)\n",
    "        self.static_out = torch.nn.Linear(code_dim, stat_channels)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch, seq_len, in_channels = x.shape\n",
    "\n",
    "        code_vec, _ = self.encoder(x)\n",
    "        code_vec = torch.add(code_vec[:,:,:self.code_dim], code_vec[:,:,self.code_dim:])\n",
    "        att_weights = torch.unsqueeze(torch.nn.functional.softmax(self.att(code_vec).squeeze(), dim=1), dim=-1)\n",
    "        code_vec = att_weights*code_vec\n",
    "\n",
    "        code_vec = self.cd(code_vec, self.cd_layer)\n",
    "\n",
    "        code_vec = torch.unsqueeze(torch.sum(code_vec, dim=1), dim=0)\n",
    "        static_out = self.relu(self.linear_1(code_vec.squeeze()))\n",
    "        #static_out = self.relu(self.linear_2(static_out))\n",
    "        static_out = self.static_out(static_out)\n",
    "\n",
    "        out = torch.zeros(batch, seq_len, in_channels).to(self.device)\n",
    "        h = code_vec\n",
    "        input = torch.zeros((batch, 1, in_channels)).to(self.device)\n",
    "#         print(h.size())\n",
    "        for step in range(seq_len):\n",
    "            input, h = self.decoder(input, h)\n",
    "            output = self.out(torch.mul(input.squeeze(), code_vec.squeeze()))\n",
    "            out[:,step] = output\n",
    "            input = output.unsqueeze(1)\n",
    "        \n",
    "        out = out.view(batch, seq_len, in_channels)\n",
    "        return code_vec.squeeze().view(batch, -1), out, static_out   \n",
    "\n",
    "    \n",
    "@variational_estimator\n",
    "class VAE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, stat_channels, code_dim, device):\n",
    "        super(VAE,self).__init__()\n",
    "        \n",
    "        self.code_dim = code_dim\n",
    "        self.device = device\n",
    "        self.encoder = torch.nn.GRU(in_channels, code_dim, batch_first=True, bidirectional=True)\n",
    "        self.att = torch.nn.Linear(code_dim, 1)\n",
    "#         self.att = BayesianLinear(code_dim, 1)\n",
    "        self.mu = torch.nn.Linear(code_dim,code_dim)\n",
    "        self.logvar = torch.nn.Linear(code_dim,code_dim)\n",
    "        self.decoder = torch.nn.GRU(in_channels, code_dim, batch_first=True)\n",
    "#         self.decoder = BayesianGRU(in_channels, code_dim)#, batch_first=True)\n",
    "        self.out = torch.nn.Linear(code_dim, in_channels)\n",
    "        self.linear_1 = torch.nn.Linear(code_dim,code_dim)\n",
    "        #self.linear_2 = torch.nn.Linear(code_dim,code_dim)\n",
    "        self.static_out = torch.nn.Linear(code_dim, stat_channels)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch, seq_len, in_channels = x.shape\n",
    "\n",
    "        code_vec, _ = self.encoder(x)\n",
    "        code_vec = torch.add(code_vec[:,:,:self.code_dim], code_vec[:,:,self.code_dim:])\n",
    "        att_weights = torch.unsqueeze(torch.nn.functional.softmax(self.att(code_vec).squeeze(), dim=1), dim=-1)\n",
    "        code_vec = att_weights*code_vec\n",
    "\n",
    "        mu, logvar = self.mu(code_vec), self.logvar(code_vec)\n",
    "        var_val = logvar#torch.exp(logvar/2)\n",
    "        code_vec = mu+var_val * torch.randn_like(var_val)\n",
    "        code_vec = torch.unsqueeze(torch.sum(code_vec, dim=1), dim=0)\n",
    "        static_out = self.relu(self.linear_1(code_vec.squeeze()))\n",
    "        #static_out = self.relu(self.linear_2(static_out))\n",
    "        static_out = self.static_out(static_out)\n",
    "\n",
    "        out = torch.zeros(batch, seq_len, in_channels).to(self.device)\n",
    "        h = code_vec\n",
    "        input = torch.zeros((batch, 1, in_channels)).to(self.device)\n",
    "#         print(h.size())\n",
    "        for step in range(seq_len):\n",
    "            input, h = self.decoder(input, h)\n",
    "            output = self.out(torch.mul(input.squeeze(), code_vec.squeeze()))\n",
    "            out[:,step] = output\n",
    "            input = output.unsqueeze(1)\n",
    "        \n",
    "        out = out.view(batch, seq_len, in_channels)\n",
    "        return code_vec.squeeze().view(batch, -1), out, static_out        \n",
    "\n",
    "model = globals()[architecture](in_channels=len(input_channels), stat_channels=len(static_channels), code_dim=code_dim, device=device)\n",
    "model = model.to(device)\n",
    "criterion = torch.nn.MSELoss(reduction=\"none\")\n",
    "triplet_criterion = torch.nn.TripletMarginLoss(margin=alpha, p=2.0, eps=1e-06, reduction=\"none\")\n",
    "# triplet_criterion = torch.nn.TripletMarginWithDistanceLoss(distance_function=torch.nn.PairwiseDistance(p=2.0, eps=1e-06), margin=alpha, reduction=\"none\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Total trainable parameters:{}\".format(pytorch_total_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD PRETRAINED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pretrain:\n",
    "    model.load_state_dict(torch.load(os.path.join(DIR, 'MODEL', \"{}_{}.pt\".format(pretrain, code_dim))), strict=False)\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model_object, train_data, validation_data, test_data, model_save_path=None):\n",
    "    model = model_object\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    validation_loss = []\n",
    "    min_val = 10000\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        #############################################################\n",
    "        # RUN ON TRAIN DATA\n",
    "        dataset = train_data\n",
    "\n",
    "        \"\"\"Generate positive years\"\"\"\n",
    "        positive_years = np.zeros((dataset.shape[0], dataset.shape[1]))\n",
    "        for node in range(dataset.shape[0]):\n",
    "            positive_years[node] = random.sample(range(dataset.shape[1]), dataset.shape[1])\n",
    "        positive_years = positive_years.astype(np.int64)\n",
    "        \"\"\"Generate negative basins\"\"\"\n",
    "        negative_basins = np.zeros((dataset.shape[0], dataset.shape[1]))\n",
    "        for year in range(dataset.shape[1]):\n",
    "            negative_basins[:,year] = random.sample(range(dataset.shape[0]), dataset.shape[0])\n",
    "        negative_basins = negative_basins.astype(np.int64)\n",
    "        \"\"\"Generate negative years\"\"\"\n",
    "        negative_years = np.zeros((dataset.shape[0], dataset.shape[1]))\n",
    "        for node in range(dataset.shape[0]):\n",
    "            negative_years[node] = random.sample(range(dataset.shape[1]), dataset.shape[1])\n",
    "        negative_years = negative_years.astype(np.int64)\n",
    "\n",
    "        total_loss = 0\n",
    "        total_recon_loss = 0\n",
    "        total_triplet_loss = 0\n",
    "        total_static_loss = 0\n",
    "        for year in range(dataset.shape[1]):\n",
    "            anchor_data = dataset[:,year]\n",
    "            positive_data = dataset[np.arange(len(dataset)), positive_years[:,year]]\n",
    "            negative_data = dataset[negative_basins[:,year], negative_years[:,year]]\n",
    "\n",
    "            # Remove triplets where (anchor,positive,negative) basins are same\n",
    "            keep_idx = np.arange(len(dataset)) != negative_basins[:,year]\n",
    "            anchor_data = anchor_data[keep_idx]\n",
    "            positive_data = positive_data[keep_idx]\n",
    "            negative_data = negative_data[keep_idx]\n",
    "\n",
    "            # Remove triplets where (anchor,positive,negative) basins have unknown in streamflow\n",
    "            keep_idx = np.zeros((anchor_data.shape[0], 3)).astype(bool)\n",
    "            keep_idx[:,0] = (anchor_data[:,:,-1]!=config.unknown).all(axis=1)\n",
    "            keep_idx[:,1] = (positive_data[:,:,-1]!=config.unknown).all(axis=1)\n",
    "            keep_idx[:,2] = (negative_data[:,:,-1]!=config.unknown).all(axis=1)\n",
    "            keep_idx = keep_idx.all(axis=1)\n",
    "            anchor_data = anchor_data[keep_idx]\n",
    "            positive_data = positive_data[keep_idx]\n",
    "            negative_data = negative_data[keep_idx]\n",
    "\n",
    "            for batch in range(math.ceil(anchor_data.shape[0]/batch_size)):\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                batch_anchor_data = torch.from_numpy(anchor_data[batch*batch_size:(batch+1)*batch_size]).to(device)\n",
    "                batch_positive_data = torch.from_numpy(positive_data[batch*batch_size:(batch+1)*batch_size]).to(device)\n",
    "                batch_negative_data = torch.from_numpy(negative_data[batch*batch_size:(batch+1)*batch_size]).to(device)\n",
    "\n",
    "                batch_anchor_data_input = batch_anchor_data[:,:,input_channels]\n",
    "                batch_positive_data_input = batch_positive_data[:,:,input_channels]\n",
    "                batch_negative_data_input = batch_negative_data[:,:,input_channels]\n",
    "\n",
    "                batch_anchor_data_static = batch_anchor_data[:,0,static_channels]\n",
    "                batch_positive_data_static = batch_positive_data[:,0,static_channels]\n",
    "                batch_negative_data_static = batch_negative_data[:,0,static_channels]\n",
    "\n",
    "                input_data = torch.cat((batch_anchor_data_input, batch_positive_data_input, batch_negative_data_input), axis=0)\n",
    "                static_data = torch.cat((batch_anchor_data_static, batch_positive_data_static, batch_negative_data_static), axis=0)\n",
    "    #             print(input_data.size())\n",
    "                code, reconstruction, static_reconstruction = model(input_data.to(device))\n",
    "\n",
    "                # Calculate reconstruction loss\n",
    "                recon_loss = torch.sum(criterion(reconstruction, input_data), axis=2)\n",
    "                recon_loss = torch.masked_select(recon_loss, (input_data[:,:,-1]!=config.unknown))\n",
    "                recon_loss = torch.mean(recon_loss)\n",
    "\n",
    "                # Calculate contrastive loss\n",
    "                anchor_code = code[:batch_anchor_data.shape[0]]\n",
    "                positive_code = code[batch_anchor_data.shape[0]:batch_anchor_data.shape[0]+batch_positive_data.shape[0]]\n",
    "                negative_code = code[batch_anchor_data.shape[0]+batch_positive_data.shape[0]:]\n",
    "                triplet_loss = torch.mean(triplet_criterion(anchor_code, positive_code, negative_code))            \n",
    "\n",
    "\n",
    "                # Calculate static loss\n",
    "                static_loss = torch.mean(criterion(static_reconstruction, static_data), axis=1)\n",
    "                static_loss = torch.mean(static_loss)\n",
    "\n",
    "                loss = (recon_weight*recon_loss + triplet_weight*triplet_loss + static_weight*static_loss)/sum_weight\n",
    "                total_loss += loss.item()\n",
    "                total_recon_loss += recon_loss.item()\n",
    "                total_triplet_loss += triplet_loss.item()\n",
    "                total_static_loss += static_loss.item()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        print('Epoch:{}\\tTrain Loss:{:.4f}\\tRecon Loss:{:.4f}\\tTriplet Loss:{:.4f}\\tStatic Loss:{:.4f}'.format(epoch, total_loss/((batch+1)*(year+1)), total_recon_loss/((batch+1)*(year+1)), total_triplet_loss/((batch+1)*(year+1)), total_static_loss/((batch+1)*(year+1))), end=\"\\t\")\n",
    "        train_loss.append(total_loss/((batch+1)*(year+1)))\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        #############################################################\n",
    "        # RUN ON VALIDATION DATA\n",
    "        dataset = validation_data\n",
    "        \"\"\"Generate positive years\"\"\"\n",
    "        positive_years = np.zeros((dataset.shape[0], dataset.shape[1]))\n",
    "        for node in range(dataset.shape[0]):\n",
    "            positive_years[node] = random.sample(range(dataset.shape[1]), dataset.shape[1])\n",
    "        positive_years = positive_years.astype(np.int64)\n",
    "        \"\"\"Generate negative basins\"\"\"\n",
    "        negative_basins = np.zeros((dataset.shape[0], dataset.shape[1]))\n",
    "        for year in range(dataset.shape[1]):\n",
    "            negative_basins[:,year] = random.sample(range(dataset.shape[0]), dataset.shape[0])\n",
    "        negative_basins = negative_basins.astype(np.int64)\n",
    "        \"\"\"Generate negative years\"\"\"\n",
    "        negative_years = np.zeros((dataset.shape[0], dataset.shape[1]))\n",
    "        for node in range(dataset.shape[0]):\n",
    "            negative_years[node] = random.sample(range(dataset.shape[1]), dataset.shape[1])\n",
    "        negative_years = negative_years.astype(np.int64)\n",
    "\n",
    "        total_loss = 0\n",
    "        total_recon_loss = 0\n",
    "        total_triplet_loss = 0\n",
    "        total_static_loss = 0\n",
    "        for year in range(dataset.shape[1]):\n",
    "            anchor_data = dataset[:,year]\n",
    "            positive_data = dataset[np.arange(len(dataset)), positive_years[:,year]]\n",
    "            negative_data = dataset[negative_basins[:,year], negative_years[:,year]]\n",
    "\n",
    "            # Remove triplets where (anchor,positive,negative) basins are same\n",
    "            keep_idx = np.arange(len(dataset)) != negative_basins[:,year]\n",
    "            anchor_data = anchor_data[keep_idx]\n",
    "            positive_data = positive_data[keep_idx]\n",
    "            negative_data = negative_data[keep_idx]\n",
    "\n",
    "            # Remove triplets where (anchor,positive,negative) basins have unknown in streamflow\n",
    "            keep_idx = np.zeros((anchor_data.shape[0], 3)).astype(bool)\n",
    "            keep_idx[:,0] = (anchor_data[:,:,-1]!=config.unknown).all(axis=1)\n",
    "            keep_idx[:,1] = (positive_data[:,:,-1]!=config.unknown).all(axis=1)\n",
    "            keep_idx[:,2] = (negative_data[:,:,-1]!=config.unknown).all(axis=1)\n",
    "            keep_idx = keep_idx.all(axis=1)\n",
    "            anchor_data = anchor_data[keep_idx]\n",
    "            positive_data = positive_data[keep_idx]\n",
    "            negative_data = negative_data[keep_idx]\n",
    "\n",
    "            for batch in range(math.ceil(anchor_data.shape[0]/batch_size)):\n",
    "\n",
    "                batch_anchor_data = torch.from_numpy(anchor_data[batch*batch_size:(batch+1)*batch_size]).to(device)\n",
    "                batch_positive_data = torch.from_numpy(positive_data[batch*batch_size:(batch+1)*batch_size]).to(device)\n",
    "                batch_negative_data = torch.from_numpy(negative_data[batch*batch_size:(batch+1)*batch_size]).to(device)\n",
    "\n",
    "                batch_anchor_data_input = batch_anchor_data[:,:,input_channels]\n",
    "                batch_positive_data_input = batch_positive_data[:,:,input_channels]\n",
    "                batch_negative_data_input = batch_negative_data[:,:,input_channels]\n",
    "\n",
    "                batch_anchor_data_static = batch_anchor_data[:,0,static_channels]\n",
    "                batch_positive_data_static = batch_positive_data[:,0,static_channels]\n",
    "                batch_negative_data_static = batch_negative_data[:,0,static_channels]\n",
    "\n",
    "                input_data = torch.cat((batch_anchor_data_input, batch_positive_data_input, batch_negative_data_input), axis=0)\n",
    "                static_data = torch.cat((batch_anchor_data_static, batch_positive_data_static, batch_negative_data_static), axis=0)\n",
    "    #             print(input_data.size())\n",
    "                code, reconstruction, static_reconstruction = model(input_data.to(device))\n",
    "\n",
    "                # Calculate reconstruction loss\n",
    "                recon_loss = torch.sum(criterion(reconstruction, input_data), axis=2)\n",
    "                recon_loss = torch.masked_select(recon_loss, (input_data[:,:,-1]!=config.unknown))\n",
    "                recon_loss = torch.mean(recon_loss)\n",
    "\n",
    "                # Calculate triplet loss\n",
    "                anchor_code = code[:batch_anchor_data.shape[0]]\n",
    "                positive_code = code[batch_anchor_data.shape[0]:batch_anchor_data.shape[0]+batch_positive_data.shape[0]]\n",
    "                negative_code = code[batch_anchor_data.shape[0]+batch_positive_data.shape[0]:]\n",
    "                triplet_loss = torch.mean(triplet_criterion(anchor_code, positive_code, negative_code))            \n",
    "    #             pos_dist = ((anchor_code-positive_code)**2).sum(axis=1)\n",
    "    #             neg_dist = ((anchor_code-negative_code)**2).sum(axis=1)\n",
    "    #             triplet_loss = torch.mean(torch.nn.functional.relu(pos_dist - neg_dist + alpha))\n",
    "\n",
    "                # Calculate static loss\n",
    "                static_loss = torch.mean(criterion(static_reconstruction, static_data), axis=1)\n",
    "                static_loss = torch.mean(static_loss)\n",
    "\n",
    "                loss = (recon_weight*recon_loss + triplet_weight*triplet_loss + static_weight*static_loss)/sum_weight\n",
    "                total_loss += loss.item()\n",
    "                total_recon_loss += recon_loss.item()\n",
    "                total_triplet_loss += triplet_loss.item()\n",
    "                total_static_loss += static_loss.item()\n",
    "        print('\\nVal Loss:{:.4f}\\tRecon Loss:{:.4f}\\tTriplet Loss:{:.4f}\\tStatic Loss:{:.4f}\\n\\n'.format(total_loss/((batch+1)*(year+1)), total_recon_loss/((batch+1)*(year+1)), total_triplet_loss/((batch+1)*(year+1)), total_static_loss/((batch+1)*(year+1))), end=\"\\t\")\n",
    "        validation_loss.append(total_loss/((batch+1)*(year+1)))\n",
    "        if min_val>validation_loss[-1] and validation_loss[-1]>0:\n",
    "            min_val = validation_loss[-1]\n",
    "            torch.save(model.state_dict(), os.path.join(MODEL_DIR, \"{}.pt\".format(model_name)))\n",
    "\n",
    "        end = time.time()\n",
    "        print(\"Time:{:.4f}\".format(end-start))\n",
    "\n",
    "        #############################################################\n",
    "        # RUN ON TEST DATA\n",
    "        dataset = test_data\n",
    "        \"\"\"Generate positive years\"\"\"\n",
    "        positive_years = np.zeros((dataset.shape[0], dataset.shape[1]))\n",
    "        for node in range(dataset.shape[0]):\n",
    "            positive_years[node] = random.sample(range(dataset.shape[1]), dataset.shape[1])\n",
    "        positive_years = positive_years.astype(np.int64)\n",
    "        \"\"\"Generate negative basins\"\"\"\n",
    "        negative_basins = np.zeros((dataset.shape[0], dataset.shape[1]))\n",
    "        for year in range(dataset.shape[1]):\n",
    "            negative_basins[:,year] = random.sample(range(dataset.shape[0]), dataset.shape[0])\n",
    "        negative_basins = negative_basins.astype(np.int64)\n",
    "        \"\"\"Generate negative years\"\"\"\n",
    "        negative_years = np.zeros((dataset.shape[0], dataset.shape[1]))\n",
    "        for node in range(dataset.shape[0]):\n",
    "            negative_years[node] = random.sample(range(dataset.shape[1]), dataset.shape[1])\n",
    "        negative_years = negative_years.astype(np.int64)\n",
    "\n",
    "        total_loss = 0\n",
    "        total_recon_loss = 0\n",
    "        total_triplet_loss = 0\n",
    "        total_static_loss = 0\n",
    "        for year in range(dataset.shape[1]):\n",
    "            anchor_data = dataset[:,year]\n",
    "            positive_data = dataset[np.arange(len(dataset)), positive_years[:,year]]\n",
    "            negative_data = dataset[negative_basins[:,year], negative_years[:,year]]\n",
    "\n",
    "            # Remove triplets where (anchor,positive,negative) basins are same\n",
    "            keep_idx = np.arange(len(dataset)) != negative_basins[:,year]\n",
    "            anchor_data = anchor_data[keep_idx]\n",
    "            positive_data = positive_data[keep_idx]\n",
    "            negative_data = negative_data[keep_idx]\n",
    "\n",
    "            # Remove triplets where (anchor,positive,negative) basins have unknown in streamflow\n",
    "            keep_idx = np.zeros((anchor_data.shape[0], 3)).astype(bool)\n",
    "            keep_idx[:,0] = (anchor_data[:,:,-1]!=config.unknown).all(axis=1)\n",
    "            keep_idx[:,1] = (positive_data[:,:,-1]!=config.unknown).all(axis=1)\n",
    "            keep_idx[:,2] = (negative_data[:,:,-1]!=config.unknown).all(axis=1)\n",
    "            keep_idx = keep_idx.all(axis=1)\n",
    "            anchor_data = anchor_data[keep_idx]\n",
    "            positive_data = positive_data[keep_idx]\n",
    "            negative_data = negative_data[keep_idx]\n",
    "\n",
    "            for batch in range(math.ceil(anchor_data.shape[0]/batch_size)):\n",
    "\n",
    "                batch_anchor_data = torch.from_numpy(anchor_data[batch*batch_size:(batch+1)*batch_size]).to(device)\n",
    "                batch_positive_data = torch.from_numpy(positive_data[batch*batch_size:(batch+1)*batch_size]).to(device)\n",
    "                batch_negative_data = torch.from_numpy(negative_data[batch*batch_size:(batch+1)*batch_size]).to(device)\n",
    "\n",
    "                batch_anchor_data_input = batch_anchor_data[:,:,input_channels]\n",
    "                batch_positive_data_input = batch_positive_data[:,:,input_channels]\n",
    "                batch_negative_data_input = batch_negative_data[:,:,input_channels]\n",
    "\n",
    "                batch_anchor_data_static = batch_anchor_data[:,0,static_channels]\n",
    "                batch_positive_data_static = batch_positive_data[:,0,static_channels]\n",
    "                batch_negative_data_static = batch_negative_data[:,0,static_channels]\n",
    "\n",
    "                input_data = torch.cat((batch_anchor_data_input, batch_positive_data_input, batch_negative_data_input), axis=0)\n",
    "                static_data = torch.cat((batch_anchor_data_static, batch_positive_data_static, batch_negative_data_static), axis=0)\n",
    "    #             print(input_data.size())\n",
    "                code, reconstruction, static_reconstruction = model(input_data.to(device))\n",
    "\n",
    "                # Calculate reconstruction loss\n",
    "                recon_loss = torch.sum(criterion(reconstruction, input_data), axis=2)\n",
    "                recon_loss = torch.masked_select(recon_loss, (input_data[:,:,-1]!=config.unknown))\n",
    "                recon_loss = torch.mean(recon_loss)\n",
    "\n",
    "                # Calculate triplet loss\n",
    "                anchor_code = code[:batch_anchor_data.shape[0]]\n",
    "                positive_code = code[batch_anchor_data.shape[0]:batch_anchor_data.shape[0]+batch_positive_data.shape[0]]\n",
    "                negative_code = code[batch_anchor_data.shape[0]+batch_positive_data.shape[0]:]\n",
    "                triplet_loss = torch.mean(triplet_criterion(anchor_code, positive_code, negative_code))            \n",
    "    #             pos_dist = ((anchor_code-positive_code)**2).sum(axis=1)\n",
    "    #             neg_dist = ((anchor_code-negative_code)**2).sum(axis=1)\n",
    "    #             triplet_loss = torch.mean(torch.nn.functional.relu(pos_dist - neg_dist + alpha))\n",
    "\n",
    "                # Calculate static loss\n",
    "                static_loss = torch.mean(criterion(static_reconstruction, static_data), axis=1)\n",
    "                static_loss = torch.mean(static_loss)\n",
    "\n",
    "                loss = (recon_weight*recon_loss + triplet_weight*triplet_loss + static_weight*static_loss)/sum_weight\n",
    "                total_loss += loss.item()\n",
    "                total_recon_loss += recon_loss.item()\n",
    "                total_triplet_loss += triplet_loss.item()\n",
    "                total_static_loss += static_loss.item()\n",
    "        print('\\nTest Loss:{:.4f}\\tRecon Loss:{:.4f}\\tTriplet Loss:{:.4f}\\tStatic Loss:{:.4f}\\n\\n'.format(total_loss/((batch+1)*(year+1)), total_recon_loss/((batch+1)*(year+1)), total_triplet_loss/((batch+1)*(year+1)), total_static_loss/((batch+1)*(year+1))), end=\"\\t\")\n",
    "        test_loss.append(total_loss/((batch+1)*(year+1)))        \n",
    "        \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.xlabel(\"#Epoch\", fontsize=50)\n",
    "    plt.plot(train_loss, linewidth=4)\n",
    "    plt.plot(test_loss, linewidth=4)\n",
    "    plt.tight_layout(pad=0.0,h_pad=0.0,w_pad=0.0)\n",
    "    plt.savefig(os.path.join(RESULT_DIR, \"{}_LOSS.png\".format(model_name)), format = \"png\")\n",
    "    plt.close()\n",
    "    \n",
    "    preds_std = torch.stack([model(input_data.to(device))[2] for i in range(10)]).std(axis=0).mean().item()\n",
    "    preds_std_reconstruction = torch.stack([model(input_data.to(device))[1] for i in range(10)]).std(axis=0).mean().item()\n",
    "    print('\\nUnc Est in Static characteristics:{:.4f}\\tUnc Est in Streamflow, dynamic:{:.4f}\\t\\n\\n'.format(preds_std, preds_std_reconstruction), end=\"\\t\")\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    return min_val, total_recon_loss/((batch+1)*(year+1)), total_triplet_loss/((batch+1)*(year+1)), total_static_loss/((batch+1)*(year+1)), preds_std, preds_std_reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATT_NL_0\n",
      "Epoch:0\tTrain Loss:0.5471\tRecon Loss:4.0932\tTriplet Loss:0.3954\tStatic Loss:0.5268\t\n",
      "Val Loss:0.4180\tRecon Loss:4.0309\tTriplet Loss:0.2686\tStatic Loss:0.3968\n",
      "\n",
      "\tTime:51.6790\n",
      "\n",
      "Test Loss:1.2908\tRecon Loss:11.9336\tTriplet Loss:0.8622\tStatic Loss:1.2272\n",
      "\n",
      "\tEpoch:1\tTrain Loss:0.3804\tRecon Loss:3.9588\tTriplet Loss:0.2418\tStatic Loss:0.3584\t\n",
      "Val Loss:0.3762\tRecon Loss:4.0082\tTriplet Loss:0.2043\tStatic Loss:0.3570\n",
      "\n",
      "\tTime:51.6685\n",
      "\n",
      "Test Loss:1.1712\tRecon Loss:11.8830\tTriplet Loss:0.7004\tStatic Loss:1.1112\n",
      "\n",
      "\tEpoch:2\tTrain Loss:0.3490\tRecon Loss:3.9496\tTriplet Loss:0.2091\tStatic Loss:0.3270\t\n",
      "Val Loss:0.3498\tRecon Loss:3.9913\tTriplet Loss:0.2013\tStatic Loss:0.3283\n",
      "\n",
      "\tTime:50.2824\n",
      "\n",
      "Test Loss:1.1034\tRecon Loss:11.8446\tTriplet Loss:0.6396\tStatic Loss:1.0423\n",
      "\n",
      "\tEpoch:3\tTrain Loss:0.3311\tRecon Loss:3.9086\tTriplet Loss:0.1858\tStatic Loss:0.3098\t\n",
      "Val Loss:0.3390\tRecon Loss:3.8896\tTriplet Loss:0.1677\tStatic Loss:0.3206\n",
      "\n",
      "\tTime:49.5650\n",
      "\n",
      "Test Loss:1.0613\tRecon Loss:11.5713\tTriplet Loss:0.6305\tStatic Loss:0.9993\n",
      "\n",
      "\tEpoch:4\tTrain Loss:0.3146\tRecon Loss:3.5894\tTriplet Loss:0.1766\tStatic Loss:0.2956\t\n",
      "Val Loss:0.3254\tRecon Loss:3.1892\tTriplet Loss:0.1744\tStatic Loss:0.3119\n",
      "\n",
      "\tTime:50.4591\n",
      "\n",
      "Test Loss:1.0034\tRecon Loss:9.4832\tTriplet Loss:0.5730\tStatic Loss:0.9616\n",
      "\n",
      "\tEpoch:5\tTrain Loss:0.2967\tRecon Loss:2.7141\tTriplet Loss:0.1700\tStatic Loss:0.2852\t\n",
      "Val Loss:0.3146\tRecon Loss:2.5396\tTriplet Loss:0.1830\tStatic Loss:0.3056\n",
      "\n",
      "\tTime:49.5249\n",
      "\n",
      "Test Loss:1.0317\tRecon Loss:7.5135\tTriplet Loss:0.5458\tStatic Loss:1.0155\n",
      "\n",
      "\tEpoch:6\tTrain Loss:0.2852\tRecon Loss:2.4424\tTriplet Loss:0.1566\tStatic Loss:0.2765\t\n",
      "Val Loss:0.2972\tRecon Loss:2.3960\tTriplet Loss:0.1553\tStatic Loss:0.2904\n",
      "\n",
      "\tTime:48.7174\n",
      "\n",
      "Test Loss:0.9484\tRecon Loss:7.3276\tTriplet Loss:0.5456\tStatic Loss:0.9249\n",
      "\n",
      "\tEpoch:7\tTrain Loss:0.2743\tRecon Loss:2.1347\tTriplet Loss:0.1513\tStatic Loss:0.2680\t\n",
      "Val Loss:0.2943\tRecon Loss:2.0333\tTriplet Loss:0.1587\tStatic Loss:0.2905\n",
      "\n",
      "\tTime:47.4236\n",
      "\n",
      "Test Loss:0.9483\tRecon Loss:6.0701\tTriplet Loss:0.5104\tStatic Loss:0.9409\n",
      "\n",
      "\tEpoch:8\tTrain Loss:0.2895\tRecon Loss:3.8628\tTriplet Loss:0.1548\tStatic Loss:0.2672\t\n",
      "Val Loss:0.3025\tRecon Loss:3.7733\tTriplet Loss:0.1543\tStatic Loss:0.2826\n",
      "\n",
      "\tTime:47.7311\n",
      "\n",
      "Test Loss:0.9743\tRecon Loss:11.1309\tTriplet Loss:0.5240\tStatic Loss:0.9178\n",
      "\n",
      "\tEpoch:9\tTrain Loss:0.2728\tRecon Loss:3.1251\tTriplet Loss:0.1506\tStatic Loss:0.2565\t\n",
      "Val Loss:0.2982\tRecon Loss:3.2805\tTriplet Loss:0.1531\tStatic Loss:0.2829\n",
      "\n",
      "\tTime:48.1159\n",
      "\n",
      "Test Loss:0.9950\tRecon Loss:9.8822\tTriplet Loss:0.5604\tStatic Loss:0.9496\n",
      "\n",
      "\tEpoch:10\tTrain Loss:0.2610\tRecon Loss:2.4716\tTriplet Loss:0.1434\tStatic Loss:0.2506\t\n",
      "Val Loss:0.2881\tRecon Loss:2.3410\tTriplet Loss:0.1542\tStatic Loss:0.2810\n",
      "\n",
      "\tTime:48.8576\n",
      "\n",
      "Test Loss:0.9676\tRecon Loss:7.0063\tTriplet Loss:0.5114\tStatic Loss:0.9529\n",
      "\n",
      "\tEpoch:11\tTrain Loss:0.2560\tRecon Loss:2.2444\tTriplet Loss:0.1418\tStatic Loss:0.2476\t\n",
      "Val Loss:0.2790\tRecon Loss:2.2197\tTriplet Loss:0.1510\tStatic Loss:0.2724\n",
      "\n",
      "\tTime:48.8490\n",
      "\n",
      "Test Loss:0.9011\tRecon Loss:6.5711\tTriplet Loss:0.5031\tStatic Loss:0.8842\n",
      "\n",
      "\tEpoch:12\tTrain Loss:0.2549\tRecon Loss:2.5809\tTriplet Loss:0.1397\tStatic Loss:0.2431\t\n",
      "Val Loss:0.2775\tRecon Loss:2.2337\tTriplet Loss:0.1471\tStatic Loss:0.2710\n",
      "\n",
      "\tTime:48.6646\n",
      "\n",
      "Test Loss:0.9028\tRecon Loss:6.6683\tTriplet Loss:0.5121\tStatic Loss:0.8842\n",
      "\n",
      "\tEpoch:13\tTrain Loss:0.2466\tRecon Loss:2.0803\tTriplet Loss:0.1334\tStatic Loss:0.2396\t\n",
      "Val Loss:0.2736\tRecon Loss:2.1028\tTriplet Loss:0.1388\tStatic Loss:0.2687\n",
      "\n",
      "\tTime:49.1791\n",
      "\n",
      "Test Loss:0.8816\tRecon Loss:6.2824\tTriplet Loss:0.4888\tStatic Loss:0.8668\n",
      "\n",
      "\tEpoch:14\tTrain Loss:0.2439\tRecon Loss:2.0808\tTriplet Loss:0.1343\tStatic Loss:0.2365\t\n",
      "Val Loss:0.2741\tRecon Loss:2.2726\tTriplet Loss:0.1481\tStatic Loss:0.2667\n",
      "\n",
      "\tTime:49.3445\n",
      "\n",
      "Test Loss:0.9079\tRecon Loss:6.7515\tTriplet Loss:0.4577\tStatic Loss:0.8945\n",
      "\n",
      "\tEpoch:15\tTrain Loss:0.2462\tRecon Loss:2.2846\tTriplet Loss:0.1378\tStatic Loss:0.2367\t\n",
      "Val Loss:0.2887\tRecon Loss:2.9067\tTriplet Loss:0.1450\tStatic Loss:0.2768\n",
      "\n",
      "\tTime:48.0679\n",
      "\n",
      "Test Loss:0.9036\tRecon Loss:8.4773\tTriplet Loss:0.5139\tStatic Loss:0.8669\n",
      "\n",
      "\tEpoch:16\tTrain Loss:0.2418\tRecon Loss:2.3007\tTriplet Loss:0.1308\tStatic Loss:0.2323\t\n",
      "Val Loss:0.2815\tRecon Loss:2.0919\tTriplet Loss:0.1508\tStatic Loss:0.2764\n",
      "\n",
      "\tTime:47.8639\n",
      "\n",
      "Test Loss:0.8718\tRecon Loss:6.1834\tTriplet Loss:0.4727\tStatic Loss:0.8586\n",
      "\n",
      "\tEpoch:17\tTrain Loss:0.2341\tRecon Loss:2.0053\tTriplet Loss:0.1260\tStatic Loss:0.2271\t\n",
      "Val Loss:0.2735\tRecon Loss:2.0267\tTriplet Loss:0.1399\tStatic Loss:0.2693\n",
      "\n",
      "\tTime:47.5053\n",
      "\n",
      "Test Loss:0.8810\tRecon Loss:6.0221\tTriplet Loss:0.4495\tStatic Loss:0.8727\n",
      "\n",
      "\tEpoch:18\tTrain Loss:0.2330\tRecon Loss:2.0156\tTriplet Loss:0.1248\tStatic Loss:0.2260\t\n",
      "Val Loss:0.2726\tRecon Loss:2.0289\tTriplet Loss:0.1481\tStatic Loss:0.2675\n",
      "\n",
      "\tTime:49.0341\n",
      "\n",
      "Test Loss:0.8577\tRecon Loss:6.0595\tTriplet Loss:0.4507\tStatic Loss:0.8464\n",
      "\n",
      "\tEpoch:19\tTrain Loss:0.2296\tRecon Loss:1.9587\tTriplet Loss:0.1172\tStatic Loss:0.2236\t\n",
      "Val Loss:0.2724\tRecon Loss:2.0306\tTriplet Loss:0.1428\tStatic Loss:0.2678\n",
      "\n",
      "\tTime:52.8422\n",
      "\n",
      "Test Loss:0.8424\tRecon Loss:6.1635\tTriplet Loss:0.4784\tStatic Loss:0.8256\n",
      "\n",
      "\tEpoch:20\tTrain Loss:0.2282\tRecon Loss:1.9559\tTriplet Loss:0.1225\tStatic Loss:0.2215\t\n",
      "Val Loss:0.2696\tRecon Loss:1.9874\tTriplet Loss:0.1262\tStatic Loss:0.2667\n",
      "\n",
      "\tTime:53.1632\n",
      "\n",
      "Test Loss:0.8457\tRecon Loss:5.9330\tTriplet Loss:0.4492\tStatic Loss:0.8344\n",
      "\n",
      "\tEpoch:21\tTrain Loss:0.2243\tRecon Loss:1.9344\tTriplet Loss:0.1163\tStatic Loss:0.2180\t\n",
      "Val Loss:0.2726\tRecon Loss:2.0405\tTriplet Loss:0.1469\tStatic Loss:0.2674\n",
      "\n",
      "\tTime:48.9694\n",
      "\n",
      "Test Loss:0.8755\tRecon Loss:6.1628\tTriplet Loss:0.4639\tStatic Loss:0.8638\n",
      "\n",
      "\tEpoch:22\tTrain Loss:0.2303\tRecon Loss:2.1987\tTriplet Loss:0.1160\tStatic Loss:0.2221\t\n",
      "Val Loss:0.2786\tRecon Loss:2.5487\tTriplet Loss:0.1429\tStatic Loss:0.2695\n",
      "\n",
      "\tTime:48.8378\n",
      "\n",
      "Test Loss:0.8685\tRecon Loss:7.5961\tTriplet Loss:0.4334\tStatic Loss:0.8447\n",
      "\n",
      "\tEpoch:23\tTrain Loss:0.2255\tRecon Loss:2.1228\tTriplet Loss:0.1194\tStatic Loss:0.2171\t\n",
      "Val Loss:0.2709\tRecon Loss:2.0872\tTriplet Loss:0.1426\tStatic Loss:0.2656\n",
      "\n",
      "\tTime:57.8331\n",
      "\n",
      "Test Loss:0.8538\tRecon Loss:6.1470\tTriplet Loss:0.4800\tStatic Loss:0.8382\n",
      "\n",
      "\tEpoch:24\tTrain Loss:0.2199\tRecon Loss:1.9852\tTriplet Loss:0.1121\tStatic Loss:0.2130\t\n",
      "Val Loss:0.2685\tRecon Loss:2.0098\tTriplet Loss:0.1382\tStatic Loss:0.2641\n",
      "\n",
      "\tTime:56.4526\n",
      "\n",
      "Test Loss:0.8228\tRecon Loss:5.9746\tTriplet Loss:0.4430\tStatic Loss:0.8093\n",
      "\n",
      "\tEpoch:25\tTrain Loss:0.2192\tRecon Loss:1.9780\tTriplet Loss:0.1173\tStatic Loss:0.2119\t\n",
      "Val Loss:0.2657\tRecon Loss:2.0044\tTriplet Loss:0.1425\tStatic Loss:0.2606\n",
      "\n",
      "\tTime:57.4005\n",
      "\n",
      "Test Loss:0.8420\tRecon Loss:5.9672\tTriplet Loss:0.4566\tStatic Loss:0.8293\n",
      "\n",
      "\tEpoch:26\tTrain Loss:0.2195\tRecon Loss:2.1193\tTriplet Loss:0.1111\tStatic Loss:0.2114\t\n",
      "Val Loss:0.2675\tRecon Loss:1.9980\tTriplet Loss:0.1470\tStatic Loss:0.2622\n",
      "\n",
      "\tTime:57.9170\n",
      "\n",
      "Test Loss:0.8083\tRecon Loss:5.9122\tTriplet Loss:0.4561\tStatic Loss:0.7925\n",
      "\n",
      "\tEpoch:27\tTrain Loss:0.2151\tRecon Loss:1.9206\tTriplet Loss:0.1129\tStatic Loss:0.2082\t\n",
      "Val Loss:0.2694\tRecon Loss:1.9746\tTriplet Loss:0.1384\tStatic Loss:0.2655\n",
      "\n",
      "\tTime:58.2994\n",
      "\n",
      "Test Loss:0.8492\tRecon Loss:5.8155\tTriplet Loss:0.4439\tStatic Loss:0.8401\n",
      "\n",
      "\tEpoch:28\tTrain Loss:0.2150\tRecon Loss:1.9164\tTriplet Loss:0.1132\tStatic Loss:0.2081\t\n",
      "Val Loss:0.2687\tRecon Loss:1.9797\tTriplet Loss:0.1300\tStatic Loss:0.2654\n",
      "\n",
      "\tTime:57.4898\n",
      "\n",
      "Test Loss:0.8326\tRecon Loss:5.8668\tTriplet Loss:0.4058\tStatic Loss:0.8250\n",
      "\n",
      "\tEpoch:29\tTrain Loss:0.2196\tRecon Loss:2.3636\tTriplet Loss:0.1091\tStatic Loss:0.2092\t\n",
      "Val Loss:0.2752\tRecon Loss:2.2511\tTriplet Loss:0.1426\tStatic Loss:0.2687\n",
      "\n",
      "\tTime:59.1350\n",
      "\n",
      "Test Loss:0.8391\tRecon Loss:6.6084\tTriplet Loss:0.4216\tStatic Loss:0.8232\n",
      "\n",
      "\tEpoch:30\tTrain Loss:0.2127\tRecon Loss:1.9758\tTriplet Loss:0.1156\tStatic Loss:0.2048\t\n",
      "Val Loss:0.2696\tRecon Loss:2.0027\tTriplet Loss:0.1316\tStatic Loss:0.2660\n",
      "\n",
      "\tTime:59.2587\n",
      "\n",
      "Test Loss:0.8134\tRecon Loss:5.9261\tTriplet Loss:0.4415\tStatic Loss:0.7995\n",
      "\n",
      "\tEpoch:31\tTrain Loss:0.2102\tRecon Loss:1.9401\tTriplet Loss:0.1035\tStatic Loss:0.2036\t\n",
      "Val Loss:0.2671\tRecon Loss:1.9717\tTriplet Loss:0.1417\tStatic Loss:0.2626\n",
      "\n",
      "\tTime:58.6512\n",
      "\n",
      "Test Loss:0.8251\tRecon Loss:5.8774\tTriplet Loss:0.4129\tStatic Loss:0.8158\n",
      "\n",
      "\tEpoch:32\tTrain Loss:0.2098\tRecon Loss:1.9097\tTriplet Loss:0.1124\tStatic Loss:0.2025\t\n",
      "Val Loss:0.2696\tRecon Loss:1.9844\tTriplet Loss:0.1279\tStatic Loss:0.2666\n",
      "\n",
      "\tTime:59.8102\n",
      "\n",
      "Test Loss:0.8242\tRecon Loss:5.8997\tTriplet Loss:0.4380\tStatic Loss:0.8121\n",
      "\n",
      "\tEpoch:33\tTrain Loss:0.2087\tRecon Loss:1.9297\tTriplet Loss:0.1029\tStatic Loss:0.2021\t\n",
      "Val Loss:0.2671\tRecon Loss:2.1437\tTriplet Loss:0.1410\tStatic Loss:0.2609\n",
      "\n",
      "\tTime:59.3372\n",
      "\n",
      "Test Loss:0.8475\tRecon Loss:6.3997\tTriplet Loss:0.4444\tStatic Loss:0.8323\n",
      "\n",
      "\tEpoch:34\tTrain Loss:0.2121\tRecon Loss:1.9842\tTriplet Loss:0.1090\tStatic Loss:0.2047\t\n",
      "Val Loss:0.2771\tRecon Loss:1.9827\tTriplet Loss:0.1422\tStatic Loss:0.2735\n",
      "\n",
      "\tTime:57.8889\n",
      "\n",
      "Test Loss:0.8772\tRecon Loss:5.8686\tTriplet Loss:0.4712\tStatic Loss:0.8678\n",
      "\n",
      "\tEpoch:35\tTrain Loss:0.2100\tRecon Loss:1.8933\tTriplet Loss:0.1075\tStatic Loss:0.2035\t\n",
      "Val Loss:0.2709\tRecon Loss:1.9576\tTriplet Loss:0.1485\tStatic Loss:0.2663\n",
      "\n",
      "\tTime:58.2675\n",
      "\n",
      "Test Loss:0.8414\tRecon Loss:5.8017\tTriplet Loss:0.4012\tStatic Loss:0.8358\n",
      "\n",
      "\tEpoch:36\tTrain Loss:0.2044\tRecon Loss:1.8916\tTriplet Loss:0.1032\tStatic Loss:0.1976\t\n",
      "Val Loss:0.2697\tRecon Loss:1.9459\tTriplet Loss:0.1419\tStatic Loss:0.2657\n",
      "\n",
      "\tTime:59.0971\n",
      "\n",
      "Test Loss:0.8121\tRecon Loss:5.7639\tTriplet Loss:0.4183\tStatic Loss:0.8020\n",
      "\n",
      "\tEpoch:37\tTrain Loss:0.2043\tRecon Loss:1.8966\tTriplet Loss:0.1027\tStatic Loss:0.1975\t\n",
      "Val Loss:0.2697\tRecon Loss:1.9586\tTriplet Loss:0.1340\tStatic Loss:0.2664\n",
      "\n",
      "\tTime:59.6982\n",
      "\n",
      "Test Loss:0.8353\tRecon Loss:5.7954\tTriplet Loss:0.4298\tStatic Loss:0.8263\n",
      "\n",
      "\tEpoch:38\tTrain Loss:0.2040\tRecon Loss:1.8864\tTriplet Loss:0.1049\tStatic Loss:0.1971\t\n",
      "Val Loss:0.2699\tRecon Loss:1.9499\tTriplet Loss:0.1396\tStatic Loss:0.2661\n",
      "\n",
      "\tTime:60.1625\n",
      "\n",
      "Test Loss:0.8078\tRecon Loss:5.7822\tTriplet Loss:0.4331\tStatic Loss:0.7955\n",
      "\n",
      "\tEpoch:39\tTrain Loss:0.2017\tRecon Loss:1.8825\tTriplet Loss:0.0987\tStatic Loss:0.1952\t\n",
      "Val Loss:0.2686\tRecon Loss:1.9434\tTriplet Loss:0.1258\tStatic Loss:0.2661\n",
      "\n",
      "\tTime:60.1048\n",
      "\n",
      "Test Loss:0.8232\tRecon Loss:5.7454\tTriplet Loss:0.4399\tStatic Loss:0.8123\n",
      "\n",
      "\tEpoch:40\tTrain Loss:0.1989\tRecon Loss:1.8887\tTriplet Loss:0.1000\tStatic Loss:0.1919\t\n",
      "Val Loss:0.2718\tRecon Loss:1.9512\tTriplet Loss:0.1395\tStatic Loss:0.2682\n",
      "\n",
      "\tTime:58.8398\n",
      "\n",
      "Test Loss:0.8384\tRecon Loss:5.7565\tTriplet Loss:0.4499\tStatic Loss:0.8281\n",
      "\n",
      "\tEpoch:41\tTrain Loss:0.2103\tRecon Loss:2.3490\tTriplet Loss:0.1106\tStatic Loss:0.1988\t\n",
      "Val Loss:0.2693\tRecon Loss:1.9862\tTriplet Loss:0.1191\tStatic Loss:0.2671\n",
      "\n",
      "\tTime:59.5611\n",
      "\n",
      "Test Loss:0.8214\tRecon Loss:5.9211\tTriplet Loss:0.4323\tStatic Loss:0.8093\n",
      "\n",
      "\tEpoch:42\tTrain Loss:0.2005\tRecon Loss:1.9430\tTriplet Loss:0.1056\tStatic Loss:0.1926\t\n",
      "Val Loss:0.2757\tRecon Loss:1.9772\tTriplet Loss:0.1375\tStatic Loss:0.2725\n",
      "\n",
      "\tTime:59.4561\n",
      "\n",
      "Test Loss:0.8325\tRecon Loss:5.8940\tTriplet Loss:0.4745\tStatic Loss:0.8177\n",
      "\n",
      "\tEpoch:43\tTrain Loss:0.1976\tRecon Loss:1.8971\tTriplet Loss:0.0988\tStatic Loss:0.1905\t\n",
      "Val Loss:0.2738\tRecon Loss:1.9511\tTriplet Loss:0.1473\tStatic Loss:0.2697\n",
      "\n",
      "\tTime:57.5876\n",
      "\n",
      "Test Loss:0.8342\tRecon Loss:5.7852\tTriplet Loss:0.4370\tStatic Loss:0.8244\n",
      "\n",
      "\tEpoch:44\tTrain Loss:0.2040\tRecon Loss:2.0683\tTriplet Loss:0.1045\tStatic Loss:0.1953\t\n",
      "Val Loss:0.3195\tRecon Loss:4.2096\tTriplet Loss:0.1453\tStatic Loss:0.2980\n",
      "\n",
      "\tTime:58.6403\n",
      "\n",
      "Test Loss:0.9688\tRecon Loss:11.7370\tTriplet Loss:0.4969\tStatic Loss:0.9083\n",
      "\n",
      "\tEpoch:45\tTrain Loss:0.2295\tRecon Loss:3.5314\tTriplet Loss:0.1101\tStatic Loss:0.2084\t\n",
      "Val Loss:0.2794\tRecon Loss:3.2691\tTriplet Loss:0.1337\tStatic Loss:0.2641\n",
      "\n",
      "\tTime:58.9498\n",
      "\n",
      "Test Loss:0.8765\tRecon Loss:9.5215\tTriplet Loss:0.4799\tStatic Loss:0.8298\n",
      "\n",
      "\tEpoch:46\tTrain Loss:0.2044\tRecon Loss:2.4559\tTriplet Loss:0.1060\tStatic Loss:0.1918\t\n",
      "Val Loss:0.2670\tRecon Loss:2.1768\tTriplet Loss:0.1308\tStatic Loss:0.2615\n",
      "\n",
      "\tTime:58.5927\n",
      "\n",
      "Test Loss:0.8163\tRecon Loss:6.3795\tTriplet Loss:0.4517\tStatic Loss:0.7971\n",
      "\n",
      "\tEpoch:47\tTrain Loss:0.1999\tRecon Loss:2.1705\tTriplet Loss:0.1047\tStatic Loss:0.1897\t\n",
      "Val Loss:0.2809\tRecon Loss:2.7921\tTriplet Loss:0.1466\tStatic Loss:0.2692\n",
      "\n",
      "\tTime:58.5575\n",
      "\n",
      "Test Loss:0.8566\tRecon Loss:8.2125\tTriplet Loss:0.4624\tStatic Loss:0.8224\n",
      "\n",
      "\tEpoch:48\tTrain Loss:0.1993\tRecon Loss:2.2567\tTriplet Loss:0.0989\tStatic Loss:0.1887\t\n",
      "Val Loss:0.2727\tRecon Loss:2.1398\tTriplet Loss:0.1448\tStatic Loss:0.2668\n",
      "\n",
      "\tTime:61.3489\n",
      "\n",
      "Test Loss:0.8244\tRecon Loss:6.1791\tTriplet Loss:0.4305\tStatic Loss:0.8103\n",
      "\n",
      "\tEpoch:49\tTrain Loss:0.1951\tRecon Loss:1.9891\tTriplet Loss:0.1000\tStatic Loss:0.1867\t\n",
      "Val Loss:0.2701\tRecon Loss:2.0093\tTriplet Loss:0.1468\tStatic Loss:0.2651\n",
      "\n",
      "\tTime:59.5230\n",
      "\n",
      "Test Loss:0.8101\tRecon Loss:5.9335\tTriplet Loss:0.4346\tStatic Loss:0.7965\n",
      "\n",
      "\tEpoch:50\tTrain Loss:0.1947\tRecon Loss:1.9438\tTriplet Loss:0.1017\tStatic Loss:0.1865\t\n",
      "Val Loss:0.2724\tRecon Loss:2.0746\tTriplet Loss:0.1452\tStatic Loss:0.2671\n",
      "\n",
      "\tTime:61.7672\n",
      "\n",
      "Test Loss:0.8433\tRecon Loss:6.0798\tTriplet Loss:0.4283\tStatic Loss:0.8325\n",
      "\n",
      "\tEpoch:51\tTrain Loss:0.1931\tRecon Loss:1.9178\tTriplet Loss:0.0979\tStatic Loss:0.1854\t\n",
      "Val Loss:0.2680\tRecon Loss:1.9682\tTriplet Loss:0.1435\tStatic Loss:0.2635\n",
      "\n",
      "\tTime:60.3627\n",
      "\n",
      "Test Loss:0.8293\tRecon Loss:5.8354\tTriplet Loss:0.4029\tStatic Loss:0.8219\n",
      "\n",
      "\tEpoch:52\tTrain Loss:0.1958\tRecon Loss:2.0206\tTriplet Loss:0.1018\tStatic Loss:0.1870\t\n",
      "Val Loss:0.2743\tRecon Loss:1.9747\tTriplet Loss:0.1328\tStatic Loss:0.2714\n",
      "\n",
      "\tTime:58.4387\n",
      "\n",
      "Test Loss:0.8151\tRecon Loss:5.8165\tTriplet Loss:0.4524\tStatic Loss:0.8013\n",
      "\n",
      "\tEpoch:53\tTrain Loss:0.1926\tRecon Loss:1.9041\tTriplet Loss:0.0994\tStatic Loss:0.1849\t\n",
      "Val Loss:0.2667\tRecon Loss:1.9728\tTriplet Loss:0.1420\tStatic Loss:0.2622\n",
      "\n",
      "\tTime:59.3188\n",
      "\n",
      "Test Loss:0.8204\tRecon Loss:5.8545\tTriplet Loss:0.4254\tStatic Loss:0.8096\n",
      "\n",
      "\tEpoch:54\tTrain Loss:0.1908\tRecon Loss:1.9093\tTriplet Loss:0.0982\tStatic Loss:0.1828\t\n",
      "Val Loss:0.2679\tRecon Loss:1.9781\tTriplet Loss:0.1423\tStatic Loss:0.2634\n",
      "\n",
      "\tTime:57.0798\n",
      "\n",
      "Test Loss:0.8102\tRecon Loss:5.8391\tTriplet Loss:0.4266\tStatic Loss:0.7983\n",
      "\n",
      "\tEpoch:55\tTrain Loss:0.1906\tRecon Loss:1.9046\tTriplet Loss:0.0949\tStatic Loss:0.1831\t\n",
      "Val Loss:0.2691\tRecon Loss:2.0005\tTriplet Loss:0.1342\tStatic Loss:0.2653\n",
      "\n",
      "\tTime:58.5414\n",
      "\n",
      "Test Loss:0.8325\tRecon Loss:5.9903\tTriplet Loss:0.4467\tStatic Loss:0.8195\n",
      "\n",
      "\tEpoch:56\tTrain Loss:0.1897\tRecon Loss:1.8846\tTriplet Loss:0.0929\tStatic Loss:0.1825\t\n",
      "Val Loss:0.2689\tRecon Loss:1.9579\tTriplet Loss:0.1329\tStatic Loss:0.2656\n",
      "\n",
      "\tTime:58.5953\n",
      "\n",
      "Test Loss:0.8185\tRecon Loss:5.7645\tTriplet Loss:0.4087\tStatic Loss:0.8100\n",
      "\n",
      "\tEpoch:57\tTrain Loss:0.1915\tRecon Loss:2.0320\tTriplet Loss:0.0997\tStatic Loss:0.1823\t\n",
      "Val Loss:0.2718\tRecon Loss:2.1509\tTriplet Loss:0.1275\tStatic Loss:0.2675\n",
      "\n",
      "\tTime:59.2826\n",
      "\n",
      "Test Loss:0.8097\tRecon Loss:6.3355\tTriplet Loss:0.4374\tStatic Loss:0.7916\n",
      "\n",
      "\tEpoch:58\tTrain Loss:0.1911\tRecon Loss:1.9373\tTriplet Loss:0.0953\tStatic Loss:0.1832\t\n",
      "Val Loss:0.2659\tRecon Loss:1.9576\tTriplet Loss:0.1433\tStatic Loss:0.2612\n",
      "\n",
      "\tTime:59.8374\n",
      "\n",
      "Test Loss:0.8112\tRecon Loss:5.8048\tTriplet Loss:0.4251\tStatic Loss:0.7999\n",
      "\n",
      "\tEpoch:59\tTrain Loss:0.1886\tRecon Loss:1.9012\tTriplet Loss:0.0946\tStatic Loss:0.1809\t\n",
      "Val Loss:0.2803\tRecon Loss:2.5636\tTriplet Loss:0.1381\tStatic Loss:0.2717\n",
      "\n",
      "\tTime:60.6782\n",
      "\n",
      "Test Loss:0.8586\tRecon Loss:7.6009\tTriplet Loss:0.4214\tStatic Loss:0.8349\n",
      "\n",
      "\tEpoch:60\tTrain Loss:0.2310\tRecon Loss:3.5245\tTriplet Loss:0.1169\tStatic Loss:0.2095\t\n",
      "Val Loss:0.2768\tRecon Loss:2.5188\tTriplet Loss:0.1505\tStatic Loss:0.2670\n",
      "\n",
      "\tTime:56.0480\n",
      "\n",
      "Test Loss:0.8185\tRecon Loss:7.5153\tTriplet Loss:0.4304\tStatic Loss:0.7904\n",
      "\n",
      "\tEpoch:61\tTrain Loss:0.1932\tRecon Loss:2.1348\tTriplet Loss:0.1050\tStatic Loss:0.1826\t\n",
      "Val Loss:0.2662\tRecon Loss:2.0819\tTriplet Loss:0.1337\tStatic Loss:0.2613\n",
      "\n",
      "\tTime:59.2281\n",
      "\n",
      "Test Loss:0.8227\tRecon Loss:6.1310\tTriplet Loss:0.4787\tStatic Loss:0.8040\n",
      "\n",
      "\tEpoch:62\tTrain Loss:0.1873\tRecon Loss:1.9708\tTriplet Loss:0.0936\tStatic Loss:0.1788\t\n",
      "Val Loss:0.2696\tRecon Loss:2.0383\tTriplet Loss:0.1430\tStatic Loss:0.2646\n",
      "\n",
      "\tTime:58.9179\n",
      "\n",
      "Test Loss:0.8176\tRecon Loss:6.0191\tTriplet Loss:0.4517\tStatic Loss:0.8021\n",
      "\n",
      "\tEpoch:63\tTrain Loss:0.1893\tRecon Loss:1.9482\tTriplet Loss:0.1037\tStatic Loss:0.1802\t\n",
      "Val Loss:0.2720\tRecon Loss:2.0179\tTriplet Loss:0.1259\tStatic Loss:0.2691\n",
      "\n",
      "\tTime:59.4832\n",
      "\n",
      "Test Loss:0.8263\tRecon Loss:5.9857\tTriplet Loss:0.4563\tStatic Loss:0.8117\n",
      "\n",
      "\tEpoch:64\tTrain Loss:0.1874\tRecon Loss:1.9284\tTriplet Loss:0.0980\tStatic Loss:0.1789\t\n",
      "Val Loss:0.2799\tRecon Loss:2.0129\tTriplet Loss:0.1336\tStatic Loss:0.2772\n",
      "\n",
      "\tTime:59.3976\n",
      "\n",
      "Test Loss:0.8418\tRecon Loss:5.8956\tTriplet Loss:0.4305\tStatic Loss:0.8324\n",
      "\n",
      "\tEpoch:65\tTrain Loss:0.1853\tRecon Loss:1.9109\tTriplet Loss:0.0938\tStatic Loss:0.1772\t\n",
      "Val Loss:0.2681\tRecon Loss:2.0008\tTriplet Loss:0.1355\tStatic Loss:0.2641\n",
      "\n",
      "\tTime:57.2229\n",
      "\n",
      "Test Loss:0.8546\tRecon Loss:5.9156\tTriplet Loss:0.4559\tStatic Loss:0.8439\n",
      "\n",
      "\tEpoch:66\tTrain Loss:0.1846\tRecon Loss:1.9008\tTriplet Loss:0.0953\tStatic Loss:0.1764\t\n",
      "Val Loss:0.2798\tRecon Loss:1.9912\tTriplet Loss:0.1510\tStatic Loss:0.2755\n",
      "\n",
      "\tTime:57.9815\n",
      "\n",
      "Test Loss:0.8402\tRecon Loss:5.8782\tTriplet Loss:0.4712\tStatic Loss:0.8268\n",
      "\n",
      "\tEpoch:67\tTrain Loss:0.1846\tRecon Loss:1.8968\tTriplet Loss:0.0919\tStatic Loss:0.1767\t\n",
      "Val Loss:0.2700\tRecon Loss:1.9768\tTriplet Loss:0.1359\tStatic Loss:0.2663\n",
      "\n",
      "\tTime:57.9964\n",
      "\n",
      "Test Loss:0.8091\tRecon Loss:5.8357\tTriplet Loss:0.4484\tStatic Loss:0.7949\n",
      "\n",
      "\tEpoch:68\tTrain Loss:0.1862\tRecon Loss:1.8929\tTriplet Loss:0.0975\tStatic Loss:0.1780\t\n",
      "Val Loss:0.2679\tRecon Loss:1.9850\tTriplet Loss:0.1274\tStatic Loss:0.2647\n",
      "\n",
      "\tTime:59.0067\n",
      "\n",
      "Test Loss:0.8398\tRecon Loss:5.9226\tTriplet Loss:0.4272\tStatic Loss:0.8302\n",
      "\n",
      "\tEpoch:69\tTrain Loss:0.1843\tRecon Loss:1.8914\tTriplet Loss:0.0974\tStatic Loss:0.1759\t\n",
      "Val Loss:0.2742\tRecon Loss:1.9590\tTriplet Loss:0.1466\tStatic Loss:0.2701\n",
      "\n",
      "\tTime:58.3289\n",
      "\n",
      "Test Loss:0.8214\tRecon Loss:5.8001\tTriplet Loss:0.4474\tStatic Loss:0.8090\n",
      "\n",
      "\tEpoch:70\tTrain Loss:0.1830\tRecon Loss:1.8760\tTriplet Loss:0.0917\tStatic Loss:0.1752\t\n",
      "Val Loss:0.2636\tRecon Loss:1.9542\tTriplet Loss:0.1361\tStatic Loss:0.2594\n",
      "\n",
      "\tTime:53.0541\n",
      "\n",
      "Test Loss:0.7949\tRecon Loss:5.7660\tTriplet Loss:0.4221\tStatic Loss:0.7825\n",
      "\n",
      "\tEpoch:71\tTrain Loss:0.1837\tRecon Loss:1.9015\tTriplet Loss:0.0975\tStatic Loss:0.1751\t\n",
      "Val Loss:0.2724\tRecon Loss:1.9421\tTriplet Loss:0.1258\tStatic Loss:0.2704\n",
      "\n",
      "\tTime:57.2790\n",
      "\n",
      "Test Loss:0.8366\tRecon Loss:5.7466\tTriplet Loss:0.4497\tStatic Loss:0.8262\n",
      "\n",
      "\tEpoch:72\tTrain Loss:0.1828\tRecon Loss:1.8718\tTriplet Loss:0.0990\tStatic Loss:0.1743\t\n",
      "Val Loss:0.2774\tRecon Loss:1.9388\tTriplet Loss:0.1321\tStatic Loss:0.2754\n",
      "\n",
      "\tTime:58.4776\n",
      "\n",
      "Test Loss:0.8552\tRecon Loss:5.7625\tTriplet Loss:0.4158\tStatic Loss:0.8500\n",
      "\n",
      "\tEpoch:73\tTrain Loss:0.1828\tRecon Loss:1.8861\tTriplet Loss:0.0874\tStatic Loss:0.1753\t\n",
      "Val Loss:0.2730\tRecon Loss:1.9334\tTriplet Loss:0.1366\tStatic Loss:0.2700\n",
      "\n",
      "\tTime:58.1138\n",
      "\n",
      "Test Loss:0.8336\tRecon Loss:5.7371\tTriplet Loss:0.4383\tStatic Loss:0.8241\n",
      "\n",
      "\tEpoch:74\tTrain Loss:0.1830\tRecon Loss:1.8708\tTriplet Loss:0.0937\tStatic Loss:0.1750\t\n",
      "Val Loss:0.2687\tRecon Loss:1.9503\tTriplet Loss:0.1330\tStatic Loss:0.2654\n",
      "\n",
      "\tTime:57.7231\n",
      "\n",
      "Test Loss:0.8339\tRecon Loss:5.7874\tTriplet Loss:0.4184\tStatic Loss:0.8259\n",
      "\n",
      "\tEpoch:75\tTrain Loss:0.1810\tRecon Loss:1.8710\tTriplet Loss:0.0899\tStatic Loss:0.1732\t\n",
      "Val Loss:0.2774\tRecon Loss:1.9599\tTriplet Loss:0.1366\tStatic Loss:0.2746\n",
      "\n",
      "\tTime:57.0758\n",
      "\n",
      "Test Loss:0.8325\tRecon Loss:5.7574\tTriplet Loss:0.4388\tStatic Loss:0.8226\n",
      "\n",
      "\tEpoch:76\tTrain Loss:0.1818\tRecon Loss:1.8745\tTriplet Loss:0.0964\tStatic Loss:0.1734\t\n",
      "Val Loss:0.2713\tRecon Loss:1.9494\tTriplet Loss:0.1320\tStatic Loss:0.2685\n",
      "\n",
      "\tTime:58.6348\n",
      "\n",
      "Test Loss:0.8479\tRecon Loss:5.7674\tTriplet Loss:0.4542\tStatic Loss:0.8381\n",
      "\n",
      "\tEpoch:77\tTrain Loss:0.1804\tRecon Loss:1.8637\tTriplet Loss:0.0957\tStatic Loss:0.1720\t\n",
      "Val Loss:0.2692\tRecon Loss:1.9779\tTriplet Loss:0.1388\tStatic Loss:0.2651\n",
      "\n",
      "\tTime:59.5642\n",
      "\n",
      "Test Loss:0.8152\tRecon Loss:5.7907\tTriplet Loss:0.4425\tStatic Loss:0.8028\n",
      "\n",
      "\tEpoch:78\tTrain Loss:0.1791\tRecon Loss:1.8591\tTriplet Loss:0.0929\tStatic Loss:0.1709\t\n",
      "Val Loss:0.2752\tRecon Loss:1.9271\tTriplet Loss:0.1412\tStatic Loss:0.2720\n",
      "\n",
      "\tTime:58.2071\n",
      "\n",
      "Test Loss:0.8340\tRecon Loss:5.7508\tTriplet Loss:0.4696\tStatic Loss:0.8212\n",
      "\n",
      "\tEpoch:79\tTrain Loss:0.1807\tRecon Loss:1.8643\tTriplet Loss:0.0918\tStatic Loss:0.1727\t\n",
      "Val Loss:0.2796\tRecon Loss:1.9606\tTriplet Loss:0.1305\tStatic Loss:0.2777\n",
      "\n",
      "\tTime:56.3513\n",
      "\n",
      "Test Loss:0.8723\tRecon Loss:5.7622\tTriplet Loss:0.4379\tStatic Loss:0.8669\n",
      "\n",
      "\tEpoch:80\tTrain Loss:0.1787\tRecon Loss:1.8600\tTriplet Loss:0.0916\tStatic Loss:0.1706\t\n",
      "Val Loss:0.2771\tRecon Loss:1.9984\tTriplet Loss:0.1329\tStatic Loss:0.2743\n",
      "\n",
      "\tTime:58.6185\n",
      "\n",
      "Test Loss:0.8320\tRecon Loss:5.7963\tTriplet Loss:0.4414\tStatic Loss:0.8214\n",
      "\n",
      "\tEpoch:81\tTrain Loss:0.1795\tRecon Loss:1.8645\tTriplet Loss:0.0912\tStatic Loss:0.1715\t\n",
      "Val Loss:0.2748\tRecon Loss:1.9618\tTriplet Loss:0.1376\tStatic Loss:0.2717\n",
      "\n",
      "\tTime:59.7525\n",
      "\n",
      "Test Loss:0.8171\tRecon Loss:5.8302\tTriplet Loss:0.4167\tStatic Loss:0.8070\n",
      "\n",
      "\tEpoch:82\tTrain Loss:0.1794\tRecon Loss:1.8641\tTriplet Loss:0.0954\tStatic Loss:0.1710\t\n",
      "Val Loss:0.2760\tRecon Loss:1.9259\tTriplet Loss:0.1412\tStatic Loss:0.2730\n",
      "\n",
      "\tTime:59.8279\n",
      "\n",
      "Test Loss:0.8236\tRecon Loss:5.7207\tTriplet Loss:0.4380\tStatic Loss:0.8132\n",
      "\n",
      "\tEpoch:83\tTrain Loss:0.1778\tRecon Loss:1.8565\tTriplet Loss:0.0865\tStatic Loss:0.1701\t\n",
      "Val Loss:0.2691\tRecon Loss:1.9567\tTriplet Loss:0.1386\tStatic Loss:0.2653\n",
      "\n",
      "\tTime:60.6467\n",
      "\n",
      "Test Loss:0.8171\tRecon Loss:5.7442\tTriplet Loss:0.4640\tStatic Loss:0.8031\n",
      "\n",
      "\tEpoch:84\tTrain Loss:0.1793\tRecon Loss:1.8616\tTriplet Loss:0.0883\tStatic Loss:0.1715\t\n",
      "Val Loss:0.2735\tRecon Loss:1.9313\tTriplet Loss:0.1312\tStatic Loss:0.2711\n",
      "\n",
      "\tTime:61.5542\n",
      "\n",
      "Test Loss:0.8387\tRecon Loss:5.6999\tTriplet Loss:0.4228\tStatic Loss:0.8317\n",
      "\n",
      "\tEpoch:85\tTrain Loss:0.1783\tRecon Loss:1.8654\tTriplet Loss:0.0942\tStatic Loss:0.1699\t\n",
      "Val Loss:0.2717\tRecon Loss:1.9703\tTriplet Loss:0.1430\tStatic Loss:0.2676\n",
      "\n",
      "\tTime:61.2918\n",
      "\n",
      "Test Loss:0.8434\tRecon Loss:5.7721\tTriplet Loss:0.4453\tStatic Loss:0.8339\n",
      "\n",
      "\tEpoch:86\tTrain Loss:0.1764\tRecon Loss:1.8575\tTriplet Loss:0.0913\tStatic Loss:0.1681\t\n",
      "Val Loss:0.2754\tRecon Loss:1.9210\tTriplet Loss:0.1355\tStatic Loss:0.2730\n",
      "\n",
      "\tTime:59.2181\n",
      "\n",
      "Test Loss:0.8130\tRecon Loss:5.7307\tTriplet Loss:0.3943\tStatic Loss:0.8057\n",
      "\n",
      "\tEpoch:87\tTrain Loss:0.1770\tRecon Loss:1.8601\tTriplet Loss:0.0934\tStatic Loss:0.1685\t\n",
      "Val Loss:0.2766\tRecon Loss:1.9276\tTriplet Loss:0.1320\tStatic Loss:0.2745\n",
      "\n",
      "\tTime:59.4669\n",
      "\n",
      "Test Loss:0.8446\tRecon Loss:5.7594\tTriplet Loss:0.4381\tStatic Loss:0.8361\n",
      "\n",
      "\tEpoch:88\tTrain Loss:0.1756\tRecon Loss:1.8564\tTriplet Loss:0.0889\tStatic Loss:0.1675\t\n",
      "Val Loss:0.2749\tRecon Loss:1.9201\tTriplet Loss:0.1304\tStatic Loss:0.2729\n",
      "\n",
      "\tTime:60.5849\n",
      "\n",
      "Test Loss:0.8236\tRecon Loss:5.7028\tTriplet Loss:0.4682\tStatic Loss:0.8103\n",
      "\n",
      "\tEpoch:89\tTrain Loss:0.1773\tRecon Loss:1.8576\tTriplet Loss:0.0933\tStatic Loss:0.1689\t\n",
      "Val Loss:0.2837\tRecon Loss:2.0014\tTriplet Loss:0.1247\tStatic Loss:0.2824\n",
      "\n",
      "\tTime:60.6023\n",
      "\n",
      "Test Loss:0.8378\tRecon Loss:5.8603\tTriplet Loss:0.4287\tStatic Loss:0.8285\n",
      "\n",
      "\tEpoch:90\tTrain Loss:0.1794\tRecon Loss:1.8775\tTriplet Loss:0.0933\tStatic Loss:0.1710\t\n",
      "Val Loss:0.2728\tRecon Loss:1.9390\tTriplet Loss:0.1369\tStatic Loss:0.2697\n",
      "\n",
      "\tTime:60.9262\n",
      "\n",
      "Test Loss:0.8436\tRecon Loss:5.7257\tTriplet Loss:0.4460\tStatic Loss:0.8345\n",
      "\n",
      "\tEpoch:91\tTrain Loss:0.1807\tRecon Loss:1.8586\tTriplet Loss:0.0870\tStatic Loss:0.1733\t\n",
      "Val Loss:0.2731\tRecon Loss:1.9076\tTriplet Loss:0.1336\tStatic Loss:0.2707\n",
      "\n",
      "\tTime:60.9214\n",
      "\n",
      "Test Loss:0.8344\tRecon Loss:5.7205\tTriplet Loss:0.4378\tStatic Loss:0.8252\n",
      "\n",
      "\tEpoch:92\tTrain Loss:0.1772\tRecon Loss:1.8984\tTriplet Loss:0.0898\tStatic Loss:0.1687\t\n",
      "Val Loss:0.2701\tRecon Loss:1.9326\tTriplet Loss:0.1307\tStatic Loss:0.2675\n",
      "\n",
      "\tTime:59.9066\n",
      "\n",
      "Test Loss:0.8087\tRecon Loss:5.7360\tTriplet Loss:0.4439\tStatic Loss:0.7959\n",
      "\n",
      "\tEpoch:93\tTrain Loss:0.1755\tRecon Loss:1.8681\tTriplet Loss:0.0947\tStatic Loss:0.1667\t\n",
      "Val Loss:0.2702\tRecon Loss:1.9434\tTriplet Loss:0.1217\tStatic Loss:0.2684\n",
      "\n",
      "\tTime:59.4151\n",
      "\n",
      "Test Loss:0.8346\tRecon Loss:5.7414\tTriplet Loss:0.4314\tStatic Loss:0.8258\n",
      "\n",
      "\tEpoch:94\tTrain Loss:0.1748\tRecon Loss:1.8664\tTriplet Loss:0.0911\tStatic Loss:0.1663\t\n",
      "Val Loss:0.2698\tRecon Loss:1.9213\tTriplet Loss:0.1302\tStatic Loss:0.2672\n",
      "\n",
      "\tTime:59.1529\n",
      "\n",
      "Test Loss:0.8316\tRecon Loss:5.7047\tTriplet Loss:0.4540\tStatic Loss:0.8206\n",
      "\n",
      "\tEpoch:95\tTrain Loss:0.1754\tRecon Loss:1.8553\tTriplet Loss:0.0888\tStatic Loss:0.1672\t\n",
      "Val Loss:0.2700\tRecon Loss:1.9417\tTriplet Loss:0.1272\tStatic Loss:0.2676\n",
      "\n",
      "\tTime:60.4585\n",
      "\n",
      "Test Loss:0.8199\tRecon Loss:5.7632\tTriplet Loss:0.4054\tStatic Loss:0.8119\n",
      "\n",
      "\tEpoch:96\tTrain Loss:0.1752\tRecon Loss:1.8501\tTriplet Loss:0.0928\tStatic Loss:0.1666\t\n",
      "Val Loss:0.2704\tRecon Loss:1.9424\tTriplet Loss:0.1289\tStatic Loss:0.2678\n",
      "\n",
      "\tTime:59.6173\n",
      "\n",
      "Test Loss:0.8359\tRecon Loss:5.7186\tTriplet Loss:0.4494\tStatic Loss:0.8258\n",
      "\n",
      "\tEpoch:97\tTrain Loss:0.1744\tRecon Loss:1.8557\tTriplet Loss:0.0903\tStatic Loss:0.1660\t\n",
      "Val Loss:0.2808\tRecon Loss:1.9667\tTriplet Loss:0.1442\tStatic Loss:0.2776\n",
      "\n",
      "\tTime:59.6473\n",
      "\n",
      "Test Loss:0.8652\tRecon Loss:5.8556\tTriplet Loss:0.4966\tStatic Loss:0.8521\n",
      "\n",
      "\tEpoch:98\tTrain Loss:0.1754\tRecon Loss:1.8524\tTriplet Loss:0.0902\tStatic Loss:0.1672\t\n",
      "Val Loss:0.2779\tRecon Loss:1.9756\tTriplet Loss:0.1346\tStatic Loss:0.2752\n",
      "\n",
      "\tTime:60.0858\n",
      "\n",
      "Test Loss:0.8565\tRecon Loss:5.7774\tTriplet Loss:0.4521\tStatic Loss:0.8477\n",
      "\n",
      "\tEpoch:99\tTrain Loss:0.1746\tRecon Loss:1.8482\tTriplet Loss:0.0923\tStatic Loss:0.1661\t\n",
      "Val Loss:0.2723\tRecon Loss:1.9076\tTriplet Loss:0.1273\tStatic Loss:0.2705\n",
      "\n",
      "\tTime:60.1480\n",
      "\n",
      "Test Loss:0.8446\tRecon Loss:5.6858\tTriplet Loss:0.4498\tStatic Loss:0.8356\n",
      "\n",
      "\tEpoch:100\tTrain Loss:0.1758\tRecon Loss:1.8470\tTriplet Loss:0.0908\tStatic Loss:0.1675\t\n",
      "Val Loss:0.2821\tRecon Loss:1.9504\tTriplet Loss:0.1347\tStatic Loss:0.2802\n",
      "\n",
      "\tTime:59.4322\n",
      "\n",
      "Test Loss:0.8124\tRecon Loss:5.8256\tTriplet Loss:0.4444\tStatic Loss:0.7991\n",
      "\n",
      "\tEpoch:101\tTrain Loss:0.1815\tRecon Loss:1.8567\tTriplet Loss:0.0902\tStatic Loss:0.1738\t\n",
      "Val Loss:0.2740\tRecon Loss:1.9588\tTriplet Loss:0.1334\tStatic Loss:0.2712\n",
      "\n",
      "\tTime:61.2074\n",
      "\n",
      "Test Loss:0.8244\tRecon Loss:5.8223\tTriplet Loss:0.4320\tStatic Loss:0.8137\n",
      "\n",
      "\tEpoch:102\tTrain Loss:0.1759\tRecon Loss:1.8560\tTriplet Loss:0.0892\tStatic Loss:0.1678\t\n",
      "Val Loss:0.2703\tRecon Loss:1.9214\tTriplet Loss:0.1309\tStatic Loss:0.2677\n",
      "\n",
      "\tTime:59.9040\n",
      "\n",
      "Test Loss:0.8346\tRecon Loss:5.7380\tTriplet Loss:0.4243\tStatic Loss:0.8266\n",
      "\n",
      "\tEpoch:103\tTrain Loss:0.1746\tRecon Loss:1.8441\tTriplet Loss:0.0902\tStatic Loss:0.1664\t\n",
      "Val Loss:0.2675\tRecon Loss:1.9132\tTriplet Loss:0.1221\tStatic Loss:0.2656\n",
      "\n",
      "\tTime:60.5516\n",
      "\n",
      "Test Loss:0.8252\tRecon Loss:5.7397\tTriplet Loss:0.4066\tStatic Loss:0.8179\n",
      "\n",
      "\tEpoch:104\tTrain Loss:0.1725\tRecon Loss:1.8439\tTriplet Loss:0.0897\tStatic Loss:0.1640\t\n",
      "Val Loss:0.2690\tRecon Loss:1.9214\tTriplet Loss:0.1236\tStatic Loss:0.2670\n",
      "\n",
      "\tTime:60.0190\n",
      "\n",
      "Test Loss:0.8127\tRecon Loss:5.7563\tTriplet Loss:0.3890\tStatic Loss:0.8056\n",
      "\n",
      "\tEpoch:105\tTrain Loss:0.1757\tRecon Loss:1.8604\tTriplet Loss:0.0930\tStatic Loss:0.1671\t\n",
      "Val Loss:0.2700\tRecon Loss:1.9292\tTriplet Loss:0.1285\tStatic Loss:0.2676\n",
      "\n",
      "\tTime:58.2229\n",
      "\n",
      "Test Loss:0.8333\tRecon Loss:5.7323\tTriplet Loss:0.4216\tStatic Loss:0.8255\n",
      "\n",
      "\tEpoch:106\tTrain Loss:0.1720\tRecon Loss:1.8433\tTriplet Loss:0.0863\tStatic Loss:0.1638\t\n",
      "Val Loss:0.2745\tRecon Loss:1.9317\tTriplet Loss:0.1342\tStatic Loss:0.2720\n",
      "\n",
      "\tTime:58.6718\n",
      "\n",
      "Test Loss:0.8520\tRecon Loss:5.7698\tTriplet Loss:0.4750\tStatic Loss:0.8405\n",
      "\n",
      "\tEpoch:107\tTrain Loss:0.1716\tRecon Loss:1.8522\tTriplet Loss:0.0872\tStatic Loss:0.1633\t\n",
      "Val Loss:0.2716\tRecon Loss:1.9267\tTriplet Loss:0.1230\tStatic Loss:0.2700\n",
      "\n",
      "\tTime:58.4172\n",
      "\n",
      "Test Loss:0.8355\tRecon Loss:5.6992\tTriplet Loss:0.4404\tStatic Loss:0.8264\n",
      "\n",
      "\tEpoch:108\tTrain Loss:0.1702\tRecon Loss:1.8458\tTriplet Loss:0.0910\tStatic Loss:0.1613\t\n",
      "Val Loss:0.2759\tRecon Loss:1.9775\tTriplet Loss:0.1377\tStatic Loss:0.2727\n",
      "\n",
      "\tTime:58.3576\n",
      "\n",
      "Test Loss:0.8467\tRecon Loss:5.8376\tTriplet Loss:0.4393\tStatic Loss:0.8375\n",
      "\n",
      "\tEpoch:109\tTrain Loss:0.1717\tRecon Loss:1.8503\tTriplet Loss:0.0890\tStatic Loss:0.1632\t\n",
      "Val Loss:0.2688\tRecon Loss:1.9010\tTriplet Loss:0.1284\tStatic Loss:0.2665\n",
      "\n",
      "\tTime:57.0437\n",
      "\n",
      "Test Loss:0.8321\tRecon Loss:5.7079\tTriplet Loss:0.4336\tStatic Loss:0.8231\n",
      "\n",
      "\tEpoch:110\tTrain Loss:0.1709\tRecon Loss:1.8448\tTriplet Loss:0.0873\tStatic Loss:0.1625\t\n",
      "Val Loss:0.2704\tRecon Loss:1.9167\tTriplet Loss:0.1275\tStatic Loss:0.2683\n",
      "\n",
      "\tTime:56.3827\n",
      "\n",
      "Test Loss:0.8570\tRecon Loss:5.7194\tTriplet Loss:0.4232\tStatic Loss:0.8517\n",
      "\n",
      "\tEpoch:111\tTrain Loss:0.1729\tRecon Loss:1.8441\tTriplet Loss:0.0862\tStatic Loss:0.1649\t\n",
      "Val Loss:0.2708\tRecon Loss:1.9166\tTriplet Loss:0.1419\tStatic Loss:0.2672\n",
      "\n",
      "\tTime:58.0257\n",
      "\n",
      "Test Loss:0.8389\tRecon Loss:5.7128\tTriplet Loss:0.4476\tStatic Loss:0.8293\n",
      "\n",
      "\tEpoch:112\tTrain Loss:0.1711\tRecon Loss:1.8507\tTriplet Loss:0.0895\tStatic Loss:0.1625\t\n",
      "Val Loss:0.2681\tRecon Loss:1.9417\tTriplet Loss:0.1323\tStatic Loss:0.2649\n",
      "\n",
      "\tTime:57.9125\n",
      "\n",
      "Test Loss:0.8541\tRecon Loss:5.7252\tTriplet Loss:0.4604\tStatic Loss:0.8447\n",
      "\n",
      "\tEpoch:113\tTrain Loss:0.1700\tRecon Loss:1.8428\tTriplet Loss:0.0806\tStatic Loss:0.1623\t\n",
      "Val Loss:0.2784\tRecon Loss:1.9104\tTriplet Loss:0.1290\tStatic Loss:0.2770\n",
      "\n",
      "\tTime:58.1298\n",
      "\n",
      "Test Loss:0.8477\tRecon Loss:5.7738\tTriplet Loss:0.4709\tStatic Loss:0.8361\n",
      "\n",
      "\tEpoch:114\tTrain Loss:0.1691\tRecon Loss:1.8384\tTriplet Loss:0.0874\tStatic Loss:0.1606\t\n",
      "Val Loss:0.2686\tRecon Loss:1.9042\tTriplet Loss:0.1235\tStatic Loss:0.2667\n",
      "\n",
      "\tTime:56.6277\n",
      "\n",
      "Test Loss:0.8350\tRecon Loss:5.7318\tTriplet Loss:0.4407\tStatic Loss:0.8254\n",
      "\n",
      "\tEpoch:115\tTrain Loss:0.1698\tRecon Loss:1.8494\tTriplet Loss:0.0871\tStatic Loss:0.1613\t\n",
      "Val Loss:0.2706\tRecon Loss:1.9390\tTriplet Loss:0.1317\tStatic Loss:0.2678\n",
      "\n",
      "\tTime:58.8278\n",
      "\n",
      "Test Loss:0.8409\tRecon Loss:5.7566\tTriplet Loss:0.4401\tStatic Loss:0.8318\n",
      "\n",
      "\tEpoch:116\tTrain Loss:0.1711\tRecon Loss:1.8556\tTriplet Loss:0.0907\tStatic Loss:0.1623\t\n",
      "Val Loss:0.2779\tRecon Loss:1.9269\tTriplet Loss:0.1242\tStatic Loss:0.2768\n",
      "\n",
      "\tTime:57.9937\n",
      "\n",
      "Test Loss:0.8712\tRecon Loss:5.7607\tTriplet Loss:0.4273\tStatic Loss:0.8667\n",
      "\n",
      "\tEpoch:117\tTrain Loss:0.1710\tRecon Loss:1.8396\tTriplet Loss:0.0892\tStatic Loss:0.1625\t\n",
      "Val Loss:0.2692\tRecon Loss:1.9386\tTriplet Loss:0.1276\tStatic Loss:0.2667\n",
      "\n",
      "\tTime:57.0693\n",
      "\n",
      "Test Loss:0.8439\tRecon Loss:5.8558\tTriplet Loss:0.4269\tStatic Loss:0.8355\n",
      "\n",
      "\tEpoch:118\tTrain Loss:0.1742\tRecon Loss:1.8488\tTriplet Loss:0.0934\tStatic Loss:0.1656\t\n",
      "Val Loss:0.2971\tRecon Loss:1.9575\tTriplet Loss:0.1454\tStatic Loss:0.2957\n",
      "\n",
      "\tTime:56.8162\n",
      "\n",
      "Test Loss:0.8914\tRecon Loss:6.0490\tTriplet Loss:0.4539\tStatic Loss:0.8836\n",
      "\n",
      "\tEpoch:119\tTrain Loss:0.1778\tRecon Loss:1.8468\tTriplet Loss:0.0936\tStatic Loss:0.1695\t\n",
      "Val Loss:0.2686\tRecon Loss:1.9251\tTriplet Loss:0.1276\tStatic Loss:0.2662\n",
      "\n",
      "\tTime:59.4860\n",
      "\n",
      "Test Loss:0.8300\tRecon Loss:5.8176\tTriplet Loss:0.4573\tStatic Loss:0.8174\n",
      "\n",
      "\tEpoch:120\tTrain Loss:0.1712\tRecon Loss:1.8452\tTriplet Loss:0.0896\tStatic Loss:0.1626\t\n",
      "Val Loss:0.2727\tRecon Loss:1.9195\tTriplet Loss:0.1220\tStatic Loss:0.2713\n",
      "\n",
      "\tTime:57.9389\n",
      "\n",
      "Test Loss:0.8575\tRecon Loss:5.7581\tTriplet Loss:0.4088\tStatic Loss:0.8533\n",
      "\n",
      "\tEpoch:121\tTrain Loss:0.1694\tRecon Loss:1.8404\tTriplet Loss:0.0874\tStatic Loss:0.1609\t\n",
      "Val Loss:0.2716\tRecon Loss:1.9122\tTriplet Loss:0.1294\tStatic Loss:0.2695\n",
      "\n",
      "\tTime:58.6376\n",
      "\n",
      "Test Loss:0.8440\tRecon Loss:5.7468\tTriplet Loss:0.4268\tStatic Loss:0.8367\n",
      "\n",
      "\tEpoch:122\tTrain Loss:0.1724\tRecon Loss:1.9474\tTriplet Loss:0.0906\tStatic Loss:0.1628\t\n",
      "Val Loss:0.2736\tRecon Loss:2.0261\tTriplet Loss:0.1273\tStatic Loss:0.2708\n",
      "\n",
      "\tTime:58.5433\n",
      "\n",
      "Test Loss:0.8440\tRecon Loss:5.8846\tTriplet Loss:0.4458\tStatic Loss:0.8334\n",
      "\n",
      "\tEpoch:123\tTrain Loss:0.1703\tRecon Loss:1.8809\tTriplet Loss:0.0904\tStatic Loss:0.1612\t\n",
      "Val Loss:0.2770\tRecon Loss:1.9826\tTriplet Loss:0.1354\tStatic Loss:0.2741\n",
      "\n",
      "\tTime:60.0469\n",
      "\n",
      "Test Loss:0.8383\tRecon Loss:5.8852\tTriplet Loss:0.4387\tStatic Loss:0.8278\n",
      "\n",
      "\tEpoch:124\tTrain Loss:0.1693\tRecon Loss:1.8844\tTriplet Loss:0.0864\tStatic Loss:0.1605\t\n",
      "Val Loss:0.2814\tRecon Loss:1.9449\tTriplet Loss:0.1343\tStatic Loss:0.2794\n",
      "\n",
      "\tTime:57.9044\n",
      "\n",
      "Test Loss:0.8492\tRecon Loss:5.8026\tTriplet Loss:0.4577\tStatic Loss:0.8388\n",
      "\n",
      "\tEpoch:125\tTrain Loss:0.1899\tRecon Loss:1.8600\tTriplet Loss:0.0997\tStatic Loss:0.1822\t\n",
      "Val Loss:0.2837\tRecon Loss:1.9428\tTriplet Loss:0.1261\tStatic Loss:0.2829\n",
      "\n",
      "\tTime:57.2215\n",
      "\n",
      "Test Loss:0.8556\tRecon Loss:5.8401\tTriplet Loss:0.4321\tStatic Loss:0.8481\n",
      "\n",
      "\tEpoch:126\tTrain Loss:0.1778\tRecon Loss:1.8537\tTriplet Loss:0.0926\tStatic Loss:0.1695\t\n",
      "Val Loss:0.2739\tRecon Loss:1.9233\tTriplet Loss:0.1252\tStatic Loss:0.2722\n",
      "\n",
      "\tTime:60.4537\n",
      "\n",
      "Test Loss:0.8644\tRecon Loss:5.8311\tTriplet Loss:0.4321\tStatic Loss:0.8580\n",
      "\n",
      "\tEpoch:127\tTrain Loss:0.1727\tRecon Loss:1.8441\tTriplet Loss:0.0845\tStatic Loss:0.1648\t\n",
      "Val Loss:0.2709\tRecon Loss:1.9267\tTriplet Loss:0.1328\tStatic Loss:0.2682\n",
      "\n",
      "\tTime:58.9756\n",
      "\n",
      "Test Loss:0.8544\tRecon Loss:5.7382\tTriplet Loss:0.4355\tStatic Loss:0.8474\n",
      "\n",
      "\tEpoch:128\tTrain Loss:0.1694\tRecon Loss:1.8407\tTriplet Loss:0.0868\tStatic Loss:0.1610\t\n",
      "Val Loss:0.2676\tRecon Loss:1.9573\tTriplet Loss:0.1262\tStatic Loss:0.2648\n",
      "\n",
      "\tTime:58.6940\n",
      "\n",
      "Test Loss:0.8562\tRecon Loss:5.8385\tTriplet Loss:0.4494\tStatic Loss:0.8470\n",
      "\n",
      "\tEpoch:129\tTrain Loss:0.1774\tRecon Loss:1.8839\tTriplet Loss:0.0960\tStatic Loss:0.1684\t\n",
      "Val Loss:0.2785\tRecon Loss:2.0519\tTriplet Loss:0.1343\tStatic Loss:0.2752\n",
      "\n",
      "\tTime:57.6343\n",
      "\n",
      "Test Loss:0.8752\tRecon Loss:5.9231\tTriplet Loss:0.4716\tStatic Loss:0.8651\n",
      "\n",
      "\tEpoch:130\tTrain Loss:0.1719\tRecon Loss:1.8561\tTriplet Loss:0.0919\tStatic Loss:0.1630\t\n",
      "Val Loss:0.2693\tRecon Loss:1.9959\tTriplet Loss:0.1131\tStatic Loss:0.2676\n",
      "\n",
      "\tTime:57.3942\n",
      "\n",
      "Test Loss:0.8347\tRecon Loss:6.0593\tTriplet Loss:0.4592\tStatic Loss:0.8200\n",
      "\n",
      "\tEpoch:131\tTrain Loss:0.1679\tRecon Loss:1.8442\tTriplet Loss:0.0846\tStatic Loss:0.1595\t\n",
      "Val Loss:0.2727\tRecon Loss:1.9921\tTriplet Loss:0.1325\tStatic Loss:0.2695\n",
      "\n",
      "\tTime:56.8084\n",
      "\n",
      "Test Loss:0.8721\tRecon Loss:5.9713\tTriplet Loss:0.4376\tStatic Loss:0.8645\n",
      "\n",
      "\tEpoch:132\tTrain Loss:0.1709\tRecon Loss:1.8578\tTriplet Loss:0.0895\tStatic Loss:0.1621\t\n",
      "Val Loss:0.2662\tRecon Loss:1.9366\tTriplet Loss:0.1275\tStatic Loss:0.2634\n",
      "\n",
      "\tTime:59.2354\n",
      "\n",
      "Test Loss:0.8552\tRecon Loss:5.8626\tTriplet Loss:0.4401\tStatic Loss:0.8466\n",
      "\n",
      "\tEpoch:133\tTrain Loss:0.1682\tRecon Loss:1.8368\tTriplet Loss:0.0916\tStatic Loss:0.1591\t\n",
      "Val Loss:0.2673\tRecon Loss:1.9233\tTriplet Loss:0.1344\tStatic Loss:0.2640\n",
      "\n",
      "\tTime:58.5939\n",
      "\n",
      "Test Loss:0.8271\tRecon Loss:5.8887\tTriplet Loss:0.4407\tStatic Loss:0.8152\n",
      "\n",
      "\tEpoch:134\tTrain Loss:0.1698\tRecon Loss:1.8498\tTriplet Loss:0.0874\tStatic Loss:0.1612\t\n",
      "Val Loss:0.2669\tRecon Loss:1.9296\tTriplet Loss:0.1197\tStatic Loss:0.2650\n",
      "\n",
      "\tTime:58.5251\n",
      "\n",
      "Test Loss:0.8304\tRecon Loss:5.8325\tTriplet Loss:0.4361\tStatic Loss:0.8198\n",
      "\n",
      "\tEpoch:135\tTrain Loss:0.1683\tRecon Loss:1.8409\tTriplet Loss:0.0883\tStatic Loss:0.1596\t\n",
      "Val Loss:0.2728\tRecon Loss:1.9200\tTriplet Loss:0.1316\tStatic Loss:0.2704\n",
      "\n",
      "\tTime:57.5914\n",
      "\n",
      "Test Loss:0.8464\tRecon Loss:5.7363\tTriplet Loss:0.4299\tStatic Loss:0.8391\n",
      "\n",
      "\tEpoch:136\tTrain Loss:0.1706\tRecon Loss:1.8373\tTriplet Loss:0.0865\tStatic Loss:0.1624\t\n",
      "Val Loss:0.2673\tRecon Loss:1.9145\tTriplet Loss:0.1268\tStatic Loss:0.2648\n",
      "\n",
      "\tTime:57.8547\n",
      "\n",
      "Test Loss:0.8420\tRecon Loss:5.7764\tTriplet Loss:0.4210\tStatic Loss:0.8347\n",
      "\n",
      "\tEpoch:137\tTrain Loss:0.1677\tRecon Loss:1.8357\tTriplet Loss:0.0896\tStatic Loss:0.1588\t\n",
      "Val Loss:0.2692\tRecon Loss:1.9214\tTriplet Loss:0.1371\tStatic Loss:0.2659\n",
      "\n",
      "\tTime:58.1814\n",
      "\n",
      "Test Loss:0.8459\tRecon Loss:5.7872\tTriplet Loss:0.4298\tStatic Loss:0.8381\n",
      "\n",
      "\tEpoch:138\tTrain Loss:0.1683\tRecon Loss:1.8367\tTriplet Loss:0.0878\tStatic Loss:0.1597\t\n",
      "Val Loss:0.2671\tRecon Loss:1.9069\tTriplet Loss:0.1208\tStatic Loss:0.2654\n",
      "\n",
      "\tTime:58.0416\n",
      "\n",
      "Test Loss:0.8478\tRecon Loss:5.7696\tTriplet Loss:0.4268\tStatic Loss:0.8407\n",
      "\n",
      "\tEpoch:139\tTrain Loss:0.1696\tRecon Loss:1.8601\tTriplet Loss:0.0863\tStatic Loss:0.1610\t\n",
      "Val Loss:0.2698\tRecon Loss:1.9174\tTriplet Loss:0.1302\tStatic Loss:0.2673\n",
      "\n",
      "\tTime:56.4167\n",
      "\n",
      "Test Loss:0.8543\tRecon Loss:5.7328\tTriplet Loss:0.4464\tStatic Loss:0.8463\n",
      "\n",
      "\tEpoch:140\tTrain Loss:0.1664\tRecon Loss:1.8400\tTriplet Loss:0.0858\tStatic Loss:0.1578\t\n",
      "Val Loss:0.2652\tRecon Loss:1.9491\tTriplet Loss:0.1108\tStatic Loss:0.2638\n",
      "\n",
      "\tTime:60.4255\n",
      "\n",
      "Test Loss:0.8592\tRecon Loss:6.2340\tTriplet Loss:0.4394\tStatic Loss:0.8474\n",
      "\n",
      "\tEpoch:141\tTrain Loss:0.1674\tRecon Loss:1.8461\tTriplet Loss:0.0878\tStatic Loss:0.1585\t\n",
      "Val Loss:0.2656\tRecon Loss:1.9071\tTriplet Loss:0.1341\tStatic Loss:0.2624\n",
      "\n",
      "\tTime:59.7517\n",
      "\n",
      "Test Loss:0.8244\tRecon Loss:5.7161\tTriplet Loss:0.4073\tStatic Loss:0.8172\n",
      "\n",
      "\tEpoch:142\tTrain Loss:0.1659\tRecon Loss:1.8319\tTriplet Loss:0.0886\tStatic Loss:0.1569\t\n",
      "Val Loss:0.2712\tRecon Loss:1.9005\tTriplet Loss:0.1294\tStatic Loss:0.2691\n",
      "\n",
      "\tTime:58.2383\n",
      "\n",
      "Test Loss:0.8517\tRecon Loss:5.7908\tTriplet Loss:0.4261\tStatic Loss:0.8449\n",
      "\n",
      "\tEpoch:143\tTrain Loss:0.1674\tRecon Loss:1.8388\tTriplet Loss:0.0864\tStatic Loss:0.1588\t\n",
      "Val Loss:0.2721\tRecon Loss:1.9007\tTriplet Loss:0.1207\tStatic Loss:0.2710\n",
      "\n",
      "\tTime:58.3339\n",
      "\n",
      "Test Loss:0.8459\tRecon Loss:5.7197\tTriplet Loss:0.4260\tStatic Loss:0.8391\n",
      "\n",
      "\tEpoch:144\tTrain Loss:0.1833\tRecon Loss:1.8603\tTriplet Loss:0.0924\tStatic Loss:0.1756\t\n",
      "Val Loss:0.2711\tRecon Loss:1.9752\tTriplet Loss:0.1241\tStatic Loss:0.2688\n",
      "\n",
      "\tTime:56.4440\n",
      "\n",
      "Test Loss:0.8554\tRecon Loss:6.0738\tTriplet Loss:0.4171\tStatic Loss:0.8470\n",
      "\n",
      "\tEpoch:145\tTrain Loss:0.1783\tRecon Loss:1.8437\tTriplet Loss:0.0882\tStatic Loss:0.1707\t\n",
      "Val Loss:0.2656\tRecon Loss:1.9075\tTriplet Loss:0.1245\tStatic Loss:0.2632\n",
      "\n",
      "\tTime:58.5810\n",
      "\n",
      "Test Loss:0.8496\tRecon Loss:5.7917\tTriplet Loss:0.4607\tStatic Loss:0.8391\n",
      "\n",
      "\tEpoch:146\tTrain Loss:0.1762\tRecon Loss:1.8458\tTriplet Loss:0.0933\tStatic Loss:0.1678\t\n",
      "Val Loss:0.2679\tRecon Loss:1.9245\tTriplet Loss:0.1263\tStatic Loss:0.2655\n",
      "\n",
      "\tTime:57.2546\n",
      "\n",
      "Test Loss:0.8385\tRecon Loss:5.7653\tTriplet Loss:0.4185\tStatic Loss:0.8312\n",
      "\n",
      "\tEpoch:147\tTrain Loss:0.1677\tRecon Loss:1.8336\tTriplet Loss:0.0857\tStatic Loss:0.1593\t\n",
      "Val Loss:0.2674\tRecon Loss:1.9020\tTriplet Loss:0.1338\tStatic Loss:0.2644\n",
      "\n",
      "\tTime:58.4673\n",
      "\n",
      "Test Loss:0.8372\tRecon Loss:5.7399\tTriplet Loss:0.4088\tStatic Loss:0.8310\n",
      "\n",
      "\tEpoch:148\tTrain Loss:0.1714\tRecon Loss:1.8428\tTriplet Loss:0.0869\tStatic Loss:0.1631\t\n",
      "Val Loss:0.2682\tRecon Loss:1.9048\tTriplet Loss:0.1311\tStatic Loss:0.2656\n",
      "\n",
      "\tTime:59.0426\n",
      "\n",
      "Test Loss:0.8272\tRecon Loss:5.7825\tTriplet Loss:0.4058\tStatic Loss:0.8198\n",
      "\n",
      "\tEpoch:149\tTrain Loss:0.1760\tRecon Loss:1.8565\tTriplet Loss:0.0904\tStatic Loss:0.1677\t\n",
      "Val Loss:0.2821\tRecon Loss:2.3113\tTriplet Loss:0.1358\tStatic Loss:0.2764\n",
      "\n",
      "\tTime:58.4300\n",
      "\n",
      "Test Loss:0.9133\tRecon Loss:7.1164\tTriplet Loss:0.4625\tStatic Loss:0.8963\n",
      "\n",
      "\tEpoch:150\tTrain Loss:0.1729\tRecon Loss:1.9225\tTriplet Loss:0.0871\tStatic Loss:0.1640\t\n",
      "Val Loss:0.2667\tRecon Loss:1.9450\tTriplet Loss:0.1231\tStatic Loss:0.2642\n",
      "\n",
      "\tTime:58.3168\n",
      "\n",
      "Test Loss:0.8401\tRecon Loss:5.8748\tTriplet Loss:0.3972\tStatic Loss:0.8340\n",
      "\n",
      "\tEpoch:151\tTrain Loss:0.1709\tRecon Loss:1.8524\tTriplet Loss:0.0881\tStatic Loss:0.1624\t\n",
      "Val Loss:0.2639\tRecon Loss:1.9237\tTriplet Loss:0.1190\tStatic Loss:0.2618\n",
      "\n",
      "\tTime:56.8478\n",
      "\n",
      "Test Loss:0.8461\tRecon Loss:5.8535\tTriplet Loss:0.4403\tStatic Loss:0.8366\n",
      "\n",
      "\tEpoch:152\tTrain Loss:0.1671\tRecon Loss:1.8366\tTriplet Loss:0.0889\tStatic Loss:0.1583\t\n",
      "Val Loss:0.2706\tRecon Loss:1.9153\tTriplet Loss:0.1245\tStatic Loss:0.2688\n",
      "\n",
      "\tTime:58.2250\n",
      "\n",
      "Test Loss:0.8557\tRecon Loss:5.7291\tTriplet Loss:0.4544\tStatic Loss:0.8471\n",
      "\n",
      "\tEpoch:153\tTrain Loss:0.1707\tRecon Loss:1.8453\tTriplet Loss:0.0860\tStatic Loss:0.1625\t\n",
      "Val Loss:0.2895\tRecon Loss:1.9991\tTriplet Loss:0.1496\tStatic Loss:0.2864\n",
      "\n",
      "\tTime:58.1581\n",
      "\n",
      "Test Loss:0.8784\tRecon Loss:5.9316\tTriplet Loss:0.4314\tStatic Loss:0.8726\n",
      "\n",
      "\tEpoch:154\tTrain Loss:0.1892\tRecon Loss:1.8592\tTriplet Loss:0.0974\tStatic Loss:0.1817\t\n",
      "Val Loss:0.2564\tRecon Loss:1.9430\tTriplet Loss:0.1211\tStatic Loss:0.2530\n",
      "\n",
      "\tTime:58.2946\n",
      "\n",
      "Test Loss:0.8141\tRecon Loss:5.7908\tTriplet Loss:0.4144\tStatic Loss:0.8043\n",
      "\n",
      "\tEpoch:155\tTrain Loss:0.1725\tRecon Loss:1.8347\tTriplet Loss:0.0876\tStatic Loss:0.1644\t\n",
      "Val Loss:0.2613\tRecon Loss:1.9098\tTriplet Loss:0.1307\tStatic Loss:0.2579\n",
      "\n",
      "\tTime:58.6315\n",
      "\n",
      "Test Loss:0.8239\tRecon Loss:5.7452\tTriplet Loss:0.4031\tStatic Loss:0.8168\n",
      "\n",
      "\tEpoch:156\tTrain Loss:0.1676\tRecon Loss:1.8348\tTriplet Loss:0.0873\tStatic Loss:0.1589\t\n",
      "Val Loss:0.2665\tRecon Loss:1.9308\tTriplet Loss:0.1246\tStatic Loss:0.2641\n",
      "\n",
      "\tTime:59.1000\n",
      "\n",
      "Test Loss:0.8580\tRecon Loss:5.7476\tTriplet Loss:0.4362\tStatic Loss:0.8513\n",
      "\n",
      "\tEpoch:157\tTrain Loss:0.1665\tRecon Loss:1.8444\tTriplet Loss:0.0866\tStatic Loss:0.1577\t\n",
      "Val Loss:0.2645\tRecon Loss:1.9227\tTriplet Loss:0.1354\tStatic Loss:0.2608\n",
      "\n",
      "\tTime:59.3942\n",
      "\n",
      "Test Loss:0.8262\tRecon Loss:5.8150\tTriplet Loss:0.4174\tStatic Loss:0.8172\n",
      "\n",
      "\tEpoch:158\tTrain Loss:0.1650\tRecon Loss:1.8416\tTriplet Loss:0.0858\tStatic Loss:0.1562\t\n",
      "Val Loss:0.2704\tRecon Loss:1.9284\tTriplet Loss:0.1165\tStatic Loss:0.2692\n",
      "\n",
      "\tTime:58.2878\n",
      "\n",
      "Test Loss:0.8377\tRecon Loss:5.7282\tTriplet Loss:0.4242\tStatic Loss:0.8301\n",
      "\n",
      "\tEpoch:159\tTrain Loss:0.1671\tRecon Loss:1.8367\tTriplet Loss:0.0927\tStatic Loss:0.1579\t\n",
      "Val Loss:0.2718\tRecon Loss:1.8942\tTriplet Loss:0.1350\tStatic Loss:0.2693\n",
      "\n",
      "\tTime:58.5539\n",
      "\n",
      "Test Loss:0.8498\tRecon Loss:5.7003\tTriplet Loss:0.4252\tStatic Loss:0.8438\n",
      "\n",
      "\tEpoch:160\tTrain Loss:0.1671\tRecon Loss:1.8376\tTriplet Loss:0.0907\tStatic Loss:0.1580\t\n",
      "Val Loss:0.2631\tRecon Loss:1.9285\tTriplet Loss:0.1219\tStatic Loss:0.2606\n",
      "\n",
      "\tTime:59.4541\n",
      "\n",
      "Test Loss:0.8488\tRecon Loss:5.7387\tTriplet Loss:0.4224\tStatic Loss:0.8425\n",
      "\n",
      "\tEpoch:161\tTrain Loss:0.1648\tRecon Loss:1.8449\tTriplet Loss:0.0887\tStatic Loss:0.1556\t\n",
      "Val Loss:0.2735\tRecon Loss:1.9530\tTriplet Loss:0.1235\tStatic Loss:0.2717\n",
      "\n",
      "\tTime:59.9667\n",
      "\n",
      "Test Loss:0.8575\tRecon Loss:5.8242\tTriplet Loss:0.4125\tStatic Loss:0.8523\n",
      "\n",
      "\tEpoch:162\tTrain Loss:0.1672\tRecon Loss:1.8586\tTriplet Loss:0.0854\tStatic Loss:0.1585\t\n",
      "Val Loss:0.2697\tRecon Loss:1.9086\tTriplet Loss:0.1377\tStatic Loss:0.2665\n",
      "\n",
      "\tTime:58.9550\n",
      "\n",
      "Test Loss:0.8266\tRecon Loss:5.7850\tTriplet Loss:0.4093\tStatic Loss:0.8188\n",
      "\n",
      "\tEpoch:163\tTrain Loss:0.1696\tRecon Loss:1.8864\tTriplet Loss:0.0884\tStatic Loss:0.1606\t\n",
      "Val Loss:0.2681\tRecon Loss:1.9132\tTriplet Loss:0.1242\tStatic Loss:0.2661\n",
      "\n",
      "\tTime:58.5927\n",
      "\n",
      "Test Loss:0.8532\tRecon Loss:5.7897\tTriplet Loss:0.4492\tStatic Loss:0.8442\n",
      "\n",
      "\tEpoch:164\tTrain Loss:0.1741\tRecon Loss:1.8720\tTriplet Loss:0.0926\tStatic Loss:0.1653\t\n",
      "Val Loss:0.2725\tRecon Loss:1.9521\tTriplet Loss:0.1259\tStatic Loss:0.2704\n",
      "\n",
      "\tTime:57.8965\n",
      "\n",
      "Test Loss:0.8259\tRecon Loss:5.9456\tTriplet Loss:0.4153\tStatic Loss:0.8158\n",
      "\n",
      "\tEpoch:165\tTrain Loss:0.1741\tRecon Loss:1.8430\tTriplet Loss:0.0922\tStatic Loss:0.1656\t\n",
      "Val Loss:0.2594\tRecon Loss:1.9017\tTriplet Loss:0.1164\tStatic Loss:0.2573\n",
      "\n",
      "\tTime:59.9803\n",
      "\n",
      "Test Loss:0.8244\tRecon Loss:5.7395\tTriplet Loss:0.4107\tStatic Loss:0.8167\n",
      "\n",
      "\tEpoch:166\tTrain Loss:0.1667\tRecon Loss:1.8451\tTriplet Loss:0.0861\tStatic Loss:0.1579\t\n",
      "Val Loss:0.3013\tRecon Loss:1.9847\tTriplet Loss:0.1371\tStatic Loss:0.3009\n",
      "\n",
      "\tTime:60.5022\n",
      "\n",
      "Test Loss:0.9656\tRecon Loss:5.8916\tTriplet Loss:0.4488\tStatic Loss:0.9680\n",
      "\n",
      "\tEpoch:167\tTrain Loss:0.1787\tRecon Loss:1.8506\tTriplet Loss:0.0879\tStatic Loss:0.1710\t\n",
      "Val Loss:0.2650\tRecon Loss:1.9026\tTriplet Loss:0.1376\tStatic Loss:0.2614\n",
      "\n",
      "\tTime:59.7277\n",
      "\n",
      "Test Loss:0.8112\tRecon Loss:5.7497\tTriplet Loss:0.4114\tStatic Loss:0.8018\n",
      "\n",
      "\tEpoch:168\tTrain Loss:0.1675\tRecon Loss:1.8304\tTriplet Loss:0.0883\tStatic Loss:0.1588\t\n",
      "Val Loss:0.2690\tRecon Loss:1.9214\tTriplet Loss:0.1288\tStatic Loss:0.2665\n",
      "\n",
      "\tTime:58.7032\n",
      "\n",
      "Test Loss:0.8477\tRecon Loss:5.7889\tTriplet Loss:0.4388\tStatic Loss:0.8392\n",
      "\n",
      "\tEpoch:169\tTrain Loss:0.1650\tRecon Loss:1.8303\tTriplet Loss:0.0856\tStatic Loss:0.1563\t\n",
      "Val Loss:0.2676\tRecon Loss:1.8990\tTriplet Loss:0.1324\tStatic Loss:0.2648\n",
      "\n",
      "\tTime:60.1507\n",
      "\n",
      "Test Loss:0.8522\tRecon Loss:5.7587\tTriplet Loss:0.4166\tStatic Loss:0.8467\n",
      "\n",
      "\tEpoch:170\tTrain Loss:0.1662\tRecon Loss:1.8278\tTriplet Loss:0.0854\tStatic Loss:0.1577\t\n",
      "Val Loss:0.2650\tRecon Loss:1.8983\tTriplet Loss:0.1108\tStatic Loss:0.2641\n",
      "\n",
      "\tTime:61.7500\n",
      "\n",
      "Test Loss:0.8334\tRecon Loss:5.7550\tTriplet Loss:0.4327\tStatic Loss:0.8243\n",
      "\n",
      "\tEpoch:171\tTrain Loss:0.1655\tRecon Loss:1.8358\tTriplet Loss:0.0876\tStatic Loss:0.1566\t\n",
      "Val Loss:0.2689\tRecon Loss:1.9160\tTriplet Loss:0.1252\tStatic Loss:0.2668\n",
      "\n",
      "\tTime:61.4467\n",
      "\n",
      "Test Loss:0.8691\tRecon Loss:5.8296\tTriplet Loss:0.4215\tStatic Loss:0.8642\n",
      "\n",
      "\tEpoch:172\tTrain Loss:0.1650\tRecon Loss:1.8274\tTriplet Loss:0.0815\tStatic Loss:0.1567\t\n",
      "Val Loss:0.2577\tRecon Loss:1.9026\tTriplet Loss:0.1328\tStatic Loss:0.2538\n",
      "\n",
      "\tTime:61.7473\n",
      "\n",
      "Test Loss:0.8429\tRecon Loss:5.7549\tTriplet Loss:0.3784\tStatic Loss:0.8402\n",
      "\n",
      "\tEpoch:173\tTrain Loss:0.1669\tRecon Loss:1.8479\tTriplet Loss:0.0888\tStatic Loss:0.1579\t\n",
      "Val Loss:0.2645\tRecon Loss:1.9205\tTriplet Loss:0.1261\tStatic Loss:0.2618\n",
      "\n",
      "\tTime:61.3065\n",
      "\n",
      "Test Loss:0.8406\tRecon Loss:5.7837\tTriplet Loss:0.4235\tStatic Loss:0.8328\n",
      "\n",
      "\tEpoch:174\tTrain Loss:0.1653\tRecon Loss:1.8308\tTriplet Loss:0.0892\tStatic Loss:0.1562\t\n",
      "Val Loss:0.2642\tRecon Loss:1.9033\tTriplet Loss:0.1116\tStatic Loss:0.2631\n",
      "\n",
      "\tTime:59.9526\n",
      "\n",
      "Test Loss:0.8124\tRecon Loss:5.7651\tTriplet Loss:0.4139\tStatic Loss:0.8027\n",
      "\n",
      "\tEpoch:175\tTrain Loss:0.1671\tRecon Loss:1.8336\tTriplet Loss:0.0875\tStatic Loss:0.1584\t\n",
      "Val Loss:0.2741\tRecon Loss:1.9144\tTriplet Loss:0.1308\tStatic Loss:0.2720\n",
      "\n",
      "\tTime:60.3344\n",
      "\n",
      "Test Loss:0.8756\tRecon Loss:5.7626\tTriplet Loss:0.4452\tStatic Loss:0.8697\n",
      "\n",
      "\tEpoch:176\tTrain Loss:0.1650\tRecon Loss:1.8365\tTriplet Loss:0.0844\tStatic Loss:0.1564\t\n",
      "Val Loss:0.2679\tRecon Loss:1.9371\tTriplet Loss:0.1282\tStatic Loss:0.2652\n",
      "\n",
      "\tTime:59.8732\n",
      "\n",
      "Test Loss:0.8352\tRecon Loss:5.7893\tTriplet Loss:0.4250\tStatic Loss:0.8267\n",
      "\n",
      "\tEpoch:177\tTrain Loss:0.1674\tRecon Loss:1.8335\tTriplet Loss:0.0887\tStatic Loss:0.1586\t\n",
      "Val Loss:0.2680\tRecon Loss:1.9268\tTriplet Loss:0.1337\tStatic Loss:0.2648\n",
      "\n",
      "\tTime:59.4825\n",
      "\n",
      "Test Loss:0.8688\tRecon Loss:5.8478\tTriplet Loss:0.4309\tStatic Loss:0.8628\n",
      "\n",
      "\tEpoch:178\tTrain Loss:0.1759\tRecon Loss:1.8373\tTriplet Loss:0.0927\tStatic Loss:0.1676\t\n",
      "Val Loss:0.2622\tRecon Loss:1.9197\tTriplet Loss:0.1255\tStatic Loss:0.2593\n",
      "\n",
      "\tTime:58.9800\n",
      "\n",
      "Test Loss:0.8565\tRecon Loss:5.8749\tTriplet Loss:0.3966\tStatic Loss:0.8523\n",
      "\n",
      "\tEpoch:179\tTrain Loss:0.1662\tRecon Loss:1.8269\tTriplet Loss:0.0851\tStatic Loss:0.1577\t\n",
      "Val Loss:0.2637\tRecon Loss:1.8841\tTriplet Loss:0.1281\tStatic Loss:0.2610\n",
      "\n",
      "\tTime:58.8713\n",
      "\n",
      "Test Loss:0.8427\tRecon Loss:5.7185\tTriplet Loss:0.4004\tStatic Loss:0.8381\n",
      "\n",
      "\tEpoch:180\tTrain Loss:0.1630\tRecon Loss:1.8261\tTriplet Loss:0.0859\tStatic Loss:0.1541\t\n",
      "Val Loss:0.2645\tRecon Loss:1.8912\tTriplet Loss:0.1294\tStatic Loss:0.2618\n",
      "\n",
      "\tTime:59.4465\n",
      "\n",
      "Test Loss:0.8511\tRecon Loss:5.7774\tTriplet Loss:0.4403\tStatic Loss:0.8430\n",
      "\n",
      "\tEpoch:181\tTrain Loss:0.1635\tRecon Loss:1.8209\tTriplet Loss:0.0840\tStatic Loss:0.1548\t\n",
      "Val Loss:0.2695\tRecon Loss:1.9028\tTriplet Loss:0.1162\tStatic Loss:0.2685\n",
      "\n",
      "\tTime:58.4471\n",
      "\n",
      "Test Loss:0.8429\tRecon Loss:5.7928\tTriplet Loss:0.4197\tStatic Loss:0.8358\n",
      "\n",
      "\tEpoch:182\tTrain Loss:0.1624\tRecon Loss:1.8321\tTriplet Loss:0.0867\tStatic Loss:0.1533\t\n",
      "Val Loss:0.2688\tRecon Loss:1.9836\tTriplet Loss:0.1334\tStatic Loss:0.2652\n",
      "\n",
      "\tTime:59.5375\n",
      "\n",
      "Test Loss:0.8471\tRecon Loss:6.2658\tTriplet Loss:0.4328\tStatic Loss:0.8343\n",
      "\n",
      "\tEpoch:183\tTrain Loss:0.1658\tRecon Loss:1.9205\tTriplet Loss:0.0862\tStatic Loss:0.1562\t\n",
      "Val Loss:0.2657\tRecon Loss:1.9523\tTriplet Loss:0.1285\tStatic Loss:0.2626\n",
      "\n",
      "\tTime:59.8707\n",
      "\n",
      "Test Loss:0.8406\tRecon Loss:5.8863\tTriplet Loss:0.4000\tStatic Loss:0.8342\n",
      "\n",
      "\tEpoch:184\tTrain Loss:0.1627\tRecon Loss:1.8464\tTriplet Loss:0.0869\tStatic Loss:0.1534\t\n",
      "Val Loss:0.2690\tRecon Loss:1.9128\tTriplet Loss:0.1310\tStatic Loss:0.2664\n",
      "\n",
      "\tTime:59.2965\n",
      "\n",
      "Test Loss:0.8431\tRecon Loss:5.8079\tTriplet Loss:0.4402\tStatic Loss:0.8338\n",
      "\n",
      "\tEpoch:185\tTrain Loss:0.1614\tRecon Loss:1.8349\tTriplet Loss:0.0857\tStatic Loss:0.1523\t\n",
      "Val Loss:0.2649\tRecon Loss:1.9209\tTriplet Loss:0.1261\tStatic Loss:0.2622\n",
      "\n",
      "\tTime:59.3963\n",
      "\n",
      "Test Loss:0.8323\tRecon Loss:5.8714\tTriplet Loss:0.4311\tStatic Loss:0.8220\n",
      "\n",
      "\tEpoch:186\tTrain Loss:0.1623\tRecon Loss:1.8368\tTriplet Loss:0.0850\tStatic Loss:0.1533\t\n",
      "Val Loss:0.2720\tRecon Loss:1.9472\tTriplet Loss:0.1378\tStatic Loss:0.2687\n",
      "\n",
      "\tTime:60.4481\n",
      "\n",
      "Test Loss:0.8453\tRecon Loss:5.8794\tTriplet Loss:0.4283\tStatic Loss:0.8367\n",
      "\n",
      "\tEpoch:187\tTrain Loss:0.1724\tRecon Loss:1.8554\tTriplet Loss:0.0842\tStatic Loss:0.1644\t\n",
      "Val Loss:0.2817\tRecon Loss:1.9257\tTriplet Loss:0.1415\tStatic Loss:0.2793\n",
      "\n",
      "\tTime:59.9065\n",
      "\n",
      "Test Loss:0.8707\tRecon Loss:5.9431\tTriplet Loss:0.4290\tStatic Loss:0.8642\n",
      "\n",
      "\tEpoch:188\tTrain Loss:0.1679\tRecon Loss:1.8341\tTriplet Loss:0.0862\tStatic Loss:0.1594\t\n",
      "Val Loss:0.2642\tRecon Loss:1.9033\tTriplet Loss:0.1075\tStatic Loss:0.2634\n",
      "\n",
      "\tTime:58.4855\n",
      "\n",
      "Test Loss:0.8658\tRecon Loss:5.7872\tTriplet Loss:0.4274\tStatic Loss:0.8604\n",
      "\n",
      "\tEpoch:189\tTrain Loss:0.1629\tRecon Loss:1.8388\tTriplet Loss:0.0853\tStatic Loss:0.1540\t\n",
      "Val Loss:0.2747\tRecon Loss:1.8983\tTriplet Loss:0.1283\tStatic Loss:0.2732\n",
      "\n",
      "\tTime:58.3344\n",
      "\n",
      "Test Loss:0.8693\tRecon Loss:5.7553\tTriplet Loss:0.4231\tStatic Loss:0.8651\n",
      "\n",
      "\tEpoch:190\tTrain Loss:0.1624\tRecon Loss:1.8354\tTriplet Loss:0.0830\tStatic Loss:0.1536\t\n",
      "Val Loss:0.2686\tRecon Loss:1.9134\tTriplet Loss:0.1197\tStatic Loss:0.2671\n",
      "\n",
      "\tTime:57.6034\n",
      "\n",
      "Test Loss:0.8651\tRecon Loss:5.7766\tTriplet Loss:0.4677\tStatic Loss:0.8557\n",
      "\n",
      "\tEpoch:191\tTrain Loss:0.1620\tRecon Loss:1.8279\tTriplet Loss:0.0814\tStatic Loss:0.1534\t\n",
      "Val Loss:0.2689\tRecon Loss:1.9240\tTriplet Loss:0.1294\tStatic Loss:0.2663\n",
      "\n",
      "\tTime:57.5705\n",
      "\n",
      "Test Loss:0.8382\tRecon Loss:5.8627\tTriplet Loss:0.4227\tStatic Loss:0.8295\n",
      "\n",
      "\tEpoch:192\tTrain Loss:0.1763\tRecon Loss:1.8658\tTriplet Loss:0.0894\tStatic Loss:0.1681\t\n",
      "Val Loss:0.2664\tRecon Loss:1.9092\tTriplet Loss:0.1236\tStatic Loss:0.2643\n",
      "\n",
      "\tTime:57.5137\n",
      "\n",
      "Test Loss:0.8677\tRecon Loss:5.7195\tTriplet Loss:0.4336\tStatic Loss:0.8626\n",
      "\n",
      "\tEpoch:193\tTrain Loss:0.1675\tRecon Loss:1.8280\tTriplet Loss:0.0906\tStatic Loss:0.1586\t\n",
      "Val Loss:0.2670\tRecon Loss:1.9367\tTriplet Loss:0.1311\tStatic Loss:0.2639\n",
      "\n",
      "\tTime:58.5001\n",
      "\n",
      "Test Loss:0.8487\tRecon Loss:5.7951\tTriplet Loss:0.3953\tStatic Loss:0.8446\n",
      "\n",
      "\tEpoch:194\tTrain Loss:0.1647\tRecon Loss:1.8273\tTriplet Loss:0.0898\tStatic Loss:0.1556\t\n",
      "Val Loss:0.2689\tRecon Loss:1.8947\tTriplet Loss:0.1219\tStatic Loss:0.2673\n",
      "\n",
      "\tTime:58.8700\n",
      "\n",
      "Test Loss:0.8752\tRecon Loss:5.7294\tTriplet Loss:0.4567\tStatic Loss:0.8685\n",
      "\n",
      "\tEpoch:195\tTrain Loss:0.1624\tRecon Loss:1.8269\tTriplet Loss:0.0794\tStatic Loss:0.1541\t\n",
      "Val Loss:0.2709\tRecon Loss:1.9449\tTriplet Loss:0.1253\tStatic Loss:0.2687\n",
      "\n",
      "\tTime:59.5936\n",
      "\n",
      "Test Loss:0.8438\tRecon Loss:5.8482\tTriplet Loss:0.4356\tStatic Loss:0.8345\n",
      "\n",
      "\tEpoch:196\tTrain Loss:0.1685\tRecon Loss:1.8403\tTriplet Loss:0.0909\tStatic Loss:0.1595\t\n",
      "Val Loss:0.3436\tRecon Loss:2.1074\tTriplet Loss:0.1525\tStatic Loss:0.3451\n",
      "\n",
      "\tTime:59.9094\n",
      "\n",
      "Test Loss:1.0842\tRecon Loss:6.3409\tTriplet Loss:0.4679\tStatic Loss:1.0933\n",
      "\n",
      "\tEpoch:197\tTrain Loss:0.2247\tRecon Loss:1.9041\tTriplet Loss:0.1260\tStatic Loss:0.2178\t\n",
      "Val Loss:0.2745\tRecon Loss:1.9467\tTriplet Loss:0.1346\tStatic Loss:0.2718\n",
      "\n",
      "\tTime:60.4094\n",
      "\n",
      "Test Loss:0.8653\tRecon Loss:5.9361\tTriplet Loss:0.4225\tStatic Loss:0.8588\n",
      "\n",
      "\tEpoch:198\tTrain Loss:0.1975\tRecon Loss:1.8562\tTriplet Loss:0.1059\tStatic Loss:0.1901\t\n",
      "Val Loss:0.2743\tRecon Loss:1.9539\tTriplet Loss:0.1268\tStatic Loss:0.2722\n",
      "\n",
      "\tTime:59.9908\n",
      "\n",
      "Test Loss:0.8648\tRecon Loss:5.7833\tTriplet Loss:0.4142\tStatic Loss:0.8607\n",
      "\n",
      "\tEpoch:199\tTrain Loss:0.1882\tRecon Loss:1.8401\tTriplet Loss:0.1014\tStatic Loss:0.1803\t\n",
      "Val Loss:0.2691\tRecon Loss:1.9598\tTriplet Loss:0.1196\tStatic Loss:0.2672\n",
      "\n",
      "\tTime:60.9471\n",
      "\n",
      "Test Loss:0.8577\tRecon Loss:5.8244\tTriplet Loss:0.4375\tStatic Loss:0.8500\n",
      "\n",
      "\t\n",
      "Unc Est in Static characteristics:0.0000\tUnc Est in Streamflow, dynamic:0.0000\t\n",
      "\n",
      "\tATT_NL_0\n",
      "Epoch:0\tTrain Loss:0.5482\tRecon Loss:4.1281\tTriplet Loss:0.4161\tStatic Loss:0.5256\t\n",
      "Val Loss:0.4375\tRecon Loss:4.0458\tTriplet Loss:0.2849\tStatic Loss:0.4167\n",
      "\n",
      "\tTime:63.5672\n",
      "\n",
      "Test Loss:1.3423\tRecon Loss:12.0086\tTriplet Loss:0.9493\tStatic Loss:1.2749\n",
      "\n",
      "\tEpoch:1\tTrain Loss:0.3926\tRecon Loss:3.9644\tTriplet Loss:0.2688\tStatic Loss:0.3693\t\n",
      "Val Loss:0.3755\tRecon Loss:4.0175\tTriplet Loss:0.2355\tStatic Loss:0.3531\n",
      "\n",
      "\tTime:60.9019\n",
      "\n",
      "Test Loss:1.1451\tRecon Loss:11.9084\tTriplet Loss:0.7761\tStatic Loss:1.0743\n",
      "\n",
      "\tEpoch:2\tTrain Loss:0.3527\tRecon Loss:3.9522\tTriplet Loss:0.2285\tStatic Loss:0.3292\t\n",
      "Val Loss:0.3474\tRecon Loss:4.0253\tTriplet Loss:0.2106\tStatic Loss:0.3243\n",
      "\n",
      "\tTime:61.1978\n",
      "\n",
      "Test Loss:1.0800\tRecon Loss:11.9200\tTriplet Loss:0.7016\tStatic Loss:1.0095\n",
      "\n",
      "\tEpoch:3\tTrain Loss:0.3334\tRecon Loss:3.9287\tTriplet Loss:0.2012\tStatic Loss:0.3107\t\n",
      "Val Loss:0.3412\tRecon Loss:3.9681\tTriplet Loss:0.1823\tStatic Loss:0.3208\n",
      "\n",
      "\tTime:61.1082\n",
      "\n",
      "Test Loss:1.0850\tRecon Loss:11.8010\tTriplet Loss:0.6322\tStatic Loss:1.0232\n",
      "\n",
      "\tEpoch:4\tTrain Loss:0.3208\tRecon Loss:3.8510\tTriplet Loss:0.1879\tStatic Loss:0.2988\t\n",
      "Val Loss:0.3256\tRecon Loss:3.8008\tTriplet Loss:0.1787\tStatic Loss:0.3055\n",
      "\n",
      "\tTime:60.8186\n",
      "\n",
      "Test Loss:1.0136\tRecon Loss:11.3727\tTriplet Loss:0.6069\tStatic Loss:0.9507\n",
      "\n",
      "\tEpoch:5\tTrain Loss:0.3083\tRecon Loss:3.5609\tTriplet Loss:0.1779\tStatic Loss:0.2888\t\n",
      "Val Loss:0.3132\tRecon Loss:3.3477\tTriplet Loss:0.1680\tStatic Loss:0.2973\n",
      "\n",
      "\tTime:61.5586\n",
      "\n",
      "Test Loss:1.0143\tRecon Loss:10.2853\tTriplet Loss:0.6109\tStatic Loss:0.9619\n",
      "\n",
      "\tEpoch:6\tTrain Loss:0.3078\tRecon Loss:3.5840\tTriplet Loss:0.1751\tStatic Loss:0.2884\t\n",
      "Val Loss:0.3088\tRecon Loss:3.8158\tTriplet Loss:0.1717\tStatic Loss:0.2875\n",
      "\n",
      "\tTime:61.0395\n",
      "\n",
      "Test Loss:0.9555\tRecon Loss:10.9714\tTriplet Loss:0.5521\tStatic Loss:0.8957\n",
      "\n",
      "\tEpoch:7\tTrain Loss:0.2924\tRecon Loss:3.4044\tTriplet Loss:0.1622\tStatic Loss:0.2743\t\n",
      "Val Loss:0.3006\tRecon Loss:2.9904\tTriplet Loss:0.1723\tStatic Loss:0.2865\n",
      "\n",
      "\tTime:60.2582\n",
      "\n",
      "Test Loss:0.9287\tRecon Loss:8.7556\tTriplet Loss:0.5390\tStatic Loss:0.8894\n",
      "\n",
      "\tEpoch:8\tTrain Loss:0.2787\tRecon Loss:2.5576\tTriplet Loss:0.1599\tStatic Loss:0.2678\t\n",
      "Val Loss:0.2909\tRecon Loss:2.5269\tTriplet Loss:0.1683\tStatic Loss:0.2808\n",
      "\n",
      "\tTime:60.7864\n",
      "\n",
      "Test Loss:0.8831\tRecon Loss:7.0036\tTriplet Loss:0.5451\tStatic Loss:0.8558\n",
      "\n",
      "\tEpoch:9\tTrain Loss:0.2700\tRecon Loss:2.1979\tTriplet Loss:0.1611\tStatic Loss:0.2616\t\n",
      "Val Loss:0.2881\tRecon Loss:2.3163\tTriplet Loss:0.1665\tStatic Loss:0.2799\n",
      "\n",
      "\tTime:59.2546\n",
      "\n",
      "Test Loss:0.8887\tRecon Loss:6.4303\tTriplet Loss:0.5540\tStatic Loss:0.8668\n",
      "\n",
      "\tEpoch:10\tTrain Loss:0.2634\tRecon Loss:2.0964\tTriplet Loss:0.1590\tStatic Loss:0.2555\t\n",
      "Val Loss:0.2846\tRecon Loss:2.1069\tTriplet Loss:0.1554\tStatic Loss:0.2793\n",
      "\n",
      "\tTime:59.3752\n",
      "\n",
      "Test Loss:0.8959\tRecon Loss:6.2121\tTriplet Loss:0.5266\tStatic Loss:0.8797\n",
      "\n",
      "\tEpoch:11\tTrain Loss:0.2580\tRecon Loss:2.0675\tTriplet Loss:0.1503\tStatic Loss:0.2507\t\n",
      "Val Loss:0.2824\tRecon Loss:2.1959\tTriplet Loss:0.1619\tStatic Loss:0.2753\n",
      "\n",
      "\tTime:56.5282\n",
      "\n",
      "Test Loss:0.8900\tRecon Loss:6.0810\tTriplet Loss:0.5406\tStatic Loss:0.8730\n",
      "\n",
      "\tEpoch:12\tTrain Loss:0.2535\tRecon Loss:1.9879\tTriplet Loss:0.1483\tStatic Loss:0.2467\t\n",
      "Val Loss:0.2828\tRecon Loss:2.1157\tTriplet Loss:0.1539\tStatic Loss:0.2774\n",
      "\n",
      "\tTime:57.6044\n",
      "\n",
      "Test Loss:0.9056\tRecon Loss:6.0295\tTriplet Loss:0.5268\tStatic Loss:0.8922\n",
      "\n",
      "\tEpoch:13\tTrain Loss:0.2515\tRecon Loss:2.0642\tTriplet Loss:0.1414\tStatic Loss:0.2444\t\n",
      "Val Loss:0.2770\tRecon Loss:2.0187\tTriplet Loss:0.1683\tStatic Loss:0.2704\n",
      "\n",
      "\tTime:57.4937\n",
      "\n",
      "Test Loss:0.8382\tRecon Loss:5.9635\tTriplet Loss:0.4950\tStatic Loss:0.8212\n",
      "\n",
      "\tEpoch:14\tTrain Loss:0.2452\tRecon Loss:1.9555\tTriplet Loss:0.1346\tStatic Loss:0.2391\t\n",
      "Val Loss:0.2749\tRecon Loss:2.0071\tTriplet Loss:0.1668\tStatic Loss:0.2684\n",
      "\n",
      "\tTime:59.1650\n",
      "\n",
      "Test Loss:0.8669\tRecon Loss:6.0229\tTriplet Loss:0.5193\tStatic Loss:0.8501\n",
      "\n",
      "\tEpoch:15\tTrain Loss:0.2413\tRecon Loss:1.9523\tTriplet Loss:0.1358\tStatic Loss:0.2347\t\n",
      "Val Loss:0.2770\tRecon Loss:2.0005\tTriplet Loss:0.1595\tStatic Loss:0.2716\n",
      "\n",
      "\tTime:57.8897\n",
      "\n",
      "Test Loss:0.8842\tRecon Loss:5.9219\tTriplet Loss:0.5365\tStatic Loss:0.8686\n",
      "\n",
      "\tEpoch:16\tTrain Loss:0.2411\tRecon Loss:1.9307\tTriplet Loss:0.1286\tStatic Loss:0.2355\t\n",
      "Val Loss:0.2770\tRecon Loss:1.9877\tTriplet Loss:0.1661\tStatic Loss:0.2710\n",
      "\n",
      "\tTime:57.4012\n",
      "\n",
      "Test Loss:0.8655\tRecon Loss:5.8744\tTriplet Loss:0.5024\tStatic Loss:0.8517\n",
      "\n",
      "\tEpoch:17\tTrain Loss:0.2376\tRecon Loss:1.9608\tTriplet Loss:0.1294\tStatic Loss:0.2312\t\n",
      "Val Loss:0.2782\tRecon Loss:1.9948\tTriplet Loss:0.1627\tStatic Loss:0.2726\n",
      "\n",
      "\tTime:59.8044\n",
      "\n",
      "Test Loss:0.8936\tRecon Loss:5.9249\tTriplet Loss:0.5212\tStatic Loss:0.8805\n",
      "\n",
      "\tEpoch:18\tTrain Loss:0.2342\tRecon Loss:1.9338\tTriplet Loss:0.1271\tStatic Loss:0.2279\t\n",
      "Val Loss:0.2731\tRecon Loss:2.0154\tTriplet Loss:0.1656\tStatic Loss:0.2664\n",
      "\n",
      "\tTime:61.7778\n",
      "\n",
      "Test Loss:0.8469\tRecon Loss:6.0287\tTriplet Loss:0.4912\tStatic Loss:0.8307\n",
      "\n",
      "\tEpoch:19\tTrain Loss:0.2314\tRecon Loss:1.9348\tTriplet Loss:0.1258\tStatic Loss:0.2250\t\n",
      "Val Loss:0.2697\tRecon Loss:1.9669\tTriplet Loss:0.1602\tStatic Loss:0.2637\n",
      "\n",
      "\tTime:60.3484\n",
      "\n",
      "Test Loss:0.8554\tRecon Loss:5.8969\tTriplet Loss:0.4772\tStatic Loss:0.8429\n",
      "\n",
      "\tEpoch:20\tTrain Loss:0.2296\tRecon Loss:1.9230\tTriplet Loss:0.1277\tStatic Loss:0.2228\t\n",
      "Val Loss:0.2718\tRecon Loss:1.9564\tTriplet Loss:0.1532\tStatic Loss:0.2669\n",
      "\n",
      "\tTime:59.3849\n",
      "\n",
      "Test Loss:0.8866\tRecon Loss:5.8622\tTriplet Loss:0.4846\tStatic Loss:0.8770\n",
      "\n",
      "\tEpoch:21\tTrain Loss:0.2294\tRecon Loss:2.0489\tTriplet Loss:0.1243\tStatic Loss:0.2217\t\n",
      "Val Loss:0.2713\tRecon Loss:1.9560\tTriplet Loss:0.1617\tStatic Loss:0.2654\n",
      "\n",
      "\tTime:58.7131\n",
      "\n",
      "Test Loss:0.8719\tRecon Loss:5.8375\tTriplet Loss:0.4785\tStatic Loss:0.8616\n",
      "\n",
      "\tEpoch:22\tTrain Loss:0.2262\tRecon Loss:1.9313\tTriplet Loss:0.1267\tStatic Loss:0.2191\t\n",
      "Val Loss:0.2701\tRecon Loss:1.9542\tTriplet Loss:0.1517\tStatic Loss:0.2651\n",
      "\n",
      "\tTime:58.8099\n",
      "\n",
      "Test Loss:0.8676\tRecon Loss:5.8486\tTriplet Loss:0.4921\tStatic Loss:0.8553\n",
      "\n",
      "\tEpoch:23\tTrain Loss:0.2266\tRecon Loss:2.0986\tTriplet Loss:0.1213\tStatic Loss:0.2184\t\n",
      "Val Loss:0.2772\tRecon Loss:2.3599\tTriplet Loss:0.1561\tStatic Loss:0.2684\n",
      "\n",
      "\tTime:58.3837\n",
      "\n",
      "Test Loss:0.8897\tRecon Loss:7.1167\tTriplet Loss:0.5546\tStatic Loss:0.8610\n",
      "\n",
      "\tEpoch:24\tTrain Loss:0.2234\tRecon Loss:1.9479\tTriplet Loss:0.1208\tStatic Loss:0.2164\t\n",
      "Val Loss:0.2682\tRecon Loss:1.9508\tTriplet Loss:0.1536\tStatic Loss:0.2628\n",
      "\n",
      "\tTime:57.8516\n",
      "\n",
      "Test Loss:0.8746\tRecon Loss:5.8205\tTriplet Loss:0.5082\tStatic Loss:0.8618\n",
      "\n",
      "\tEpoch:25\tTrain Loss:0.2201\tRecon Loss:1.8946\tTriplet Loss:0.1263\tStatic Loss:0.2127\t\n",
      "Val Loss:0.2640\tRecon Loss:1.9651\tTriplet Loss:0.1398\tStatic Loss:0.2594\n",
      "\n",
      "\tTime:57.3907\n",
      "\n",
      "Test Loss:0.8604\tRecon Loss:5.8653\tTriplet Loss:0.4822\tStatic Loss:0.8482\n",
      "\n",
      "\tEpoch:26\tTrain Loss:0.2194\tRecon Loss:1.8942\tTriplet Loss:0.1240\tStatic Loss:0.2122\t\n",
      "Val Loss:0.2654\tRecon Loss:1.9792\tTriplet Loss:0.1601\tStatic Loss:0.2588\n",
      "\n",
      "\tTime:57.4175\n",
      "\n",
      "Test Loss:0.8363\tRecon Loss:5.8219\tTriplet Loss:0.5072\tStatic Loss:0.8194\n",
      "\n",
      "\tEpoch:27\tTrain Loss:0.2169\tRecon Loss:1.8827\tTriplet Loss:0.1176\tStatic Loss:0.2102\t\n",
      "Val Loss:0.2668\tRecon Loss:1.9673\tTriplet Loss:0.1491\tStatic Loss:0.2616\n",
      "\n",
      "\tTime:59.5085\n",
      "\n",
      "Test Loss:0.8395\tRecon Loss:5.8156\tTriplet Loss:0.4884\tStatic Loss:0.8249\n",
      "\n",
      "\tEpoch:28\tTrain Loss:0.2168\tRecon Loss:1.9016\tTriplet Loss:0.1163\tStatic Loss:0.2101\t\n",
      "Val Loss:0.2688\tRecon Loss:2.1297\tTriplet Loss:0.1574\tStatic Loss:0.2614\n",
      "\n",
      "\tTime:58.3642\n",
      "\n",
      "Test Loss:0.8432\tRecon Loss:6.5102\tTriplet Loss:0.4916\tStatic Loss:0.8217\n",
      "\n",
      "\tEpoch:29\tTrain Loss:0.2209\tRecon Loss:2.1378\tTriplet Loss:0.1244\tStatic Loss:0.2114\t\n",
      "Val Loss:0.2879\tRecon Loss:3.6320\tTriplet Loss:0.1668\tStatic Loss:0.2665\n",
      "\n",
      "\tTime:59.1699\n",
      "\n",
      "Test Loss:0.9053\tRecon Loss:10.8040\tTriplet Loss:0.5201\tStatic Loss:0.8449\n",
      "\n",
      "\tEpoch:30\tTrain Loss:0.2312\tRecon Loss:2.7549\tTriplet Loss:0.1282\tStatic Loss:0.2162\t\n",
      "Val Loss:0.2713\tRecon Loss:2.3291\tTriplet Loss:0.1497\tStatic Loss:0.2629\n",
      "\n",
      "\tTime:58.4705\n",
      "\n",
      "Test Loss:0.8561\tRecon Loss:7.0637\tTriplet Loss:0.4906\tStatic Loss:0.8306\n",
      "\n",
      "\tEpoch:31\tTrain Loss:0.2180\tRecon Loss:2.1224\tTriplet Loss:0.1212\tStatic Loss:0.2087\t\n",
      "Val Loss:0.2728\tRecon Loss:2.0782\tTriplet Loss:0.1537\tStatic Loss:0.2667\n",
      "\n",
      "\tTime:57.1445\n",
      "\n",
      "Test Loss:0.8661\tRecon Loss:6.4110\tTriplet Loss:0.4997\tStatic Loss:0.8473\n",
      "\n",
      "\tEpoch:32\tTrain Loss:0.2140\tRecon Loss:1.9777\tTriplet Loss:0.1148\tStatic Loss:0.2063\t\n",
      "Val Loss:0.2664\tRecon Loss:1.9939\tTriplet Loss:0.1524\tStatic Loss:0.2605\n",
      "\n",
      "\tTime:58.1496\n",
      "\n",
      "Test Loss:0.8492\tRecon Loss:6.1006\tTriplet Loss:0.5154\tStatic Loss:0.8300\n",
      "\n",
      "\tEpoch:33\tTrain Loss:0.2131\tRecon Loss:2.1267\tTriplet Loss:0.1169\tStatic Loss:0.2036\t\n",
      "Val Loss:0.2693\tRecon Loss:2.1668\tTriplet Loss:0.1473\tStatic Loss:0.2625\n",
      "\n",
      "\tTime:60.5046\n",
      "\n",
      "Test Loss:0.8595\tRecon Loss:6.5196\tTriplet Loss:0.4971\tStatic Loss:0.8391\n",
      "\n",
      "\tEpoch:34\tTrain Loss:0.2109\tRecon Loss:1.9802\tTriplet Loss:0.1207\tStatic Loss:0.2022\t\n",
      "Val Loss:0.2644\tRecon Loss:2.0582\tTriplet Loss:0.1470\tStatic Loss:0.2582\n",
      "\n",
      "\tTime:58.7186\n",
      "\n",
      "Test Loss:0.8527\tRecon Loss:6.1677\tTriplet Loss:0.4707\tStatic Loss:0.8377\n",
      "\n",
      "\tEpoch:35\tTrain Loss:0.2086\tRecon Loss:1.9325\tTriplet Loss:0.1137\tStatic Loss:0.2009\t\n",
      "Val Loss:0.2661\tRecon Loss:1.9957\tTriplet Loss:0.1567\tStatic Loss:0.2598\n",
      "\n",
      "\tTime:59.7896\n",
      "\n",
      "Test Loss:0.8382\tRecon Loss:6.0400\tTriplet Loss:0.4829\tStatic Loss:0.8217\n",
      "\n",
      "\tEpoch:36\tTrain Loss:0.2073\tRecon Loss:1.8917\tTriplet Loss:0.1174\tStatic Loss:0.1994\t\n",
      "Val Loss:0.2677\tRecon Loss:1.9759\tTriplet Loss:0.1582\tStatic Loss:0.2616\n",
      "\n",
      "\tTime:56.7862\n",
      "\n",
      "Test Loss:0.8545\tRecon Loss:6.0413\tTriplet Loss:0.5002\tStatic Loss:0.8380\n",
      "\n",
      "\tEpoch:37\tTrain Loss:0.2087\tRecon Loss:1.9211\tTriplet Loss:0.1225\tStatic Loss:0.2002\t\n",
      "Val Loss:0.2707\tRecon Loss:1.9688\tTriplet Loss:0.1463\tStatic Loss:0.2662\n",
      "\n",
      "\tTime:55.6473\n",
      "\n",
      "Test Loss:0.8869\tRecon Loss:5.9712\tTriplet Loss:0.4773\tStatic Loss:0.8771\n",
      "\n",
      "\tEpoch:38\tTrain Loss:0.2168\tRecon Loss:1.9779\tTriplet Loss:0.1195\tStatic Loss:0.2089\t\n",
      "Val Loss:0.2668\tRecon Loss:1.9751\tTriplet Loss:0.1465\tStatic Loss:0.2618\n",
      "\n",
      "\tTime:56.2067\n",
      "\n",
      "Test Loss:0.8530\tRecon Loss:5.8618\tTriplet Loss:0.4895\tStatic Loss:0.8393\n",
      "\n",
      "\tEpoch:39\tTrain Loss:0.2070\tRecon Loss:1.8948\tTriplet Loss:0.1177\tStatic Loss:0.1990\t\n",
      "Val Loss:0.2622\tRecon Loss:1.9898\tTriplet Loss:0.1505\tStatic Loss:0.2561\n",
      "\n",
      "\tTime:56.2387\n",
      "\n",
      "Test Loss:0.8389\tRecon Loss:5.9317\tTriplet Loss:0.4891\tStatic Loss:0.8229\n",
      "\n",
      "\tEpoch:40\tTrain Loss:0.2036\tRecon Loss:1.8819\tTriplet Loss:0.1135\tStatic Loss:0.1959\t\n",
      "Val Loss:0.2675\tRecon Loss:1.9553\tTriplet Loss:0.1415\tStatic Loss:0.2632\n",
      "\n",
      "\tTime:56.9014\n",
      "\n",
      "Test Loss:0.8494\tRecon Loss:5.9193\tTriplet Loss:0.5075\tStatic Loss:0.8328\n",
      "\n",
      "\tEpoch:41\tTrain Loss:0.2044\tRecon Loss:1.8779\tTriplet Loss:0.1181\tStatic Loss:0.1963\t\n",
      "Val Loss:0.2651\tRecon Loss:1.9638\tTriplet Loss:0.1499\tStatic Loss:0.2596\n",
      "\n",
      "\tTime:57.9522\n",
      "\n",
      "Test Loss:0.8533\tRecon Loss:5.9202\tTriplet Loss:0.4592\tStatic Loss:0.8421\n",
      "\n",
      "\tEpoch:42\tTrain Loss:0.2063\tRecon Loss:2.0385\tTriplet Loss:0.1193\tStatic Loss:0.1967\t\n",
      "Val Loss:0.2662\tRecon Loss:1.9884\tTriplet Loss:0.1416\tStatic Loss:0.2614\n",
      "\n",
      "\tTime:57.7471\n",
      "\n",
      "Test Loss:0.8634\tRecon Loss:5.9635\tTriplet Loss:0.5006\tStatic Loss:0.8486\n",
      "\n",
      "\tEpoch:43\tTrain Loss:0.2035\tRecon Loss:2.0042\tTriplet Loss:0.1158\tStatic Loss:0.1942\t\n",
      "Val Loss:0.2655\tRecon Loss:2.0380\tTriplet Loss:0.1516\tStatic Loss:0.2592\n",
      "\n",
      "\tTime:55.5787\n",
      "\n",
      "Test Loss:0.8477\tRecon Loss:6.0851\tTriplet Loss:0.4962\tStatic Loss:0.8305\n",
      "\n",
      "\tEpoch:44\tTrain Loss:0.2016\tRecon Loss:1.8929\tTriplet Loss:0.1147\tStatic Loss:0.1934\t\n",
      "Val Loss:0.2640\tRecon Loss:1.9915\tTriplet Loss:0.1455\tStatic Loss:0.2586\n",
      "\n",
      "\tTime:56.5432\n",
      "\n",
      "Test Loss:0.8384\tRecon Loss:5.9632\tTriplet Loss:0.4847\tStatic Loss:0.8225\n",
      "\n",
      "\tEpoch:45\tTrain Loss:0.2155\tRecon Loss:1.8999\tTriplet Loss:0.1174\tStatic Loss:0.2085\t\n",
      "Val Loss:0.2686\tRecon Loss:1.9551\tTriplet Loss:0.1523\tStatic Loss:0.2633\n",
      "\n",
      "\tTime:54.7697\n",
      "\n",
      "Test Loss:0.8606\tRecon Loss:5.8452\tTriplet Loss:0.4949\tStatic Loss:0.8473\n",
      "\n",
      "\tEpoch:46\tTrain Loss:0.2062\tRecon Loss:1.8706\tTriplet Loss:0.1160\tStatic Loss:0.1986\t\n",
      "Val Loss:0.2633\tRecon Loss:1.9999\tTriplet Loss:0.1503\tStatic Loss:0.2572\n",
      "\n",
      "\tTime:55.6322\n",
      "\n",
      "Test Loss:0.8408\tRecon Loss:5.8798\tTriplet Loss:0.4731\tStatic Loss:0.8271\n",
      "\n",
      "\tEpoch:47\tTrain Loss:0.2012\tRecon Loss:1.8783\tTriplet Loss:0.1133\tStatic Loss:0.1932\t\n",
      "Val Loss:0.2631\tRecon Loss:2.1199\tTriplet Loss:0.1558\tStatic Loss:0.2552\n",
      "\n",
      "\tTime:56.8324\n",
      "\n",
      "Test Loss:0.8402\tRecon Loss:6.1367\tTriplet Loss:0.4662\tStatic Loss:0.8246\n",
      "\n",
      "\tEpoch:48\tTrain Loss:0.1990\tRecon Loss:1.8853\tTriplet Loss:0.1101\tStatic Loss:0.1911\t\n",
      "Val Loss:0.2668\tRecon Loss:1.9967\tTriplet Loss:0.1527\tStatic Loss:0.2609\n",
      "\n",
      "\tTime:58.0328\n",
      "\n",
      "Test Loss:0.8500\tRecon Loss:5.8768\tTriplet Loss:0.4716\tStatic Loss:0.8376\n",
      "\n",
      "\tEpoch:49\tTrain Loss:0.2002\tRecon Loss:1.9469\tTriplet Loss:0.1189\tStatic Loss:0.1908\t\n",
      "Val Loss:0.2667\tRecon Loss:2.0663\tTriplet Loss:0.1507\tStatic Loss:0.2603\n",
      "\n",
      "\tTime:57.6016\n",
      "\n",
      "Test Loss:0.8220\tRecon Loss:6.1605\tTriplet Loss:0.4744\tStatic Loss:0.8034\n",
      "\n",
      "\tEpoch:50\tTrain Loss:0.1993\tRecon Loss:1.9189\tTriplet Loss:0.1112\tStatic Loss:0.1909\t\n",
      "Val Loss:0.2593\tRecon Loss:1.9889\tTriplet Loss:0.1446\tStatic Loss:0.2535\n",
      "\n",
      "\tTime:55.6932\n",
      "\n",
      "Test Loss:0.8296\tRecon Loss:6.0147\tTriplet Loss:0.4443\tStatic Loss:0.8163\n",
      "\n",
      "\tEpoch:51\tTrain Loss:0.1979\tRecon Loss:1.8781\tTriplet Loss:0.1147\tStatic Loss:0.1894\t\n",
      "Val Loss:0.2630\tRecon Loss:1.9295\tTriplet Loss:0.1444\tStatic Loss:0.2582\n",
      "\n",
      "\tTime:57.5262\n",
      "\n",
      "Test Loss:0.8324\tRecon Loss:5.7825\tTriplet Loss:0.4641\tStatic Loss:0.8198\n",
      "\n",
      "\tEpoch:52\tTrain Loss:0.1958\tRecon Loss:1.8577\tTriplet Loss:0.1144\tStatic Loss:0.1873\t\n",
      "Val Loss:0.2633\tRecon Loss:1.9824\tTriplet Loss:0.1487\tStatic Loss:0.2575\n",
      "\n",
      "\tTime:57.1926\n",
      "\n",
      "Test Loss:0.8498\tRecon Loss:5.7964\tTriplet Loss:0.4728\tStatic Loss:0.8380\n",
      "\n",
      "\tEpoch:53\tTrain Loss:0.1959\tRecon Loss:1.8618\tTriplet Loss:0.1136\tStatic Loss:0.1875\t\n",
      "Val Loss:0.2642\tRecon Loss:1.9495\tTriplet Loss:0.1461\tStatic Loss:0.2591\n",
      "\n",
      "\tTime:60.1600\n",
      "\n",
      "Test Loss:0.8450\tRecon Loss:5.7878\tTriplet Loss:0.4756\tStatic Loss:0.8325\n",
      "\n",
      "\tEpoch:54\tTrain Loss:0.1960\tRecon Loss:1.8701\tTriplet Loss:0.1109\tStatic Loss:0.1878\t\n",
      "Val Loss:0.2637\tRecon Loss:1.9647\tTriplet Loss:0.1475\tStatic Loss:0.2583\n",
      "\n",
      "\tTime:59.8004\n",
      "\n",
      "Test Loss:0.8565\tRecon Loss:5.9021\tTriplet Loss:0.4996\tStatic Loss:0.8417\n",
      "\n",
      "\tEpoch:55\tTrain Loss:0.1949\tRecon Loss:1.8628\tTriplet Loss:0.1088\tStatic Loss:0.1869\t\n",
      "Val Loss:0.2594\tRecon Loss:1.9471\tTriplet Loss:0.1381\tStatic Loss:0.2546\n",
      "\n",
      "\tTime:61.4344\n",
      "\n",
      "Test Loss:0.8351\tRecon Loss:5.7690\tTriplet Loss:0.4584\tStatic Loss:0.8235\n",
      "\n",
      "\tEpoch:56\tTrain Loss:0.1975\tRecon Loss:1.8668\tTriplet Loss:0.1152\tStatic Loss:0.1890\t\n",
      "Val Loss:0.2661\tRecon Loss:1.9613\tTriplet Loss:0.1537\tStatic Loss:0.2603\n",
      "\n",
      "\tTime:60.3366\n",
      "\n",
      "Test Loss:0.8725\tRecon Loss:5.9196\tTriplet Loss:0.4858\tStatic Loss:0.8606\n",
      "\n",
      "\tEpoch:57\tTrain Loss:0.1958\tRecon Loss:1.8733\tTriplet Loss:0.1145\tStatic Loss:0.1871\t\n",
      "Val Loss:0.2626\tRecon Loss:2.1037\tTriplet Loss:0.1540\tStatic Loss:0.2551\n",
      "\n",
      "\tTime:61.6892\n",
      "\n",
      "Test Loss:0.8189\tRecon Loss:6.2185\tTriplet Loss:0.4530\tStatic Loss:0.8015\n",
      "\n",
      "\tEpoch:58\tTrain Loss:0.1959\tRecon Loss:1.8963\tTriplet Loss:0.1142\tStatic Loss:0.1871\t\n",
      "Val Loss:0.2602\tRecon Loss:1.9765\tTriplet Loss:0.1325\tStatic Loss:0.2558\n",
      "\n",
      "\tTime:60.4437\n",
      "\n",
      "Test Loss:0.8699\tRecon Loss:5.8485\tTriplet Loss:0.4648\tStatic Loss:0.8607\n",
      "\n",
      "\tEpoch:59\tTrain Loss:0.1932\tRecon Loss:1.8613\tTriplet Loss:0.1071\tStatic Loss:0.1852\t\n",
      "Val Loss:0.2600\tRecon Loss:1.9295\tTriplet Loss:0.1365\tStatic Loss:0.2556\n",
      "\n",
      "\tTime:61.6329\n",
      "\n",
      "Test Loss:0.8426\tRecon Loss:5.8201\tTriplet Loss:0.4697\tStatic Loss:0.8301\n",
      "\n",
      "\tEpoch:60\tTrain Loss:0.1916\tRecon Loss:1.8620\tTriplet Loss:0.1135\tStatic Loss:0.1827\t\n",
      "Val Loss:0.2583\tRecon Loss:1.9165\tTriplet Loss:0.1426\tStatic Loss:0.2533\n",
      "\n",
      "\tTime:59.4284\n",
      "\n",
      "Test Loss:0.8315\tRecon Loss:5.8522\tTriplet Loss:0.4730\tStatic Loss:0.8171\n",
      "\n",
      "\tEpoch:61\tTrain Loss:0.1935\tRecon Loss:1.8650\tTriplet Loss:0.1114\tStatic Loss:0.1850\t\n",
      "Val Loss:0.2615\tRecon Loss:1.9225\tTriplet Loss:0.1391\tStatic Loss:0.2571\n",
      "\n",
      "\tTime:58.6812\n",
      "\n",
      "Test Loss:0.8210\tRecon Loss:5.7194\tTriplet Loss:0.4485\tStatic Loss:0.8092\n",
      "\n",
      "\tEpoch:62\tTrain Loss:0.1927\tRecon Loss:1.8498\tTriplet Loss:0.1126\tStatic Loss:0.1841\t\n",
      "Val Loss:0.2584\tRecon Loss:1.9474\tTriplet Loss:0.1476\tStatic Loss:0.2526\n",
      "\n",
      "\tTime:59.3084\n",
      "\n",
      "Test Loss:0.8181\tRecon Loss:5.7792\tTriplet Loss:0.4868\tStatic Loss:0.8016\n",
      "\n",
      "\tEpoch:63\tTrain Loss:0.1919\tRecon Loss:1.8545\tTriplet Loss:0.1101\tStatic Loss:0.1835\t\n",
      "Val Loss:0.2649\tRecon Loss:1.9489\tTriplet Loss:0.1533\tStatic Loss:0.2592\n",
      "\n",
      "\tTime:62.1632\n",
      "\n",
      "Test Loss:0.8402\tRecon Loss:5.7410\tTriplet Loss:0.4559\tStatic Loss:0.8296\n",
      "\n",
      "\tEpoch:64\tTrain Loss:0.1902\tRecon Loss:1.8542\tTriplet Loss:0.1099\tStatic Loss:0.1816\t\n",
      "Val Loss:0.2629\tRecon Loss:1.9275\tTriplet Loss:0.1468\tStatic Loss:0.2579\n",
      "\n",
      "\tTime:59.6746\n",
      "\n",
      "Test Loss:0.8471\tRecon Loss:5.7237\tTriplet Loss:0.4833\tStatic Loss:0.8347\n",
      "\n",
      "\tEpoch:65\tTrain Loss:0.1917\tRecon Loss:1.8521\tTriplet Loss:0.1134\tStatic Loss:0.1829\t\n",
      "Val Loss:0.2627\tRecon Loss:1.9425\tTriplet Loss:0.1578\tStatic Loss:0.2564\n",
      "\n",
      "\tTime:59.0999\n",
      "\n",
      "Test Loss:0.8190\tRecon Loss:5.7602\tTriplet Loss:0.4982\tStatic Loss:0.8017\n",
      "\n",
      "\tEpoch:66\tTrain Loss:0.1898\tRecon Loss:1.8453\tTriplet Loss:0.1139\tStatic Loss:0.1808\t\n",
      "Val Loss:0.2578\tRecon Loss:1.9479\tTriplet Loss:0.1407\tStatic Loss:0.2526\n",
      "\n",
      "\tTime:59.2261\n",
      "\n",
      "Test Loss:0.8447\tRecon Loss:5.8565\tTriplet Loss:0.4683\tStatic Loss:0.8322\n",
      "\n",
      "\tEpoch:67\tTrain Loss:0.2261\tRecon Loss:1.9046\tTriplet Loss:0.1316\tStatic Loss:0.2188\t\n",
      "Val Loss:0.3309\tRecon Loss:1.9978\tTriplet Loss:0.1982\tStatic Loss:0.3275\n",
      "\n",
      "\tTime:58.6091\n",
      "\n",
      "Test Loss:0.9907\tRecon Loss:6.1664\tTriplet Loss:0.5906\tStatic Loss:0.9789\n",
      "\n",
      "\tEpoch:68\tTrain Loss:0.2367\tRecon Loss:1.9018\tTriplet Loss:0.1557\tStatic Loss:0.2282\t\n",
      "Val Loss:0.2788\tRecon Loss:1.9504\tTriplet Loss:0.1735\tStatic Loss:0.2726\n",
      "\n",
      "\tTime:58.2072\n",
      "\n",
      "Test Loss:0.8980\tRecon Loss:5.8229\tTriplet Loss:0.5800\tStatic Loss:0.8805\n",
      "\n",
      "\tEpoch:69\tTrain Loss:0.2186\tRecon Loss:1.8599\tTriplet Loss:0.1398\tStatic Loss:0.2101\t\n",
      "Val Loss:0.2682\tRecon Loss:1.9269\tTriplet Loss:0.1654\tStatic Loss:0.2619\n",
      "\n",
      "\tTime:60.2965\n",
      "\n",
      "Test Loss:0.8524\tRecon Loss:5.7640\tTriplet Loss:0.5180\tStatic Loss:0.8367\n",
      "\n",
      "\tEpoch:70\tTrain Loss:0.2092\tRecon Loss:1.8492\tTriplet Loss:0.1225\tStatic Loss:0.2015\t\n",
      "Val Loss:0.2657\tRecon Loss:1.9277\tTriplet Loss:0.1657\tStatic Loss:0.2591\n",
      "\n",
      "\tTime:61.8165\n",
      "\n",
      "Test Loss:0.8610\tRecon Loss:5.8021\tTriplet Loss:0.5157\tStatic Loss:0.8461\n",
      "\n",
      "\tEpoch:71\tTrain Loss:0.2068\tRecon Loss:1.8552\tTriplet Loss:0.1284\tStatic Loss:0.1981\t\n",
      "Val Loss:0.2669\tRecon Loss:1.9301\tTriplet Loss:0.1568\tStatic Loss:0.2612\n",
      "\n",
      "\tTime:59.8362\n",
      "\n",
      "Test Loss:0.8605\tRecon Loss:5.8272\tTriplet Loss:0.5224\tStatic Loss:0.8446\n",
      "\n",
      "\tEpoch:72\tTrain Loss:0.2020\tRecon Loss:1.8572\tTriplet Loss:0.1192\tStatic Loss:0.1938\t\n",
      "Val Loss:0.2617\tRecon Loss:1.9435\tTriplet Loss:0.1514\tStatic Loss:0.2559\n",
      "\n",
      "\tTime:60.1881\n",
      "\n",
      "Test Loss:0.8589\tRecon Loss:5.7691\tTriplet Loss:0.5000\tStatic Loss:0.8457\n",
      "\n",
      "\tEpoch:73\tTrain Loss:0.2005\tRecon Loss:1.8425\tTriplet Loss:0.1229\tStatic Loss:0.1919\t\n",
      "Val Loss:0.2641\tRecon Loss:1.9277\tTriplet Loss:0.1543\tStatic Loss:0.2584\n",
      "\n",
      "\tTime:59.2805\n",
      "\n",
      "Test Loss:0.8642\tRecon Loss:5.6837\tTriplet Loss:0.5056\tStatic Loss:0.8518\n",
      "\n",
      "\tEpoch:74\tTrain Loss:0.1972\tRecon Loss:1.8444\tTriplet Loss:0.1138\tStatic Loss:0.1891\t\n",
      "Val Loss:0.2591\tRecon Loss:1.9189\tTriplet Loss:0.1464\tStatic Loss:0.2538\n",
      "\n",
      "\tTime:59.1832\n",
      "\n",
      "Test Loss:0.8396\tRecon Loss:5.7087\tTriplet Loss:0.4753\tStatic Loss:0.8274\n",
      "\n",
      "\tEpoch:75\tTrain Loss:0.1963\tRecon Loss:1.8403\tTriplet Loss:0.1148\tStatic Loss:0.1880\t\n",
      "Val Loss:0.2624\tRecon Loss:1.9297\tTriplet Loss:0.1392\tStatic Loss:0.2580\n",
      "\n",
      "\tTime:59.5778\n",
      "\n",
      "Test Loss:0.8614\tRecon Loss:5.6848\tTriplet Loss:0.4708\tStatic Loss:0.8522\n",
      "\n",
      "\tEpoch:76\tTrain Loss:0.1963\tRecon Loss:1.8485\tTriplet Loss:0.1116\tStatic Loss:0.1883\t\n",
      "Val Loss:0.2616\tRecon Loss:1.9381\tTriplet Loss:0.1468\tStatic Loss:0.2563\n",
      "\n",
      "\tTime:60.3016\n",
      "\n",
      "Test Loss:0.8450\tRecon Loss:5.7333\tTriplet Loss:0.4868\tStatic Loss:0.8319\n",
      "\n",
      "\tEpoch:77\tTrain Loss:0.1938\tRecon Loss:1.8364\tTriplet Loss:0.1159\tStatic Loss:0.1851\t\n",
      "Val Loss:0.2604\tRecon Loss:1.9441\tTriplet Loss:0.1437\tStatic Loss:0.2553\n",
      "\n",
      "\tTime:61.0847\n",
      "\n",
      "Test Loss:0.8390\tRecon Loss:5.7481\tTriplet Loss:0.4876\tStatic Loss:0.8250\n",
      "\n",
      "\tEpoch:78\tTrain Loss:0.1918\tRecon Loss:1.8551\tTriplet Loss:0.1089\tStatic Loss:0.1834\t\n",
      "Val Loss:0.2585\tRecon Loss:2.0085\tTriplet Loss:0.1389\tStatic Loss:0.2530\n",
      "\n",
      "\tTime:59.2368\n",
      "\n",
      "Test Loss:0.8389\tRecon Loss:6.1408\tTriplet Loss:0.4697\tStatic Loss:0.8228\n",
      "\n",
      "\tEpoch:79\tTrain Loss:0.1917\tRecon Loss:1.8604\tTriplet Loss:0.1120\tStatic Loss:0.1830\t\n",
      "Val Loss:0.2607\tRecon Loss:1.9088\tTriplet Loss:0.1360\tStatic Loss:0.2567\n",
      "\n",
      "\tTime:59.2615\n",
      "\n",
      "Test Loss:0.8507\tRecon Loss:5.7822\tTriplet Loss:0.4648\tStatic Loss:0.8400\n",
      "\n",
      "\tEpoch:80\tTrain Loss:0.1902\tRecon Loss:1.8350\tTriplet Loss:0.1133\tStatic Loss:0.1814\t\n",
      "Val Loss:0.2585\tRecon Loss:1.9063\tTriplet Loss:0.1497\tStatic Loss:0.2529\n",
      "\n",
      "\tTime:59.9053\n",
      "\n",
      "Test Loss:0.8325\tRecon Loss:5.7321\tTriplet Loss:0.4609\tStatic Loss:0.8207\n",
      "\n",
      "\tEpoch:81\tTrain Loss:0.1909\tRecon Loss:1.8398\tTriplet Loss:0.1083\tStatic Loss:0.1826\t\n",
      "Val Loss:0.2633\tRecon Loss:1.9097\tTriplet Loss:0.1426\tStatic Loss:0.2589\n",
      "\n",
      "\tTime:58.6550\n",
      "\n",
      "Test Loss:0.8235\tRecon Loss:5.7426\tTriplet Loss:0.4494\tStatic Loss:0.8117\n",
      "\n",
      "\tEpoch:82\tTrain Loss:0.1890\tRecon Loss:1.8649\tTriplet Loss:0.1093\tStatic Loss:0.1802\t\n",
      "Val Loss:0.2585\tRecon Loss:1.9067\tTriplet Loss:0.1440\tStatic Loss:0.2535\n",
      "\n",
      "\tTime:58.7882\n",
      "\n",
      "Test Loss:0.8369\tRecon Loss:5.7133\tTriplet Loss:0.5044\tStatic Loss:0.8214\n",
      "\n",
      "\tEpoch:83\tTrain Loss:0.1880\tRecon Loss:1.8420\tTriplet Loss:0.1183\tStatic Loss:0.1784\t\n",
      "Val Loss:0.2586\tRecon Loss:1.9342\tTriplet Loss:0.1340\tStatic Loss:0.2543\n",
      "\n",
      "\tTime:59.8195\n",
      "\n",
      "Test Loss:0.8457\tRecon Loss:5.8049\tTriplet Loss:0.4621\tStatic Loss:0.8345\n",
      "\n",
      "\tEpoch:84\tTrain Loss:0.1875\tRecon Loss:1.8393\tTriplet Loss:0.1076\tStatic Loss:0.1790\t\n",
      "Val Loss:0.2538\tRecon Loss:1.9086\tTriplet Loss:0.1321\tStatic Loss:0.2494\n",
      "\n",
      "\tTime:57.0806\n",
      "\n",
      "Test Loss:0.8244\tRecon Loss:5.6921\tTriplet Loss:0.4827\tStatic Loss:0.8099\n",
      "\n",
      "\tEpoch:85\tTrain Loss:0.1854\tRecon Loss:1.8395\tTriplet Loss:0.1072\tStatic Loss:0.1767\t\n",
      "Val Loss:0.2602\tRecon Loss:1.9193\tTriplet Loss:0.1334\tStatic Loss:0.2563\n",
      "\n",
      "\tTime:56.4887\n",
      "\n",
      "Test Loss:0.8511\tRecon Loss:5.7729\tTriplet Loss:0.4930\tStatic Loss:0.8377\n",
      "\n",
      "\tEpoch:86\tTrain Loss:0.1883\tRecon Loss:1.8743\tTriplet Loss:0.1018\tStatic Loss:0.1800\t\n",
      "Val Loss:0.2593\tRecon Loss:1.9391\tTriplet Loss:0.1340\tStatic Loss:0.2551\n",
      "\n",
      "\tTime:61.1816\n",
      "\n",
      "Test Loss:0.8270\tRecon Loss:5.7825\tTriplet Loss:0.4849\tStatic Loss:0.8117\n",
      "\n",
      "\tEpoch:87\tTrain Loss:0.1850\tRecon Loss:1.8466\tTriplet Loss:0.1045\tStatic Loss:0.1765\t\n",
      "Val Loss:0.2572\tRecon Loss:1.9547\tTriplet Loss:0.1402\tStatic Loss:0.2520\n",
      "\n",
      "\tTime:58.9894\n",
      "\n",
      "Test Loss:0.8419\tRecon Loss:5.7735\tTriplet Loss:0.4734\tStatic Loss:0.8294\n",
      "\n",
      "\tEpoch:88\tTrain Loss:0.1855\tRecon Loss:1.8311\tTriplet Loss:0.1102\tStatic Loss:0.1765\t\n",
      "Val Loss:0.2600\tRecon Loss:1.9323\tTriplet Loss:0.1332\tStatic Loss:0.2560\n",
      "\n",
      "\tTime:58.4688\n",
      "\n",
      "Test Loss:0.8299\tRecon Loss:5.7338\tTriplet Loss:0.5014\tStatic Loss:0.8137\n",
      "\n",
      "\tEpoch:89\tTrain Loss:0.1846\tRecon Loss:1.8397\tTriplet Loss:0.1091\tStatic Loss:0.1756\t\n",
      "Val Loss:0.2647\tRecon Loss:1.9216\tTriplet Loss:0.1426\tStatic Loss:0.2603\n",
      "\n",
      "\tTime:62.1918\n",
      "\n",
      "Test Loss:0.8453\tRecon Loss:5.6883\tTriplet Loss:0.4720\tStatic Loss:0.8342\n",
      "\n",
      "\tEpoch:90\tTrain Loss:0.1843\tRecon Loss:1.8562\tTriplet Loss:0.1027\tStatic Loss:0.1758\t\n",
      "Val Loss:0.2574\tRecon Loss:1.9343\tTriplet Loss:0.1345\tStatic Loss:0.2529\n",
      "\n",
      "\tTime:57.5335\n",
      "\n",
      "Test Loss:0.8442\tRecon Loss:5.7285\tTriplet Loss:0.4666\tStatic Loss:0.8332\n",
      "\n",
      "\tEpoch:91\tTrain Loss:0.1826\tRecon Loss:1.8342\tTriplet Loss:0.1114\tStatic Loss:0.1732\t\n",
      "Val Loss:0.2558\tRecon Loss:1.9032\tTriplet Loss:0.1405\tStatic Loss:0.2509\n",
      "\n",
      "\tTime:61.1271\n",
      "\n",
      "Test Loss:0.8228\tRecon Loss:5.6651\tTriplet Loss:0.4650\tStatic Loss:0.8102\n",
      "\n",
      "\tEpoch:92\tTrain Loss:0.1821\tRecon Loss:1.8333\tTriplet Loss:0.1069\tStatic Loss:0.1731\t\n",
      "Val Loss:0.2575\tRecon Loss:1.9463\tTriplet Loss:0.1440\tStatic Loss:0.2519\n",
      "\n",
      "\tTime:59.0939\n",
      "\n",
      "Test Loss:0.8273\tRecon Loss:5.7916\tTriplet Loss:0.4410\tStatic Loss:0.8163\n",
      "\n",
      "\tEpoch:93\tTrain Loss:0.1827\tRecon Loss:1.8477\tTriplet Loss:0.1130\tStatic Loss:0.1730\t\n",
      "Val Loss:0.2531\tRecon Loss:1.9005\tTriplet Loss:0.1385\tStatic Loss:0.2480\n",
      "\n",
      "\tTime:59.0016\n",
      "\n",
      "Test Loss:0.8279\tRecon Loss:5.6641\tTriplet Loss:0.4487\tStatic Loss:0.8175\n",
      "\n",
      "\tEpoch:94\tTrain Loss:0.1839\tRecon Loss:1.8425\tTriplet Loss:0.1038\tStatic Loss:0.1753\t\n",
      "Val Loss:0.2568\tRecon Loss:1.9143\tTriplet Loss:0.1332\tStatic Loss:0.2526\n",
      "\n",
      "\tTime:58.6583\n",
      "\n",
      "Test Loss:0.8393\tRecon Loss:5.6628\tTriplet Loss:0.4568\tStatic Loss:0.8293\n",
      "\n",
      "\tEpoch:95\tTrain Loss:0.1825\tRecon Loss:1.8335\tTriplet Loss:0.1076\tStatic Loss:0.1735\t\n",
      "Val Loss:0.2594\tRecon Loss:1.9523\tTriplet Loss:0.1419\tStatic Loss:0.2542\n",
      "\n",
      "\tTime:59.4210\n",
      "\n",
      "Test Loss:0.8546\tRecon Loss:5.7470\tTriplet Loss:0.4388\tStatic Loss:0.8473\n",
      "\n",
      "\tEpoch:96\tTrain Loss:0.1849\tRecon Loss:1.8655\tTriplet Loss:0.1042\tStatic Loss:0.1762\t\n",
      "Val Loss:0.2589\tRecon Loss:1.9180\tTriplet Loss:0.1440\tStatic Loss:0.2538\n",
      "\n",
      "\tTime:60.5617\n",
      "\n",
      "Test Loss:0.8485\tRecon Loss:5.7143\tTriplet Loss:0.4723\tStatic Loss:0.8375\n",
      "\n",
      "\tEpoch:97\tTrain Loss:0.1819\tRecon Loss:1.8523\tTriplet Loss:0.1057\tStatic Loss:0.1728\t\n",
      "Val Loss:0.2566\tRecon Loss:1.9263\tTriplet Loss:0.1269\tStatic Loss:0.2529\n",
      "\n",
      "\tTime:58.1924\n",
      "\n",
      "Test Loss:0.8344\tRecon Loss:5.7656\tTriplet Loss:0.4653\tStatic Loss:0.8220\n",
      "\n",
      "\tEpoch:98\tTrain Loss:0.1817\tRecon Loss:1.8347\tTriplet Loss:0.1046\tStatic Loss:0.1728\t\n",
      "Val Loss:0.2590\tRecon Loss:1.9058\tTriplet Loss:0.1339\tStatic Loss:0.2551\n",
      "\n",
      "\tTime:57.5368\n",
      "\n",
      "Test Loss:0.8529\tRecon Loss:5.7005\tTriplet Loss:0.4506\tStatic Loss:0.8446\n",
      "\n",
      "\tEpoch:99\tTrain Loss:0.1815\tRecon Loss:1.8366\tTriplet Loss:0.1065\tStatic Loss:0.1725\t\n",
      "Val Loss:0.2620\tRecon Loss:1.9734\tTriplet Loss:0.1388\tStatic Loss:0.2572\n",
      "\n",
      "\tTime:60.3966\n",
      "\n",
      "Test Loss:0.8668\tRecon Loss:5.9467\tTriplet Loss:0.4706\tStatic Loss:0.8556\n",
      "\n",
      "\tEpoch:100\tTrain Loss:0.1831\tRecon Loss:1.8437\tTriplet Loss:0.1053\tStatic Loss:0.1743\t\n",
      "Val Loss:0.2568\tRecon Loss:1.9273\tTriplet Loss:0.1423\tStatic Loss:0.2516\n",
      "\n",
      "\tTime:58.4777\n",
      "\n",
      "Test Loss:0.8297\tRecon Loss:5.7267\tTriplet Loss:0.4719\tStatic Loss:0.8165\n",
      "\n",
      "\tEpoch:101\tTrain Loss:0.1812\tRecon Loss:1.8363\tTriplet Loss:0.1056\tStatic Loss:0.1722\t\n",
      "Val Loss:0.2573\tRecon Loss:1.9278\tTriplet Loss:0.1437\tStatic Loss:0.2519\n",
      "\n",
      "\tTime:58.7474\n",
      "\n",
      "Test Loss:0.8311\tRecon Loss:5.7470\tTriplet Loss:0.4591\tStatic Loss:0.8192\n",
      "\n",
      "\tEpoch:102\tTrain Loss:0.1805\tRecon Loss:1.8383\tTriplet Loss:0.1075\tStatic Loss:0.1712\t\n",
      "Val Loss:0.2591\tRecon Loss:2.0369\tTriplet Loss:0.1334\tStatic Loss:0.2539\n",
      "\n",
      "\tTime:59.6171\n",
      "\n",
      "Test Loss:0.8291\tRecon Loss:6.1102\tTriplet Loss:0.4704\tStatic Loss:0.8122\n",
      "\n",
      "\tEpoch:103\tTrain Loss:0.1796\tRecon Loss:1.8351\tTriplet Loss:0.1038\tStatic Loss:0.1707\t\n",
      "Val Loss:0.2604\tRecon Loss:1.9397\tTriplet Loss:0.1333\tStatic Loss:0.2563\n",
      "\n",
      "\tTime:59.1428\n",
      "\n",
      "Test Loss:0.8569\tRecon Loss:5.6897\tTriplet Loss:0.4765\tStatic Loss:0.8467\n",
      "\n",
      "\tEpoch:104\tTrain Loss:0.1809\tRecon Loss:1.8499\tTriplet Loss:0.1004\tStatic Loss:0.1723\t\n",
      "Val Loss:0.2571\tRecon Loss:1.9496\tTriplet Loss:0.1433\tStatic Loss:0.2516\n",
      "\n",
      "\tTime:59.6380\n",
      "\n",
      "Test Loss:0.8203\tRecon Loss:5.8824\tTriplet Loss:0.4804\tStatic Loss:0.8037\n",
      "\n",
      "\tEpoch:105\tTrain Loss:0.1784\tRecon Loss:1.8335\tTriplet Loss:0.1025\tStatic Loss:0.1695\t\n",
      "Val Loss:0.2549\tRecon Loss:1.9566\tTriplet Loss:0.1382\tStatic Loss:0.2496\n",
      "\n",
      "\tTime:60.8198\n",
      "\n",
      "Test Loss:0.8304\tRecon Loss:5.7697\tTriplet Loss:0.4587\tStatic Loss:0.8182\n",
      "\n",
      "\tEpoch:106\tTrain Loss:0.1842\tRecon Loss:1.8345\tTriplet Loss:0.1062\tStatic Loss:0.1755\t\n",
      "Val Loss:0.2588\tRecon Loss:1.9343\tTriplet Loss:0.1428\tStatic Loss:0.2537\n",
      "\n",
      "\tTime:59.6177\n",
      "\n",
      "Test Loss:0.8123\tRecon Loss:5.7389\tTriplet Loss:0.4752\tStatic Loss:0.7967\n",
      "\n",
      "\tEpoch:107\tTrain Loss:0.1802\tRecon Loss:1.8347\tTriplet Loss:0.1035\tStatic Loss:0.1713\t\n",
      "Val Loss:0.2618\tRecon Loss:1.9099\tTriplet Loss:0.1387\tStatic Loss:0.2576\n",
      "\n",
      "\tTime:60.0138\n",
      "\n",
      "Test Loss:0.8362\tRecon Loss:5.7049\tTriplet Loss:0.4406\tStatic Loss:0.8270\n",
      "\n",
      "\tEpoch:108\tTrain Loss:0.1790\tRecon Loss:1.8322\tTriplet Loss:0.1074\tStatic Loss:0.1696\t\n",
      "Val Loss:0.2552\tRecon Loss:1.9401\tTriplet Loss:0.1453\tStatic Loss:0.2494\n",
      "\n",
      "\tTime:57.7866\n",
      "\n",
      "Test Loss:0.8122\tRecon Loss:5.7495\tTriplet Loss:0.4366\tStatic Loss:0.8004\n",
      "\n",
      "\tEpoch:109\tTrain Loss:0.1788\tRecon Loss:1.8428\tTriplet Loss:0.1020\tStatic Loss:0.1698\t\n",
      "Val Loss:0.2538\tRecon Loss:1.9913\tTriplet Loss:0.1375\tStatic Loss:0.2480\n",
      "\n",
      "\tTime:57.0924\n",
      "\n",
      "Test Loss:0.8257\tRecon Loss:5.9471\tTriplet Loss:0.4457\tStatic Loss:0.8125\n",
      "\n",
      "\tEpoch:110\tTrain Loss:0.1810\tRecon Loss:1.8432\tTriplet Loss:0.1026\tStatic Loss:0.1722\t\n",
      "Val Loss:0.2516\tRecon Loss:1.8939\tTriplet Loss:0.1436\tStatic Loss:0.2460\n",
      "\n",
      "\tTime:58.7819\n",
      "\n",
      "Test Loss:0.8298\tRecon Loss:5.6811\tTriplet Loss:0.4339\tStatic Loss:0.8209\n",
      "\n",
      "\tEpoch:111\tTrain Loss:0.1784\tRecon Loss:1.8328\tTriplet Loss:0.1031\tStatic Loss:0.1693\t\n",
      "Val Loss:0.2548\tRecon Loss:1.9385\tTriplet Loss:0.1395\tStatic Loss:0.2495\n",
      "\n",
      "\tTime:58.6842\n",
      "\n",
      "Test Loss:0.8482\tRecon Loss:5.7510\tTriplet Loss:0.4649\tStatic Loss:0.8374\n",
      "\n",
      "\tEpoch:112\tTrain Loss:0.1778\tRecon Loss:1.8446\tTriplet Loss:0.1003\tStatic Loss:0.1688\t\n",
      "Val Loss:0.2586\tRecon Loss:1.9368\tTriplet Loss:0.1431\tStatic Loss:0.2533\n",
      "\n",
      "\tTime:58.4357\n",
      "\n",
      "Test Loss:0.8096\tRecon Loss:5.7629\tTriplet Loss:0.4665\tStatic Loss:0.7944\n",
      "\n",
      "\tEpoch:113\tTrain Loss:0.1772\tRecon Loss:1.8322\tTriplet Loss:0.1029\tStatic Loss:0.1681\t\n",
      "Val Loss:0.2557\tRecon Loss:1.9264\tTriplet Loss:0.1426\tStatic Loss:0.2503\n",
      "\n",
      "\tTime:60.4335\n",
      "\n",
      "Test Loss:0.8139\tRecon Loss:5.7926\tTriplet Loss:0.4882\tStatic Loss:0.7967\n",
      "\n",
      "\tEpoch:114\tTrain Loss:0.1809\tRecon Loss:1.8495\tTriplet Loss:0.1054\tStatic Loss:0.1717\t\n",
      "Val Loss:0.2550\tRecon Loss:1.9503\tTriplet Loss:0.1381\tStatic Loss:0.2498\n",
      "\n",
      "\tTime:59.7497\n",
      "\n",
      "Test Loss:0.8379\tRecon Loss:5.8630\tTriplet Loss:0.4390\tStatic Loss:0.8276\n",
      "\n",
      "\tEpoch:115\tTrain Loss:0.1771\tRecon Loss:1.8364\tTriplet Loss:0.1037\tStatic Loss:0.1679\t\n",
      "Val Loss:0.2598\tRecon Loss:1.9409\tTriplet Loss:0.1429\tStatic Loss:0.2547\n",
      "\n",
      "\tTime:59.0345\n",
      "\n",
      "Test Loss:0.8275\tRecon Loss:5.8911\tTriplet Loss:0.4358\tStatic Loss:0.8160\n",
      "\n",
      "\tEpoch:116\tTrain Loss:0.1765\tRecon Loss:1.8312\tTriplet Loss:0.1073\tStatic Loss:0.1669\t\n",
      "Val Loss:0.2569\tRecon Loss:1.9555\tTriplet Loss:0.1429\tStatic Loss:0.2514\n",
      "\n",
      "\tTime:60.6329\n",
      "\n",
      "Test Loss:0.8414\tRecon Loss:5.8099\tTriplet Loss:0.4494\tStatic Loss:0.8309\n",
      "\n",
      "\tEpoch:117\tTrain Loss:0.1764\tRecon Loss:1.8725\tTriplet Loss:0.1005\tStatic Loss:0.1670\t\n",
      "Val Loss:0.2566\tRecon Loss:1.9120\tTriplet Loss:0.1414\tStatic Loss:0.2515\n",
      "\n",
      "\tTime:58.0735\n",
      "\n",
      "Test Loss:0.8501\tRecon Loss:5.7507\tTriplet Loss:0.4719\tStatic Loss:0.8389\n",
      "\n",
      "\tEpoch:118\tTrain Loss:0.1765\tRecon Loss:1.8503\tTriplet Loss:0.1028\tStatic Loss:0.1671\t\n",
      "Val Loss:0.2548\tRecon Loss:1.9498\tTriplet Loss:0.1447\tStatic Loss:0.2488\n",
      "\n",
      "\tTime:58.2691\n",
      "\n",
      "Test Loss:0.8236\tRecon Loss:5.7499\tTriplet Loss:0.4719\tStatic Loss:0.8095\n",
      "\n",
      "\tEpoch:119\tTrain Loss:0.1752\tRecon Loss:1.8451\tTriplet Loss:0.1004\tStatic Loss:0.1660\t\n",
      "Val Loss:0.2547\tRecon Loss:1.9088\tTriplet Loss:0.1406\tStatic Loss:0.2495\n",
      "\n",
      "\tTime:59.7936\n",
      "\n",
      "Test Loss:0.8210\tRecon Loss:5.7051\tTriplet Loss:0.4848\tStatic Loss:0.8057\n",
      "\n",
      "\tEpoch:120\tTrain Loss:0.1810\tRecon Loss:1.8436\tTriplet Loss:0.1106\tStatic Loss:0.1715\t\n",
      "Val Loss:0.2583\tRecon Loss:1.9354\tTriplet Loss:0.1396\tStatic Loss:0.2534\n",
      "\n",
      "\tTime:60.5224\n",
      "\n",
      "Test Loss:0.8312\tRecon Loss:5.8459\tTriplet Loss:0.4491\tStatic Loss:0.8192\n",
      "\n",
      "\tEpoch:121\tTrain Loss:0.1777\tRecon Loss:1.8426\tTriplet Loss:0.0981\tStatic Loss:0.1690\t\n",
      "Val Loss:0.2571\tRecon Loss:1.9286\tTriplet Loss:0.1330\tStatic Loss:0.2528\n",
      "\n",
      "\tTime:58.6816\n",
      "\n",
      "Test Loss:0.8247\tRecon Loss:5.7830\tTriplet Loss:0.4229\tStatic Loss:0.8153\n",
      "\n",
      "\tEpoch:122\tTrain Loss:0.1772\tRecon Loss:1.8359\tTriplet Loss:0.1073\tStatic Loss:0.1676\t\n",
      "Val Loss:0.2566\tRecon Loss:1.9212\tTriplet Loss:0.1395\tStatic Loss:0.2517\n",
      "\n",
      "\tTime:59.2743\n",
      "\n",
      "Test Loss:0.8205\tRecon Loss:5.7568\tTriplet Loss:0.4466\tStatic Loss:0.8085\n",
      "\n",
      "\tEpoch:123\tTrain Loss:0.1778\tRecon Loss:1.8369\tTriplet Loss:0.1031\tStatic Loss:0.1686\t\n",
      "Val Loss:0.2538\tRecon Loss:1.9053\tTriplet Loss:0.1427\tStatic Loss:0.2484\n",
      "\n",
      "\tTime:59.5559\n",
      "\n",
      "Test Loss:0.8130\tRecon Loss:5.6942\tTriplet Loss:0.4448\tStatic Loss:0.8010\n",
      "\n",
      "\tEpoch:124\tTrain Loss:0.1768\tRecon Loss:1.8371\tTriplet Loss:0.1039\tStatic Loss:0.1675\t\n",
      "Val Loss:0.2591\tRecon Loss:1.9477\tTriplet Loss:0.1352\tStatic Loss:0.2546\n",
      "\n",
      "\tTime:59.1115\n",
      "\n",
      "Test Loss:0.8393\tRecon Loss:5.7754\tTriplet Loss:0.4476\tStatic Loss:0.8291\n",
      "\n",
      "\tEpoch:125\tTrain Loss:0.1775\tRecon Loss:1.8431\tTriplet Loss:0.1026\tStatic Loss:0.1683\t\n",
      "Val Loss:0.2562\tRecon Loss:1.9535\tTriplet Loss:0.1338\tStatic Loss:0.2514\n",
      "\n",
      "\tTime:60.5619\n",
      "\n",
      "Test Loss:0.8164\tRecon Loss:5.9299\tTriplet Loss:0.4183\tStatic Loss:0.8050\n",
      "\n",
      "\tEpoch:126\tTrain Loss:0.1779\tRecon Loss:1.9042\tTriplet Loss:0.1016\tStatic Loss:0.1683\t\n",
      "Val Loss:0.2564\tRecon Loss:1.9365\tTriplet Loss:0.1345\tStatic Loss:0.2518\n",
      "\n",
      "\tTime:61.5679\n",
      "\n",
      "Test Loss:0.8264\tRecon Loss:5.8198\tTriplet Loss:0.4573\tStatic Loss:0.8134\n",
      "\n",
      "\tEpoch:127\tTrain Loss:0.1772\tRecon Loss:1.8435\tTriplet Loss:0.0995\tStatic Loss:0.1683\t\n",
      "Val Loss:0.2571\tRecon Loss:1.9230\tTriplet Loss:0.1407\tStatic Loss:0.2520\n",
      "\n",
      "\tTime:60.4204\n",
      "\n",
      "Test Loss:0.8399\tRecon Loss:5.8197\tTriplet Loss:0.4300\tStatic Loss:0.8311\n",
      "\n",
      "\tEpoch:128\tTrain Loss:0.1752\tRecon Loss:1.8336\tTriplet Loss:0.1014\tStatic Loss:0.1660\t\n",
      "Val Loss:0.2604\tRecon Loss:1.9210\tTriplet Loss:0.1371\tStatic Loss:0.2561\n",
      "\n",
      "\tTime:60.2302\n",
      "\n",
      "Test Loss:0.8411\tRecon Loss:5.6985\tTriplet Loss:0.4281\tStatic Loss:0.8338\n",
      "\n",
      "\tEpoch:129\tTrain Loss:0.1781\tRecon Loss:1.8345\tTriplet Loss:0.1021\tStatic Loss:0.1692\t\n",
      "Val Loss:0.2555\tRecon Loss:1.9775\tTriplet Loss:0.1319\tStatic Loss:0.2507\n",
      "\n",
      "\tTime:59.8714\n",
      "\n",
      "Test Loss:0.8216\tRecon Loss:5.8078\tTriplet Loss:0.4343\tStatic Loss:0.8105\n",
      "\n",
      "\tEpoch:130\tTrain Loss:0.1744\tRecon Loss:1.8475\tTriplet Loss:0.1021\tStatic Loss:0.1649\t\n",
      "Val Loss:0.2567\tRecon Loss:1.9429\tTriplet Loss:0.1411\tStatic Loss:0.2514\n",
      "\n",
      "\tTime:58.9013\n",
      "\n",
      "Test Loss:0.8600\tRecon Loss:5.8149\tTriplet Loss:0.4650\tStatic Loss:0.8500\n",
      "\n",
      "\tEpoch:131\tTrain Loss:0.1768\tRecon Loss:1.8332\tTriplet Loss:0.1029\tStatic Loss:0.1676\t\n",
      "Val Loss:0.2569\tRecon Loss:1.9339\tTriplet Loss:0.1398\tStatic Loss:0.2519\n",
      "\n",
      "\tTime:57.7339\n",
      "\n",
      "Test Loss:0.8132\tRecon Loss:5.7481\tTriplet Loss:0.4711\tStatic Loss:0.7981\n",
      "\n",
      "\tEpoch:132\tTrain Loss:0.1753\tRecon Loss:1.8253\tTriplet Loss:0.1031\tStatic Loss:0.1660\t\n",
      "Val Loss:0.2557\tRecon Loss:1.9196\tTriplet Loss:0.1296\tStatic Loss:0.2517\n",
      "\n",
      "\tTime:57.5584\n",
      "\n",
      "Test Loss:0.8309\tRecon Loss:5.7828\tTriplet Loss:0.4562\tStatic Loss:0.8189\n",
      "\n",
      "\tEpoch:133\tTrain Loss:0.1769\tRecon Loss:1.8449\tTriplet Loss:0.1046\tStatic Loss:0.1674\t\n",
      "Val Loss:0.2547\tRecon Loss:1.9200\tTriplet Loss:0.1399\tStatic Loss:0.2496\n",
      "\n",
      "\tTime:58.7766\n",
      "\n",
      "Test Loss:0.8242\tRecon Loss:5.7312\tTriplet Loss:0.4526\tStatic Loss:0.8123\n",
      "\n",
      "\tEpoch:134\tTrain Loss:0.1790\tRecon Loss:1.8290\tTriplet Loss:0.1068\tStatic Loss:0.1697\t\n",
      "Val Loss:0.2582\tRecon Loss:1.9354\tTriplet Loss:0.1323\tStatic Loss:0.2540\n",
      "\n",
      "\tTime:57.1325\n",
      "\n",
      "Test Loss:0.8209\tRecon Loss:5.7269\tTriplet Loss:0.4637\tStatic Loss:0.8075\n",
      "\n",
      "\tEpoch:135\tTrain Loss:0.1735\tRecon Loss:1.8309\tTriplet Loss:0.1005\tStatic Loss:0.1642\t\n",
      "Val Loss:0.2610\tRecon Loss:1.9973\tTriplet Loss:0.1405\tStatic Loss:0.2557\n",
      "\n",
      "\tTime:58.5249\n",
      "\n",
      "Test Loss:0.8271\tRecon Loss:5.8389\tTriplet Loss:0.4453\tStatic Loss:0.8152\n",
      "\n",
      "\tEpoch:136\tTrain Loss:0.1742\tRecon Loss:1.8411\tTriplet Loss:0.0998\tStatic Loss:0.1650\t\n",
      "Val Loss:0.2561\tRecon Loss:2.0014\tTriplet Loss:0.1305\tStatic Loss:0.2512\n",
      "\n",
      "\tTime:59.0992\n",
      "\n",
      "Test Loss:0.8197\tRecon Loss:5.8903\tTriplet Loss:0.4268\tStatic Loss:0.8083\n",
      "\n",
      "\tEpoch:137\tTrain Loss:0.1743\tRecon Loss:1.8442\tTriplet Loss:0.1053\tStatic Loss:0.1645\t\n",
      "Val Loss:0.2548\tRecon Loss:1.9278\tTriplet Loss:0.1299\tStatic Loss:0.2506\n",
      "\n",
      "\tTime:58.6957\n",
      "\n",
      "Test Loss:0.8238\tRecon Loss:5.7294\tTriplet Loss:0.4366\tStatic Loss:0.8135\n",
      "\n",
      "\tEpoch:138\tTrain Loss:0.1821\tRecon Loss:1.8352\tTriplet Loss:0.1081\tStatic Loss:0.1730\t\n",
      "Val Loss:0.2595\tRecon Loss:1.9608\tTriplet Loss:0.1376\tStatic Loss:0.2547\n",
      "\n",
      "\tTime:61.2350\n",
      "\n",
      "Test Loss:0.8204\tRecon Loss:5.9757\tTriplet Loss:0.4410\tStatic Loss:0.8068\n",
      "\n",
      "\tEpoch:139\tTrain Loss:0.1768\tRecon Loss:1.8252\tTriplet Loss:0.1043\tStatic Loss:0.1676\t\n",
      "Val Loss:0.2537\tRecon Loss:1.9013\tTriplet Loss:0.1348\tStatic Loss:0.2491\n",
      "\n",
      "\tTime:59.5549\n",
      "\n",
      "Test Loss:0.8248\tRecon Loss:5.7199\tTriplet Loss:0.4443\tStatic Loss:0.8139\n",
      "\n",
      "\tEpoch:140\tTrain Loss:0.1734\tRecon Loss:1.8381\tTriplet Loss:0.1042\tStatic Loss:0.1637\t\n",
      "Val Loss:0.2562\tRecon Loss:2.0203\tTriplet Loss:0.1254\tStatic Loss:0.2517\n",
      "\n",
      "\tTime:57.9047\n",
      "\n",
      "Test Loss:0.8308\tRecon Loss:5.8754\tTriplet Loss:0.4659\tStatic Loss:0.8169\n",
      "\n",
      "\tEpoch:141\tTrain Loss:0.1736\tRecon Loss:1.8315\tTriplet Loss:0.1042\tStatic Loss:0.1640\t\n",
      "Val Loss:0.2536\tRecon Loss:1.9605\tTriplet Loss:0.1448\tStatic Loss:0.2475\n",
      "\n",
      "\tTime:60.2899\n",
      "\n",
      "Test Loss:0.8123\tRecon Loss:5.7137\tTriplet Loss:0.4272\tStatic Loss:0.8018\n",
      "\n",
      "\tEpoch:142\tTrain Loss:0.1738\tRecon Loss:1.8430\tTriplet Loss:0.1002\tStatic Loss:0.1645\t\n",
      "Val Loss:0.2519\tRecon Loss:1.9177\tTriplet Loss:0.1328\tStatic Loss:0.2472\n",
      "\n",
      "\tTime:58.1690\n",
      "\n",
      "Test Loss:0.8172\tRecon Loss:5.6681\tTriplet Loss:0.4519\tStatic Loss:0.8052\n",
      "\n",
      "\tEpoch:143\tTrain Loss:0.1840\tRecon Loss:1.8374\tTriplet Loss:0.1059\tStatic Loss:0.1753\t\n",
      "Val Loss:0.2544\tRecon Loss:1.9282\tTriplet Loss:0.1476\tStatic Loss:0.2484\n",
      "\n",
      "\tTime:59.4453\n",
      "\n",
      "Test Loss:0.8261\tRecon Loss:5.7496\tTriplet Loss:0.4338\tStatic Loss:0.8161\n",
      "\n",
      "\tEpoch:144\tTrain Loss:0.1810\tRecon Loss:1.8307\tTriplet Loss:0.1044\tStatic Loss:0.1721\t\n",
      "Val Loss:0.2590\tRecon Loss:1.9387\tTriplet Loss:0.1374\tStatic Loss:0.2543\n",
      "\n",
      "\tTime:60.8462\n",
      "\n",
      "Test Loss:0.8392\tRecon Loss:5.6988\tTriplet Loss:0.4566\tStatic Loss:0.8289\n",
      "\n",
      "\tEpoch:145\tTrain Loss:0.1757\tRecon Loss:1.8290\tTriplet Loss:0.1060\tStatic Loss:0.1661\t\n",
      "Val Loss:0.2523\tRecon Loss:1.9245\tTriplet Loss:0.1317\tStatic Loss:0.2477\n",
      "\n",
      "\tTime:59.2658\n",
      "\n",
      "Test Loss:0.8283\tRecon Loss:5.7174\tTriplet Loss:0.4182\tStatic Loss:0.8204\n",
      "\n",
      "\tEpoch:146\tTrain Loss:0.1771\tRecon Loss:1.8497\tTriplet Loss:0.1022\tStatic Loss:0.1679\t\n",
      "Val Loss:0.2550\tRecon Loss:2.0006\tTriplet Loss:0.1307\tStatic Loss:0.2500\n",
      "\n",
      "\tTime:60.9813\n",
      "\n",
      "Test Loss:0.8189\tRecon Loss:5.8980\tTriplet Loss:0.4373\tStatic Loss:0.8063\n",
      "\n",
      "\tEpoch:147\tTrain Loss:0.1754\tRecon Loss:1.8253\tTriplet Loss:0.1074\tStatic Loss:0.1657\t\n",
      "Val Loss:0.2497\tRecon Loss:1.9338\tTriplet Loss:0.1345\tStatic Loss:0.2444\n",
      "\n",
      "\tTime:58.9937\n",
      "\n",
      "Test Loss:0.8140\tRecon Loss:5.7409\tTriplet Loss:0.4367\tStatic Loss:0.8025\n",
      "\n",
      "\tEpoch:148\tTrain Loss:0.1740\tRecon Loss:1.8378\tTriplet Loss:0.1057\tStatic Loss:0.1642\t\n",
      "Val Loss:0.2530\tRecon Loss:1.9635\tTriplet Loss:0.1308\tStatic Loss:0.2482\n",
      "\n",
      "\tTime:58.4507\n",
      "\n",
      "Test Loss:0.8396\tRecon Loss:5.8683\tTriplet Loss:0.4510\tStatic Loss:0.8282\n",
      "\n",
      "\tEpoch:149\tTrain Loss:0.1739\tRecon Loss:1.8383\tTriplet Loss:0.1029\tStatic Loss:0.1643\t\n",
      "Val Loss:0.2543\tRecon Loss:1.9321\tTriplet Loss:0.1243\tStatic Loss:0.2505\n",
      "\n",
      "\tTime:58.4002\n",
      "\n",
      "Test Loss:0.8483\tRecon Loss:5.6981\tTriplet Loss:0.4435\tStatic Loss:0.8403\n",
      "\n",
      "\tEpoch:150\tTrain Loss:0.1716\tRecon Loss:1.8251\tTriplet Loss:0.1041\tStatic Loss:0.1618\t\n",
      "Val Loss:0.2540\tRecon Loss:1.9055\tTriplet Loss:0.1405\tStatic Loss:0.2489\n",
      "\n",
      "\tTime:59.1193\n",
      "\n",
      "Test Loss:0.8210\tRecon Loss:5.7945\tTriplet Loss:0.4254\tStatic Loss:0.8109\n",
      "\n",
      "\tEpoch:151\tTrain Loss:0.1829\tRecon Loss:1.8380\tTriplet Loss:0.1043\tStatic Loss:0.1742\t\n",
      "Val Loss:0.2551\tRecon Loss:1.9363\tTriplet Loss:0.1218\tStatic Loss:0.2516\n",
      "\n",
      "\tTime:59.1447\n",
      "\n",
      "Test Loss:0.8397\tRecon Loss:5.7398\tTriplet Loss:0.4446\tStatic Loss:0.8302\n",
      "\n",
      "\tEpoch:152\tTrain Loss:0.1739\tRecon Loss:1.8334\tTriplet Loss:0.1014\tStatic Loss:0.1646\t\n",
      "Val Loss:0.2542\tRecon Loss:1.9716\tTriplet Loss:0.1403\tStatic Loss:0.2485\n",
      "\n",
      "\tTime:57.5093\n",
      "\n",
      "Test Loss:0.8435\tRecon Loss:5.8696\tTriplet Loss:0.4441\tStatic Loss:0.8332\n",
      "\n",
      "\tEpoch:153\tTrain Loss:0.1764\tRecon Loss:1.8287\tTriplet Loss:0.1064\tStatic Loss:0.1669\t\n",
      "Val Loss:0.2578\tRecon Loss:1.9591\tTriplet Loss:0.1346\tStatic Loss:0.2531\n",
      "\n",
      "\tTime:56.8321\n",
      "\n",
      "Test Loss:0.8453\tRecon Loss:5.7866\tTriplet Loss:0.4641\tStatic Loss:0.8340\n",
      "\n",
      "\tEpoch:154\tTrain Loss:0.1795\tRecon Loss:1.8520\tTriplet Loss:0.1038\tStatic Loss:0.1704\t\n",
      "Val Loss:0.2540\tRecon Loss:1.9067\tTriplet Loss:0.1332\tStatic Loss:0.2495\n",
      "\n",
      "\tTime:57.6463\n",
      "\n",
      "Test Loss:0.8482\tRecon Loss:5.7139\tTriplet Loss:0.4621\tStatic Loss:0.8382\n",
      "\n",
      "\tEpoch:155\tTrain Loss:0.1754\tRecon Loss:1.8345\tTriplet Loss:0.1039\tStatic Loss:0.1659\t\n",
      "Val Loss:0.2574\tRecon Loss:2.0092\tTriplet Loss:0.1315\tStatic Loss:0.2524\n",
      "\n",
      "\tTime:58.5974\n",
      "\n",
      "Test Loss:0.8293\tRecon Loss:5.9822\tTriplet Loss:0.4458\tStatic Loss:0.8161\n",
      "\n",
      "\tEpoch:156\tTrain Loss:0.1740\tRecon Loss:1.8577\tTriplet Loss:0.1069\tStatic Loss:0.1639\t\n",
      "Val Loss:0.2552\tRecon Loss:1.9689\tTriplet Loss:0.1278\tStatic Loss:0.2509\n",
      "\n",
      "\tTime:58.2458\n",
      "\n",
      "Test Loss:0.8464\tRecon Loss:5.8334\tTriplet Loss:0.4715\tStatic Loss:0.8341\n",
      "\n",
      "\tEpoch:157\tTrain Loss:0.1788\tRecon Loss:1.8379\tTriplet Loss:0.1064\tStatic Loss:0.1694\t\n",
      "Val Loss:0.2582\tRecon Loss:1.9566\tTriplet Loss:0.1421\tStatic Loss:0.2528\n",
      "\n",
      "\tTime:57.2831\n",
      "\n",
      "Test Loss:0.8308\tRecon Loss:5.8408\tTriplet Loss:0.4247\tStatic Loss:0.8213\n",
      "\n",
      "\tEpoch:158\tTrain Loss:0.1743\tRecon Loss:1.8271\tTriplet Loss:0.1055\tStatic Loss:0.1646\t\n",
      "Val Loss:0.2505\tRecon Loss:1.9258\tTriplet Loss:0.1312\tStatic Loss:0.2457\n",
      "\n",
      "\tTime:58.3907\n",
      "\n",
      "Test Loss:0.8672\tRecon Loss:5.7611\tTriplet Loss:0.4494\tStatic Loss:0.8600\n",
      "\n",
      "\tEpoch:159\tTrain Loss:0.1711\tRecon Loss:1.8191\tTriplet Loss:0.1059\tStatic Loss:0.1612\t\n",
      "Val Loss:0.2550\tRecon Loss:1.9668\tTriplet Loss:0.1368\tStatic Loss:0.2497\n",
      "\n",
      "\tTime:59.0805\n",
      "\n",
      "Test Loss:0.8401\tRecon Loss:5.8624\tTriplet Loss:0.4376\tStatic Loss:0.8301\n",
      "\n",
      "\tEpoch:160\tTrain Loss:0.1794\tRecon Loss:1.8472\tTriplet Loss:0.1051\tStatic Loss:0.1702\t\n",
      "Val Loss:0.2499\tRecon Loss:1.9545\tTriplet Loss:0.1293\tStatic Loss:0.2450\n",
      "\n",
      "\tTime:59.3052\n",
      "\n",
      "Test Loss:0.8252\tRecon Loss:5.7757\tTriplet Loss:0.4481\tStatic Loss:0.8134\n",
      "\n",
      "\tEpoch:161\tTrain Loss:0.1714\tRecon Loss:1.8311\tTriplet Loss:0.1009\tStatic Loss:0.1619\t\n",
      "Val Loss:0.2525\tRecon Loss:1.9138\tTriplet Loss:0.1278\tStatic Loss:0.2483\n",
      "\n",
      "\tTime:56.5027\n",
      "\n",
      "Test Loss:0.8313\tRecon Loss:5.7572\tTriplet Loss:0.4510\tStatic Loss:0.8201\n",
      "\n",
      "\tEpoch:162\tTrain Loss:0.1734\tRecon Loss:1.8376\tTriplet Loss:0.1037\tStatic Loss:0.1637\t\n",
      "Val Loss:0.2493\tRecon Loss:1.9339\tTriplet Loss:0.1377\tStatic Loss:0.2436\n",
      "\n",
      "\tTime:59.9068\n",
      "\n",
      "Test Loss:0.8267\tRecon Loss:5.8275\tTriplet Loss:0.4436\tStatic Loss:0.8150\n",
      "\n",
      "\tEpoch:163\tTrain Loss:0.1837\tRecon Loss:1.8292\tTriplet Loss:0.1072\tStatic Loss:0.1749\t\n",
      "Val Loss:0.2507\tRecon Loss:1.9116\tTriplet Loss:0.1261\tStatic Loss:0.2465\n",
      "\n",
      "\tTime:58.7743\n",
      "\n",
      "Test Loss:0.8342\tRecon Loss:5.7239\tTriplet Loss:0.4396\tStatic Loss:0.8247\n",
      "\n",
      "\tEpoch:164\tTrain Loss:0.1915\tRecon Loss:1.8651\tTriplet Loss:0.1053\tStatic Loss:0.1834\t\n",
      "Val Loss:0.2545\tRecon Loss:1.9191\tTriplet Loss:0.1450\tStatic Loss:0.2488\n",
      "\n",
      "\tTime:57.4407\n",
      "\n",
      "Test Loss:0.8368\tRecon Loss:5.7670\tTriplet Loss:0.4464\tStatic Loss:0.8266\n",
      "\n",
      "\tEpoch:165\tTrain Loss:0.1845\tRecon Loss:1.8256\tTriplet Loss:0.1072\tStatic Loss:0.1758\t\n",
      "Val Loss:0.2521\tRecon Loss:1.9208\tTriplet Loss:0.1407\tStatic Loss:0.2466\n",
      "\n",
      "\tTime:57.8488\n",
      "\n",
      "Test Loss:0.8330\tRecon Loss:5.7687\tTriplet Loss:0.4313\tStatic Loss:0.8238\n",
      "\n",
      "\tEpoch:166\tTrain Loss:0.1798\tRecon Loss:1.8300\tTriplet Loss:0.1052\tStatic Loss:0.1707\t\n",
      "Val Loss:0.2484\tRecon Loss:1.8921\tTriplet Loss:0.1257\tStatic Loss:0.2442\n",
      "\n",
      "\tTime:59.7645\n",
      "\n",
      "Test Loss:0.8136\tRecon Loss:5.7580\tTriplet Loss:0.4294\tStatic Loss:0.8026\n",
      "\n",
      "\tEpoch:167\tTrain Loss:0.1813\tRecon Loss:1.8313\tTriplet Loss:0.1042\tStatic Loss:0.1725\t\n",
      "Val Loss:0.2621\tRecon Loss:1.9558\tTriplet Loss:0.1278\tStatic Loss:0.2586\n",
      "\n",
      "\tTime:57.2273\n",
      "\n",
      "Test Loss:0.8429\tRecon Loss:5.8795\tTriplet Loss:0.4534\tStatic Loss:0.8315\n",
      "\n",
      "\tEpoch:168\tTrain Loss:0.1827\tRecon Loss:1.8382\tTriplet Loss:0.1021\tStatic Loss:0.1742\t\n",
      "Val Loss:0.2529\tRecon Loss:1.9134\tTriplet Loss:0.1393\tStatic Loss:0.2476\n",
      "\n",
      "\tTime:57.8307\n",
      "\n",
      "Test Loss:0.8223\tRecon Loss:5.7401\tTriplet Loss:0.4106\tStatic Loss:0.8143\n",
      "\n",
      "\tEpoch:169\tTrain Loss:0.1745\tRecon Loss:1.8248\tTriplet Loss:0.0982\tStatic Loss:0.1657\t\n",
      "Val Loss:0.2511\tRecon Loss:1.8974\tTriplet Loss:0.1298\tStatic Loss:0.2468\n",
      "\n",
      "\tTime:59.9214\n",
      "\n",
      "Test Loss:0.8345\tRecon Loss:5.7499\tTriplet Loss:0.4607\tStatic Loss:0.8227\n",
      "\n",
      "\tEpoch:170\tTrain Loss:0.1738\tRecon Loss:1.8218\tTriplet Loss:0.1043\tStatic Loss:0.1643\t\n",
      "Val Loss:0.2527\tRecon Loss:1.9250\tTriplet Loss:0.1434\tStatic Loss:0.2469\n",
      "\n",
      "\tTime:56.9531\n",
      "\n",
      "Test Loss:0.8242\tRecon Loss:5.8590\tTriplet Loss:0.4172\tStatic Loss:0.8146\n",
      "\n",
      "\tEpoch:171\tTrain Loss:0.1714\tRecon Loss:1.8239\tTriplet Loss:0.1009\tStatic Loss:0.1619\t\n",
      "Val Loss:0.2528\tRecon Loss:1.9274\tTriplet Loss:0.1250\tStatic Loss:0.2488\n",
      "\n",
      "\tTime:58.4121\n",
      "\n",
      "Test Loss:0.8435\tRecon Loss:5.8030\tTriplet Loss:0.4573\tStatic Loss:0.8325\n",
      "\n",
      "\tEpoch:172\tTrain Loss:0.1739\tRecon Loss:1.8348\tTriplet Loss:0.1018\tStatic Loss:0.1645\t\n",
      "Val Loss:0.2533\tRecon Loss:1.9106\tTriplet Loss:0.1423\tStatic Loss:0.2478\n",
      "\n",
      "\tTime:57.6652\n",
      "\n",
      "Test Loss:0.8367\tRecon Loss:5.8509\tTriplet Loss:0.4391\tStatic Loss:0.8263\n",
      "\n",
      "\tEpoch:173\tTrain Loss:0.1729\tRecon Loss:1.8383\tTriplet Loss:0.1034\tStatic Loss:0.1632\t\n",
      "Val Loss:0.2531\tRecon Loss:1.9213\tTriplet Loss:0.1388\tStatic Loss:0.2478\n",
      "\n",
      "\tTime:57.1775\n",
      "\n",
      "Test Loss:0.8491\tRecon Loss:5.7470\tTriplet Loss:0.4529\tStatic Loss:0.8397\n",
      "\n",
      "\tEpoch:174\tTrain Loss:0.1772\tRecon Loss:1.8360\tTriplet Loss:0.0997\tStatic Loss:0.1684\t\n",
      "Val Loss:0.2491\tRecon Loss:1.9198\tTriplet Loss:0.1329\tStatic Loss:0.2440\n",
      "\n",
      "\tTime:57.4429\n",
      "\n",
      "Test Loss:0.8128\tRecon Loss:5.7883\tTriplet Loss:0.4282\tStatic Loss:0.8015\n",
      "\n",
      "\tEpoch:175\tTrain Loss:0.1727\tRecon Loss:1.8250\tTriplet Loss:0.1005\tStatic Loss:0.1634\t\n",
      "Val Loss:0.2529\tRecon Loss:1.9013\tTriplet Loss:0.1325\tStatic Loss:0.2485\n",
      "\n",
      "\tTime:59.2553\n",
      "\n",
      "Test Loss:0.8193\tRecon Loss:5.7831\tTriplet Loss:0.4288\tStatic Loss:0.8087\n",
      "\n",
      "\tEpoch:176\tTrain Loss:0.1713\tRecon Loss:1.8257\tTriplet Loss:0.0961\tStatic Loss:0.1623\t\n",
      "Val Loss:0.2507\tRecon Loss:1.9207\tTriplet Loss:0.1309\tStatic Loss:0.2460\n",
      "\n",
      "\tTime:56.7739\n",
      "\n",
      "Test Loss:0.8177\tRecon Loss:5.7350\tTriplet Loss:0.4269\tStatic Loss:0.8076\n",
      "\n",
      "\tEpoch:177\tTrain Loss:0.1702\tRecon Loss:1.8306\tTriplet Loss:0.1014\tStatic Loss:0.1605\t\n",
      "Val Loss:0.2549\tRecon Loss:1.9629\tTriplet Loss:0.1267\tStatic Loss:0.2507\n",
      "\n",
      "\tTime:59.0556\n",
      "\n",
      "Test Loss:0.8336\tRecon Loss:6.0418\tTriplet Loss:0.4465\tStatic Loss:0.8202\n",
      "\n",
      "\tEpoch:178\tTrain Loss:0.1715\tRecon Loss:1.8361\tTriplet Loss:0.1006\tStatic Loss:0.1620\t\n",
      "Val Loss:0.2538\tRecon Loss:1.9290\tTriplet Loss:0.1340\tStatic Loss:0.2491\n",
      "\n",
      "\tTime:58.4666\n",
      "\n",
      "Test Loss:0.8431\tRecon Loss:5.7875\tTriplet Loss:0.4607\tStatic Loss:0.8319\n",
      "\n",
      "\tEpoch:179\tTrain Loss:0.1692\tRecon Loss:1.8314\tTriplet Loss:0.0981\tStatic Loss:0.1596\t\n",
      "Val Loss:0.2563\tRecon Loss:1.8936\tTriplet Loss:0.1469\tStatic Loss:0.2508\n",
      "\n",
      "\tTime:59.1187\n",
      "\n",
      "Test Loss:0.8353\tRecon Loss:5.6940\tTriplet Loss:0.4575\tStatic Loss:0.8244\n",
      "\n",
      "\tEpoch:180\tTrain Loss:0.1748\tRecon Loss:1.8277\tTriplet Loss:0.1037\tStatic Loss:0.1654\t\n",
      "Val Loss:0.2536\tRecon Loss:1.9288\tTriplet Loss:0.1434\tStatic Loss:0.2479\n",
      "\n",
      "\tTime:58.0159\n",
      "\n",
      "Test Loss:0.8260\tRecon Loss:5.7180\tTriplet Loss:0.4261\tStatic Loss:0.8171\n",
      "\n",
      "\tEpoch:181\tTrain Loss:0.1746\tRecon Loss:1.8403\tTriplet Loss:0.1003\tStatic Loss:0.1653\t\n",
      "Val Loss:0.2562\tRecon Loss:1.9208\tTriplet Loss:0.1406\tStatic Loss:0.2511\n",
      "\n",
      "\tTime:60.5207\n",
      "\n",
      "Test Loss:0.8306\tRecon Loss:5.8140\tTriplet Loss:0.4293\tStatic Loss:0.8209\n",
      "\n",
      "\tEpoch:182\tTrain Loss:0.1695\tRecon Loss:1.8215\tTriplet Loss:0.1000\tStatic Loss:0.1600\t\n",
      "Val Loss:0.2528\tRecon Loss:1.9144\tTriplet Loss:0.1350\tStatic Loss:0.2480\n",
      "\n",
      "\tTime:60.0881\n",
      "\n",
      "Test Loss:0.8223\tRecon Loss:5.7504\tTriplet Loss:0.4536\tStatic Loss:0.8098\n",
      "\n",
      "\tEpoch:183\tTrain Loss:0.1694\tRecon Loss:1.8211\tTriplet Loss:0.1045\tStatic Loss:0.1594\t\n",
      "Val Loss:0.2523\tRecon Loss:1.9141\tTriplet Loss:0.1263\tStatic Loss:0.2482\n",
      "\n",
      "\tTime:60.2954\n",
      "\n",
      "Test Loss:0.8262\tRecon Loss:5.9887\tTriplet Loss:0.4419\tStatic Loss:0.8130\n",
      "\n",
      "\tEpoch:184\tTrain Loss:0.1754\tRecon Loss:1.8377\tTriplet Loss:0.1068\tStatic Loss:0.1656\t\n",
      "Val Loss:0.2524\tRecon Loss:1.9391\tTriplet Loss:0.1230\tStatic Loss:0.2485\n",
      "\n",
      "\tTime:59.3054\n",
      "\n",
      "Test Loss:0.8394\tRecon Loss:5.8725\tTriplet Loss:0.4497\tStatic Loss:0.8281\n",
      "\n",
      "\tEpoch:185\tTrain Loss:0.1717\tRecon Loss:1.8340\tTriplet Loss:0.0988\tStatic Loss:0.1623\t\n",
      "Val Loss:0.2524\tRecon Loss:1.9151\tTriplet Loss:0.1403\tStatic Loss:0.2470\n",
      "\n",
      "\tTime:61.1147\n",
      "\n",
      "Test Loss:0.8444\tRecon Loss:5.7749\tTriplet Loss:0.4554\tStatic Loss:0.8340\n",
      "\n",
      "\tEpoch:186\tTrain Loss:0.1701\tRecon Loss:1.8285\tTriplet Loss:0.0971\tStatic Loss:0.1608\t\n",
      "Val Loss:0.2528\tRecon Loss:1.9518\tTriplet Loss:0.1368\tStatic Loss:0.2474\n",
      "\n",
      "\tTime:59.2911\n",
      "\n",
      "Test Loss:0.8355\tRecon Loss:5.8810\tTriplet Loss:0.4368\tStatic Loss:0.8250\n",
      "\n",
      "\tEpoch:187\tTrain Loss:0.1744\tRecon Loss:1.8435\tTriplet Loss:0.1042\tStatic Loss:0.1647\t\n",
      "Val Loss:0.2601\tRecon Loss:1.9577\tTriplet Loss:0.1364\tStatic Loss:0.2555\n",
      "\n",
      "\tTime:58.6583\n",
      "\n",
      "Test Loss:0.8389\tRecon Loss:5.8218\tTriplet Loss:0.4646\tStatic Loss:0.8265\n",
      "\n",
      "\tEpoch:188\tTrain Loss:0.1727\tRecon Loss:1.8309\tTriplet Loss:0.1027\tStatic Loss:0.1632\t\n",
      "Val Loss:0.2544\tRecon Loss:1.9342\tTriplet Loss:0.1357\tStatic Loss:0.2495\n",
      "\n",
      "\tTime:59.7322\n",
      "\n",
      "Test Loss:0.8386\tRecon Loss:5.8274\tTriplet Loss:0.4760\tStatic Loss:0.8249\n",
      "\n",
      "\tEpoch:189\tTrain Loss:0.1702\tRecon Loss:1.8217\tTriplet Loss:0.0994\tStatic Loss:0.1607\t\n",
      "Val Loss:0.2516\tRecon Loss:1.9416\tTriplet Loss:0.1389\tStatic Loss:0.2460\n",
      "\n",
      "\tTime:60.3742\n",
      "\n",
      "Test Loss:0.8255\tRecon Loss:5.7868\tTriplet Loss:0.4440\tStatic Loss:0.8140\n",
      "\n",
      "\tEpoch:190\tTrain Loss:0.1695\tRecon Loss:1.8231\tTriplet Loss:0.0988\tStatic Loss:0.1601\t\n",
      "Val Loss:0.2557\tRecon Loss:1.9358\tTriplet Loss:0.1462\tStatic Loss:0.2498\n",
      "\n",
      "\tTime:59.9659\n",
      "\n",
      "Test Loss:0.8409\tRecon Loss:5.8707\tTriplet Loss:0.4275\tStatic Loss:0.8319\n",
      "\n",
      "\tEpoch:191\tTrain Loss:0.1685\tRecon Loss:1.8312\tTriplet Loss:0.0964\tStatic Loss:0.1591\t\n",
      "Val Loss:0.2502\tRecon Loss:1.9605\tTriplet Loss:0.1200\tStatic Loss:0.2461\n",
      "\n",
      "\tTime:62.0664\n",
      "\n",
      "Test Loss:0.8233\tRecon Loss:5.9073\tTriplet Loss:0.4291\tStatic Loss:0.8119\n",
      "\n",
      "\tEpoch:192\tTrain Loss:0.1744\tRecon Loss:1.8619\tTriplet Loss:0.0988\tStatic Loss:0.1651\t\n",
      "Val Loss:0.2535\tRecon Loss:1.9481\tTriplet Loss:0.1403\tStatic Loss:0.2479\n",
      "\n",
      "\tTime:60.0235\n",
      "\n",
      "Test Loss:0.8194\tRecon Loss:5.9164\tTriplet Loss:0.4476\tStatic Loss:0.8057\n",
      "\n",
      "\tEpoch:193\tTrain Loss:0.1695\tRecon Loss:1.8292\tTriplet Loss:0.0964\tStatic Loss:0.1602\t\n",
      "Val Loss:0.2549\tRecon Loss:1.9299\tTriplet Loss:0.1380\tStatic Loss:0.2498\n",
      "\n",
      "\tTime:62.5745\n",
      "\n",
      "Test Loss:0.8343\tRecon Loss:5.7322\tTriplet Loss:0.4582\tStatic Loss:0.8230\n",
      "\n",
      "\tEpoch:194\tTrain Loss:0.3618\tRecon Loss:5.9220\tTriplet Loss:0.2646\tStatic Loss:0.3159\t\n",
      "Val Loss:0.7577\tRecon Loss:19.6774\tTriplet Loss:0.6722\tStatic Loss:0.5771\n",
      "\n",
      "\tTime:61.6960\n",
      "\n",
      "Test Loss:2.2583\tRecon Loss:59.4421\tTriplet Loss:2.1187\tStatic Loss:1.7004\n",
      "\n",
      "\tEpoch:195\tTrain Loss:0.6796\tRecon Loss:19.5604\tTriplet Loss:0.7467\tStatic Loss:0.4841\t\n",
      "Val Loss:0.6746\tRecon Loss:20.2477\tTriplet Loss:0.7226\tStatic Loss:0.4740\n",
      "\n",
      "\tTime:58.3052\n",
      "\n",
      "Test Loss:2.0414\tRecon Loss:61.4498\tTriplet Loss:2.1982\tStatic Loss:1.4316\n",
      "\n",
      "\tEpoch:196\tTrain Loss:0.6349\tRecon Loss:19.6329\tTriplet Loss:0.7515\tStatic Loss:0.4333\t\n",
      "Val Loss:0.6480\tRecon Loss:20.2343\tTriplet Loss:0.6951\tStatic Loss:0.4474\n",
      "\n",
      "\tTime:58.4009\n",
      "\n",
      "Test Loss:1.9876\tRecon Loss:61.4004\tTriplet Loss:2.2006\tStatic Loss:1.3722\n",
      "\n",
      "\tEpoch:197\tTrain Loss:0.6194\tRecon Loss:19.6297\tTriplet Loss:0.7450\tStatic Loss:0.4168\t\n",
      "Val Loss:0.6376\tRecon Loss:20.2221\tTriplet Loss:0.6943\tStatic Loss:0.4361\n",
      "\n",
      "\tTime:57.7389\n",
      "\n",
      "Test Loss:1.9479\tRecon Loss:61.4212\tTriplet Loss:2.1943\tStatic Loss:1.3285\n",
      "\n",
      "\tEpoch:198\tTrain Loss:0.6108\tRecon Loss:19.6789\tTriplet Loss:0.7530\tStatic Loss:0.4059\t\n",
      "Val Loss:0.6269\tRecon Loss:20.2275\tTriplet Loss:0.6889\tStatic Loss:0.4247\n",
      "\n",
      "\tTime:57.7363\n",
      "\n",
      "Test Loss:1.9269\tRecon Loss:61.6133\tTriplet Loss:2.2057\tStatic Loss:1.3022\n",
      "\n",
      "\tEpoch:199\tTrain Loss:0.6024\tRecon Loss:19.6253\tTriplet Loss:0.7493\tStatic Loss:0.3974\t\n",
      "Val Loss:0.6230\tRecon Loss:20.2173\tTriplet Loss:0.7159\tStatic Loss:0.4177\n",
      "\n",
      "\tTime:56.3482\n",
      "\n",
      "Test Loss:1.9029\tRecon Loss:61.5958\tTriplet Loss:2.1620\tStatic Loss:1.2801\n",
      "\n",
      "\t\n",
      "Unc Est in Static characteristics:0.0000\tUnc Est in Streamflow, dynamic:0.0000\t\n",
      "\n",
      "\tATT_NL_0\n",
      "Epoch:0\tTrain Loss:0.5637\tRecon Loss:4.1172\tTriplet Loss:0.3895\tStatic Loss:0.5456\t\n",
      "Val Loss:0.4223\tRecon Loss:4.0317\tTriplet Loss:0.2513\tStatic Loss:0.4033\n",
      "\n",
      "\tTime:55.7578\n",
      "\n",
      "Test Loss:1.2745\tRecon Loss:11.9376\tTriplet Loss:0.8400\tStatic Loss:1.2113\n",
      "\n",
      "\tEpoch:1\tTrain Loss:0.3834\tRecon Loss:3.9636\tTriplet Loss:0.2460\tStatic Loss:0.3614\t\n",
      "Val Loss:0.3651\tRecon Loss:4.0141\tTriplet Loss:0.1983\tStatic Loss:0.3453\n",
      "\n",
      "\tTime:57.1267\n",
      "\n",
      "Test Loss:1.1008\tRecon Loss:11.8691\tTriplet Loss:0.6657\tStatic Loss:1.0367\n",
      "\n",
      "\tEpoch:2\tTrain Loss:0.3471\tRecon Loss:3.9517\tTriplet Loss:0.2116\tStatic Loss:0.3246\t\n",
      "Val Loss:0.3414\tRecon Loss:4.0080\tTriplet Loss:0.1842\tStatic Loss:0.3205\n",
      "\n",
      "\tTime:59.4152\n",
      "\n",
      "Test Loss:1.0531\tRecon Loss:11.8790\tTriplet Loss:0.6307\tStatic Loss:0.9870\n",
      "\n",
      "\tEpoch:3\tTrain Loss:0.3303\tRecon Loss:3.9258\tTriplet Loss:0.1861\tStatic Loss:0.3088\t\n",
      "Val Loss:0.3296\tRecon Loss:3.9766\tTriplet Loss:0.1659\tStatic Loss:0.3095\n",
      "\n",
      "\tTime:59.7580\n",
      "\n",
      "Test Loss:1.0375\tRecon Loss:11.7958\tTriplet Loss:0.5785\tStatic Loss:0.9758\n",
      "\n",
      "\tEpoch:4\tTrain Loss:0.3152\tRecon Loss:3.7875\tTriplet Loss:0.1772\tStatic Loss:0.2943\t\n",
      "Val Loss:0.3277\tRecon Loss:4.1225\tTriplet Loss:0.1709\tStatic Loss:0.3054\n",
      "\n",
      "\tTime:58.9954\n",
      "\n",
      "Test Loss:1.0436\tRecon Loss:12.1518\tTriplet Loss:0.5904\tStatic Loss:0.9778\n",
      "\n",
      "\tEpoch:5\tTrain Loss:0.3036\tRecon Loss:3.8094\tTriplet Loss:0.1616\tStatic Loss:0.2828\t\n",
      "Val Loss:0.3136\tRecon Loss:3.2894\tTriplet Loss:0.1566\tStatic Loss:0.2995\n",
      "\n",
      "\tTime:58.2548\n",
      "\n",
      "Test Loss:0.9927\tRecon Loss:10.1670\tTriplet Loss:0.5601\tStatic Loss:0.9442\n",
      "\n",
      "\tEpoch:6\tTrain Loss:0.2913\tRecon Loss:3.1236\tTriplet Loss:0.1625\tStatic Loss:0.2759\t\n",
      "Val Loss:0.2933\tRecon Loss:2.4897\tTriplet Loss:0.1671\tStatic Loss:0.2840\n",
      "\n",
      "\tTime:59.5847\n",
      "\n",
      "Test Loss:0.9157\tRecon Loss:7.6775\tTriplet Loss:0.5203\tStatic Loss:0.8876\n",
      "\n",
      "\tEpoch:7\tTrain Loss:0.2727\tRecon Loss:2.3023\tTriplet Loss:0.1607\tStatic Loss:0.2636\t\n",
      "Val Loss:0.2853\tRecon Loss:2.2553\tTriplet Loss:0.1638\tStatic Loss:0.2777\n",
      "\n",
      "\tTime:58.2797\n",
      "\n",
      "Test Loss:0.8764\tRecon Loss:6.7727\tTriplet Loss:0.5476\tStatic Loss:0.8503\n",
      "\n",
      "\tEpoch:8\tTrain Loss:0.2647\tRecon Loss:2.1313\tTriplet Loss:0.1460\tStatic Loss:0.2579\t\n",
      "Val Loss:0.2833\tRecon Loss:2.1806\tTriplet Loss:0.1450\tStatic Loss:0.2781\n",
      "\n",
      "\tTime:56.9002\n",
      "\n",
      "Test Loss:0.8918\tRecon Loss:6.5075\tTriplet Loss:0.4980\tStatic Loss:0.8750\n",
      "\n",
      "\tEpoch:9\tTrain Loss:0.2578\tRecon Loss:2.0734\tTriplet Loss:0.1448\tStatic Loss:0.2509\t\n",
      "Val Loss:0.2793\tRecon Loss:2.3133\tTriplet Loss:0.1557\tStatic Loss:0.2713\n",
      "\n",
      "\tTime:57.2760\n",
      "\n",
      "Test Loss:0.8732\tRecon Loss:7.0293\tTriplet Loss:0.4937\tStatic Loss:0.8496\n",
      "\n",
      "\tEpoch:10\tTrain Loss:0.2525\tRecon Loss:2.0253\tTriplet Loss:0.1441\tStatic Loss:0.2457\t\n",
      "Val Loss:0.2756\tRecon Loss:2.0486\tTriplet Loss:0.1552\tStatic Loss:0.2699\n",
      "\n",
      "\tTime:57.6039\n",
      "\n",
      "Test Loss:0.8745\tRecon Loss:6.0947\tTriplet Loss:0.5157\tStatic Loss:0.8581\n",
      "\n",
      "\tEpoch:11\tTrain Loss:0.2470\tRecon Loss:1.9878\tTriplet Loss:0.1385\tStatic Loss:0.2404\t\n",
      "Val Loss:0.2752\tRecon Loss:2.0112\tTriplet Loss:0.1574\tStatic Loss:0.2697\n",
      "\n",
      "\tTime:56.4778\n",
      "\n",
      "Test Loss:0.8641\tRecon Loss:5.9987\tTriplet Loss:0.4826\tStatic Loss:0.8509\n",
      "\n",
      "\tEpoch:12\tTrain Loss:0.2408\tRecon Loss:1.9407\tTriplet Loss:0.1298\tStatic Loss:0.2349\t\n",
      "Val Loss:0.2749\tRecon Loss:2.0515\tTriplet Loss:0.1553\tStatic Loss:0.2691\n",
      "\n",
      "\tTime:57.9659\n",
      "\n",
      "Test Loss:0.8503\tRecon Loss:6.1066\tTriplet Loss:0.4745\tStatic Loss:0.8354\n",
      "\n",
      "\tEpoch:13\tTrain Loss:0.2368\tRecon Loss:1.9409\tTriplet Loss:0.1322\tStatic Loss:0.2302\t\n",
      "Val Loss:0.2663\tRecon Loss:2.0228\tTriplet Loss:0.1419\tStatic Loss:0.2612\n",
      "\n",
      "\tTime:57.9397\n",
      "\n",
      "Test Loss:0.8615\tRecon Loss:6.0596\tTriplet Loss:0.4831\tStatic Loss:0.8474\n",
      "\n",
      "\tEpoch:14\tTrain Loss:0.2345\tRecon Loss:1.9266\tTriplet Loss:0.1284\tStatic Loss:0.2282\t\n",
      "Val Loss:0.2686\tRecon Loss:1.9830\tTriplet Loss:0.1460\tStatic Loss:0.2637\n",
      "\n",
      "\tTime:56.9933\n",
      "\n",
      "Test Loss:0.8265\tRecon Loss:5.9165\tTriplet Loss:0.4820\tStatic Loss:0.8101\n",
      "\n",
      "\tEpoch:15\tTrain Loss:0.2314\tRecon Loss:1.9157\tTriplet Loss:0.1263\tStatic Loss:0.2251\t\n",
      "Val Loss:0.2680\tRecon Loss:2.0408\tTriplet Loss:0.1524\tStatic Loss:0.2618\n",
      "\n",
      "\tTime:59.6758\n",
      "\n",
      "Test Loss:0.8426\tRecon Loss:6.0178\tTriplet Loss:0.4550\tStatic Loss:0.8296\n",
      "\n",
      "\tEpoch:16\tTrain Loss:0.2288\tRecon Loss:1.9102\tTriplet Loss:0.1215\tStatic Loss:0.2227\t\n",
      "Val Loss:0.2665\tRecon Loss:1.9652\tTriplet Loss:0.1435\tStatic Loss:0.2618\n",
      "\n",
      "\tTime:59.1439\n",
      "\n",
      "Test Loss:0.8593\tRecon Loss:5.8461\tTriplet Loss:0.4631\tStatic Loss:0.8491\n",
      "\n",
      "\tEpoch:17\tTrain Loss:0.2255\tRecon Loss:1.9030\tTriplet Loss:0.1231\tStatic Loss:0.2189\t\n",
      "Val Loss:0.2704\tRecon Loss:2.0097\tTriplet Loss:0.1341\tStatic Loss:0.2667\n",
      "\n",
      "\tTime:60.0479\n",
      "\n",
      "Test Loss:0.8407\tRecon Loss:5.9764\tTriplet Loss:0.4563\tStatic Loss:0.8278\n",
      "\n",
      "\tEpoch:18\tTrain Loss:0.2232\tRecon Loss:1.8921\tTriplet Loss:0.1222\tStatic Loss:0.2166\t\n",
      "Val Loss:0.2677\tRecon Loss:1.9574\tTriplet Loss:0.1445\tStatic Loss:0.2631\n",
      "\n",
      "\tTime:59.7977\n",
      "\n",
      "Test Loss:0.8344\tRecon Loss:6.0143\tTriplet Loss:0.4378\tStatic Loss:0.8223\n",
      "\n",
      "\tEpoch:19\tTrain Loss:0.2209\tRecon Loss:1.9041\tTriplet Loss:0.1218\tStatic Loss:0.2140\t\n",
      "Val Loss:0.2681\tRecon Loss:1.9754\tTriplet Loss:0.1430\tStatic Loss:0.2635\n",
      "\n",
      "\tTime:57.8908\n",
      "\n",
      "Test Loss:0.8658\tRecon Loss:5.9460\tTriplet Loss:0.4595\tStatic Loss:0.8556\n",
      "\n",
      "\tEpoch:20\tTrain Loss:0.2178\tRecon Loss:1.8891\tTriplet Loss:0.1169\tStatic Loss:0.2112\t\n",
      "Val Loss:0.2723\tRecon Loss:1.9490\tTriplet Loss:0.1279\tStatic Loss:0.2700\n",
      "\n",
      "\tTime:58.6592\n",
      "\n",
      "Test Loss:0.8506\tRecon Loss:5.8195\tTriplet Loss:0.4269\tStatic Loss:0.8432\n",
      "\n",
      "\tEpoch:21\tTrain Loss:0.2179\tRecon Loss:1.8840\tTriplet Loss:0.1176\tStatic Loss:0.2113\t\n",
      "Val Loss:0.2571\tRecon Loss:1.9471\tTriplet Loss:0.1383\tStatic Loss:0.2521\n",
      "\n",
      "\tTime:58.8820\n",
      "\n",
      "Test Loss:0.8225\tRecon Loss:6.0689\tTriplet Loss:0.4684\tStatic Loss:0.8054\n",
      "\n",
      "\tEpoch:22\tTrain Loss:0.2135\tRecon Loss:1.8859\tTriplet Loss:0.1104\tStatic Loss:0.2070\t\n",
      "Val Loss:0.2591\tRecon Loss:2.0366\tTriplet Loss:0.1331\tStatic Loss:0.2540\n",
      "\n",
      "\tTime:60.8801\n",
      "\n",
      "Test Loss:0.8065\tRecon Loss:5.9277\tTriplet Loss:0.4181\tStatic Loss:0.7941\n",
      "\n",
      "\tEpoch:23\tTrain Loss:0.2120\tRecon Loss:1.8837\tTriplet Loss:0.1144\tStatic Loss:0.2050\t\n",
      "Val Loss:0.2657\tRecon Loss:1.9773\tTriplet Loss:0.1382\tStatic Loss:0.2614\n",
      "\n",
      "\tTime:60.7421\n",
      "\n",
      "Test Loss:0.8141\tRecon Loss:5.9315\tTriplet Loss:0.4354\tStatic Loss:0.8008\n",
      "\n",
      "\tEpoch:24\tTrain Loss:0.2114\tRecon Loss:1.8964\tTriplet Loss:0.1148\tStatic Loss:0.2042\t\n",
      "Val Loss:0.2621\tRecon Loss:2.0403\tTriplet Loss:0.1377\tStatic Loss:0.2568\n",
      "\n",
      "\tTime:57.0935\n",
      "\n",
      "Test Loss:0.8278\tRecon Loss:5.9966\tTriplet Loss:0.4526\tStatic Loss:0.8136\n",
      "\n",
      "\tEpoch:25\tTrain Loss:0.2089\tRecon Loss:1.8745\tTriplet Loss:0.1103\tStatic Loss:0.2021\t\n",
      "Val Loss:0.2543\tRecon Loss:2.0013\tTriplet Loss:0.1242\tStatic Loss:0.2498\n",
      "\n",
      "\tTime:60.5593\n",
      "\n",
      "Test Loss:0.8214\tRecon Loss:5.8407\tTriplet Loss:0.4586\tStatic Loss:0.8074\n",
      "\n",
      "\tEpoch:26\tTrain Loss:0.2076\tRecon Loss:1.8705\tTriplet Loss:0.1073\tStatic Loss:0.2010\t\n",
      "Val Loss:0.2625\tRecon Loss:1.9830\tTriplet Loss:0.1337\tStatic Loss:0.2581\n",
      "\n",
      "\tTime:59.5497\n",
      "\n",
      "Test Loss:0.8371\tRecon Loss:5.8715\tTriplet Loss:0.4312\tStatic Loss:0.8274\n",
      "\n",
      "\tEpoch:27\tTrain Loss:0.2068\tRecon Loss:1.8902\tTriplet Loss:0.1160\tStatic Loss:0.1990\t\n",
      "Val Loss:0.2569\tRecon Loss:1.9343\tTriplet Loss:0.1355\tStatic Loss:0.2522\n",
      "\n",
      "\tTime:58.8605\n",
      "\n",
      "Test Loss:0.8290\tRecon Loss:5.8081\tTriplet Loss:0.4510\tStatic Loss:0.8170\n",
      "\n",
      "\tEpoch:28\tTrain Loss:0.2055\tRecon Loss:1.8700\tTriplet Loss:0.1142\tStatic Loss:0.1979\t\n",
      "Val Loss:0.2569\tRecon Loss:1.9297\tTriplet Loss:0.1363\tStatic Loss:0.2522\n",
      "\n",
      "\tTime:60.0830\n",
      "\n",
      "Test Loss:0.8228\tRecon Loss:5.7499\tTriplet Loss:0.4519\tStatic Loss:0.8106\n",
      "\n",
      "\tEpoch:29\tTrain Loss:0.2034\tRecon Loss:1.8733\tTriplet Loss:0.1088\tStatic Loss:0.1962\t\n",
      "Val Loss:0.2599\tRecon Loss:1.9584\tTriplet Loss:0.1356\tStatic Loss:0.2553\n",
      "\n",
      "\tTime:60.1429\n",
      "\n",
      "Test Loss:0.8565\tRecon Loss:5.8109\tTriplet Loss:0.4409\tStatic Loss:0.8485\n",
      "\n",
      "\tEpoch:30\tTrain Loss:0.2053\tRecon Loss:1.8941\tTriplet Loss:0.1065\tStatic Loss:0.1982\t\n",
      "Val Loss:0.2577\tRecon Loss:1.9818\tTriplet Loss:0.1289\tStatic Loss:0.2533\n",
      "\n",
      "\tTime:59.1588\n",
      "\n",
      "Test Loss:0.8357\tRecon Loss:5.8649\tTriplet Loss:0.4324\tStatic Loss:0.8258\n",
      "\n",
      "\tEpoch:31\tTrain Loss:0.2023\tRecon Loss:1.8699\tTriplet Loss:0.1111\tStatic Loss:0.1947\t\n",
      "Val Loss:0.2555\tRecon Loss:1.9382\tTriplet Loss:0.1435\tStatic Loss:0.2499\n",
      "\n",
      "\tTime:58.2521\n",
      "\n",
      "Test Loss:0.8077\tRecon Loss:5.7636\tTriplet Loss:0.4523\tStatic Loss:0.7937\n",
      "\n",
      "\tEpoch:32\tTrain Loss:0.2012\tRecon Loss:1.8873\tTriplet Loss:0.1099\tStatic Loss:0.1934\t\n",
      "Val Loss:0.2590\tRecon Loss:1.9738\tTriplet Loss:0.1458\tStatic Loss:0.2532\n",
      "\n",
      "\tTime:59.2898\n",
      "\n",
      "Test Loss:0.8245\tRecon Loss:5.8908\tTriplet Loss:0.4561\tStatic Loss:0.8107\n",
      "\n",
      "\tEpoch:33\tTrain Loss:0.1986\tRecon Loss:1.8760\tTriplet Loss:0.1027\tStatic Loss:0.1915\t\n",
      "Val Loss:0.2521\tRecon Loss:2.0140\tTriplet Loss:0.1274\tStatic Loss:0.2469\n",
      "\n",
      "\tTime:60.4016\n",
      "\n",
      "Test Loss:0.8275\tRecon Loss:5.9779\tTriplet Loss:0.4291\tStatic Loss:0.8159\n",
      "\n",
      "\tEpoch:34\tTrain Loss:0.1977\tRecon Loss:1.8781\tTriplet Loss:0.1026\tStatic Loss:0.1904\t\n",
      "Val Loss:0.2579\tRecon Loss:1.9458\tTriplet Loss:0.1359\tStatic Loss:0.2532\n",
      "\n",
      "\tTime:59.1809\n",
      "\n",
      "Test Loss:0.8475\tRecon Loss:5.7821\tTriplet Loss:0.4406\tStatic Loss:0.8389\n",
      "\n",
      "\tEpoch:35\tTrain Loss:0.1969\tRecon Loss:1.8641\tTriplet Loss:0.1058\tStatic Loss:0.1893\t\n",
      "Val Loss:0.2516\tRecon Loss:1.9284\tTriplet Loss:0.1343\tStatic Loss:0.2465\n",
      "\n",
      "\tTime:58.2073\n",
      "\n",
      "Test Loss:0.8113\tRecon Loss:5.7882\tTriplet Loss:0.4040\tStatic Loss:0.8023\n",
      "\n",
      "\tEpoch:36\tTrain Loss:0.1956\tRecon Loss:1.8628\tTriplet Loss:0.1033\tStatic Loss:0.1881\t\n",
      "Val Loss:0.2616\tRecon Loss:2.0013\tTriplet Loss:0.1363\tStatic Loss:0.2567\n",
      "\n",
      "\tTime:60.9045\n",
      "\n",
      "Test Loss:0.8297\tRecon Loss:5.9127\tTriplet Loss:0.4029\tStatic Loss:0.8216\n",
      "\n",
      "\tEpoch:37\tTrain Loss:0.1969\tRecon Loss:1.8763\tTriplet Loss:0.1079\tStatic Loss:0.1890\t\n",
      "Val Loss:0.2515\tRecon Loss:2.0119\tTriplet Loss:0.1290\tStatic Loss:0.2462\n",
      "\n",
      "\tTime:59.6935\n",
      "\n",
      "Test Loss:0.8331\tRecon Loss:5.7815\tTriplet Loss:0.4245\tStatic Loss:0.8245\n",
      "\n",
      "\tEpoch:38\tTrain Loss:0.1950\tRecon Loss:1.8629\tTriplet Loss:0.1117\tStatic Loss:0.1867\t\n",
      "Val Loss:0.2558\tRecon Loss:1.9353\tTriplet Loss:0.1341\tStatic Loss:0.2512\n",
      "\n",
      "\tTime:60.0490\n",
      "\n",
      "Test Loss:0.8238\tRecon Loss:5.7499\tTriplet Loss:0.3946\tStatic Loss:0.8174\n",
      "\n",
      "\tEpoch:39\tTrain Loss:0.1967\tRecon Loss:1.8599\tTriplet Loss:0.1063\tStatic Loss:0.1891\t\n",
      "Val Loss:0.2533\tRecon Loss:1.9519\tTriplet Loss:0.1254\tStatic Loss:0.2491\n",
      "\n",
      "\tTime:58.3365\n",
      "\n",
      "Test Loss:0.8064\tRecon Loss:5.7898\tTriplet Loss:0.4380\tStatic Loss:0.7934\n",
      "\n",
      "\tEpoch:40\tTrain Loss:0.1922\tRecon Loss:1.8574\tTriplet Loss:0.0992\tStatic Loss:0.1848\t\n",
      "Val Loss:0.2534\tRecon Loss:1.9483\tTriplet Loss:0.1292\tStatic Loss:0.2488\n",
      "\n",
      "\tTime:61.1852\n",
      "\n",
      "Test Loss:0.8113\tRecon Loss:5.7743\tTriplet Loss:0.4394\tStatic Loss:0.7989\n",
      "\n",
      "\tEpoch:41\tTrain Loss:0.1912\tRecon Loss:1.8662\tTriplet Loss:0.1022\tStatic Loss:0.1834\t\n",
      "Val Loss:0.2618\tRecon Loss:1.9447\tTriplet Loss:0.1233\tStatic Loss:0.2588\n",
      "\n",
      "\tTime:62.3673\n",
      "\n",
      "Test Loss:0.8396\tRecon Loss:5.8152\tTriplet Loss:0.4405\tStatic Loss:0.8298\n",
      "\n",
      "\tEpoch:42\tTrain Loss:0.1922\tRecon Loss:1.8632\tTriplet Loss:0.1012\tStatic Loss:0.1846\t\n",
      "Val Loss:0.2587\tRecon Loss:1.9266\tTriplet Loss:0.1358\tStatic Loss:0.2543\n",
      "\n",
      "\tTime:61.9743\n",
      "\n",
      "Test Loss:0.8216\tRecon Loss:5.7087\tTriplet Loss:0.4336\tStatic Loss:0.8116\n",
      "\n",
      "\tEpoch:43\tTrain Loss:0.1902\tRecon Loss:1.8610\tTriplet Loss:0.1032\tStatic Loss:0.1822\t\n",
      "Val Loss:0.2572\tRecon Loss:1.9363\tTriplet Loss:0.1271\tStatic Loss:0.2535\n",
      "\n",
      "\tTime:61.8339\n",
      "\n",
      "Test Loss:0.8483\tRecon Loss:5.7755\tTriplet Loss:0.4210\tStatic Loss:0.8418\n",
      "\n",
      "\tEpoch:44\tTrain Loss:0.1895\tRecon Loss:1.8697\tTriplet Loss:0.1032\tStatic Loss:0.1813\t\n",
      "Val Loss:0.2576\tRecon Loss:2.1289\tTriplet Loss:0.1440\tStatic Loss:0.2503\n",
      "\n",
      "\tTime:61.4606\n",
      "\n",
      "Test Loss:0.8448\tRecon Loss:6.3936\tTriplet Loss:0.4318\tStatic Loss:0.8306\n",
      "\n",
      "\tEpoch:45\tTrain Loss:0.1876\tRecon Loss:1.8619\tTriplet Loss:0.1006\tStatic Loss:0.1796\t\n",
      "Val Loss:0.2537\tRecon Loss:1.9569\tTriplet Loss:0.1339\tStatic Loss:0.2487\n",
      "\n",
      "\tTime:60.8643\n",
      "\n",
      "Test Loss:0.8347\tRecon Loss:5.7868\tTriplet Loss:0.4197\tStatic Loss:0.8267\n",
      "\n",
      "\tEpoch:46\tTrain Loss:0.1867\tRecon Loss:1.8606\tTriplet Loss:0.1030\tStatic Loss:0.1783\t\n",
      "Val Loss:0.2555\tRecon Loss:1.9813\tTriplet Loss:0.1290\tStatic Loss:0.2509\n",
      "\n",
      "\tTime:60.9523\n",
      "\n",
      "Test Loss:0.8467\tRecon Loss:5.9463\tTriplet Loss:0.4407\tStatic Loss:0.8363\n",
      "\n",
      "\tEpoch:47\tTrain Loss:0.1877\tRecon Loss:1.8610\tTriplet Loss:0.1019\tStatic Loss:0.1796\t\n",
      "Val Loss:0.2521\tRecon Loss:1.9292\tTriplet Loss:0.1268\tStatic Loss:0.2479\n",
      "\n",
      "\tTime:61.9511\n",
      "\n",
      "Test Loss:0.8390\tRecon Loss:5.8066\tTriplet Loss:0.4029\tStatic Loss:0.8329\n",
      "\n",
      "\tEpoch:48\tTrain Loss:0.1882\tRecon Loss:1.8699\tTriplet Loss:0.1070\tStatic Loss:0.1795\t\n",
      "Val Loss:0.2563\tRecon Loss:1.9325\tTriplet Loss:0.1372\tStatic Loss:0.2514\n",
      "\n",
      "\tTime:60.2885\n",
      "\n",
      "Test Loss:0.8310\tRecon Loss:5.7623\tTriplet Loss:0.4711\tStatic Loss:0.8176\n",
      "\n",
      "\tEpoch:49\tTrain Loss:0.1871\tRecon Loss:1.8546\tTriplet Loss:0.1043\tStatic Loss:0.1786\t\n",
      "Val Loss:0.2572\tRecon Loss:1.9295\tTriplet Loss:0.1284\tStatic Loss:0.2533\n",
      "\n",
      "\tTime:61.3721\n",
      "\n",
      "Test Loss:0.8415\tRecon Loss:5.7234\tTriplet Loss:0.4309\tStatic Loss:0.8337\n",
      "\n",
      "\tEpoch:50\tTrain Loss:0.1860\tRecon Loss:1.8616\tTriplet Loss:0.1009\tStatic Loss:0.1778\t\n",
      "Val Loss:0.2541\tRecon Loss:1.9414\tTriplet Loss:0.1292\tStatic Loss:0.2498\n",
      "\n",
      "\tTime:60.6306\n",
      "\n",
      "Test Loss:0.8375\tRecon Loss:5.7258\tTriplet Loss:0.4508\tStatic Loss:0.8273\n",
      "\n",
      "\tEpoch:51\tTrain Loss:0.1853\tRecon Loss:1.8624\tTriplet Loss:0.1000\tStatic Loss:0.1770\t\n",
      "Val Loss:0.2542\tRecon Loss:1.9319\tTriplet Loss:0.1347\tStatic Loss:0.2493\n",
      "\n",
      "\tTime:60.6182\n",
      "\n",
      "Test Loss:0.8432\tRecon Loss:5.7352\tTriplet Loss:0.4294\tStatic Loss:0.8357\n",
      "\n",
      "\tEpoch:52\tTrain Loss:0.1842\tRecon Loss:1.8667\tTriplet Loss:0.1029\tStatic Loss:0.1756\t\n",
      "Val Loss:0.2558\tRecon Loss:1.9358\tTriplet Loss:0.1291\tStatic Loss:0.2516\n",
      "\n",
      "\tTime:60.7501\n",
      "\n",
      "Test Loss:0.8317\tRecon Loss:5.7310\tTriplet Loss:0.4398\tStatic Loss:0.8219\n",
      "\n",
      "\tEpoch:53\tTrain Loss:0.1838\tRecon Loss:1.8517\tTriplet Loss:0.1005\tStatic Loss:0.1755\t\n",
      "Val Loss:0.2566\tRecon Loss:1.9320\tTriplet Loss:0.1310\tStatic Loss:0.2524\n",
      "\n",
      "\tTime:62.0661\n",
      "\n",
      "Test Loss:0.8232\tRecon Loss:5.7544\tTriplet Loss:0.3990\tStatic Loss:0.8163\n",
      "\n",
      "\tEpoch:54\tTrain Loss:0.1839\tRecon Loss:1.8590\tTriplet Loss:0.1034\tStatic Loss:0.1752\t\n",
      "Val Loss:0.2548\tRecon Loss:1.9403\tTriplet Loss:0.1221\tStatic Loss:0.2512\n",
      "\n",
      "\tTime:62.6362\n",
      "\n",
      "Test Loss:0.8354\tRecon Loss:5.7788\tTriplet Loss:0.4179\tStatic Loss:0.8277\n",
      "\n",
      "\tEpoch:55\tTrain Loss:0.1810\tRecon Loss:1.8469\tTriplet Loss:0.0976\tStatic Loss:0.1727\t\n",
      "Val Loss:0.2570\tRecon Loss:1.9320\tTriplet Loss:0.1252\tStatic Loss:0.2535\n",
      "\n",
      "\tTime:61.6540\n",
      "\n",
      "Test Loss:0.8259\tRecon Loss:5.8029\tTriplet Loss:0.4279\tStatic Loss:0.8159\n",
      "\n",
      "\tEpoch:56\tTrain Loss:0.1812\tRecon Loss:1.8543\tTriplet Loss:0.0949\tStatic Loss:0.1731\t\n",
      "Val Loss:0.2556\tRecon Loss:1.9395\tTriplet Loss:0.1407\tStatic Loss:0.2503\n",
      "\n",
      "\tTime:62.3926\n",
      "\n",
      "Test Loss:0.8501\tRecon Loss:5.8564\tTriplet Loss:0.4607\tStatic Loss:0.8390\n",
      "\n",
      "\tEpoch:57\tTrain Loss:0.1837\tRecon Loss:1.8571\tTriplet Loss:0.0997\tStatic Loss:0.1754\t\n",
      "Val Loss:0.2564\tRecon Loss:1.9344\tTriplet Loss:0.1326\tStatic Loss:0.2520\n",
      "\n",
      "\tTime:61.2923\n",
      "\n",
      "Test Loss:0.8388\tRecon Loss:5.7608\tTriplet Loss:0.4648\tStatic Loss:0.8270\n",
      "\n",
      "\tEpoch:58\tTrain Loss:0.1811\tRecon Loss:1.8503\tTriplet Loss:0.1007\tStatic Loss:0.1724\t\n",
      "Val Loss:0.2555\tRecon Loss:1.9271\tTriplet Loss:0.1250\tStatic Loss:0.2518\n",
      "\n",
      "\tTime:63.1958\n",
      "\n",
      "Test Loss:0.8459\tRecon Loss:5.7982\tTriplet Loss:0.4065\tStatic Loss:0.8403\n",
      "\n",
      "\tEpoch:59\tTrain Loss:0.1808\tRecon Loss:1.8517\tTriplet Loss:0.1045\tStatic Loss:0.1717\t\n",
      "Val Loss:0.2613\tRecon Loss:1.9614\tTriplet Loss:0.1268\tStatic Loss:0.2577\n",
      "\n",
      "\tTime:63.4023\n",
      "\n",
      "Test Loss:0.8452\tRecon Loss:5.9367\tTriplet Loss:0.4421\tStatic Loss:0.8346\n",
      "\n",
      "\tEpoch:60\tTrain Loss:0.1802\tRecon Loss:1.8595\tTriplet Loss:0.0973\tStatic Loss:0.1717\t\n",
      "Val Loss:0.2523\tRecon Loss:1.9288\tTriplet Loss:0.1321\tStatic Loss:0.2475\n",
      "\n",
      "\tTime:63.0578\n",
      "\n",
      "Test Loss:0.8454\tRecon Loss:5.8125\tTriplet Loss:0.4271\tStatic Loss:0.8376\n",
      "\n",
      "\tEpoch:61\tTrain Loss:0.1804\tRecon Loss:1.8540\tTriplet Loss:0.0978\tStatic Loss:0.1719\t\n",
      "Val Loss:0.2610\tRecon Loss:1.9190\tTriplet Loss:0.1206\tStatic Loss:0.2584\n",
      "\n",
      "\tTime:60.7368\n",
      "\n",
      "Test Loss:0.8462\tRecon Loss:5.7362\tTriplet Loss:0.4197\tStatic Loss:0.8399\n",
      "\n",
      "\tEpoch:62\tTrain Loss:0.1795\tRecon Loss:1.8590\tTriplet Loss:0.1016\tStatic Loss:0.1705\t\n",
      "Val Loss:0.2534\tRecon Loss:1.9120\tTriplet Loss:0.1291\tStatic Loss:0.2492\n",
      "\n",
      "\tTime:61.7919\n",
      "\n",
      "Test Loss:0.8486\tRecon Loss:5.7007\tTriplet Loss:0.4287\tStatic Loss:0.8420\n",
      "\n",
      "\tEpoch:63\tTrain Loss:0.1777\tRecon Loss:1.8452\tTriplet Loss:0.0967\tStatic Loss:0.1692\t\n",
      "Val Loss:0.2545\tRecon Loss:1.9348\tTriplet Loss:0.1318\tStatic Loss:0.2500\n",
      "\n",
      "\tTime:60.2715\n",
      "\n",
      "Test Loss:0.8150\tRecon Loss:5.7469\tTriplet Loss:0.4097\tStatic Loss:0.8062\n",
      "\n",
      "\tEpoch:64\tTrain Loss:0.1805\tRecon Loss:1.8575\tTriplet Loss:0.0999\tStatic Loss:0.1718\t\n",
      "Val Loss:0.2586\tRecon Loss:2.0136\tTriplet Loss:0.1243\tStatic Loss:0.2545\n",
      "\n",
      "\tTime:59.0465\n",
      "\n",
      "Test Loss:0.8096\tRecon Loss:6.0427\tTriplet Loss:0.4073\tStatic Loss:0.7975\n",
      "\n",
      "\tEpoch:65\tTrain Loss:0.1787\tRecon Loss:1.8745\tTriplet Loss:0.0966\tStatic Loss:0.1700\t\n",
      "Val Loss:0.2631\tRecon Loss:1.9502\tTriplet Loss:0.1276\tStatic Loss:0.2597\n",
      "\n",
      "\tTime:59.6067\n",
      "\n",
      "Test Loss:0.8175\tRecon Loss:5.7608\tTriplet Loss:0.4617\tStatic Loss:0.8037\n",
      "\n",
      "\tEpoch:66\tTrain Loss:0.1795\tRecon Loss:1.8522\tTriplet Loss:0.0954\tStatic Loss:0.1712\t\n",
      "Val Loss:0.2591\tRecon Loss:1.9495\tTriplet Loss:0.1436\tStatic Loss:0.2537\n",
      "\n",
      "\tTime:59.7661\n",
      "\n",
      "Test Loss:0.8634\tRecon Loss:5.8178\tTriplet Loss:0.4310\tStatic Loss:0.8571\n",
      "\n",
      "\tEpoch:67\tTrain Loss:0.1801\tRecon Loss:1.8505\tTriplet Loss:0.0973\tStatic Loss:0.1717\t\n",
      "Val Loss:0.2522\tRecon Loss:1.9382\tTriplet Loss:0.1308\tStatic Loss:0.2475\n",
      "\n",
      "\tTime:60.8737\n",
      "\n",
      "Test Loss:0.8095\tRecon Loss:5.8813\tTriplet Loss:0.4201\tStatic Loss:0.7977\n",
      "\n",
      "\tEpoch:68\tTrain Loss:0.1756\tRecon Loss:1.8487\tTriplet Loss:0.0963\tStatic Loss:0.1668\t\n",
      "Val Loss:0.2545\tRecon Loss:1.9260\tTriplet Loss:0.1220\tStatic Loss:0.2510\n",
      "\n",
      "\tTime:61.3439\n",
      "\n",
      "Test Loss:0.8297\tRecon Loss:5.7095\tTriplet Loss:0.4424\tStatic Loss:0.8196\n",
      "\n",
      "\tEpoch:69\tTrain Loss:0.1762\tRecon Loss:1.8489\tTriplet Loss:0.0949\tStatic Loss:0.1676\t\n",
      "Val Loss:0.2597\tRecon Loss:1.9292\tTriplet Loss:0.1318\tStatic Loss:0.2558\n",
      "\n",
      "\tTime:61.4164\n",
      "\n",
      "Test Loss:0.8444\tRecon Loss:5.7820\tTriplet Loss:0.4664\tStatic Loss:0.8328\n",
      "\n",
      "\tEpoch:70\tTrain Loss:0.1777\tRecon Loss:1.8457\tTriplet Loss:0.1004\tStatic Loss:0.1688\t\n",
      "Val Loss:0.2577\tRecon Loss:1.9372\tTriplet Loss:0.1244\tStatic Loss:0.2543\n",
      "\n",
      "\tTime:59.7191\n",
      "\n",
      "Test Loss:0.8439\tRecon Loss:5.7835\tTriplet Loss:0.4581\tStatic Loss:0.8331\n",
      "\n",
      "\tEpoch:71\tTrain Loss:0.1769\tRecon Loss:1.8571\tTriplet Loss:0.1005\tStatic Loss:0.1678\t\n",
      "Val Loss:0.2570\tRecon Loss:1.9703\tTriplet Loss:0.1292\tStatic Loss:0.2526\n",
      "\n",
      "\tTime:60.7125\n",
      "\n",
      "Test Loss:0.8477\tRecon Loss:5.7787\tTriplet Loss:0.4391\tStatic Loss:0.8392\n",
      "\n",
      "\tEpoch:72\tTrain Loss:0.1771\tRecon Loss:1.8519\tTriplet Loss:0.1002\tStatic Loss:0.1680\t\n",
      "Val Loss:0.2585\tRecon Loss:1.9188\tTriplet Loss:0.1268\tStatic Loss:0.2551\n",
      "\n",
      "\tTime:61.9657\n",
      "\n",
      "Test Loss:0.8633\tRecon Loss:5.7392\tTriplet Loss:0.4626\tStatic Loss:0.8546\n",
      "\n",
      "\tEpoch:73\tTrain Loss:0.1794\tRecon Loss:1.8468\tTriplet Loss:0.0957\tStatic Loss:0.1710\t\n",
      "Val Loss:0.2608\tRecon Loss:1.9567\tTriplet Loss:0.1305\tStatic Loss:0.2569\n",
      "\n",
      "\tTime:61.7891\n",
      "\n",
      "Test Loss:0.8724\tRecon Loss:5.7795\tTriplet Loss:0.4420\tStatic Loss:0.8664\n",
      "\n",
      "\tEpoch:74\tTrain Loss:0.1782\tRecon Loss:1.8494\tTriplet Loss:0.0986\tStatic Loss:0.1695\t\n",
      "Val Loss:0.2606\tRecon Loss:1.9504\tTriplet Loss:0.1230\tStatic Loss:0.2574\n",
      "\n",
      "\tTime:61.2630\n",
      "\n",
      "Test Loss:0.8325\tRecon Loss:5.7195\tTriplet Loss:0.4593\tStatic Loss:0.8209\n",
      "\n",
      "\tEpoch:75\tTrain Loss:0.1753\tRecon Loss:1.8537\tTriplet Loss:0.0971\tStatic Loss:0.1664\t\n",
      "Val Loss:0.2583\tRecon Loss:1.9384\tTriplet Loss:0.1374\tStatic Loss:0.2536\n",
      "\n",
      "\tTime:61.2251\n",
      "\n",
      "Test Loss:0.8419\tRecon Loss:5.7286\tTriplet Loss:0.4266\tStatic Loss:0.8345\n",
      "\n",
      "\tEpoch:76\tTrain Loss:0.1742\tRecon Loss:1.8549\tTriplet Loss:0.0954\tStatic Loss:0.1653\t\n",
      "Val Loss:0.2542\tRecon Loss:1.9239\tTriplet Loss:0.1457\tStatic Loss:0.2484\n",
      "\n",
      "\tTime:62.3270\n",
      "\n",
      "Test Loss:0.8394\tRecon Loss:5.7082\tTriplet Loss:0.4425\tStatic Loss:0.8305\n",
      "\n",
      "\tEpoch:77\tTrain Loss:0.1783\tRecon Loss:1.8475\tTriplet Loss:0.0993\tStatic Loss:0.1695\t\n",
      "Val Loss:0.2590\tRecon Loss:1.9441\tTriplet Loss:0.1321\tStatic Loss:0.2549\n",
      "\n",
      "\tTime:61.7923\n",
      "\n",
      "Test Loss:0.8769\tRecon Loss:5.7437\tTriplet Loss:0.4128\tStatic Loss:0.8747\n",
      "\n",
      "\tEpoch:78\tTrain Loss:0.1749\tRecon Loss:1.8443\tTriplet Loss:0.1001\tStatic Loss:0.1657\t\n",
      "Val Loss:0.2601\tRecon Loss:1.9149\tTriplet Loss:0.1397\tStatic Loss:0.2556\n",
      "\n",
      "\tTime:61.8779\n",
      "\n",
      "Test Loss:0.8340\tRecon Loss:5.7585\tTriplet Loss:0.4308\tStatic Loss:0.8251\n",
      "\n",
      "\tEpoch:79\tTrain Loss:0.1753\tRecon Loss:1.8428\tTriplet Loss:0.0954\tStatic Loss:0.1666\t\n",
      "Val Loss:0.2561\tRecon Loss:1.9378\tTriplet Loss:0.1248\tStatic Loss:0.2524\n",
      "\n",
      "\tTime:62.4004\n",
      "\n",
      "Test Loss:0.8484\tRecon Loss:5.7336\tTriplet Loss:0.4148\tStatic Loss:0.8429\n",
      "\n",
      "\tEpoch:80\tTrain Loss:0.1790\tRecon Loss:1.8522\tTriplet Loss:0.1006\tStatic Loss:0.1701\t\n",
      "Val Loss:0.2501\tRecon Loss:1.9440\tTriplet Loss:0.1217\tStatic Loss:0.2460\n",
      "\n",
      "\tTime:61.5242\n",
      "\n",
      "Test Loss:0.8192\tRecon Loss:5.8319\tTriplet Loss:0.4265\tStatic Loss:0.8083\n",
      "\n",
      "\tEpoch:81\tTrain Loss:0.1740\tRecon Loss:1.8470\tTriplet Loss:0.0948\tStatic Loss:0.1652\t\n",
      "Val Loss:0.2534\tRecon Loss:1.9442\tTriplet Loss:0.1305\tStatic Loss:0.2488\n",
      "\n",
      "\tTime:61.6154\n",
      "\n",
      "Test Loss:0.8487\tRecon Loss:5.7789\tTriplet Loss:0.4445\tStatic Loss:0.8398\n",
      "\n",
      "\tEpoch:82\tTrain Loss:0.1743\tRecon Loss:1.8459\tTriplet Loss:0.0932\tStatic Loss:0.1657\t\n",
      "Val Loss:0.2587\tRecon Loss:1.9853\tTriplet Loss:0.1417\tStatic Loss:0.2531\n",
      "\n",
      "\tTime:61.7120\n",
      "\n",
      "Test Loss:0.8549\tRecon Loss:5.7740\tTriplet Loss:0.4473\tStatic Loss:0.8465\n",
      "\n",
      "\tEpoch:83\tTrain Loss:0.1734\tRecon Loss:1.8449\tTriplet Loss:0.0979\tStatic Loss:0.1642\t\n",
      "Val Loss:0.2592\tRecon Loss:1.9562\tTriplet Loss:0.1331\tStatic Loss:0.2549\n",
      "\n",
      "\tTime:61.6590\n",
      "\n",
      "Test Loss:0.8362\tRecon Loss:5.7992\tTriplet Loss:0.4194\tStatic Loss:0.8282\n",
      "\n",
      "\tEpoch:84\tTrain Loss:0.1739\tRecon Loss:1.8657\tTriplet Loss:0.0935\tStatic Loss:0.1650\t\n",
      "Val Loss:0.2598\tRecon Loss:1.9132\tTriplet Loss:0.1330\tStatic Loss:0.2559\n",
      "\n",
      "\tTime:60.4463\n",
      "\n",
      "Test Loss:0.8588\tRecon Loss:5.7212\tTriplet Loss:0.4423\tStatic Loss:0.8519\n",
      "\n",
      "\tEpoch:85\tTrain Loss:0.1753\tRecon Loss:1.8474\tTriplet Loss:0.0952\tStatic Loss:0.1666\t\n",
      "Val Loss:0.2586\tRecon Loss:1.9557\tTriplet Loss:0.1415\tStatic Loss:0.2534\n",
      "\n",
      "\tTime:61.2638\n",
      "\n",
      "Test Loss:0.8727\tRecon Loss:5.7787\tTriplet Loss:0.4684\tStatic Loss:0.8640\n",
      "\n",
      "\tEpoch:86\tTrain Loss:0.1785\tRecon Loss:1.8486\tTriplet Loss:0.0989\tStatic Loss:0.1698\t\n",
      "Val Loss:0.2633\tRecon Loss:1.9434\tTriplet Loss:0.1354\tStatic Loss:0.2593\n",
      "\n",
      "\tTime:60.5518\n",
      "\n",
      "Test Loss:0.8426\tRecon Loss:5.7624\tTriplet Loss:0.4452\tStatic Loss:0.8332\n",
      "\n",
      "\tEpoch:87\tTrain Loss:0.1740\tRecon Loss:1.8460\tTriplet Loss:0.0935\tStatic Loss:0.1653\t\n",
      "Val Loss:0.2545\tRecon Loss:1.9136\tTriplet Loss:0.1319\tStatic Loss:0.2501\n",
      "\n",
      "\tTime:60.7676\n",
      "\n",
      "Test Loss:0.8547\tRecon Loss:5.7295\tTriplet Loss:0.4198\tStatic Loss:0.8495\n",
      "\n",
      "\tEpoch:88\tTrain Loss:0.1742\tRecon Loss:1.8583\tTriplet Loss:0.0964\tStatic Loss:0.1651\t\n",
      "Val Loss:0.2620\tRecon Loss:1.9197\tTriplet Loss:0.1396\tStatic Loss:0.2577\n",
      "\n",
      "\tTime:60.9196\n",
      "\n",
      "Test Loss:0.8737\tRecon Loss:5.6975\tTriplet Loss:0.4398\tStatic Loss:0.8689\n",
      "\n",
      "\tEpoch:89\tTrain Loss:0.1766\tRecon Loss:1.8513\tTriplet Loss:0.1000\tStatic Loss:0.1676\t\n",
      "Val Loss:0.2578\tRecon Loss:1.9584\tTriplet Loss:0.1274\tStatic Loss:0.2538\n",
      "\n",
      "\tTime:59.9049\n",
      "\n",
      "Test Loss:0.8613\tRecon Loss:5.7525\tTriplet Loss:0.4475\tStatic Loss:0.8537\n",
      "\n",
      "\tEpoch:90\tTrain Loss:0.1734\tRecon Loss:1.8430\tTriplet Loss:0.0974\tStatic Loss:0.1643\t\n",
      "Val Loss:0.2595\tRecon Loss:1.9223\tTriplet Loss:0.1240\tStatic Loss:0.2564\n",
      "\n",
      "\tTime:60.5608\n",
      "\n",
      "Test Loss:0.8721\tRecon Loss:5.7109\tTriplet Loss:0.4233\tStatic Loss:0.8686\n",
      "\n",
      "\tEpoch:91\tTrain Loss:0.1713\tRecon Loss:1.8484\tTriplet Loss:0.0961\tStatic Loss:0.1621\t\n",
      "Val Loss:0.2581\tRecon Loss:1.9324\tTriplet Loss:0.1328\tStatic Loss:0.2539\n",
      "\n",
      "\tTime:60.1399\n",
      "\n",
      "Test Loss:0.8591\tRecon Loss:5.7283\tTriplet Loss:0.4873\tStatic Loss:0.8476\n",
      "\n",
      "\tEpoch:92\tTrain Loss:0.1715\tRecon Loss:1.8435\tTriplet Loss:0.0962\tStatic Loss:0.1623\t\n",
      "Val Loss:0.2536\tRecon Loss:1.9180\tTriplet Loss:0.1338\tStatic Loss:0.2489\n",
      "\n",
      "\tTime:62.9819\n",
      "\n",
      "Test Loss:0.8218\tRecon Loss:5.7182\tTriplet Loss:0.4415\tStatic Loss:0.8109\n",
      "\n",
      "\tEpoch:93\tTrain Loss:0.1715\tRecon Loss:1.8421\tTriplet Loss:0.0949\tStatic Loss:0.1625\t\n",
      "Val Loss:0.2581\tRecon Loss:1.9449\tTriplet Loss:0.1316\tStatic Loss:0.2539\n",
      "\n",
      "\tTime:61.2443\n",
      "\n",
      "Test Loss:0.8427\tRecon Loss:5.7537\tTriplet Loss:0.4384\tStatic Loss:0.8341\n",
      "\n",
      "\tEpoch:94\tTrain Loss:0.1738\tRecon Loss:1.8562\tTriplet Loss:0.0905\tStatic Loss:0.1653\t\n",
      "Val Loss:0.2482\tRecon Loss:1.9121\tTriplet Loss:0.1191\tStatic Loss:0.2445\n",
      "\n",
      "\tTime:60.6155\n",
      "\n",
      "Test Loss:0.8262\tRecon Loss:5.7117\tTriplet Loss:0.4409\tStatic Loss:0.8159\n",
      "\n",
      "\tEpoch:95\tTrain Loss:0.1757\tRecon Loss:1.8412\tTriplet Loss:0.1006\tStatic Loss:0.1666\t\n",
      "Val Loss:0.2616\tRecon Loss:1.9360\tTriplet Loss:0.1350\tStatic Loss:0.2575\n",
      "\n",
      "\tTime:61.5094\n",
      "\n",
      "Test Loss:0.8985\tRecon Loss:5.7774\tTriplet Loss:0.4547\tStatic Loss:0.8941\n",
      "\n",
      "\tEpoch:96\tTrain Loss:0.1752\tRecon Loss:1.8432\tTriplet Loss:0.0994\tStatic Loss:0.1661\t\n",
      "Val Loss:0.2516\tRecon Loss:1.9223\tTriplet Loss:0.1226\tStatic Loss:0.2478\n",
      "\n",
      "\tTime:60.6090\n",
      "\n",
      "Test Loss:0.8348\tRecon Loss:5.6948\tTriplet Loss:0.4280\tStatic Loss:0.8268\n",
      "\n",
      "\tEpoch:97\tTrain Loss:0.1733\tRecon Loss:1.8443\tTriplet Loss:0.0991\tStatic Loss:0.1641\t\n",
      "Val Loss:0.2647\tRecon Loss:1.9155\tTriplet Loss:0.1230\tStatic Loss:0.2624\n",
      "\n",
      "\tTime:61.0135\n",
      "\n",
      "Test Loss:0.8700\tRecon Loss:5.7121\tTriplet Loss:0.4432\tStatic Loss:0.8643\n",
      "\n",
      "\tEpoch:98\tTrain Loss:0.1717\tRecon Loss:1.8424\tTriplet Loss:0.0941\tStatic Loss:0.1627\t\n",
      "Val Loss:0.2599\tRecon Loss:1.9376\tTriplet Loss:0.1309\tStatic Loss:0.2561\n",
      "\n",
      "\tTime:61.6084\n",
      "\n",
      "Test Loss:0.8510\tRecon Loss:5.7370\tTriplet Loss:0.4608\tStatic Loss:0.8412\n",
      "\n",
      "\tEpoch:99\tTrain Loss:0.1817\tRecon Loss:1.8475\tTriplet Loss:0.1012\tStatic Loss:0.1730\t\n",
      "Val Loss:0.2584\tRecon Loss:1.9062\tTriplet Loss:0.1358\tStatic Loss:0.2542\n",
      "\n",
      "\tTime:61.6404\n",
      "\n",
      "Test Loss:0.8255\tRecon Loss:5.6877\tTriplet Loss:0.4661\tStatic Loss:0.8129\n",
      "\n",
      "\tEpoch:100\tTrain Loss:0.1724\tRecon Loss:1.8476\tTriplet Loss:0.1005\tStatic Loss:0.1629\t\n",
      "Val Loss:0.2583\tRecon Loss:1.9498\tTriplet Loss:0.1358\tStatic Loss:0.2536\n",
      "\n",
      "\tTime:61.5090\n",
      "\n",
      "Test Loss:0.8511\tRecon Loss:5.7870\tTriplet Loss:0.4183\tStatic Loss:0.8450\n",
      "\n",
      "\tEpoch:101\tTrain Loss:0.1725\tRecon Loss:1.8524\tTriplet Loss:0.0960\tStatic Loss:0.1634\t\n",
      "Val Loss:0.2580\tRecon Loss:1.9592\tTriplet Loss:0.1374\tStatic Loss:0.2531\n",
      "\n",
      "\tTime:62.6062\n",
      "\n",
      "Test Loss:0.8609\tRecon Loss:5.7714\tTriplet Loss:0.4350\tStatic Loss:0.8544\n",
      "\n",
      "\tEpoch:102\tTrain Loss:0.1699\tRecon Loss:1.8445\tTriplet Loss:0.0928\tStatic Loss:0.1608\t\n",
      "Val Loss:0.2553\tRecon Loss:1.9633\tTriplet Loss:0.1284\tStatic Loss:0.2509\n",
      "\n",
      "\tTime:60.6480\n",
      "\n",
      "Test Loss:0.8124\tRecon Loss:5.9243\tTriplet Loss:0.4398\tStatic Loss:0.7986\n",
      "\n",
      "\tEpoch:103\tTrain Loss:0.1704\tRecon Loss:1.8452\tTriplet Loss:0.0975\tStatic Loss:0.1609\t\n",
      "Val Loss:0.2519\tRecon Loss:1.9400\tTriplet Loss:0.1249\tStatic Loss:0.2477\n",
      "\n",
      "\tTime:60.9104\n",
      "\n",
      "Test Loss:0.8399\tRecon Loss:5.7444\tTriplet Loss:0.4073\tStatic Loss:0.8341\n",
      "\n",
      "\tEpoch:104\tTrain Loss:0.1722\tRecon Loss:1.8520\tTriplet Loss:0.0973\tStatic Loss:0.1629\t\n",
      "Val Loss:0.2587\tRecon Loss:2.1473\tTriplet Loss:0.1375\tStatic Loss:0.2519\n",
      "\n",
      "\tTime:60.5103\n",
      "\n",
      "Test Loss:0.8364\tRecon Loss:6.3634\tTriplet Loss:0.4500\tStatic Loss:0.8198\n",
      "\n",
      "\tEpoch:105\tTrain Loss:0.1694\tRecon Loss:1.8541\tTriplet Loss:0.0924\tStatic Loss:0.1602\t\n",
      "Val Loss:0.2618\tRecon Loss:1.9497\tTriplet Loss:0.1401\tStatic Loss:0.2571\n",
      "\n",
      "\tTime:60.8512\n",
      "\n",
      "Test Loss:0.8866\tRecon Loss:5.8314\tTriplet Loss:0.4339\tStatic Loss:0.8824\n",
      "\n",
      "\tEpoch:106\tTrain Loss:0.1694\tRecon Loss:1.8324\tTriplet Loss:0.0929\tStatic Loss:0.1604\t\n",
      "Val Loss:0.2573\tRecon Loss:1.9490\tTriplet Loss:0.1282\tStatic Loss:0.2533\n",
      "\n",
      "\tTime:62.6157\n",
      "\n",
      "Test Loss:0.8666\tRecon Loss:5.7391\tTriplet Loss:0.4455\tStatic Loss:0.8600\n",
      "\n",
      "\tEpoch:107\tTrain Loss:0.1692\tRecon Loss:1.8363\tTriplet Loss:0.0930\tStatic Loss:0.1602\t\n",
      "Val Loss:0.2587\tRecon Loss:1.9297\tTriplet Loss:0.1330\tStatic Loss:0.2545\n",
      "\n",
      "\tTime:63.7301\n",
      "\n",
      "Test Loss:0.8532\tRecon Loss:5.7204\tTriplet Loss:0.4100\tStatic Loss:0.8488\n",
      "\n",
      "\tEpoch:108\tTrain Loss:0.1820\tRecon Loss:1.8613\tTriplet Loss:0.1006\tStatic Loss:0.1733\t\n",
      "Val Loss:0.2650\tRecon Loss:1.9455\tTriplet Loss:0.1236\tStatic Loss:0.2623\n",
      "\n",
      "\tTime:62.2990\n",
      "\n",
      "Test Loss:0.9292\tRecon Loss:5.7797\tTriplet Loss:0.4177\tStatic Loss:0.9319\n",
      "\n",
      "\tEpoch:109\tTrain Loss:0.1727\tRecon Loss:1.8389\tTriplet Loss:0.1009\tStatic Loss:0.1632\t\n",
      "Val Loss:0.2548\tRecon Loss:1.9175\tTriplet Loss:0.1394\tStatic Loss:0.2497\n",
      "\n",
      "\tTime:62.1047\n",
      "\n",
      "Test Loss:0.8161\tRecon Loss:5.7531\tTriplet Loss:0.4361\tStatic Loss:0.8048\n",
      "\n",
      "\tEpoch:110\tTrain Loss:0.1721\tRecon Loss:1.8441\tTriplet Loss:0.0988\tStatic Loss:0.1627\t\n",
      "Val Loss:0.2569\tRecon Loss:1.9714\tTriplet Loss:0.1293\tStatic Loss:0.2525\n",
      "\n",
      "\tTime:60.1608\n",
      "\n",
      "Test Loss:0.8693\tRecon Loss:5.8099\tTriplet Loss:0.4244\tStatic Loss:0.8643\n",
      "\n",
      "\tEpoch:111\tTrain Loss:0.1681\tRecon Loss:1.8429\tTriplet Loss:0.0980\tStatic Loss:0.1584\t\n",
      "Val Loss:0.2572\tRecon Loss:1.9053\tTriplet Loss:0.1333\tStatic Loss:0.2531\n",
      "\n",
      "\tTime:60.0849\n",
      "\n",
      "Test Loss:0.8658\tRecon Loss:5.7129\tTriplet Loss:0.4270\tStatic Loss:0.8612\n",
      "\n",
      "\tEpoch:112\tTrain Loss:0.1697\tRecon Loss:1.8405\tTriplet Loss:0.0944\tStatic Loss:0.1605\t\n",
      "Val Loss:0.2577\tRecon Loss:1.9321\tTriplet Loss:0.1408\tStatic Loss:0.2527\n",
      "\n",
      "\tTime:60.8814\n",
      "\n",
      "Test Loss:0.8502\tRecon Loss:5.7499\tTriplet Loss:0.4340\tStatic Loss:0.8428\n",
      "\n",
      "\tEpoch:113\tTrain Loss:0.1693\tRecon Loss:1.8339\tTriplet Loss:0.0968\tStatic Loss:0.1599\t\n",
      "Val Loss:0.2563\tRecon Loss:1.9252\tTriplet Loss:0.1279\tStatic Loss:0.2524\n",
      "\n",
      "\tTime:61.7590\n",
      "\n",
      "Test Loss:0.8269\tRecon Loss:5.7341\tTriplet Loss:0.4242\tStatic Loss:0.8181\n",
      "\n",
      "\tEpoch:114\tTrain Loss:0.1685\tRecon Loss:1.8389\tTriplet Loss:0.0940\tStatic Loss:0.1592\t\n",
      "Val Loss:0.2552\tRecon Loss:1.9026\tTriplet Loss:0.1181\tStatic Loss:0.2525\n",
      "\n",
      "\tTime:59.2985\n",
      "\n",
      "Test Loss:0.8677\tRecon Loss:5.6953\tTriplet Loss:0.4528\tStatic Loss:0.8610\n",
      "\n",
      "\tEpoch:115\tTrain Loss:0.1880\tRecon Loss:1.8706\tTriplet Loss:0.1021\tStatic Loss:0.1798\t\n",
      "Val Loss:0.2566\tRecon Loss:1.8983\tTriplet Loss:0.1194\tStatic Loss:0.2538\n",
      "\n",
      "\tTime:58.8616\n",
      "\n",
      "Test Loss:0.8674\tRecon Loss:5.7255\tTriplet Loss:0.4429\tStatic Loss:0.8613\n",
      "\n",
      "\tEpoch:116\tTrain Loss:0.1726\tRecon Loss:1.8323\tTriplet Loss:0.0991\tStatic Loss:0.1633\t\n",
      "Val Loss:0.2594\tRecon Loss:1.9068\tTriplet Loss:0.1248\tStatic Loss:0.2563\n",
      "\n",
      "\tTime:60.4043\n",
      "\n",
      "Test Loss:0.8766\tRecon Loss:5.7236\tTriplet Loss:0.4432\tStatic Loss:0.8715\n",
      "\n",
      "\tEpoch:117\tTrain Loss:0.1824\tRecon Loss:1.8500\tTriplet Loss:0.1000\tStatic Loss:0.1740\t\n",
      "Val Loss:0.2544\tRecon Loss:1.9088\tTriplet Loss:0.1261\tStatic Loss:0.2506\n",
      "\n",
      "\tTime:60.7316\n",
      "\n",
      "Test Loss:0.8237\tRecon Loss:5.7325\tTriplet Loss:0.4153\tStatic Loss:0.8154\n",
      "\n",
      "\tEpoch:118\tTrain Loss:0.1700\tRecon Loss:1.8356\tTriplet Loss:0.0995\tStatic Loss:0.1603\t\n",
      "Val Loss:0.2564\tRecon Loss:1.9299\tTriplet Loss:0.1387\tStatic Loss:0.2515\n",
      "\n",
      "\tTime:59.8391\n",
      "\n",
      "Test Loss:0.8492\tRecon Loss:5.7448\tTriplet Loss:0.4451\tStatic Loss:0.8406\n",
      "\n",
      "\tEpoch:119\tTrain Loss:0.1676\tRecon Loss:1.8387\tTriplet Loss:0.0951\tStatic Loss:0.1581\t\n",
      "Val Loss:0.2557\tRecon Loss:1.9064\tTriplet Loss:0.1284\tStatic Loss:0.2519\n",
      "\n",
      "\tTime:59.9365\n",
      "\n",
      "Test Loss:0.8094\tRecon Loss:5.6707\tTriplet Loss:0.4159\tStatic Loss:0.8001\n",
      "\n",
      "\tEpoch:120\tTrain Loss:0.1695\tRecon Loss:1.8409\tTriplet Loss:0.0953\tStatic Loss:0.1602\t\n",
      "Val Loss:0.2573\tRecon Loss:1.9415\tTriplet Loss:0.1295\tStatic Loss:0.2532\n",
      "\n",
      "\tTime:60.4173\n",
      "\n",
      "Test Loss:0.8461\tRecon Loss:5.7242\tTriplet Loss:0.4149\tStatic Loss:0.8405\n",
      "\n",
      "\tEpoch:121\tTrain Loss:0.1672\tRecon Loss:1.8332\tTriplet Loss:0.0948\tStatic Loss:0.1578\t\n",
      "Val Loss:0.2562\tRecon Loss:1.9709\tTriplet Loss:0.1254\tStatic Loss:0.2522\n",
      "\n",
      "\tTime:59.5844\n",
      "\n",
      "Test Loss:0.8499\tRecon Loss:5.7224\tTriplet Loss:0.4456\tStatic Loss:0.8417\n",
      "\n",
      "\tEpoch:122\tTrain Loss:0.1674\tRecon Loss:1.8438\tTriplet Loss:0.0981\tStatic Loss:0.1575\t\n",
      "Val Loss:0.2575\tRecon Loss:1.9231\tTriplet Loss:0.1359\tStatic Loss:0.2530\n",
      "\n",
      "\tTime:60.7485\n",
      "\n",
      "Test Loss:0.8240\tRecon Loss:5.6966\tTriplet Loss:0.3926\tStatic Loss:0.8184\n",
      "\n",
      "\tEpoch:123\tTrain Loss:0.1731\tRecon Loss:1.8473\tTriplet Loss:0.0936\tStatic Loss:0.1643\t\n",
      "Val Loss:0.2516\tRecon Loss:1.9169\tTriplet Loss:0.1196\tStatic Loss:0.2482\n",
      "\n",
      "\tTime:60.4735\n",
      "\n",
      "Test Loss:0.8277\tRecon Loss:5.7056\tTriplet Loss:0.4129\tStatic Loss:0.8204\n",
      "\n",
      "\tEpoch:124\tTrain Loss:0.1673\tRecon Loss:1.8349\tTriplet Loss:0.0933\tStatic Loss:0.1580\t\n",
      "Val Loss:0.2538\tRecon Loss:1.9112\tTriplet Loss:0.1331\tStatic Loss:0.2493\n",
      "\n",
      "\tTime:59.9163\n",
      "\n",
      "Test Loss:0.8439\tRecon Loss:5.7744\tTriplet Loss:0.4528\tStatic Loss:0.8337\n",
      "\n",
      "\tEpoch:125\tTrain Loss:0.1700\tRecon Loss:1.8549\tTriplet Loss:0.0911\tStatic Loss:0.1610\t\n",
      "Val Loss:0.2551\tRecon Loss:1.9536\tTriplet Loss:0.1229\tStatic Loss:0.2514\n",
      "\n",
      "\tTime:61.5515\n",
      "\n",
      "Test Loss:0.8571\tRecon Loss:5.7798\tTriplet Loss:0.4291\tStatic Loss:0.8507\n",
      "\n",
      "\tEpoch:126\tTrain Loss:0.1689\tRecon Loss:1.8430\tTriplet Loss:0.0947\tStatic Loss:0.1595\t\n",
      "Val Loss:0.2561\tRecon Loss:1.9174\tTriplet Loss:0.1251\tStatic Loss:0.2526\n",
      "\n",
      "\tTime:61.2670\n",
      "\n",
      "Test Loss:0.8521\tRecon Loss:5.7289\tTriplet Loss:0.4343\tStatic Loss:0.8451\n",
      "\n",
      "\tEpoch:127\tTrain Loss:0.1674\tRecon Loss:1.8430\tTriplet Loss:0.0949\tStatic Loss:0.1579\t\n",
      "Val Loss:0.2560\tRecon Loss:1.9183\tTriplet Loss:0.1242\tStatic Loss:0.2525\n",
      "\n",
      "\tTime:60.8731\n",
      "\n",
      "Test Loss:0.8580\tRecon Loss:5.7633\tTriplet Loss:0.4459\tStatic Loss:0.8502\n",
      "\n",
      "\tEpoch:128\tTrain Loss:0.1677\tRecon Loss:1.8352\tTriplet Loss:0.0927\tStatic Loss:0.1585\t\n",
      "Val Loss:0.2587\tRecon Loss:1.9149\tTriplet Loss:0.1279\tStatic Loss:0.2552\n",
      "\n",
      "\tTime:60.8797\n",
      "\n",
      "Test Loss:0.8697\tRecon Loss:5.7111\tTriplet Loss:0.4443\tStatic Loss:0.8639\n",
      "\n",
      "\tEpoch:129\tTrain Loss:0.1663\tRecon Loss:1.8400\tTriplet Loss:0.0948\tStatic Loss:0.1567\t\n",
      "Val Loss:0.2557\tRecon Loss:1.9192\tTriplet Loss:0.1261\tStatic Loss:0.2520\n",
      "\n",
      "\tTime:59.8018\n",
      "\n",
      "Test Loss:0.8259\tRecon Loss:5.6888\tTriplet Loss:0.4410\tStatic Loss:0.8158\n",
      "\n",
      "\tEpoch:130\tTrain Loss:0.1681\tRecon Loss:1.8478\tTriplet Loss:0.0935\tStatic Loss:0.1588\t\n",
      "Val Loss:0.2608\tRecon Loss:1.9372\tTriplet Loss:0.1325\tStatic Loss:0.2569\n",
      "\n",
      "\tTime:60.8159\n",
      "\n",
      "Test Loss:0.8430\tRecon Loss:5.7351\tTriplet Loss:0.4394\tStatic Loss:0.8344\n",
      "\n",
      "\tEpoch:131\tTrain Loss:0.1691\tRecon Loss:1.8368\tTriplet Loss:0.0952\tStatic Loss:0.1598\t\n",
      "Val Loss:0.2606\tRecon Loss:1.9426\tTriplet Loss:0.1191\tStatic Loss:0.2579\n",
      "\n",
      "\tTime:50.9940\n",
      "\n",
      "Test Loss:0.8374\tRecon Loss:5.8026\tTriplet Loss:0.4262\tStatic Loss:0.8289\n",
      "\n",
      "\tEpoch:132\tTrain Loss:0.1690\tRecon Loss:1.8429\tTriplet Loss:0.0950\tStatic Loss:0.1597\t\n",
      "Val Loss:0.2565\tRecon Loss:1.9166\tTriplet Loss:0.1249\tStatic Loss:0.2530\n",
      "\n",
      "\tTime:48.8609\n",
      "\n",
      "Test Loss:0.8326\tRecon Loss:5.7098\tTriplet Loss:0.3966\tStatic Loss:0.8275\n",
      "\n",
      "\tEpoch:133\tTrain Loss:0.1713\tRecon Loss:1.8419\tTriplet Loss:0.0939\tStatic Loss:0.1623\t\n",
      "Val Loss:0.2575\tRecon Loss:1.9583\tTriplet Loss:0.1303\tStatic Loss:0.2533\n",
      "\n",
      "\tTime:48.9745\n",
      "\n",
      "Test Loss:0.8572\tRecon Loss:5.7479\tTriplet Loss:0.4203\tStatic Loss:0.8520\n",
      "\n",
      "\tEpoch:134\tTrain Loss:0.1649\tRecon Loss:1.8332\tTriplet Loss:0.0966\tStatic Loss:0.1551\t\n",
      "Val Loss:0.2581\tRecon Loss:1.9102\tTriplet Loss:0.1374\tStatic Loss:0.2537\n",
      "\n",
      "\tTime:49.1676\n",
      "\n",
      "Test Loss:0.8486\tRecon Loss:5.7202\tTriplet Loss:0.4506\tStatic Loss:0.8397\n",
      "\n",
      "\tEpoch:135\tTrain Loss:0.1667\tRecon Loss:1.8520\tTriplet Loss:0.0966\tStatic Loss:0.1569\t\n",
      "Val Loss:0.2584\tRecon Loss:1.9424\tTriplet Loss:0.1219\tStatic Loss:0.2552\n",
      "\n",
      "\tTime:50.0430\n",
      "\n",
      "Test Loss:0.8271\tRecon Loss:5.7779\tTriplet Loss:0.4204\tStatic Loss:0.8183\n",
      "\n",
      "\tEpoch:136\tTrain Loss:0.1649\tRecon Loss:1.8468\tTriplet Loss:0.0910\tStatic Loss:0.1554\t\n",
      "Val Loss:0.2535\tRecon Loss:2.0024\tTriplet Loss:0.1286\tStatic Loss:0.2485\n",
      "\n",
      "\tTime:50.6938\n",
      "\n",
      "Test Loss:0.8465\tRecon Loss:5.8639\tTriplet Loss:0.4365\tStatic Loss:0.8373\n",
      "\n",
      "\tEpoch:137\tTrain Loss:0.1663\tRecon Loss:1.8363\tTriplet Loss:0.0924\tStatic Loss:0.1570\t\n",
      "Val Loss:0.2519\tRecon Loss:1.9079\tTriplet Loss:0.1318\tStatic Loss:0.2473\n",
      "\n",
      "\tTime:50.3184\n",
      "\n",
      "Test Loss:0.8488\tRecon Loss:5.7188\tTriplet Loss:0.4297\tStatic Loss:0.8420\n",
      "\n",
      "\tEpoch:138\tTrain Loss:0.1698\tRecon Loss:1.8451\tTriplet Loss:0.0942\tStatic Loss:0.1606\t\n",
      "Val Loss:0.2553\tRecon Loss:1.9376\tTriplet Loss:0.1360\tStatic Loss:0.2504\n",
      "\n",
      "\tTime:50.7388\n",
      "\n",
      "Test Loss:0.8226\tRecon Loss:5.7527\tTriplet Loss:0.4344\tStatic Loss:0.8121\n",
      "\n",
      "\tEpoch:139\tTrain Loss:0.1754\tRecon Loss:1.8562\tTriplet Loss:0.1004\tStatic Loss:0.1661\t\n",
      "Val Loss:0.2593\tRecon Loss:1.9510\tTriplet Loss:0.1311\tStatic Loss:0.2552\n",
      "\n",
      "\tTime:49.6849\n",
      "\n",
      "Test Loss:0.8666\tRecon Loss:5.8286\tTriplet Loss:0.4630\tStatic Loss:0.8574\n",
      "\n",
      "\tEpoch:140\tTrain Loss:0.1720\tRecon Loss:1.8388\tTriplet Loss:0.0958\tStatic Loss:0.1629\t\n",
      "Val Loss:0.2558\tRecon Loss:1.9156\tTriplet Loss:0.1329\tStatic Loss:0.2515\n",
      "\n",
      "\tTime:50.0473\n",
      "\n",
      "Test Loss:0.8105\tRecon Loss:5.6568\tTriplet Loss:0.4476\tStatic Loss:0.7983\n",
      "\n",
      "\tEpoch:141\tTrain Loss:0.1703\tRecon Loss:1.8392\tTriplet Loss:0.0936\tStatic Loss:0.1613\t\n",
      "Val Loss:0.2533\tRecon Loss:1.9272\tTriplet Loss:0.1203\tStatic Loss:0.2499\n",
      "\n",
      "\tTime:50.2371\n",
      "\n",
      "Test Loss:0.8513\tRecon Loss:5.6900\tTriplet Loss:0.4543\tStatic Loss:0.8426\n",
      "\n",
      "\tEpoch:142\tTrain Loss:0.1690\tRecon Loss:1.8325\tTriplet Loss:0.0927\tStatic Loss:0.1600\t\n",
      "Val Loss:0.2618\tRecon Loss:1.9740\tTriplet Loss:0.1384\tStatic Loss:0.2570\n",
      "\n",
      "\tTime:50.1650\n",
      "\n",
      "Test Loss:0.8352\tRecon Loss:5.8148\tTriplet Loss:0.4009\tStatic Loss:0.8289\n",
      "\n",
      "\tEpoch:143\tTrain Loss:0.1703\tRecon Loss:1.8382\tTriplet Loss:0.0946\tStatic Loss:0.1612\t\n",
      "Val Loss:0.2544\tRecon Loss:1.9018\tTriplet Loss:0.1290\tStatic Loss:0.2505\n",
      "\n",
      "\tTime:49.3979\n",
      "\n",
      "Test Loss:0.8439\tRecon Loss:5.7170\tTriplet Loss:0.4439\tStatic Loss:0.8352\n",
      "\n",
      "\tEpoch:144\tTrain Loss:0.1657\tRecon Loss:1.8369\tTriplet Loss:0.0960\tStatic Loss:0.1560\t\n",
      "Val Loss:0.2555\tRecon Loss:1.9327\tTriplet Loss:0.1298\tStatic Loss:0.2513\n",
      "\n",
      "\tTime:49.7203\n",
      "\n",
      "Test Loss:0.8458\tRecon Loss:5.6827\tTriplet Loss:0.4354\tStatic Loss:0.8385\n",
      "\n",
      "\tEpoch:145\tTrain Loss:0.1660\tRecon Loss:1.8313\tTriplet Loss:0.0904\tStatic Loss:0.1569\t\n",
      "Val Loss:0.2544\tRecon Loss:1.9114\tTriplet Loss:0.1312\tStatic Loss:0.2501\n",
      "\n",
      "\tTime:49.7503\n",
      "\n",
      "Test Loss:0.8367\tRecon Loss:5.7257\tTriplet Loss:0.4516\tStatic Loss:0.8263\n",
      "\n",
      "\tEpoch:146\tTrain Loss:0.1652\tRecon Loss:1.8473\tTriplet Loss:0.0945\tStatic Loss:0.1555\t\n",
      "Val Loss:0.2510\tRecon Loss:1.9419\tTriplet Loss:0.1282\tStatic Loss:0.2464\n",
      "\n",
      "\tTime:50.0749\n",
      "\n",
      "Test Loss:0.8401\tRecon Loss:5.7562\tTriplet Loss:0.4321\tStatic Loss:0.8318\n",
      "\n",
      "\tEpoch:147\tTrain Loss:0.1654\tRecon Loss:1.8494\tTriplet Loss:0.0962\tStatic Loss:0.1555\t\n",
      "Val Loss:0.2554\tRecon Loss:1.9201\tTriplet Loss:0.1275\tStatic Loss:0.2516\n",
      "\n",
      "\tTime:51.0532\n",
      "\n",
      "Test Loss:0.8708\tRecon Loss:5.7487\tTriplet Loss:0.4652\tStatic Loss:0.8626\n",
      "\n",
      "\tEpoch:148\tTrain Loss:0.1669\tRecon Loss:1.8419\tTriplet Loss:0.0988\tStatic Loss:0.1569\t\n",
      "Val Loss:0.2544\tRecon Loss:1.9273\tTriplet Loss:0.1281\tStatic Loss:0.2503\n",
      "\n",
      "\tTime:49.2962\n",
      "\n",
      "Test Loss:0.8756\tRecon Loss:5.7004\tTriplet Loss:0.4363\tStatic Loss:0.8712\n",
      "\n",
      "\tEpoch:149\tTrain Loss:0.1651\tRecon Loss:1.8367\tTriplet Loss:0.0919\tStatic Loss:0.1557\t\n",
      "Val Loss:0.2580\tRecon Loss:1.9510\tTriplet Loss:0.1292\tStatic Loss:0.2539\n",
      "\n",
      "\tTime:49.1794\n",
      "\n",
      "Test Loss:0.8280\tRecon Loss:5.7205\tTriplet Loss:0.4195\tStatic Loss:0.8199\n",
      "\n",
      "\tEpoch:150\tTrain Loss:0.1639\tRecon Loss:1.8296\tTriplet Loss:0.0936\tStatic Loss:0.1543\t\n",
      "Val Loss:0.2571\tRecon Loss:1.9376\tTriplet Loss:0.1254\tStatic Loss:0.2534\n",
      "\n",
      "\tTime:49.2833\n",
      "\n",
      "Test Loss:0.8551\tRecon Loss:5.7208\tTriplet Loss:0.4381\tStatic Loss:0.8482\n",
      "\n",
      "\tEpoch:151\tTrain Loss:0.1641\tRecon Loss:1.8363\tTriplet Loss:0.0958\tStatic Loss:0.1542\t\n",
      "Val Loss:0.2593\tRecon Loss:1.9392\tTriplet Loss:0.1257\tStatic Loss:0.2558\n",
      "\n",
      "\tTime:49.3819\n",
      "\n",
      "Test Loss:0.8595\tRecon Loss:5.7241\tTriplet Loss:0.4551\tStatic Loss:0.8513\n",
      "\n",
      "\tEpoch:152\tTrain Loss:0.1724\tRecon Loss:1.8464\tTriplet Loss:0.0999\tStatic Loss:0.1629\t\n",
      "Val Loss:0.2581\tRecon Loss:1.9315\tTriplet Loss:0.1319\tStatic Loss:0.2539\n",
      "\n",
      "\tTime:48.5758\n",
      "\n",
      "Test Loss:0.8188\tRecon Loss:5.6987\tTriplet Loss:0.4379\tStatic Loss:0.8081\n",
      "\n",
      "\tEpoch:153\tTrain Loss:0.1643\tRecon Loss:1.8279\tTriplet Loss:0.0924\tStatic Loss:0.1548\t\n",
      "Val Loss:0.2597\tRecon Loss:1.9764\tTriplet Loss:0.1340\tStatic Loss:0.2551\n",
      "\n",
      "\tTime:49.3576\n",
      "\n",
      "Test Loss:0.8270\tRecon Loss:5.7468\tTriplet Loss:0.4091\tStatic Loss:0.8196\n",
      "\n",
      "\tEpoch:154\tTrain Loss:0.1647\tRecon Loss:1.8471\tTriplet Loss:0.0919\tStatic Loss:0.1551\t\n",
      "Val Loss:0.2551\tRecon Loss:1.9216\tTriplet Loss:0.1267\tStatic Loss:0.2512\n",
      "\n",
      "\tTime:49.8674\n",
      "\n",
      "Test Loss:0.8318\tRecon Loss:5.6899\tTriplet Loss:0.4192\tStatic Loss:0.8244\n",
      "\n",
      "\tEpoch:155\tTrain Loss:0.1762\tRecon Loss:1.8560\tTriplet Loss:0.0991\tStatic Loss:0.1671\t\n",
      "Val Loss:0.2560\tRecon Loss:1.9018\tTriplet Loss:0.1312\tStatic Loss:0.2521\n",
      "\n",
      "\tTime:50.5431\n",
      "\n",
      "Test Loss:0.8446\tRecon Loss:5.7096\tTriplet Loss:0.4248\tStatic Loss:0.8379\n",
      "\n",
      "\tEpoch:156\tTrain Loss:0.1647\tRecon Loss:1.8310\tTriplet Loss:0.0912\tStatic Loss:0.1553\t\n",
      "Val Loss:0.2555\tRecon Loss:1.9083\tTriplet Loss:0.1242\tStatic Loss:0.2521\n",
      "\n",
      "\tTime:55.6443\n",
      "\n",
      "Test Loss:0.8379\tRecon Loss:5.7011\tTriplet Loss:0.4433\tStatic Loss:0.8288\n",
      "\n",
      "\tEpoch:157\tTrain Loss:0.1626\tRecon Loss:1.8374\tTriplet Loss:0.0964\tStatic Loss:0.1525\t\n",
      "Val Loss:0.2550\tRecon Loss:1.9483\tTriplet Loss:0.1215\tStatic Loss:0.2514\n",
      "\n",
      "\tTime:49.9702\n",
      "\n",
      "Test Loss:0.8471\tRecon Loss:5.7519\tTriplet Loss:0.4155\tStatic Loss:0.8412\n",
      "\n",
      "\tEpoch:158\tTrain Loss:0.1705\tRecon Loss:1.8407\tTriplet Loss:0.0978\tStatic Loss:0.1611\t\n",
      "Val Loss:0.2521\tRecon Loss:1.9219\tTriplet Loss:0.1373\tStatic Loss:0.2469\n",
      "\n",
      "\tTime:49.4063\n",
      "\n",
      "Test Loss:0.8443\tRecon Loss:5.7516\tTriplet Loss:0.4313\tStatic Loss:0.8365\n",
      "\n",
      "\tEpoch:159\tTrain Loss:0.1658\tRecon Loss:1.8343\tTriplet Loss:0.0880\tStatic Loss:0.1569\t\n",
      "Val Loss:0.2614\tRecon Loss:1.9346\tTriplet Loss:0.1299\tStatic Loss:0.2578\n",
      "\n",
      "\tTime:49.6768\n",
      "\n",
      "Test Loss:0.8543\tRecon Loss:5.7181\tTriplet Loss:0.4141\tStatic Loss:0.8497\n",
      "\n",
      "\tEpoch:160\tTrain Loss:0.1656\tRecon Loss:1.8327\tTriplet Loss:0.0918\tStatic Loss:0.1563\t\n",
      "Val Loss:0.2554\tRecon Loss:1.9614\tTriplet Loss:0.1303\tStatic Loss:0.2508\n",
      "\n",
      "\tTime:49.2823\n",
      "\n",
      "Test Loss:0.8196\tRecon Loss:5.7496\tTriplet Loss:0.4540\tStatic Loss:0.8069\n",
      "\n",
      "\tEpoch:161\tTrain Loss:0.1632\tRecon Loss:1.8278\tTriplet Loss:0.0921\tStatic Loss:0.1537\t\n",
      "Val Loss:0.2561\tRecon Loss:1.9083\tTriplet Loss:0.1285\tStatic Loss:0.2523\n",
      "\n",
      "\tTime:49.6252\n",
      "\n",
      "Test Loss:0.8552\tRecon Loss:5.7212\tTriplet Loss:0.4490\tStatic Loss:0.8472\n",
      "\n",
      "\tEpoch:162\tTrain Loss:0.1638\tRecon Loss:1.8304\tTriplet Loss:0.0951\tStatic Loss:0.1539\t\n",
      "Val Loss:0.2547\tRecon Loss:1.9373\tTriplet Loss:0.1338\tStatic Loss:0.2499\n",
      "\n",
      "\tTime:48.9493\n",
      "\n",
      "Test Loss:0.8323\tRecon Loss:5.7621\tTriplet Loss:0.4105\tStatic Loss:0.8251\n",
      "\n",
      "\tEpoch:163\tTrain Loss:0.1674\tRecon Loss:1.8407\tTriplet Loss:0.0928\tStatic Loss:0.1582\t\n",
      "Val Loss:0.2540\tRecon Loss:1.9111\tTriplet Loss:0.1349\tStatic Loss:0.2493\n",
      "\n",
      "\tTime:49.4793\n",
      "\n",
      "Test Loss:0.8431\tRecon Loss:5.6892\tTriplet Loss:0.4470\tStatic Loss:0.8343\n",
      "\n",
      "\tEpoch:164\tTrain Loss:0.1657\tRecon Loss:1.8295\tTriplet Loss:0.0929\tStatic Loss:0.1563\t\n",
      "Val Loss:0.2606\tRecon Loss:1.9274\tTriplet Loss:0.1309\tStatic Loss:0.2569\n",
      "\n",
      "\tTime:49.0155\n",
      "\n",
      "Test Loss:0.8803\tRecon Loss:5.7615\tTriplet Loss:0.4660\tStatic Loss:0.8729\n",
      "\n",
      "\tEpoch:165\tTrain Loss:0.1642\tRecon Loss:1.8452\tTriplet Loss:0.0915\tStatic Loss:0.1546\t\n",
      "Val Loss:0.2547\tRecon Loss:1.9163\tTriplet Loss:0.1268\tStatic Loss:0.2509\n",
      "\n",
      "\tTime:49.2734\n",
      "\n",
      "Test Loss:0.8216\tRecon Loss:5.8135\tTriplet Loss:0.4240\tStatic Loss:0.8115\n",
      "\n",
      "\tEpoch:166\tTrain Loss:0.1786\tRecon Loss:1.8693\tTriplet Loss:0.1000\tStatic Loss:0.1695\t\n",
      "Val Loss:0.2516\tRecon Loss:1.9342\tTriplet Loss:0.1218\tStatic Loss:0.2478\n",
      "\n",
      "\tTime:49.4227\n",
      "\n",
      "Test Loss:0.8306\tRecon Loss:5.7353\tTriplet Loss:0.4340\tStatic Loss:0.8212\n",
      "\n",
      "\tEpoch:167\tTrain Loss:0.1726\tRecon Loss:1.8337\tTriplet Loss:0.0955\tStatic Loss:0.1637\t\n",
      "Val Loss:0.2566\tRecon Loss:1.9395\tTriplet Loss:0.1321\tStatic Loss:0.2523\n",
      "\n",
      "\tTime:49.6261\n",
      "\n",
      "Test Loss:0.8264\tRecon Loss:5.7689\tTriplet Loss:0.4284\tStatic Loss:0.8168\n",
      "\n",
      "\tEpoch:168\tTrain Loss:0.1653\tRecon Loss:1.8420\tTriplet Loss:0.0913\tStatic Loss:0.1560\t\n",
      "Val Loss:0.2499\tRecon Loss:1.9231\tTriplet Loss:0.1222\tStatic Loss:0.2459\n",
      "\n",
      "\tTime:49.8507\n",
      "\n",
      "Test Loss:0.8140\tRecon Loss:5.7203\tTriplet Loss:0.4044\tStatic Loss:0.8059\n",
      "\n",
      "\tEpoch:169\tTrain Loss:0.1619\tRecon Loss:1.8336\tTriplet Loss:0.0919\tStatic Loss:0.1522\t\n",
      "Val Loss:0.2544\tRecon Loss:1.9037\tTriplet Loss:0.1265\tStatic Loss:0.2507\n",
      "\n",
      "\tTime:49.6383\n",
      "\n",
      "Test Loss:0.8375\tRecon Loss:5.6862\tTriplet Loss:0.4311\tStatic Loss:0.8297\n",
      "\n",
      "\tEpoch:170\tTrain Loss:0.1647\tRecon Loss:1.8295\tTriplet Loss:0.0961\tStatic Loss:0.1549\t\n",
      "Val Loss:0.2553\tRecon Loss:1.9307\tTriplet Loss:0.1165\tStatic Loss:0.2524\n",
      "\n",
      "\tTime:49.2181\n",
      "\n",
      "Test Loss:0.8377\tRecon Loss:5.7742\tTriplet Loss:0.4331\tStatic Loss:0.8288\n",
      "\n",
      "\tEpoch:171\tTrain Loss:0.1745\tRecon Loss:1.8669\tTriplet Loss:0.0992\tStatic Loss:0.1651\t\n",
      "Val Loss:0.2612\tRecon Loss:1.9231\tTriplet Loss:0.1223\tStatic Loss:0.2585\n",
      "\n",
      "\tTime:48.5702\n",
      "\n",
      "Test Loss:0.8464\tRecon Loss:5.7489\tTriplet Loss:0.4017\tStatic Loss:0.8419\n",
      "\n",
      "\tEpoch:172\tTrain Loss:0.1759\tRecon Loss:1.8611\tTriplet Loss:0.0984\tStatic Loss:0.1668\t\n",
      "Val Loss:0.2645\tRecon Loss:1.9761\tTriplet Loss:0.1225\tStatic Loss:0.2616\n",
      "\n",
      "\tTime:48.4408\n",
      "\n",
      "Test Loss:0.8301\tRecon Loss:5.8418\tTriplet Loss:0.4531\tStatic Loss:0.8176\n",
      "\n",
      "\tEpoch:173\tTrain Loss:0.1707\tRecon Loss:1.8438\tTriplet Loss:0.0956\tStatic Loss:0.1615\t\n",
      "Val Loss:0.2485\tRecon Loss:1.9115\tTriplet Loss:0.1140\tStatic Loss:0.2453\n",
      "\n",
      "\tTime:48.9160\n",
      "\n",
      "Test Loss:0.8349\tRecon Loss:5.6879\tTriplet Loss:0.4086\tStatic Loss:0.8290\n",
      "\n",
      "\tEpoch:174\tTrain Loss:0.1630\tRecon Loss:1.8248\tTriplet Loss:0.0951\tStatic Loss:0.1532\t\n",
      "Val Loss:0.2559\tRecon Loss:1.9520\tTriplet Loss:0.1166\tStatic Loss:0.2529\n",
      "\n",
      "\tTime:49.5675\n",
      "\n",
      "Test Loss:0.8558\tRecon Loss:5.7907\tTriplet Loss:0.4415\tStatic Loss:0.8479\n",
      "\n",
      "\tEpoch:175\tTrain Loss:0.1631\tRecon Loss:1.8406\tTriplet Loss:0.0862\tStatic Loss:0.1540\t\n",
      "Val Loss:0.2500\tRecon Loss:1.9595\tTriplet Loss:0.1184\tStatic Loss:0.2461\n",
      "\n",
      "\tTime:50.5641\n",
      "\n",
      "Test Loss:0.8320\tRecon Loss:5.7624\tTriplet Loss:0.4373\tStatic Loss:0.8222\n",
      "\n",
      "\tEpoch:176\tTrain Loss:0.1621\tRecon Loss:1.8288\tTriplet Loss:0.0902\tStatic Loss:0.1526\t\n",
      "Val Loss:0.2564\tRecon Loss:1.9102\tTriplet Loss:0.1241\tStatic Loss:0.2531\n",
      "\n",
      "\tTime:49.7352\n",
      "\n",
      "Test Loss:0.8622\tRecon Loss:5.7276\tTriplet Loss:0.4568\tStatic Loss:0.8541\n",
      "\n",
      "\tEpoch:177\tTrain Loss:0.1664\tRecon Loss:1.8658\tTriplet Loss:0.0902\tStatic Loss:0.1570\t\n",
      "Val Loss:0.2600\tRecon Loss:1.9061\tTriplet Loss:0.1389\tStatic Loss:0.2556\n",
      "\n",
      "\tTime:49.6081\n",
      "\n",
      "Test Loss:0.8728\tRecon Loss:5.7316\tTriplet Loss:0.4340\tStatic Loss:0.8681\n",
      "\n",
      "\tEpoch:178\tTrain Loss:0.1615\tRecon Loss:1.8269\tTriplet Loss:0.0942\tStatic Loss:0.1516\t\n",
      "Val Loss:0.2564\tRecon Loss:1.9384\tTriplet Loss:0.1331\tStatic Loss:0.2519\n",
      "\n",
      "\tTime:49.5171\n",
      "\n",
      "Test Loss:0.8276\tRecon Loss:5.7609\tTriplet Loss:0.4302\tStatic Loss:0.8180\n",
      "\n",
      "\tEpoch:179\tTrain Loss:0.1714\tRecon Loss:1.8483\tTriplet Loss:0.0974\tStatic Loss:0.1620\t\n",
      "Val Loss:0.2569\tRecon Loss:1.9383\tTriplet Loss:0.1269\tStatic Loss:0.2531\n",
      "\n",
      "\tTime:49.7877\n",
      "\n",
      "Test Loss:0.8398\tRecon Loss:5.7804\tTriplet Loss:0.4293\tStatic Loss:0.8315\n",
      "\n",
      "\tEpoch:180\tTrain Loss:0.1669\tRecon Loss:1.8327\tTriplet Loss:0.0952\tStatic Loss:0.1574\t\n",
      "Val Loss:0.2608\tRecon Loss:1.9337\tTriplet Loss:0.1223\tStatic Loss:0.2579\n",
      "\n",
      "\tTime:49.3838\n",
      "\n",
      "Test Loss:0.8786\tRecon Loss:5.7382\tTriplet Loss:0.4291\tStatic Loss:0.8750\n",
      "\n",
      "\tEpoch:181\tTrain Loss:0.1663\tRecon Loss:1.8358\tTriplet Loss:0.0967\tStatic Loss:0.1566\t\n",
      "Val Loss:0.2572\tRecon Loss:1.9543\tTriplet Loss:0.1251\tStatic Loss:0.2535\n",
      "\n",
      "\tTime:48.8380\n",
      "\n",
      "Test Loss:0.8475\tRecon Loss:5.7393\tTriplet Loss:0.4117\tStatic Loss:0.8422\n",
      "\n",
      "\tEpoch:182\tTrain Loss:0.1633\tRecon Loss:1.8389\tTriplet Loss:0.0926\tStatic Loss:0.1536\t\n",
      "Val Loss:0.2634\tRecon Loss:1.9270\tTriplet Loss:0.1266\tStatic Loss:0.2604\n",
      "\n",
      "\tTime:49.1985\n",
      "\n",
      "Test Loss:0.8640\tRecon Loss:5.7090\tTriplet Loss:0.4110\tStatic Loss:0.8608\n",
      "\n",
      "\tEpoch:183\tTrain Loss:0.1627\tRecon Loss:1.8369\tTriplet Loss:0.0932\tStatic Loss:0.1529\t\n",
      "Val Loss:0.2557\tRecon Loss:1.9344\tTriplet Loss:0.1213\tStatic Loss:0.2524\n",
      "\n",
      "\tTime:49.6483\n",
      "\n",
      "Test Loss:0.8300\tRecon Loss:5.7238\tTriplet Loss:0.4290\tStatic Loss:0.8212\n",
      "\n",
      "\tEpoch:184\tTrain Loss:0.1638\tRecon Loss:1.8340\tTriplet Loss:0.0903\tStatic Loss:0.1544\t\n",
      "Val Loss:0.2590\tRecon Loss:1.9791\tTriplet Loss:0.1338\tStatic Loss:0.2543\n",
      "\n",
      "\tTime:49.3276\n",
      "\n",
      "Test Loss:0.8627\tRecon Loss:5.7337\tTriplet Loss:0.4474\tStatic Loss:0.8555\n",
      "\n",
      "\tEpoch:185\tTrain Loss:0.1638\tRecon Loss:1.8404\tTriplet Loss:0.0915\tStatic Loss:0.1543\t\n",
      "Val Loss:0.2612\tRecon Loss:1.9658\tTriplet Loss:0.1280\tStatic Loss:0.2575\n",
      "\n",
      "\tTime:49.7930\n",
      "\n",
      "Test Loss:0.8839\tRecon Loss:5.7777\tTriplet Loss:0.4176\tStatic Loss:0.8816\n",
      "\n",
      "\tEpoch:186\tTrain Loss:0.1635\tRecon Loss:1.8314\tTriplet Loss:0.0960\tStatic Loss:0.1536\t\n",
      "Val Loss:0.2524\tRecon Loss:1.9169\tTriplet Loss:0.1319\tStatic Loss:0.2478\n",
      "\n",
      "\tTime:49.3610\n",
      "\n",
      "Test Loss:0.8319\tRecon Loss:5.7582\tTriplet Loss:0.4422\tStatic Loss:0.8216\n",
      "\n",
      "\tEpoch:187\tTrain Loss:0.1673\tRecon Loss:1.8375\tTriplet Loss:0.0945\tStatic Loss:0.1579\t\n",
      "Val Loss:0.2552\tRecon Loss:1.9097\tTriplet Loss:0.1248\tStatic Loss:0.2517\n",
      "\n",
      "\tTime:49.3353\n",
      "\n",
      "Test Loss:0.8477\tRecon Loss:5.7695\tTriplet Loss:0.4387\tStatic Loss:0.8394\n",
      "\n",
      "\tEpoch:188\tTrain Loss:0.1649\tRecon Loss:1.8347\tTriplet Loss:0.0968\tStatic Loss:0.1550\t\n",
      "Val Loss:0.2503\tRecon Loss:1.9235\tTriplet Loss:0.1246\tStatic Loss:0.2461\n",
      "\n",
      "\tTime:48.7768\n",
      "\n",
      "Test Loss:0.8050\tRecon Loss:5.6978\tTriplet Loss:0.4245\tStatic Loss:0.7942\n",
      "\n",
      "\tEpoch:189\tTrain Loss:0.1620\tRecon Loss:1.8342\tTriplet Loss:0.0926\tStatic Loss:0.1523\t\n",
      "Val Loss:0.2524\tRecon Loss:1.9222\tTriplet Loss:0.1251\tStatic Loss:0.2484\n",
      "\n",
      "\tTime:49.0537\n",
      "\n",
      "Test Loss:0.8596\tRecon Loss:5.7548\tTriplet Loss:0.4258\tStatic Loss:0.8541\n",
      "\n",
      "\tEpoch:190\tTrain Loss:0.1649\tRecon Loss:1.8483\tTriplet Loss:0.0925\tStatic Loss:0.1554\t\n",
      "Val Loss:0.2603\tRecon Loss:1.9323\tTriplet Loss:0.1171\tStatic Loss:0.2580\n",
      "\n",
      "\tTime:48.7452\n",
      "\n",
      "Test Loss:0.8399\tRecon Loss:5.7899\tTriplet Loss:0.4081\tStatic Loss:0.8335\n",
      "\n",
      "\tEpoch:191\tTrain Loss:0.1667\tRecon Loss:1.8475\tTriplet Loss:0.0954\tStatic Loss:0.1571\t\n",
      "Val Loss:0.2555\tRecon Loss:1.9707\tTriplet Loss:0.1197\tStatic Loss:0.2520\n",
      "\n",
      "\tTime:48.6031\n",
      "\n",
      "Test Loss:0.8148\tRecon Loss:5.7836\tTriplet Loss:0.4253\tStatic Loss:0.8041\n",
      "\n",
      "\tEpoch:192\tTrain Loss:0.1620\tRecon Loss:1.8375\tTriplet Loss:0.0938\tStatic Loss:0.1521\t\n",
      "Val Loss:0.2552\tRecon Loss:1.9405\tTriplet Loss:0.1411\tStatic Loss:0.2497\n",
      "\n",
      "\tTime:49.1383\n",
      "\n",
      "Test Loss:0.8529\tRecon Loss:5.7599\tTriplet Loss:0.4185\tStatic Loss:0.8473\n",
      "\n",
      "\tEpoch:193\tTrain Loss:0.1632\tRecon Loss:1.8306\tTriplet Loss:0.0882\tStatic Loss:0.1540\t\n",
      "Val Loss:0.2540\tRecon Loss:1.9182\tTriplet Loss:0.1262\tStatic Loss:0.2502\n",
      "\n",
      "\tTime:49.1322\n",
      "\n",
      "Test Loss:0.8255\tRecon Loss:5.6970\tTriplet Loss:0.4017\tStatic Loss:0.8192\n",
      "\n",
      "\tEpoch:194\tTrain Loss:0.1628\tRecon Loss:1.8578\tTriplet Loss:0.0948\tStatic Loss:0.1527\t\n",
      "Val Loss:0.2573\tRecon Loss:2.0101\tTriplet Loss:0.1181\tStatic Loss:0.2537\n",
      "\n",
      "\tTime:49.4768\n",
      "\n",
      "Test Loss:0.8458\tRecon Loss:5.8598\tTriplet Loss:0.4189\tStatic Loss:0.8384\n",
      "\n",
      "\tEpoch:195\tTrain Loss:0.1675\tRecon Loss:1.8326\tTriplet Loss:0.0974\tStatic Loss:0.1578\t\n",
      "Val Loss:0.2537\tRecon Loss:1.9056\tTriplet Loss:0.1284\tStatic Loss:0.2497\n",
      "\n",
      "\tTime:49.7431\n",
      "\n",
      "Test Loss:0.8452\tRecon Loss:5.7215\tTriplet Loss:0.4387\tStatic Loss:0.8371\n",
      "\n",
      "\tEpoch:196\tTrain Loss:0.1622\tRecon Loss:1.8285\tTriplet Loss:0.0951\tStatic Loss:0.1522\t\n",
      "Val Loss:0.2633\tRecon Loss:1.9300\tTriplet Loss:0.1307\tStatic Loss:0.2599\n",
      "\n",
      "\tTime:48.6580\n",
      "\n",
      "Test Loss:0.8333\tRecon Loss:5.7679\tTriplet Loss:0.4194\tStatic Loss:0.8254\n",
      "\n",
      "\tEpoch:197\tTrain Loss:0.1648\tRecon Loss:1.8456\tTriplet Loss:0.0912\tStatic Loss:0.1554\t\n",
      "Val Loss:0.2639\tRecon Loss:2.0392\tTriplet Loss:0.1297\tStatic Loss:0.2596\n",
      "\n",
      "\tTime:49.1936\n",
      "\n",
      "Test Loss:0.8734\tRecon Loss:6.0157\tTriplet Loss:0.4545\tStatic Loss:0.8639\n",
      "\n",
      "\tEpoch:198\tTrain Loss:0.1646\tRecon Loss:1.8317\tTriplet Loss:0.0901\tStatic Loss:0.1554\t\n",
      "Val Loss:0.2566\tRecon Loss:1.9563\tTriplet Loss:0.1339\tStatic Loss:0.2519\n",
      "\n",
      "\tTime:48.5719\n",
      "\n",
      "Test Loss:0.8306\tRecon Loss:5.7386\tTriplet Loss:0.4476\tStatic Loss:0.8198\n",
      "\n",
      "\tEpoch:199\tTrain Loss:0.1672\tRecon Loss:1.8371\tTriplet Loss:0.0971\tStatic Loss:0.1576\t\n",
      "Val Loss:0.2533\tRecon Loss:1.9548\tTriplet Loss:0.1212\tStatic Loss:0.2495\n",
      "\n",
      "\tTime:48.6519\n",
      "\n",
      "Test Loss:0.8422\tRecon Loss:5.7540\tTriplet Loss:0.4198\tStatic Loss:0.8353\n",
      "\n",
      "\t\n",
      "Unc Est in Static characteristics:0.0000\tUnc Est in Streamflow, dynamic:0.0000\t\n",
      "\n",
      "\tATT_NL_0\n",
      "Epoch:0\tTrain Loss:0.5582\tRecon Loss:4.1078\tTriplet Loss:0.3892\tStatic Loss:0.5396\t\n",
      "Val Loss:0.4226\tRecon Loss:4.0259\tTriplet Loss:0.2554\tStatic Loss:0.4033\n",
      "\n",
      "\tTime:49.5857\n",
      "\n",
      "Test Loss:1.2836\tRecon Loss:11.9365\tTriplet Loss:0.8567\tStatic Loss:1.2198\n",
      "\n",
      "\tEpoch:1\tTrain Loss:0.3913\tRecon Loss:3.9671\tTriplet Loss:0.2606\tStatic Loss:0.3686\t\n",
      "Val Loss:0.3731\tRecon Loss:4.0199\tTriplet Loss:0.2214\tStatic Loss:0.3518\n",
      "\n",
      "\tTime:49.6874\n",
      "\n",
      "Test Loss:1.1436\tRecon Loss:11.8722\tTriplet Loss:0.6964\tStatic Loss:1.0810\n",
      "\n",
      "\tEpoch:2\tTrain Loss:0.3565\tRecon Loss:3.9505\tTriplet Loss:0.2126\tStatic Loss:0.3350\t\n",
      "Val Loss:0.3559\tRecon Loss:4.0082\tTriplet Loss:0.1989\tStatic Loss:0.3351\n",
      "\n",
      "\tTime:50.3620\n",
      "\n",
      "Test Loss:1.0660\tRecon Loss:11.8634\tTriplet Loss:0.6735\tStatic Loss:0.9972\n",
      "\n",
      "\tEpoch:3\tTrain Loss:0.3385\tRecon Loss:3.9290\tTriplet Loss:0.1990\tStatic Loss:0.3165\t\n",
      "Val Loss:0.3412\tRecon Loss:3.9408\tTriplet Loss:0.1771\tStatic Loss:0.3216\n",
      "\n",
      "\tTime:50.2944\n",
      "\n",
      "Test Loss:1.0879\tRecon Loss:11.7163\tTriplet Loss:0.6385\tStatic Loss:1.0266\n",
      "\n",
      "\tEpoch:4\tTrain Loss:0.3225\tRecon Loss:3.7356\tTriplet Loss:0.1836\tStatic Loss:0.3023\t\n",
      "Val Loss:0.3313\tRecon Loss:3.5330\tTriplet Loss:0.1802\tStatic Loss:0.3144\n",
      "\n",
      "\tTime:49.8839\n",
      "\n",
      "Test Loss:1.0624\tRecon Loss:10.7137\tTriplet Loss:0.6678\tStatic Loss:1.0053\n",
      "\n",
      "\tEpoch:5\tTrain Loss:0.3062\tRecon Loss:2.9858\tTriplet Loss:0.1797\tStatic Loss:0.2920\t\n",
      "Val Loss:0.3168\tRecon Loss:2.8933\tTriplet Loss:0.1791\tStatic Loss:0.3048\n",
      "\n",
      "\tTime:50.6528\n",
      "\n",
      "Test Loss:0.9810\tRecon Loss:8.7223\tTriplet Loss:0.6013\tStatic Loss:0.9416\n",
      "\n",
      "\tEpoch:6\tTrain Loss:0.2933\tRecon Loss:2.3860\tTriplet Loss:0.1790\tStatic Loss:0.2838\t\n",
      "Val Loss:0.3014\tRecon Loss:2.2398\tTriplet Loss:0.1935\tStatic Loss:0.2928\n",
      "\n",
      "\tTime:50.3773\n",
      "\n",
      "Test Loss:0.9389\tRecon Loss:6.5032\tTriplet Loss:0.6410\tStatic Loss:0.9130\n",
      "\n",
      "\tEpoch:7\tTrain Loss:0.2835\tRecon Loss:2.2165\tTriplet Loss:0.1690\tStatic Loss:0.2756\t\n",
      "Val Loss:0.3035\tRecon Loss:2.7426\tTriplet Loss:0.1765\tStatic Loss:0.2919\n",
      "\n",
      "\tTime:49.8653\n",
      "\n",
      "Test Loss:0.9442\tRecon Loss:8.3204\tTriplet Loss:0.5718\tStatic Loss:0.9076\n",
      "\n",
      "\tEpoch:8\tTrain Loss:0.2764\tRecon Loss:2.2878\tTriplet Loss:0.1648\tStatic Loss:0.2674\t\n",
      "Val Loss:0.2988\tRecon Loss:2.1073\tTriplet Loss:0.1663\tStatic Loss:0.2939\n",
      "\n",
      "\tTime:48.7305\n",
      "\n",
      "Test Loss:0.9281\tRecon Loss:6.2971\tTriplet Loss:0.5828\tStatic Loss:0.9089\n",
      "\n",
      "\tEpoch:9\tTrain Loss:0.2687\tRecon Loss:2.0254\tTriplet Loss:0.1597\tStatic Loss:0.2621\t\n",
      "Val Loss:0.2873\tRecon Loss:2.0753\tTriplet Loss:0.1598\tStatic Loss:0.2822\n",
      "\n",
      "\tTime:48.8615\n",
      "\n",
      "Test Loss:0.8673\tRecon Loss:6.2601\tTriplet Loss:0.5279\tStatic Loss:0.8474\n",
      "\n",
      "\tEpoch:10\tTrain Loss:0.2629\tRecon Loss:1.9808\tTriplet Loss:0.1547\tStatic Loss:0.2565\t\n",
      "Val Loss:0.2816\tRecon Loss:1.9794\tTriplet Loss:0.1464\tStatic Loss:0.2781\n",
      "\n",
      "\tTime:49.2407\n",
      "\n",
      "Test Loss:0.8753\tRecon Loss:5.8794\tTriplet Loss:0.5281\tStatic Loss:0.8600\n",
      "\n",
      "\tEpoch:11\tTrain Loss:0.2605\tRecon Loss:2.1585\tTriplet Loss:0.1503\tStatic Loss:0.2526\t\n",
      "Val Loss:0.2949\tRecon Loss:2.9402\tTriplet Loss:0.1563\tStatic Loss:0.2823\n",
      "\n",
      "\tTime:49.5942\n",
      "\n",
      "Test Loss:0.9043\tRecon Loss:8.7984\tTriplet Loss:0.5434\tStatic Loss:0.8615\n",
      "\n",
      "\tEpoch:12\tTrain Loss:0.2557\tRecon Loss:2.0289\tTriplet Loss:0.1515\tStatic Loss:0.2483\t\n",
      "Val Loss:0.2738\tRecon Loss:2.0177\tTriplet Loss:0.1554\tStatic Loss:0.2682\n",
      "\n",
      "\tTime:50.0627\n",
      "\n",
      "Test Loss:0.8488\tRecon Loss:5.9067\tTriplet Loss:0.4956\tStatic Loss:0.8336\n",
      "\n",
      "\tEpoch:13\tTrain Loss:0.2501\tRecon Loss:1.9173\tTriplet Loss:0.1457\tStatic Loss:0.2439\t\n",
      "Val Loss:0.2739\tRecon Loss:2.0061\tTriplet Loss:0.1488\tStatic Loss:0.2690\n",
      "\n",
      "\tTime:51.8399\n",
      "\n",
      "Test Loss:0.8530\tRecon Loss:5.8799\tTriplet Loss:0.5169\tStatic Loss:0.8364\n",
      "\n",
      "\tEpoch:14\tTrain Loss:0.2462\tRecon Loss:1.9125\tTriplet Loss:0.1425\tStatic Loss:0.2399\t\n",
      "Val Loss:0.2744\tRecon Loss:2.1096\tTriplet Loss:0.1482\tStatic Loss:0.2686\n",
      "\n",
      "\tTime:51.6551\n",
      "\n",
      "Test Loss:0.8672\tRecon Loss:6.0193\tTriplet Loss:0.5058\tStatic Loss:0.8518\n",
      "\n",
      "\tEpoch:15\tTrain Loss:0.2451\tRecon Loss:1.9776\tTriplet Loss:0.1394\tStatic Loss:0.2384\t\n",
      "Val Loss:0.2697\tRecon Loss:1.9777\tTriplet Loss:0.1435\tStatic Loss:0.2653\n",
      "\n",
      "\tTime:52.9894\n",
      "\n",
      "Test Loss:0.8365\tRecon Loss:5.9088\tTriplet Loss:0.5037\tStatic Loss:0.8191\n",
      "\n",
      "\tEpoch:16\tTrain Loss:0.2397\tRecon Loss:1.8866\tTriplet Loss:0.1391\tStatic Loss:0.2333\t\n",
      "Val Loss:0.2727\tRecon Loss:1.9996\tTriplet Loss:0.1528\tStatic Loss:0.2674\n",
      "\n",
      "\tTime:51.6098\n",
      "\n",
      "Test Loss:0.8469\tRecon Loss:5.8592\tTriplet Loss:0.4913\tStatic Loss:0.8324\n",
      "\n",
      "\tEpoch:17\tTrain Loss:0.2367\tRecon Loss:1.9172\tTriplet Loss:0.1333\tStatic Loss:0.2303\t\n",
      "Val Loss:0.2642\tRecon Loss:1.9864\tTriplet Loss:0.1488\tStatic Loss:0.2586\n",
      "\n",
      "\tTime:51.9156\n",
      "\n",
      "Test Loss:0.8345\tRecon Loss:5.8453\tTriplet Loss:0.4764\tStatic Loss:0.8202\n",
      "\n",
      "\tEpoch:18\tTrain Loss:0.2333\tRecon Loss:1.8932\tTriplet Loss:0.1228\tStatic Loss:0.2277\t\n",
      "Val Loss:0.2644\tRecon Loss:1.9738\tTriplet Loss:0.1469\tStatic Loss:0.2591\n",
      "\n",
      "\tTime:50.2689\n",
      "\n",
      "Test Loss:0.8207\tRecon Loss:5.8277\tTriplet Loss:0.4903\tStatic Loss:0.8037\n",
      "\n",
      "\tEpoch:19\tTrain Loss:0.2319\tRecon Loss:1.8843\tTriplet Loss:0.1345\tStatic Loss:0.2251\t\n",
      "Val Loss:0.2597\tRecon Loss:2.0163\tTriplet Loss:0.1279\tStatic Loss:0.2554\n",
      "\n",
      "\tTime:51.0188\n",
      "\n",
      "Test Loss:0.8353\tRecon Loss:5.9183\tTriplet Loss:0.4738\tStatic Loss:0.8206\n",
      "\n",
      "\tEpoch:20\tTrain Loss:0.2287\tRecon Loss:1.9241\tTriplet Loss:0.1270\tStatic Loss:0.2219\t\n",
      "Val Loss:0.2608\tRecon Loss:1.9939\tTriplet Loss:0.1499\tStatic Loss:0.2546\n",
      "\n",
      "\tTime:51.6888\n",
      "\n",
      "Test Loss:0.8343\tRecon Loss:5.9407\tTriplet Loss:0.5316\tStatic Loss:0.8135\n",
      "\n",
      "\tEpoch:21\tTrain Loss:0.2264\tRecon Loss:1.8906\tTriplet Loss:0.1202\tStatic Loss:0.2204\t\n",
      "Val Loss:0.2654\tRecon Loss:2.0736\tTriplet Loss:0.1450\tStatic Loss:0.2594\n",
      "\n",
      "\tTime:50.5200\n",
      "\n",
      "Test Loss:0.8332\tRecon Loss:6.1684\tTriplet Loss:0.4659\tStatic Loss:0.8166\n",
      "\n",
      "\tEpoch:22\tTrain Loss:0.2249\tRecon Loss:1.8748\tTriplet Loss:0.1234\tStatic Loss:0.2186\t\n",
      "Val Loss:0.2591\tRecon Loss:1.9679\tTriplet Loss:0.1460\tStatic Loss:0.2534\n",
      "\n",
      "\tTime:49.5892\n",
      "\n",
      "Test Loss:0.8197\tRecon Loss:5.8587\tTriplet Loss:0.4866\tStatic Loss:0.8026\n",
      "\n",
      "\tEpoch:23\tTrain Loss:0.2225\tRecon Loss:1.8737\tTriplet Loss:0.1199\tStatic Loss:0.2162\t\n",
      "Val Loss:0.2570\tRecon Loss:1.9824\tTriplet Loss:0.1442\tStatic Loss:0.2510\n",
      "\n",
      "\tTime:49.5829\n",
      "\n",
      "Test Loss:0.8013\tRecon Loss:5.8814\tTriplet Loss:0.4583\tStatic Loss:0.7848\n",
      "\n",
      "\tEpoch:24\tTrain Loss:0.2212\tRecon Loss:1.8839\tTriplet Loss:0.1242\tStatic Loss:0.2143\t\n",
      "Val Loss:0.2597\tRecon Loss:2.1957\tTriplet Loss:0.1430\tStatic Loss:0.2520\n",
      "\n",
      "\tTime:48.2700\n",
      "\n",
      "Test Loss:0.8314\tRecon Loss:6.3029\tTriplet Loss:0.4816\tStatic Loss:0.8117\n",
      "\n",
      "\tEpoch:25\tTrain Loss:0.2189\tRecon Loss:1.8935\tTriplet Loss:0.1168\tStatic Loss:0.2123\t\n",
      "Val Loss:0.2640\tRecon Loss:1.9585\tTriplet Loss:0.1355\tStatic Loss:0.2600\n",
      "\n",
      "\tTime:48.5535\n",
      "\n",
      "Test Loss:0.8248\tRecon Loss:5.9394\tTriplet Loss:0.4940\tStatic Loss:0.8067\n",
      "\n",
      "\tEpoch:26\tTrain Loss:0.2207\tRecon Loss:2.1362\tTriplet Loss:0.1190\tStatic Loss:0.2117\t\n",
      "Val Loss:0.2562\tRecon Loss:1.9913\tTriplet Loss:0.1403\tStatic Loss:0.2504\n",
      "\n",
      "\tTime:48.6658\n",
      "\n",
      "Test Loss:0.8079\tRecon Loss:5.8436\tTriplet Loss:0.4784\tStatic Loss:0.7905\n",
      "\n",
      "\tEpoch:27\tTrain Loss:0.2159\tRecon Loss:1.8772\tTriplet Loss:0.1140\tStatic Loss:0.2095\t\n",
      "Val Loss:0.2557\tRecon Loss:1.9518\tTriplet Loss:0.1395\tStatic Loss:0.2503\n",
      "\n",
      "\tTime:48.9048\n",
      "\n",
      "Test Loss:0.8214\tRecon Loss:5.9209\tTriplet Loss:0.4635\tStatic Loss:0.8062\n",
      "\n",
      "\tEpoch:28\tTrain Loss:0.2133\tRecon Loss:1.8661\tTriplet Loss:0.1171\tStatic Loss:0.2064\t\n",
      "Val Loss:0.2576\tRecon Loss:1.9695\tTriplet Loss:0.1358\tStatic Loss:0.2527\n",
      "\n",
      "\tTime:48.8160\n",
      "\n",
      "Test Loss:0.8223\tRecon Loss:5.8673\tTriplet Loss:0.4925\tStatic Loss:0.8048\n",
      "\n",
      "\tEpoch:29\tTrain Loss:0.2135\tRecon Loss:1.8672\tTriplet Loss:0.1208\tStatic Loss:0.2062\t\n",
      "Val Loss:0.2551\tRecon Loss:1.9869\tTriplet Loss:0.1377\tStatic Loss:0.2495\n",
      "\n",
      "\tTime:48.7935\n",
      "\n",
      "Test Loss:0.7962\tRecon Loss:5.9394\tTriplet Loss:0.4768\tStatic Loss:0.7767\n",
      "\n",
      "\tEpoch:30\tTrain Loss:0.2112\tRecon Loss:1.8699\tTriplet Loss:0.1139\tStatic Loss:0.2044\t\n",
      "Val Loss:0.2518\tRecon Loss:2.0031\tTriplet Loss:0.1277\tStatic Loss:0.2467\n",
      "\n",
      "\tTime:49.3704\n",
      "\n",
      "Test Loss:0.8141\tRecon Loss:5.9126\tTriplet Loss:0.4904\tStatic Loss:0.7954\n",
      "\n",
      "\tEpoch:31\tTrain Loss:0.2105\tRecon Loss:1.8963\tTriplet Loss:0.1154\tStatic Loss:0.2031\t\n",
      "Val Loss:0.2564\tRecon Loss:2.0084\tTriplet Loss:0.1422\tStatic Loss:0.2504\n",
      "\n",
      "\tTime:50.1570\n",
      "\n",
      "Test Loss:0.8137\tRecon Loss:5.9346\tTriplet Loss:0.4922\tStatic Loss:0.7947\n",
      "\n",
      "\tEpoch:32\tTrain Loss:0.2096\tRecon Loss:1.8900\tTriplet Loss:0.1122\tStatic Loss:0.2025\t\n",
      "Val Loss:0.2608\tRecon Loss:1.9812\tTriplet Loss:0.1397\tStatic Loss:0.2557\n",
      "\n",
      "\tTime:49.9499\n",
      "\n",
      "Test Loss:0.8306\tRecon Loss:5.8274\tTriplet Loss:0.4454\tStatic Loss:0.8192\n",
      "\n",
      "\tEpoch:33\tTrain Loss:0.2081\tRecon Loss:1.8786\tTriplet Loss:0.1070\tStatic Loss:0.2015\t\n",
      "Val Loss:0.2577\tRecon Loss:1.9506\tTriplet Loss:0.1376\tStatic Loss:0.2527\n",
      "\n",
      "\tTime:50.5484\n",
      "\n",
      "Test Loss:0.8387\tRecon Loss:5.7841\tTriplet Loss:0.4646\tStatic Loss:0.8267\n",
      "\n",
      "\tEpoch:34\tTrain Loss:0.2079\tRecon Loss:1.9008\tTriplet Loss:0.1111\tStatic Loss:0.2006\t\n",
      "Val Loss:0.2532\tRecon Loss:1.9760\tTriplet Loss:0.1296\tStatic Loss:0.2484\n",
      "\n",
      "\tTime:50.8548\n",
      "\n",
      "Test Loss:0.8160\tRecon Loss:5.8581\tTriplet Loss:0.4321\tStatic Loss:0.8039\n",
      "\n",
      "\tEpoch:35\tTrain Loss:0.2068\tRecon Loss:1.9189\tTriplet Loss:0.1063\tStatic Loss:0.1997\t\n",
      "Val Loss:0.2526\tRecon Loss:1.9710\tTriplet Loss:0.1383\tStatic Loss:0.2468\n",
      "\n",
      "\tTime:49.9536\n",
      "\n",
      "Test Loss:0.8114\tRecon Loss:5.8672\tTriplet Loss:0.4663\tStatic Loss:0.7953\n",
      "\n",
      "\tEpoch:36\tTrain Loss:0.2072\tRecon Loss:1.9146\tTriplet Loss:0.1032\tStatic Loss:0.2005\t\n",
      "Val Loss:0.2598\tRecon Loss:1.9412\tTriplet Loss:0.1343\tStatic Loss:0.2556\n",
      "\n",
      "\tTime:49.1422\n",
      "\n",
      "Test Loss:0.8280\tRecon Loss:5.7615\tTriplet Loss:0.4547\tStatic Loss:0.8160\n",
      "\n",
      "\tEpoch:37\tTrain Loss:0.2036\tRecon Loss:1.8552\tTriplet Loss:0.1046\tStatic Loss:0.1969\t\n",
      "Val Loss:0.2565\tRecon Loss:2.0331\tTriplet Loss:0.1339\tStatic Loss:0.2510\n",
      "\n",
      "\tTime:49.6768\n",
      "\n",
      "Test Loss:0.8213\tRecon Loss:5.8712\tTriplet Loss:0.4797\tStatic Loss:0.8050\n",
      "\n",
      "\tEpoch:38\tTrain Loss:0.2023\tRecon Loss:1.8699\tTriplet Loss:0.1045\tStatic Loss:0.1954\t\n",
      "Val Loss:0.2660\tRecon Loss:2.4336\tTriplet Loss:0.1487\tStatic Loss:0.2561\n",
      "\n",
      "\tTime:50.5032\n",
      "\n",
      "Test Loss:0.8272\tRecon Loss:6.8449\tTriplet Loss:0.4500\tStatic Loss:0.8047\n",
      "\n",
      "\tEpoch:39\tTrain Loss:0.2025\tRecon Loss:1.8954\tTriplet Loss:0.1064\tStatic Loss:0.1952\t\n",
      "Val Loss:0.2565\tRecon Loss:1.9827\tTriplet Loss:0.1256\tStatic Loss:0.2523\n",
      "\n",
      "\tTime:49.2304\n",
      "\n",
      "Test Loss:0.7987\tRecon Loss:5.7717\tTriplet Loss:0.4270\tStatic Loss:0.7861\n",
      "\n",
      "\tEpoch:40\tTrain Loss:0.2003\tRecon Loss:1.8588\tTriplet Loss:0.0999\tStatic Loss:0.1938\t\n",
      "Val Loss:0.2567\tRecon Loss:1.9707\tTriplet Loss:0.1383\tStatic Loss:0.2514\n",
      "\n",
      "\tTime:49.5946\n",
      "\n",
      "Test Loss:0.8377\tRecon Loss:5.7977\tTriplet Loss:0.4736\tStatic Loss:0.8246\n",
      "\n",
      "\tEpoch:41\tTrain Loss:0.1995\tRecon Loss:1.8666\tTriplet Loss:0.0989\tStatic Loss:0.1929\t\n",
      "Val Loss:0.2567\tRecon Loss:1.9589\tTriplet Loss:0.1325\tStatic Loss:0.2521\n",
      "\n",
      "\tTime:49.9224\n",
      "\n",
      "Test Loss:0.8115\tRecon Loss:5.7709\tTriplet Loss:0.4494\tStatic Loss:0.7981\n",
      "\n",
      "\tEpoch:42\tTrain Loss:0.1998\tRecon Loss:1.8595\tTriplet Loss:0.1032\tStatic Loss:0.1928\t\n",
      "Val Loss:0.2551\tRecon Loss:2.0016\tTriplet Loss:0.1343\tStatic Loss:0.2497\n",
      "\n",
      "\tTime:49.4026\n",
      "\n",
      "Test Loss:0.8001\tRecon Loss:5.9053\tTriplet Loss:0.4486\tStatic Loss:0.7842\n",
      "\n",
      "\tEpoch:43\tTrain Loss:0.1992\tRecon Loss:1.8912\tTriplet Loss:0.1062\tStatic Loss:0.1916\t\n",
      "Val Loss:0.2626\tRecon Loss:3.2331\tTriplet Loss:0.1475\tStatic Loss:0.2444\n",
      "\n",
      "\tTime:49.2994\n",
      "\n",
      "Test Loss:0.8544\tRecon Loss:9.1816\tTriplet Loss:0.4637\tStatic Loss:0.8102\n",
      "\n",
      "\tEpoch:44\tTrain Loss:0.1994\tRecon Loss:2.0034\tTriplet Loss:0.1022\tStatic Loss:0.1911\t\n",
      "Val Loss:0.2474\tRecon Loss:1.9421\tTriplet Loss:0.1308\tStatic Loss:0.2421\n",
      "\n",
      "\tTime:49.1487\n",
      "\n",
      "Test Loss:0.8022\tRecon Loss:5.7768\tTriplet Loss:0.4491\tStatic Loss:0.7878\n",
      "\n",
      "\tEpoch:45\tTrain Loss:0.1979\tRecon Loss:1.8719\tTriplet Loss:0.1045\tStatic Loss:0.1905\t\n",
      "Val Loss:0.2531\tRecon Loss:1.9463\tTriplet Loss:0.1418\tStatic Loss:0.2473\n",
      "\n",
      "\tTime:50.2700\n",
      "\n",
      "Test Loss:0.8126\tRecon Loss:5.7515\tTriplet Loss:0.4281\tStatic Loss:0.8017\n",
      "\n",
      "\tEpoch:46\tTrain Loss:0.1969\tRecon Loss:1.8693\tTriplet Loss:0.1009\tStatic Loss:0.1897\t\n",
      "Val Loss:0.2529\tRecon Loss:1.9384\tTriplet Loss:0.1357\tStatic Loss:0.2478\n",
      "\n",
      "\tTime:49.6566\n",
      "\n",
      "Test Loss:0.7971\tRecon Loss:5.7551\tTriplet Loss:0.4340\tStatic Loss:0.7838\n",
      "\n",
      "\tEpoch:47\tTrain Loss:0.1958\tRecon Loss:1.8557\tTriplet Loss:0.0969\tStatic Loss:0.1891\t\n",
      "Val Loss:0.2521\tRecon Loss:1.9929\tTriplet Loss:0.1348\tStatic Loss:0.2464\n",
      "\n",
      "\tTime:49.6345\n",
      "\n",
      "Test Loss:0.8154\tRecon Loss:5.8886\tTriplet Loss:0.4771\tStatic Loss:0.7985\n",
      "\n",
      "\tEpoch:48\tTrain Loss:0.1958\tRecon Loss:1.8520\tTriplet Loss:0.1049\tStatic Loss:0.1883\t\n",
      "Val Loss:0.2538\tRecon Loss:2.0102\tTriplet Loss:0.1320\tStatic Loss:0.2484\n",
      "\n",
      "\tTime:49.9448\n",
      "\n",
      "Test Loss:0.8255\tRecon Loss:5.8692\tTriplet Loss:0.4521\tStatic Loss:0.8124\n",
      "\n",
      "\tEpoch:49\tTrain Loss:0.1934\tRecon Loss:1.8568\tTriplet Loss:0.0953\tStatic Loss:0.1866\t\n",
      "Val Loss:0.2521\tRecon Loss:1.9586\tTriplet Loss:0.1425\tStatic Loss:0.2460\n",
      "\n",
      "\tTime:49.6088\n",
      "\n",
      "Test Loss:0.8149\tRecon Loss:5.7850\tTriplet Loss:0.4516\tStatic Loss:0.8015\n",
      "\n",
      "\tEpoch:50\tTrain Loss:0.1955\tRecon Loss:1.8809\tTriplet Loss:0.0998\tStatic Loss:0.1882\t\n",
      "Val Loss:0.2723\tRecon Loss:2.2017\tTriplet Loss:0.1508\tStatic Loss:0.2652\n",
      "\n",
      "\tTime:50.2919\n",
      "\n",
      "Test Loss:0.8961\tRecon Loss:6.2074\tTriplet Loss:0.4991\tStatic Loss:0.8827\n",
      "\n",
      "\tEpoch:51\tTrain Loss:0.1975\tRecon Loss:1.8779\tTriplet Loss:0.1081\tStatic Loss:0.1897\t\n",
      "Val Loss:0.2446\tRecon Loss:1.9744\tTriplet Loss:0.1257\tStatic Loss:0.2392\n",
      "\n",
      "\tTime:50.2991\n",
      "\n",
      "Test Loss:0.7862\tRecon Loss:5.8392\tTriplet Loss:0.4264\tStatic Loss:0.7716\n",
      "\n",
      "\tEpoch:52\tTrain Loss:0.1941\tRecon Loss:1.8896\tTriplet Loss:0.0992\tStatic Loss:0.1866\t\n",
      "Val Loss:0.2933\tRecon Loss:3.9188\tTriplet Loss:0.1414\tStatic Loss:0.2722\n",
      "\n",
      "\tTime:49.7428\n",
      "\n",
      "Test Loss:0.9280\tRecon Loss:12.1915\tTriplet Loss:0.4490\tStatic Loss:0.8632\n",
      "\n",
      "\tEpoch:53\tTrain Loss:0.2048\tRecon Loss:2.6663\tTriplet Loss:0.1013\tStatic Loss:0.1906\t\n",
      "Val Loss:0.2550\tRecon Loss:2.1545\tTriplet Loss:0.1415\tStatic Loss:0.2474\n",
      "\n",
      "\tTime:49.5414\n",
      "\n",
      "Test Loss:0.8188\tRecon Loss:6.4107\tTriplet Loss:0.4521\tStatic Loss:0.7995\n",
      "\n",
      "\tEpoch:54\tTrain Loss:0.1928\tRecon Loss:1.9211\tTriplet Loss:0.1000\tStatic Loss:0.1848\t\n",
      "Val Loss:0.2500\tRecon Loss:1.9871\tTriplet Loss:0.1332\tStatic Loss:0.2443\n",
      "\n",
      "\tTime:49.3560\n",
      "\n",
      "Test Loss:0.8045\tRecon Loss:5.9100\tTriplet Loss:0.4323\tStatic Loss:0.7906\n",
      "\n",
      "\tEpoch:55\tTrain Loss:0.1919\tRecon Loss:1.8932\tTriplet Loss:0.1001\tStatic Loss:0.1840\t\n",
      "Val Loss:0.2530\tRecon Loss:1.9738\tTriplet Loss:0.1278\tStatic Loss:0.2484\n",
      "\n",
      "\tTime:49.3957\n",
      "\n",
      "Test Loss:0.8013\tRecon Loss:5.8629\tTriplet Loss:0.4346\tStatic Loss:0.7873\n",
      "\n",
      "\tEpoch:56\tTrain Loss:0.1909\tRecon Loss:1.8684\tTriplet Loss:0.0995\tStatic Loss:0.1833\t\n",
      "Val Loss:0.2533\tRecon Loss:1.9409\tTriplet Loss:0.1401\tStatic Loss:0.2478\n",
      "\n",
      "\tTime:48.9521\n",
      "\n",
      "Test Loss:0.8152\tRecon Loss:5.7726\tTriplet Loss:0.4221\tStatic Loss:0.8049\n",
      "\n",
      "\tEpoch:57\tTrain Loss:0.1932\tRecon Loss:1.8673\tTriplet Loss:0.1046\tStatic Loss:0.1853\t\n",
      "Val Loss:0.2516\tRecon Loss:1.9806\tTriplet Loss:0.1331\tStatic Loss:0.2462\n",
      "\n",
      "\tTime:48.7566\n",
      "\n",
      "Test Loss:0.8093\tRecon Loss:5.8309\tTriplet Loss:0.4236\tStatic Loss:0.7976\n",
      "\n",
      "\tEpoch:58\tTrain Loss:0.1903\tRecon Loss:1.8996\tTriplet Loss:0.1004\tStatic Loss:0.1822\t\n",
      "Val Loss:0.2503\tRecon Loss:1.9816\tTriplet Loss:0.1311\tStatic Loss:0.2450\n",
      "\n",
      "\tTime:49.4217\n",
      "\n",
      "Test Loss:0.7952\tRecon Loss:5.8327\tTriplet Loss:0.4498\tStatic Loss:0.7794\n",
      "\n",
      "\tEpoch:59\tTrain Loss:0.1918\tRecon Loss:1.8637\tTriplet Loss:0.1027\tStatic Loss:0.1840\t\n",
      "Val Loss:0.2533\tRecon Loss:1.9705\tTriplet Loss:0.1473\tStatic Loss:0.2467\n",
      "\n",
      "\tTime:49.2932\n",
      "\n",
      "Test Loss:0.8287\tRecon Loss:5.8433\tTriplet Loss:0.4379\tStatic Loss:0.8177\n",
      "\n",
      "\tEpoch:60\tTrain Loss:0.1908\tRecon Loss:1.8573\tTriplet Loss:0.0976\tStatic Loss:0.1834\t\n",
      "Val Loss:0.2474\tRecon Loss:1.9455\tTriplet Loss:0.1271\tStatic Loss:0.2424\n",
      "\n",
      "\tTime:49.0609\n",
      "\n",
      "Test Loss:0.8017\tRecon Loss:5.7863\tTriplet Loss:0.4100\tStatic Loss:0.7910\n",
      "\n",
      "\tEpoch:61\tTrain Loss:0.1886\tRecon Loss:1.8839\tTriplet Loss:0.1002\tStatic Loss:0.1805\t\n",
      "Val Loss:0.2495\tRecon Loss:1.9463\tTriplet Loss:0.1350\tStatic Loss:0.2439\n",
      "\n",
      "\tTime:49.6009\n",
      "\n",
      "Test Loss:0.8015\tRecon Loss:5.7945\tTriplet Loss:0.4316\tStatic Loss:0.7885\n",
      "\n",
      "\tEpoch:62\tTrain Loss:0.1965\tRecon Loss:1.9488\tTriplet Loss:0.1012\tStatic Loss:0.1885\t\n",
      "Val Loss:0.2483\tRecon Loss:1.9631\tTriplet Loss:0.1271\tStatic Loss:0.2432\n",
      "\n",
      "\tTime:50.3302\n",
      "\n",
      "Test Loss:0.7764\tRecon Loss:5.7896\tTriplet Loss:0.4685\tStatic Loss:0.7571\n",
      "\n",
      "\tEpoch:63\tTrain Loss:0.1912\tRecon Loss:1.8563\tTriplet Loss:0.1036\tStatic Loss:0.1833\t\n",
      "Val Loss:0.2487\tRecon Loss:1.9368\tTriplet Loss:0.1352\tStatic Loss:0.2432\n",
      "\n",
      "\tTime:49.7243\n",
      "\n",
      "Test Loss:0.7931\tRecon Loss:5.7666\tTriplet Loss:0.4200\tStatic Loss:0.7807\n",
      "\n",
      "\tEpoch:64\tTrain Loss:0.1870\tRecon Loss:1.8535\tTriplet Loss:0.0979\tStatic Loss:0.1792\t\n",
      "Val Loss:0.2494\tRecon Loss:1.9949\tTriplet Loss:0.1274\tStatic Loss:0.2441\n",
      "\n",
      "\tTime:51.4403\n",
      "\n",
      "Test Loss:0.8109\tRecon Loss:5.9501\tTriplet Loss:0.4149\tStatic Loss:0.7991\n",
      "\n",
      "\tEpoch:65\tTrain Loss:0.1864\tRecon Loss:1.8567\tTriplet Loss:0.0959\tStatic Loss:0.1787\t\n",
      "Val Loss:0.2490\tRecon Loss:1.9463\tTriplet Loss:0.1275\tStatic Loss:0.2441\n",
      "\n",
      "\tTime:51.1996\n",
      "\n",
      "Test Loss:0.7989\tRecon Loss:5.7572\tTriplet Loss:0.4365\tStatic Loss:0.7856\n",
      "\n",
      "\tEpoch:66\tTrain Loss:0.1849\tRecon Loss:1.8506\tTriplet Loss:0.0934\tStatic Loss:0.1774\t\n",
      "Val Loss:0.2476\tRecon Loss:1.9574\tTriplet Loss:0.1248\tStatic Loss:0.2428\n",
      "\n",
      "\tTime:49.8396\n",
      "\n",
      "Test Loss:0.8050\tRecon Loss:5.8023\tTriplet Loss:0.4330\tStatic Loss:0.7922\n",
      "\n",
      "\tEpoch:67\tTrain Loss:0.1851\tRecon Loss:1.8566\tTriplet Loss:0.0957\tStatic Loss:0.1773\t\n",
      "Val Loss:0.2499\tRecon Loss:2.0004\tTriplet Loss:0.1358\tStatic Loss:0.2438\n",
      "\n",
      "\tTime:51.0528\n",
      "\n",
      "Test Loss:0.7924\tRecon Loss:5.9056\tTriplet Loss:0.4347\tStatic Loss:0.7771\n",
      "\n",
      "\tEpoch:68\tTrain Loss:0.1858\tRecon Loss:1.8619\tTriplet Loss:0.0932\tStatic Loss:0.1783\t\n",
      "Val Loss:0.2488\tRecon Loss:1.9426\tTriplet Loss:0.1237\tStatic Loss:0.2444\n",
      "\n",
      "\tTime:50.3510\n",
      "\n",
      "Test Loss:0.8056\tRecon Loss:5.7755\tTriplet Loss:0.4427\tStatic Loss:0.7922\n",
      "\n",
      "\tEpoch:69\tTrain Loss:0.1850\tRecon Loss:1.8546\tTriplet Loss:0.0965\tStatic Loss:0.1772\t\n",
      "Val Loss:0.2513\tRecon Loss:1.9762\tTriplet Loss:0.1306\tStatic Loss:0.2462\n",
      "\n",
      "\tTime:50.3138\n",
      "\n",
      "Test Loss:0.8130\tRecon Loss:5.8213\tTriplet Loss:0.4362\tStatic Loss:0.8006\n",
      "\n",
      "\tEpoch:70\tTrain Loss:0.1829\tRecon Loss:1.8646\tTriplet Loss:0.0981\tStatic Loss:0.1745\t\n",
      "Val Loss:0.2498\tRecon Loss:2.0747\tTriplet Loss:0.1255\tStatic Loss:0.2440\n",
      "\n",
      "\tTime:50.5123\n",
      "\n",
      "Test Loss:0.8145\tRecon Loss:6.1109\tTriplet Loss:0.4484\tStatic Loss:0.7981\n",
      "\n",
      "\tEpoch:71\tTrain Loss:0.1845\tRecon Loss:1.9461\tTriplet Loss:0.0915\tStatic Loss:0.1762\t\n",
      "Val Loss:0.2556\tRecon Loss:1.9676\tTriplet Loss:0.1261\tStatic Loss:0.2514\n",
      "\n",
      "\tTime:50.2274\n",
      "\n",
      "Test Loss:0.8330\tRecon Loss:5.8952\tTriplet Loss:0.4486\tStatic Loss:0.8208\n",
      "\n",
      "\tEpoch:72\tTrain Loss:0.1847\tRecon Loss:2.0366\tTriplet Loss:0.0903\tStatic Loss:0.1756\t\n",
      "Val Loss:0.2537\tRecon Loss:1.9658\tTriplet Loss:0.1324\tStatic Loss:0.2487\n",
      "\n",
      "\tTime:50.3176\n",
      "\n",
      "Test Loss:0.8234\tRecon Loss:5.8671\tTriplet Loss:0.4411\tStatic Loss:0.8112\n",
      "\n",
      "\tEpoch:73\tTrain Loss:0.1844\tRecon Loss:1.8580\tTriplet Loss:0.0949\tStatic Loss:0.1767\t\n",
      "Val Loss:0.2535\tRecon Loss:1.9541\tTriplet Loss:0.1270\tStatic Loss:0.2492\n",
      "\n",
      "\tTime:50.1292\n",
      "\n",
      "Test Loss:0.8074\tRecon Loss:5.7805\tTriplet Loss:0.4250\tStatic Loss:0.7959\n",
      "\n",
      "\tEpoch:74\tTrain Loss:0.1830\tRecon Loss:1.8608\tTriplet Loss:0.0980\tStatic Loss:0.1748\t\n",
      "Val Loss:0.2528\tRecon Loss:2.1005\tTriplet Loss:0.1307\tStatic Loss:0.2465\n",
      "\n",
      "\tTime:50.2231\n",
      "\n",
      "Test Loss:0.8157\tRecon Loss:6.1679\tTriplet Loss:0.4160\tStatic Loss:0.8021\n",
      "\n",
      "\tEpoch:75\tTrain Loss:0.1804\tRecon Loss:1.8694\tTriplet Loss:0.0921\tStatic Loss:0.1723\t\n",
      "Val Loss:0.2483\tRecon Loss:1.9325\tTriplet Loss:0.1274\tStatic Loss:0.2436\n",
      "\n",
      "\tTime:48.9615\n",
      "\n",
      "Test Loss:0.8072\tRecon Loss:5.7307\tTriplet Loss:0.4422\tStatic Loss:0.7945\n",
      "\n",
      "\tEpoch:76\tTrain Loss:0.1807\tRecon Loss:1.8538\tTriplet Loss:0.0897\tStatic Loss:0.1730\t\n",
      "Val Loss:0.2496\tRecon Loss:1.9482\tTriplet Loss:0.1276\tStatic Loss:0.2448\n",
      "\n",
      "\tTime:48.8209\n",
      "\n",
      "Test Loss:0.8140\tRecon Loss:5.7856\tTriplet Loss:0.4122\tStatic Loss:0.8045\n",
      "\n",
      "\tEpoch:77\tTrain Loss:0.1835\tRecon Loss:1.9890\tTriplet Loss:0.0954\tStatic Loss:0.1743\t\n",
      "Val Loss:0.2476\tRecon Loss:2.0698\tTriplet Loss:0.1503\tStatic Loss:0.2391\n",
      "\n",
      "\tTime:49.0340\n",
      "\n",
      "Test Loss:0.8101\tRecon Loss:6.0647\tTriplet Loss:0.4279\tStatic Loss:0.7958\n",
      "\n",
      "\tEpoch:78\tTrain Loss:0.1817\tRecon Loss:1.8952\tTriplet Loss:0.0990\tStatic Loss:0.1729\t\n",
      "Val Loss:0.2507\tRecon Loss:2.0613\tTriplet Loss:0.1373\tStatic Loss:0.2439\n",
      "\n",
      "\tTime:48.7507\n",
      "\n",
      "Test Loss:0.8236\tRecon Loss:6.0267\tTriplet Loss:0.4674\tStatic Loss:0.8072\n",
      "\n",
      "\tEpoch:79\tTrain Loss:0.1810\tRecon Loss:1.8628\tTriplet Loss:0.0897\tStatic Loss:0.1733\t\n",
      "Val Loss:0.2494\tRecon Loss:1.9508\tTriplet Loss:0.1322\tStatic Loss:0.2441\n",
      "\n",
      "\tTime:49.3593\n",
      "\n",
      "Test Loss:0.8148\tRecon Loss:5.7783\tTriplet Loss:0.4298\tStatic Loss:0.8036\n",
      "\n",
      "\tEpoch:80\tTrain Loss:0.1791\tRecon Loss:1.8576\tTriplet Loss:0.0927\tStatic Loss:0.1710\t\n",
      "Val Loss:0.2497\tRecon Loss:1.9381\tTriplet Loss:0.1312\tStatic Loss:0.2446\n",
      "\n",
      "\tTime:50.0250\n",
      "\n",
      "Test Loss:0.8134\tRecon Loss:5.7885\tTriplet Loss:0.4421\tStatic Loss:0.8008\n",
      "\n",
      "\tEpoch:81\tTrain Loss:0.1800\tRecon Loss:1.8615\tTriplet Loss:0.0924\tStatic Loss:0.1719\t\n",
      "Val Loss:0.2525\tRecon Loss:1.9555\tTriplet Loss:0.1256\tStatic Loss:0.2481\n",
      "\n",
      "\tTime:49.0728\n",
      "\n",
      "Test Loss:0.8421\tRecon Loss:5.7714\tTriplet Loss:0.4295\tStatic Loss:0.8341\n",
      "\n",
      "\tEpoch:82\tTrain Loss:0.1839\tRecon Loss:2.0235\tTriplet Loss:0.0935\tStatic Loss:0.1745\t\n",
      "Val Loss:0.2595\tRecon Loss:2.1593\tTriplet Loss:0.1319\tStatic Loss:0.2532\n",
      "\n",
      "\tTime:49.3164\n",
      "\n",
      "Test Loss:0.8561\tRecon Loss:6.4401\tTriplet Loss:0.4627\tStatic Loss:0.8396\n",
      "\n",
      "\tEpoch:83\tTrain Loss:0.1825\tRecon Loss:2.0167\tTriplet Loss:0.0941\tStatic Loss:0.1730\t\n",
      "Val Loss:0.2540\tRecon Loss:2.0811\tTriplet Loss:0.1318\tStatic Loss:0.2480\n",
      "\n",
      "\tTime:49.3678\n",
      "\n",
      "Test Loss:0.8355\tRecon Loss:6.1016\tTriplet Loss:0.4243\tStatic Loss:0.8240\n",
      "\n",
      "\tEpoch:84\tTrain Loss:0.1781\tRecon Loss:1.9091\tTriplet Loss:0.0913\tStatic Loss:0.1695\t\n",
      "Val Loss:0.2464\tRecon Loss:2.0062\tTriplet Loss:0.1341\tStatic Loss:0.2400\n",
      "\n",
      "\tTime:50.3312\n",
      "\n",
      "Test Loss:0.7831\tRecon Loss:6.0213\tTriplet Loss:0.4089\tStatic Loss:0.7681\n",
      "\n",
      "\tEpoch:85\tTrain Loss:0.1786\tRecon Loss:1.8775\tTriplet Loss:0.0928\tStatic Loss:0.1702\t\n",
      "Val Loss:0.2569\tRecon Loss:1.9431\tTriplet Loss:0.1259\tStatic Loss:0.2531\n",
      "\n",
      "\tTime:49.3030\n",
      "\n",
      "Test Loss:0.8413\tRecon Loss:5.8247\tTriplet Loss:0.4212\tStatic Loss:0.8335\n",
      "\n",
      "\tEpoch:86\tTrain Loss:0.1776\tRecon Loss:1.8603\tTriplet Loss:0.0867\tStatic Loss:0.1698\t\n",
      "Val Loss:0.2510\tRecon Loss:1.9454\tTriplet Loss:0.1369\tStatic Loss:0.2454\n",
      "\n",
      "\tTime:48.7656\n",
      "\n",
      "Test Loss:0.8071\tRecon Loss:5.7657\tTriplet Loss:0.4345\tStatic Loss:0.7947\n",
      "\n",
      "\tEpoch:87\tTrain Loss:0.1777\tRecon Loss:1.8546\tTriplet Loss:0.0930\tStatic Loss:0.1694\t\n",
      "Val Loss:0.2544\tRecon Loss:1.9971\tTriplet Loss:0.1332\tStatic Loss:0.2491\n",
      "\n",
      "\tTime:49.8170\n",
      "\n",
      "Test Loss:0.8292\tRecon Loss:5.8373\tTriplet Loss:0.4266\tStatic Loss:0.8194\n",
      "\n",
      "\tEpoch:88\tTrain Loss:0.1787\tRecon Loss:1.8667\tTriplet Loss:0.0931\tStatic Loss:0.1704\t\n",
      "Val Loss:0.2488\tRecon Loss:1.9813\tTriplet Loss:0.1409\tStatic Loss:0.2422\n",
      "\n",
      "\tTime:48.7147\n",
      "\n",
      "Test Loss:0.7960\tRecon Loss:5.8051\tTriplet Loss:0.4114\tStatic Loss:0.7844\n",
      "\n",
      "\tEpoch:89\tTrain Loss:0.1762\tRecon Loss:1.8499\tTriplet Loss:0.0909\tStatic Loss:0.1679\t\n",
      "Val Loss:0.2508\tRecon Loss:1.9722\tTriplet Loss:0.1224\tStatic Loss:0.2464\n",
      "\n",
      "\tTime:49.3940\n",
      "\n",
      "Test Loss:0.8164\tRecon Loss:5.8406\tTriplet Loss:0.4143\tStatic Loss:0.8063\n",
      "\n",
      "\tEpoch:90\tTrain Loss:0.1775\tRecon Loss:1.8561\tTriplet Loss:0.0937\tStatic Loss:0.1691\t\n",
      "Val Loss:0.2503\tRecon Loss:1.9420\tTriplet Loss:0.1374\tStatic Loss:0.2446\n",
      "\n",
      "\tTime:48.5168\n",
      "\n",
      "Test Loss:0.8177\tRecon Loss:5.7826\tTriplet Loss:0.4603\tStatic Loss:0.8038\n",
      "\n",
      "\tEpoch:91\tTrain Loss:0.1750\tRecon Loss:1.8472\tTriplet Loss:0.0896\tStatic Loss:0.1668\t\n",
      "Val Loss:0.2564\tRecon Loss:1.9738\tTriplet Loss:0.1294\tStatic Loss:0.2520\n",
      "\n",
      "\tTime:48.2118\n",
      "\n",
      "Test Loss:0.8443\tRecon Loss:5.8148\tTriplet Loss:0.4267\tStatic Loss:0.8363\n",
      "\n",
      "\tEpoch:92\tTrain Loss:0.1791\tRecon Loss:1.9136\tTriplet Loss:0.0923\tStatic Loss:0.1704\t\n",
      "Val Loss:0.2504\tRecon Loss:1.9641\tTriplet Loss:0.1296\tStatic Loss:0.2454\n",
      "\n",
      "\tTime:49.4439\n",
      "\n",
      "Test Loss:0.8125\tRecon Loss:5.7584\tTriplet Loss:0.4211\tStatic Loss:0.8022\n",
      "\n",
      "\tEpoch:93\tTrain Loss:0.1802\tRecon Loss:1.8580\tTriplet Loss:0.0920\tStatic Loss:0.1722\t\n",
      "Val Loss:0.2471\tRecon Loss:1.9594\tTriplet Loss:0.1230\tStatic Loss:0.2424\n",
      "\n",
      "\tTime:49.6097\n",
      "\n",
      "Test Loss:0.8031\tRecon Loss:5.8606\tTriplet Loss:0.4051\tStatic Loss:0.7923\n",
      "\n",
      "\tEpoch:94\tTrain Loss:0.1755\tRecon Loss:1.8467\tTriplet Loss:0.0888\tStatic Loss:0.1674\t\n",
      "Val Loss:0.2517\tRecon Loss:1.9820\tTriplet Loss:0.1243\tStatic Loss:0.2472\n",
      "\n",
      "\tTime:48.7636\n",
      "\n",
      "Test Loss:0.8056\tRecon Loss:5.9912\tTriplet Loss:0.4125\tStatic Loss:0.7931\n",
      "\n",
      "\tEpoch:95\tTrain Loss:0.1767\tRecon Loss:1.8563\tTriplet Loss:0.0940\tStatic Loss:0.1682\t\n",
      "Val Loss:0.2476\tRecon Loss:1.9465\tTriplet Loss:0.1309\tStatic Loss:0.2423\n",
      "\n",
      "\tTime:49.7973\n",
      "\n",
      "Test Loss:0.8116\tRecon Loss:5.8288\tTriplet Loss:0.4381\tStatic Loss:0.7987\n",
      "\n",
      "\tEpoch:96\tTrain Loss:0.1758\tRecon Loss:1.8590\tTriplet Loss:0.0885\tStatic Loss:0.1677\t\n",
      "Val Loss:0.2479\tRecon Loss:1.9448\tTriplet Loss:0.1207\tStatic Loss:0.2437\n",
      "\n",
      "\tTime:48.8828\n",
      "\n",
      "Test Loss:0.8108\tRecon Loss:5.8486\tTriplet Loss:0.4068\tStatic Loss:0.8009\n",
      "\n",
      "\tEpoch:97\tTrain Loss:0.1759\tRecon Loss:1.8519\tTriplet Loss:0.0886\tStatic Loss:0.1678\t\n",
      "Val Loss:0.2488\tRecon Loss:1.9616\tTriplet Loss:0.1255\tStatic Loss:0.2440\n",
      "\n",
      "\tTime:49.1634\n",
      "\n",
      "Test Loss:0.8078\tRecon Loss:5.8479\tTriplet Loss:0.4138\tStatic Loss:0.7968\n",
      "\n",
      "\tEpoch:98\tTrain Loss:0.1744\tRecon Loss:1.8482\tTriplet Loss:0.0881\tStatic Loss:0.1663\t\n",
      "Val Loss:0.2488\tRecon Loss:1.9833\tTriplet Loss:0.1302\tStatic Loss:0.2434\n",
      "\n",
      "\tTime:50.7045\n",
      "\n",
      "Test Loss:0.8260\tRecon Loss:5.8318\tTriplet Loss:0.4268\tStatic Loss:0.8158\n",
      "\n",
      "\tEpoch:99\tTrain Loss:0.1753\tRecon Loss:1.8701\tTriplet Loss:0.0890\tStatic Loss:0.1670\t\n",
      "Val Loss:0.2469\tRecon Loss:1.9441\tTriplet Loss:0.1276\tStatic Loss:0.2419\n",
      "\n",
      "\tTime:49.9890\n",
      "\n",
      "Test Loss:0.8111\tRecon Loss:5.7927\tTriplet Loss:0.4158\tStatic Loss:0.8008\n",
      "\n",
      "\tEpoch:100\tTrain Loss:0.1746\tRecon Loss:1.8441\tTriplet Loss:0.0937\tStatic Loss:0.1660\t\n",
      "Val Loss:0.2521\tRecon Loss:1.9480\tTriplet Loss:0.1356\tStatic Loss:0.2468\n",
      "\n",
      "\tTime:50.2282\n",
      "\n",
      "Test Loss:0.8373\tRecon Loss:5.7859\tTriplet Loss:0.4437\tStatic Loss:0.8272\n",
      "\n",
      "\tEpoch:101\tTrain Loss:0.1757\tRecon Loss:1.8510\tTriplet Loss:0.0888\tStatic Loss:0.1677\t\n",
      "Val Loss:0.2505\tRecon Loss:1.9721\tTriplet Loss:0.1317\tStatic Loss:0.2452\n",
      "\n",
      "\tTime:49.1436\n",
      "\n",
      "Test Loss:0.8252\tRecon Loss:5.8062\tTriplet Loss:0.4265\tStatic Loss:0.8153\n",
      "\n",
      "\tEpoch:102\tTrain Loss:0.1788\tRecon Loss:2.0576\tTriplet Loss:0.0935\tStatic Loss:0.1686\t\n",
      "Val Loss:0.2681\tRecon Loss:2.9025\tTriplet Loss:0.1215\tStatic Loss:0.2564\n",
      "\n",
      "\tTime:48.6840\n",
      "\n",
      "Test Loss:0.8622\tRecon Loss:8.5197\tTriplet Loss:0.4317\tStatic Loss:0.8287\n",
      "\n",
      "\tEpoch:103\tTrain Loss:0.1805\tRecon Loss:2.1442\tTriplet Loss:0.0954\tStatic Loss:0.1693\t\n",
      "Val Loss:0.2506\tRecon Loss:1.9854\tTriplet Loss:0.1417\tStatic Loss:0.2441\n",
      "\n",
      "\tTime:48.8879\n",
      "\n",
      "Test Loss:0.8238\tRecon Loss:5.8614\tTriplet Loss:0.4243\tStatic Loss:0.8134\n",
      "\n",
      "\tEpoch:104\tTrain Loss:0.1759\tRecon Loss:1.8890\tTriplet Loss:0.0929\tStatic Loss:0.1671\t\n",
      "Val Loss:0.2485\tRecon Loss:1.9442\tTriplet Loss:0.1216\tStatic Loss:0.2442\n",
      "\n",
      "\tTime:48.6034\n",
      "\n",
      "Test Loss:0.8326\tRecon Loss:5.8486\tTriplet Loss:0.4387\tStatic Loss:0.8219\n",
      "\n",
      "\tEpoch:105\tTrain Loss:0.1729\tRecon Loss:1.8614\tTriplet Loss:0.0902\tStatic Loss:0.1643\t\n",
      "Val Loss:0.2564\tRecon Loss:1.9570\tTriplet Loss:0.1258\tStatic Loss:0.2525\n",
      "\n",
      "\tTime:50.2619\n",
      "\n",
      "Test Loss:0.8399\tRecon Loss:5.8443\tTriplet Loss:0.4362\tStatic Loss:0.8303\n",
      "\n",
      "\tEpoch:106\tTrain Loss:0.1730\tRecon Loss:1.8520\tTriplet Loss:0.0888\tStatic Loss:0.1647\t\n",
      "Val Loss:0.2464\tRecon Loss:1.9937\tTriplet Loss:0.1397\tStatic Loss:0.2396\n",
      "\n",
      "\tTime:50.2384\n",
      "\n",
      "Test Loss:0.8034\tRecon Loss:5.8685\tTriplet Loss:0.4236\tStatic Loss:0.7907\n",
      "\n",
      "\tEpoch:107\tTrain Loss:0.1762\tRecon Loss:1.8569\tTriplet Loss:0.0940\tStatic Loss:0.1676\t\n",
      "Val Loss:0.2510\tRecon Loss:1.9665\tTriplet Loss:0.1312\tStatic Loss:0.2459\n",
      "\n",
      "\tTime:49.3807\n",
      "\n",
      "Test Loss:0.8324\tRecon Loss:5.8709\tTriplet Loss:0.3973\tStatic Loss:0.8255\n",
      "\n",
      "\tEpoch:108\tTrain Loss:0.1735\tRecon Loss:1.8513\tTriplet Loss:0.0890\tStatic Loss:0.1652\t\n",
      "Val Loss:0.2527\tRecon Loss:1.9568\tTriplet Loss:0.1219\tStatic Loss:0.2487\n",
      "\n",
      "\tTime:49.8198\n",
      "\n",
      "Test Loss:0.8520\tRecon Loss:5.7979\tTriplet Loss:0.4318\tStatic Loss:0.8446\n",
      "\n",
      "\tEpoch:109\tTrain Loss:0.1722\tRecon Loss:1.8651\tTriplet Loss:0.0880\tStatic Loss:0.1637\t\n",
      "Val Loss:0.2529\tRecon Loss:1.9679\tTriplet Loss:0.1282\tStatic Loss:0.2482\n",
      "\n",
      "\tTime:49.9880\n",
      "\n",
      "Test Loss:0.8479\tRecon Loss:5.7894\tTriplet Loss:0.4036\tStatic Loss:0.8429\n",
      "\n",
      "\tEpoch:110\tTrain Loss:0.1734\tRecon Loss:1.8468\tTriplet Loss:0.0832\tStatic Loss:0.1657\t\n",
      "Val Loss:0.2513\tRecon Loss:1.9603\tTriplet Loss:0.1184\tStatic Loss:0.2475\n",
      "\n",
      "\tTime:50.4673\n",
      "\n",
      "Test Loss:0.8248\tRecon Loss:5.8815\tTriplet Loss:0.4324\tStatic Loss:0.8135\n",
      "\n",
      "\tEpoch:111\tTrain Loss:0.1719\tRecon Loss:1.8502\tTriplet Loss:0.0899\tStatic Loss:0.1633\t\n",
      "Val Loss:0.2481\tRecon Loss:1.9399\tTriplet Loss:0.1246\tStatic Loss:0.2435\n",
      "\n",
      "\tTime:49.9390\n",
      "\n",
      "Test Loss:0.8196\tRecon Loss:5.8225\tTriplet Loss:0.4007\tStatic Loss:0.8115\n",
      "\n",
      "\tEpoch:112\tTrain Loss:0.1713\tRecon Loss:1.8456\tTriplet Loss:0.0925\tStatic Loss:0.1625\t\n",
      "Val Loss:0.2508\tRecon Loss:2.0143\tTriplet Loss:0.1279\tStatic Loss:0.2454\n",
      "\n",
      "\tTime:49.5767\n",
      "\n",
      "Test Loss:0.8151\tRecon Loss:5.9977\tTriplet Loss:0.4057\tStatic Loss:0.8042\n",
      "\n",
      "\tEpoch:113\tTrain Loss:0.1723\tRecon Loss:1.8581\tTriplet Loss:0.0880\tStatic Loss:0.1638\t\n",
      "Val Loss:0.2506\tRecon Loss:1.9630\tTriplet Loss:0.1201\tStatic Loss:0.2465\n",
      "\n",
      "\tTime:48.9145\n",
      "\n",
      "Test Loss:0.8167\tRecon Loss:5.7689\tTriplet Loss:0.4218\tStatic Loss:0.8067\n",
      "\n",
      "\tEpoch:114\tTrain Loss:0.1725\tRecon Loss:1.8469\tTriplet Loss:0.0881\tStatic Loss:0.1642\t\n",
      "Val Loss:0.2543\tRecon Loss:1.9768\tTriplet Loss:0.1340\tStatic Loss:0.2491\n",
      "\n",
      "\tTime:50.0520\n",
      "\n",
      "Test Loss:0.8237\tRecon Loss:5.7822\tTriplet Loss:0.4234\tStatic Loss:0.8141\n",
      "\n",
      "\tEpoch:115\tTrain Loss:0.1731\tRecon Loss:1.8584\tTriplet Loss:0.0906\tStatic Loss:0.1645\t\n",
      "Val Loss:0.2517\tRecon Loss:1.9522\tTriplet Loss:0.1175\tStatic Loss:0.2481\n",
      "\n",
      "\tTime:48.8965\n",
      "\n",
      "Test Loss:0.8107\tRecon Loss:5.7940\tTriplet Loss:0.4118\tStatic Loss:0.8008\n",
      "\n",
      "\tEpoch:116\tTrain Loss:0.1728\tRecon Loss:1.8426\tTriplet Loss:0.0898\tStatic Loss:0.1644\t\n",
      "Val Loss:0.2465\tRecon Loss:1.9538\tTriplet Loss:0.1248\tStatic Loss:0.2416\n",
      "\n",
      "\tTime:49.3414\n",
      "\n",
      "Test Loss:0.8105\tRecon Loss:5.7916\tTriplet Loss:0.4242\tStatic Loss:0.7993\n",
      "\n",
      "\tEpoch:117\tTrain Loss:0.1737\tRecon Loss:1.8450\tTriplet Loss:0.0877\tStatic Loss:0.1656\t\n",
      "Val Loss:0.2570\tRecon Loss:1.9693\tTriplet Loss:0.1170\tStatic Loss:0.2539\n",
      "\n",
      "\tTime:49.1900\n",
      "\n",
      "Test Loss:0.8485\tRecon Loss:5.8526\tTriplet Loss:0.4220\tStatic Loss:0.8411\n",
      "\n",
      "\tEpoch:118\tTrain Loss:0.1801\tRecon Loss:1.8587\tTriplet Loss:0.0922\tStatic Loss:0.1721\t\n",
      "Val Loss:0.2543\tRecon Loss:1.9303\tTriplet Loss:0.1214\tStatic Loss:0.2508\n",
      "\n",
      "\tTime:49.1563\n",
      "\n",
      "Test Loss:0.8217\tRecon Loss:5.7908\tTriplet Loss:0.4385\tStatic Loss:0.8103\n",
      "\n",
      "\tEpoch:119\tTrain Loss:0.1728\tRecon Loss:1.8419\tTriplet Loss:0.0878\tStatic Loss:0.1646\t\n",
      "Val Loss:0.2526\tRecon Loss:1.9322\tTriplet Loss:0.1316\tStatic Loss:0.2479\n",
      "\n",
      "\tTime:50.0849\n",
      "\n",
      "Test Loss:0.8335\tRecon Loss:5.7472\tTriplet Loss:0.4394\tStatic Loss:0.8238\n",
      "\n",
      "\tEpoch:120\tTrain Loss:0.1740\tRecon Loss:1.8422\tTriplet Loss:0.0914\tStatic Loss:0.1656\t\n",
      "Val Loss:0.2458\tRecon Loss:1.9593\tTriplet Loss:0.1219\tStatic Loss:0.2410\n",
      "\n",
      "\tTime:49.1954\n",
      "\n",
      "Test Loss:0.8157\tRecon Loss:5.7604\tTriplet Loss:0.4263\tStatic Loss:0.8052\n",
      "\n",
      "\tEpoch:121\tTrain Loss:0.1701\tRecon Loss:1.8401\tTriplet Loss:0.0890\tStatic Loss:0.1615\t\n",
      "Val Loss:0.2468\tRecon Loss:1.9368\tTriplet Loss:0.1251\tStatic Loss:0.2421\n",
      "\n",
      "\tTime:48.9365\n",
      "\n",
      "Test Loss:0.8148\tRecon Loss:5.7533\tTriplet Loss:0.4371\tStatic Loss:0.8032\n",
      "\n",
      "\tEpoch:122\tTrain Loss:0.1698\tRecon Loss:1.8456\tTriplet Loss:0.0916\tStatic Loss:0.1609\t\n",
      "Val Loss:0.2550\tRecon Loss:1.9370\tTriplet Loss:0.1266\tStatic Loss:0.2510\n",
      "\n",
      "\tTime:49.9895\n",
      "\n",
      "Test Loss:0.8608\tRecon Loss:5.8069\tTriplet Loss:0.4209\tStatic Loss:0.8554\n",
      "\n",
      "\tEpoch:123\tTrain Loss:0.1704\tRecon Loss:1.8391\tTriplet Loss:0.0879\tStatic Loss:0.1619\t\n",
      "Val Loss:0.2481\tRecon Loss:2.0007\tTriplet Loss:0.1267\tStatic Loss:0.2427\n",
      "\n",
      "\tTime:50.2113\n",
      "\n",
      "Test Loss:0.8085\tRecon Loss:5.9376\tTriplet Loss:0.4017\tStatic Loss:0.7979\n",
      "\n",
      "\tEpoch:124\tTrain Loss:0.1735\tRecon Loss:1.8760\tTriplet Loss:0.0910\tStatic Loss:0.1648\t\n",
      "Val Loss:0.2541\tRecon Loss:1.9480\tTriplet Loss:0.1272\tStatic Loss:0.2498\n",
      "\n",
      "\tTime:49.8260\n",
      "\n",
      "Test Loss:0.8449\tRecon Loss:5.7391\tTriplet Loss:0.3899\tStatic Loss:0.8415\n",
      "\n",
      "\tEpoch:125\tTrain Loss:0.1731\tRecon Loss:1.8473\tTriplet Loss:0.0893\tStatic Loss:0.1648\t\n",
      "Val Loss:0.2586\tRecon Loss:2.0027\tTriplet Loss:0.1311\tStatic Loss:0.2539\n",
      "\n",
      "\tTime:49.3559\n",
      "\n",
      "Test Loss:0.8302\tRecon Loss:5.8536\tTriplet Loss:0.4257\tStatic Loss:0.8204\n",
      "\n",
      "\tEpoch:126\tTrain Loss:0.1743\tRecon Loss:1.8584\tTriplet Loss:0.0960\tStatic Loss:0.1653\t\n",
      "Val Loss:0.2477\tRecon Loss:1.9414\tTriplet Loss:0.1317\tStatic Loss:0.2423\n",
      "\n",
      "\tTime:49.1559\n",
      "\n",
      "Test Loss:0.8265\tRecon Loss:5.7641\tTriplet Loss:0.4180\tStatic Loss:0.8180\n",
      "\n",
      "\tEpoch:127\tTrain Loss:0.1703\tRecon Loss:1.8459\tTriplet Loss:0.0857\tStatic Loss:0.1620\t\n",
      "Val Loss:0.2483\tRecon Loss:1.9479\tTriplet Loss:0.1289\tStatic Loss:0.2432\n",
      "\n",
      "\tTime:50.7804\n",
      "\n",
      "Test Loss:0.8170\tRecon Loss:5.8133\tTriplet Loss:0.4132\tStatic Loss:0.8074\n",
      "\n",
      "\tEpoch:128\tTrain Loss:0.1735\tRecon Loss:1.8435\tTriplet Loss:0.0925\tStatic Loss:0.1649\t\n",
      "Val Loss:0.2472\tRecon Loss:1.9557\tTriplet Loss:0.1281\tStatic Loss:0.2420\n",
      "\n",
      "\tTime:50.6768\n",
      "\n",
      "Test Loss:0.8027\tRecon Loss:5.7813\tTriplet Loss:0.3996\tStatic Loss:0.7932\n",
      "\n",
      "\tEpoch:129\tTrain Loss:0.1731\tRecon Loss:1.9090\tTriplet Loss:0.0884\tStatic Loss:0.1642\t\n",
      "Val Loss:0.2640\tRecon Loss:1.9549\tTriplet Loss:0.1336\tStatic Loss:0.2601\n",
      "\n",
      "\tTime:49.8201\n",
      "\n",
      "Test Loss:0.8767\tRecon Loss:5.7900\tTriplet Loss:0.4329\tStatic Loss:0.8720\n",
      "\n",
      "\tEpoch:130\tTrain Loss:0.1770\tRecon Loss:1.8531\tTriplet Loss:0.0943\tStatic Loss:0.1685\t\n",
      "Val Loss:0.2461\tRecon Loss:1.9361\tTriplet Loss:0.1198\tStatic Loss:0.2418\n",
      "\n",
      "\tTime:50.1358\n",
      "\n",
      "Test Loss:0.8176\tRecon Loss:5.8194\tTriplet Loss:0.4158\tStatic Loss:0.8077\n",
      "\n",
      "\tEpoch:131\tTrain Loss:0.1739\tRecon Loss:2.1042\tTriplet Loss:0.0896\tStatic Loss:0.1630\t\n",
      "Val Loss:0.2488\tRecon Loss:2.0106\tTriplet Loss:0.1273\tStatic Loss:0.2434\n",
      "\n",
      "\tTime:49.8150\n",
      "\n",
      "Test Loss:0.8197\tRecon Loss:5.9822\tTriplet Loss:0.4097\tStatic Loss:0.8091\n",
      "\n",
      "\tEpoch:132\tTrain Loss:0.1699\tRecon Loss:1.8663\tTriplet Loss:0.0894\tStatic Loss:0.1610\t\n",
      "Val Loss:0.2524\tRecon Loss:1.9520\tTriplet Loss:0.1196\tStatic Loss:0.2487\n",
      "\n",
      "\tTime:54.8601\n",
      "\n",
      "Test Loss:0.8221\tRecon Loss:5.8011\tTriplet Loss:0.3984\tStatic Loss:0.8147\n",
      "\n",
      "\tEpoch:133\tTrain Loss:0.1689\tRecon Loss:1.8498\tTriplet Loss:0.0900\tStatic Loss:0.1600\t\n",
      "Val Loss:0.2481\tRecon Loss:1.9602\tTriplet Loss:0.1220\tStatic Loss:0.2436\n",
      "\n",
      "\tTime:49.8311\n",
      "\n",
      "Test Loss:0.8160\tRecon Loss:5.8259\tTriplet Loss:0.4028\tStatic Loss:0.8072\n",
      "\n",
      "\tEpoch:134\tTrain Loss:0.1719\tRecon Loss:1.8755\tTriplet Loss:0.0941\tStatic Loss:0.1627\t\n",
      "Val Loss:0.2508\tRecon Loss:1.9394\tTriplet Loss:0.1218\tStatic Loss:0.2468\n",
      "\n",
      "\tTime:49.7174\n",
      "\n",
      "Test Loss:0.8315\tRecon Loss:5.7761\tTriplet Loss:0.4306\tStatic Loss:0.8221\n",
      "\n",
      "\tEpoch:135\tTrain Loss:0.1696\tRecon Loss:1.8431\tTriplet Loss:0.0893\tStatic Loss:0.1609\t\n",
      "Val Loss:0.2454\tRecon Loss:1.9396\tTriplet Loss:0.1185\tStatic Loss:0.2412\n",
      "\n",
      "\tTime:49.6078\n",
      "\n",
      "Test Loss:0.8223\tRecon Loss:5.8346\tTriplet Loss:0.4102\tStatic Loss:0.8134\n",
      "\n",
      "\tEpoch:136\tTrain Loss:0.1689\tRecon Loss:1.8404\tTriplet Loss:0.0888\tStatic Loss:0.1601\t\n",
      "Val Loss:0.2498\tRecon Loss:1.9907\tTriplet Loss:0.1253\tStatic Loss:0.2448\n",
      "\n",
      "\tTime:48.8264\n",
      "\n",
      "Test Loss:0.8193\tRecon Loss:5.8392\tTriplet Loss:0.4164\tStatic Loss:0.8094\n",
      "\n",
      "\tEpoch:137\tTrain Loss:0.1681\tRecon Loss:1.8444\tTriplet Loss:0.0860\tStatic Loss:0.1596\t\n",
      "Val Loss:0.2478\tRecon Loss:1.9427\tTriplet Loss:0.1282\tStatic Loss:0.2428\n",
      "\n",
      "\tTime:49.4493\n",
      "\n",
      "Test Loss:0.8030\tRecon Loss:5.7651\tTriplet Loss:0.4192\tStatic Loss:0.7918\n",
      "\n",
      "\tEpoch:138\tTrain Loss:0.1673\tRecon Loss:1.8371\tTriplet Loss:0.0862\tStatic Loss:0.1587\t\n",
      "Val Loss:0.2502\tRecon Loss:1.9766\tTriplet Loss:0.1183\tStatic Loss:0.2461\n",
      "\n",
      "\tTime:49.0678\n",
      "\n",
      "Test Loss:0.8268\tRecon Loss:5.8666\tTriplet Loss:0.4238\tStatic Loss:0.8167\n",
      "\n",
      "\tEpoch:139\tTrain Loss:0.1702\tRecon Loss:1.8443\tTriplet Loss:0.0883\tStatic Loss:0.1616\t\n",
      "Val Loss:0.2478\tRecon Loss:1.9473\tTriplet Loss:0.1256\tStatic Loss:0.2430\n",
      "\n",
      "\tTime:49.0339\n",
      "\n",
      "Test Loss:0.8246\tRecon Loss:5.8091\tTriplet Loss:0.4080\tStatic Loss:0.8164\n",
      "\n",
      "\tEpoch:140\tTrain Loss:0.1678\tRecon Loss:1.8434\tTriplet Loss:0.0872\tStatic Loss:0.1592\t\n",
      "Val Loss:0.2499\tRecon Loss:1.9461\tTriplet Loss:0.1199\tStatic Loss:0.2459\n",
      "\n",
      "\tTime:49.1086\n",
      "\n",
      "Test Loss:0.8311\tRecon Loss:5.8790\tTriplet Loss:0.4257\tStatic Loss:0.8211\n",
      "\n",
      "\tEpoch:141\tTrain Loss:0.1682\tRecon Loss:1.8397\tTriplet Loss:0.0872\tStatic Loss:0.1596\t\n",
      "Val Loss:0.2543\tRecon Loss:1.9389\tTriplet Loss:0.1230\tStatic Loss:0.2506\n",
      "\n",
      "\tTime:48.7457\n",
      "\n",
      "Test Loss:0.8276\tRecon Loss:5.8221\tTriplet Loss:0.4101\tStatic Loss:0.8194\n",
      "\n",
      "\tEpoch:142\tTrain Loss:0.1678\tRecon Loss:1.8520\tTriplet Loss:0.0890\tStatic Loss:0.1588\t\n",
      "Val Loss:0.2514\tRecon Loss:1.9359\tTriplet Loss:0.1337\tStatic Loss:0.2463\n",
      "\n",
      "\tTime:49.5071\n",
      "\n",
      "Test Loss:0.8272\tRecon Loss:5.8647\tTriplet Loss:0.4147\tStatic Loss:0.8181\n",
      "\n",
      "\tEpoch:143\tTrain Loss:0.1668\tRecon Loss:1.8748\tTriplet Loss:0.0854\tStatic Loss:0.1578\t\n",
      "Val Loss:0.2525\tRecon Loss:1.9374\tTriplet Loss:0.1301\tStatic Loss:0.2479\n",
      "\n",
      "\tTime:48.7662\n",
      "\n",
      "Test Loss:0.8207\tRecon Loss:5.8462\tTriplet Loss:0.4287\tStatic Loss:0.8096\n",
      "\n",
      "\tEpoch:144\tTrain Loss:0.1670\tRecon Loss:1.8442\tTriplet Loss:0.0887\tStatic Loss:0.1581\t\n",
      "Val Loss:0.2535\tRecon Loss:1.9439\tTriplet Loss:0.1321\tStatic Loss:0.2487\n",
      "\n",
      "\tTime:48.4895\n",
      "\n",
      "Test Loss:0.8092\tRecon Loss:5.8329\tTriplet Loss:0.4188\tStatic Loss:0.7979\n",
      "\n",
      "\tEpoch:145\tTrain Loss:0.1695\tRecon Loss:1.8540\tTriplet Loss:0.0911\tStatic Loss:0.1605\t\n",
      "Val Loss:0.2450\tRecon Loss:1.9598\tTriplet Loss:0.1199\tStatic Loss:0.2404\n",
      "\n",
      "\tTime:48.5060\n",
      "\n",
      "Test Loss:0.8238\tRecon Loss:5.8539\tTriplet Loss:0.4235\tStatic Loss:0.8135\n",
      "\n",
      "\tEpoch:146\tTrain Loss:0.1694\tRecon Loss:1.8673\tTriplet Loss:0.0863\tStatic Loss:0.1607\t\n",
      "Val Loss:0.2549\tRecon Loss:1.9431\tTriplet Loss:0.1287\tStatic Loss:0.2506\n",
      "\n",
      "\tTime:48.4966\n",
      "\n",
      "Test Loss:0.8321\tRecon Loss:5.8593\tTriplet Loss:0.4095\tStatic Loss:0.8241\n",
      "\n",
      "\tEpoch:147\tTrain Loss:0.1686\tRecon Loss:1.8534\tTriplet Loss:0.0873\tStatic Loss:0.1599\t\n",
      "Val Loss:0.2471\tRecon Loss:1.9323\tTriplet Loss:0.1243\tStatic Loss:0.2426\n",
      "\n",
      "\tTime:49.0920\n",
      "\n",
      "Test Loss:0.8170\tRecon Loss:5.7620\tTriplet Loss:0.4245\tStatic Loss:0.8068\n",
      "\n",
      "\tEpoch:148\tTrain Loss:0.1661\tRecon Loss:1.8340\tTriplet Loss:0.0871\tStatic Loss:0.1573\t\n",
      "Val Loss:0.2469\tRecon Loss:1.9560\tTriplet Loss:0.1305\tStatic Loss:0.2414\n",
      "\n",
      "\tTime:48.4490\n",
      "\n",
      "Test Loss:0.8074\tRecon Loss:5.8338\tTriplet Loss:0.4076\tStatic Loss:0.7971\n",
      "\n",
      "\tEpoch:149\tTrain Loss:0.1717\tRecon Loss:1.8469\tTriplet Loss:0.0898\tStatic Loss:0.1632\t\n",
      "Val Loss:0.2459\tRecon Loss:1.9868\tTriplet Loss:0.1328\tStatic Loss:0.2397\n",
      "\n",
      "\tTime:48.5352\n",
      "\n",
      "Test Loss:0.7918\tRecon Loss:5.9334\tTriplet Loss:0.3624\tStatic Loss:0.7834\n",
      "\n",
      "\tEpoch:150\tTrain Loss:0.1703\tRecon Loss:1.8496\tTriplet Loss:0.0883\tStatic Loss:0.1617\t\n",
      "Val Loss:0.2453\tRecon Loss:1.9427\tTriplet Loss:0.1183\tStatic Loss:0.2410\n",
      "\n",
      "\tTime:48.9476\n",
      "\n",
      "Test Loss:0.8256\tRecon Loss:5.8386\tTriplet Loss:0.4024\tStatic Loss:0.8177\n",
      "\n",
      "\tEpoch:151\tTrain Loss:0.1647\tRecon Loss:1.8340\tTriplet Loss:0.0849\tStatic Loss:0.1559\t\n",
      "Val Loss:0.2514\tRecon Loss:1.9404\tTriplet Loss:0.1240\tStatic Loss:0.2472\n",
      "\n",
      "\tTime:49.2680\n",
      "\n",
      "Test Loss:0.8290\tRecon Loss:5.7434\tTriplet Loss:0.4119\tStatic Loss:0.8216\n",
      "\n",
      "\tEpoch:152\tTrain Loss:0.1709\tRecon Loss:1.8658\tTriplet Loss:0.0882\tStatic Loss:0.1622\t\n",
      "Val Loss:0.2643\tRecon Loss:2.1807\tTriplet Loss:0.1389\tStatic Loss:0.2577\n",
      "\n",
      "\tTime:48.6388\n",
      "\n",
      "Test Loss:0.8559\tRecon Loss:6.2694\tTriplet Loss:0.4239\tStatic Loss:0.8450\n",
      "\n",
      "\tEpoch:153\tTrain Loss:0.1730\tRecon Loss:1.8733\tTriplet Loss:0.0872\tStatic Loss:0.1645\t\n",
      "Val Loss:0.2541\tRecon Loss:1.9413\tTriplet Loss:0.1336\tStatic Loss:0.2493\n",
      "\n",
      "\tTime:48.7067\n",
      "\n",
      "Test Loss:0.8365\tRecon Loss:5.8485\tTriplet Loss:0.4100\tStatic Loss:0.8291\n",
      "\n",
      "\tEpoch:154\tTrain Loss:0.1676\tRecon Loss:1.8416\tTriplet Loss:0.0883\tStatic Loss:0.1588\t\n",
      "Val Loss:0.2534\tRecon Loss:1.9663\tTriplet Loss:0.1250\tStatic Loss:0.2491\n",
      "\n",
      "\tTime:48.2184\n",
      "\n",
      "Test Loss:0.8344\tRecon Loss:5.8535\tTriplet Loss:0.4193\tStatic Loss:0.8257\n",
      "\n",
      "\tEpoch:155\tTrain Loss:0.1681\tRecon Loss:1.8480\tTriplet Loss:0.0878\tStatic Loss:0.1594\t\n",
      "Val Loss:0.2491\tRecon Loss:2.0352\tTriplet Loss:0.1196\tStatic Loss:0.2442\n",
      "\n",
      "\tTime:48.6195\n",
      "\n",
      "Test Loss:0.8185\tRecon Loss:6.0820\tTriplet Loss:0.4044\tStatic Loss:0.8073\n",
      "\n",
      "\tEpoch:156\tTrain Loss:0.1655\tRecon Loss:1.8379\tTriplet Loss:0.0899\tStatic Loss:0.1564\t\n",
      "Val Loss:0.2500\tRecon Loss:1.9310\tTriplet Loss:0.1217\tStatic Loss:0.2460\n",
      "\n",
      "\tTime:47.6764\n",
      "\n",
      "Test Loss:0.8179\tRecon Loss:5.8350\tTriplet Loss:0.3872\tStatic Loss:0.8108\n",
      "\n",
      "\tEpoch:157\tTrain Loss:0.1886\tRecon Loss:1.8792\tTriplet Loss:0.1029\tStatic Loss:0.1803\t\n",
      "Val Loss:0.2620\tRecon Loss:1.9331\tTriplet Loss:0.1330\tStatic Loss:0.2582\n",
      "\n",
      "\tTime:48.2658\n",
      "\n",
      "Test Loss:0.8208\tRecon Loss:5.8738\tTriplet Loss:0.4127\tStatic Loss:0.8111\n",
      "\n",
      "\tEpoch:158\tTrain Loss:0.1833\tRecon Loss:1.8486\tTriplet Loss:0.0972\tStatic Loss:0.1752\t\n",
      "Val Loss:0.2446\tRecon Loss:1.9159\tTriplet Loss:0.1254\tStatic Loss:0.2398\n",
      "\n",
      "\tTime:48.4077\n",
      "\n",
      "Test Loss:0.8095\tRecon Loss:5.8321\tTriplet Loss:0.4184\tStatic Loss:0.7984\n",
      "\n",
      "\tEpoch:159\tTrain Loss:0.1734\tRecon Loss:1.8384\tTriplet Loss:0.0894\tStatic Loss:0.1652\t\n",
      "Val Loss:0.2496\tRecon Loss:1.9480\tTriplet Loss:0.1221\tStatic Loss:0.2453\n",
      "\n",
      "\tTime:48.9256\n",
      "\n",
      "Test Loss:0.8142\tRecon Loss:5.7990\tTriplet Loss:0.4194\tStatic Loss:0.8039\n",
      "\n",
      "\tEpoch:160\tTrain Loss:0.1807\tRecon Loss:1.8462\tTriplet Loss:0.0906\tStatic Loss:0.1731\t\n",
      "Val Loss:0.2538\tRecon Loss:1.9404\tTriplet Loss:0.1231\tStatic Loss:0.2500\n",
      "\n",
      "\tTime:49.8107\n",
      "\n",
      "Test Loss:0.8309\tRecon Loss:5.8160\tTriplet Loss:0.4105\tStatic Loss:0.8231\n",
      "\n",
      "\tEpoch:161\tTrain Loss:0.1704\tRecon Loss:1.8324\tTriplet Loss:0.0922\tStatic Loss:0.1616\t\n",
      "Val Loss:0.2563\tRecon Loss:2.1214\tTriplet Loss:0.1285\tStatic Loss:0.2505\n",
      "\n",
      "\tTime:49.3819\n",
      "\n",
      "Test Loss:0.8344\tRecon Loss:6.3952\tTriplet Loss:0.4317\tStatic Loss:0.8190\n",
      "\n",
      "\tEpoch:162\tTrain Loss:0.1700\tRecon Loss:1.8583\tTriplet Loss:0.0869\tStatic Loss:0.1614\t\n",
      "Val Loss:0.2585\tRecon Loss:1.9695\tTriplet Loss:0.1228\tStatic Loss:0.2549\n",
      "\n",
      "\tTime:48.5869\n",
      "\n",
      "Test Loss:0.8337\tRecon Loss:6.0078\tTriplet Loss:0.4589\tStatic Loss:0.8195\n",
      "\n",
      "\tEpoch:163\tTrain Loss:0.1669\tRecon Loss:1.8370\tTriplet Loss:0.0834\tStatic Loss:0.1585\t\n",
      "Val Loss:0.2544\tRecon Loss:1.9485\tTriplet Loss:0.1225\tStatic Loss:0.2506\n",
      "\n",
      "\tTime:48.5748\n",
      "\n",
      "Test Loss:0.8222\tRecon Loss:5.7429\tTriplet Loss:0.4035\tStatic Loss:0.8149\n",
      "\n",
      "\tEpoch:164\tTrain Loss:0.1660\tRecon Loss:1.8367\tTriplet Loss:0.0865\tStatic Loss:0.1572\t\n",
      "Val Loss:0.2474\tRecon Loss:1.9195\tTriplet Loss:0.1325\tStatic Loss:0.2422\n",
      "\n",
      "\tTime:47.6936\n",
      "\n",
      "Test Loss:0.8156\tRecon Loss:5.8057\tTriplet Loss:0.4053\tStatic Loss:0.8067\n",
      "\n",
      "\tEpoch:165\tTrain Loss:0.1690\tRecon Loss:1.8368\tTriplet Loss:0.0847\tStatic Loss:0.1608\t\n",
      "Val Loss:0.2524\tRecon Loss:1.9403\tTriplet Loss:0.1223\tStatic Loss:0.2486\n",
      "\n",
      "\tTime:49.0253\n",
      "\n",
      "Test Loss:0.8240\tRecon Loss:5.7837\tTriplet Loss:0.3806\tStatic Loss:0.8188\n",
      "\n",
      "\tEpoch:166\tTrain Loss:0.1665\tRecon Loss:1.8411\tTriplet Loss:0.0886\tStatic Loss:0.1575\t\n",
      "Val Loss:0.2580\tRecon Loss:1.9838\tTriplet Loss:0.1198\tStatic Loss:0.2545\n",
      "\n",
      "\tTime:49.3628\n",
      "\n",
      "Test Loss:0.8450\tRecon Loss:5.9275\tTriplet Loss:0.4203\tStatic Loss:0.8367\n",
      "\n",
      "\tEpoch:167\tTrain Loss:0.1656\tRecon Loss:1.8391\tTriplet Loss:0.0839\tStatic Loss:0.1570\t\n",
      "Val Loss:0.2486\tRecon Loss:1.9387\tTriplet Loss:0.1165\tStatic Loss:0.2449\n",
      "\n",
      "\tTime:48.5756\n",
      "\n",
      "Test Loss:0.8141\tRecon Loss:5.8419\tTriplet Loss:0.3949\tStatic Loss:0.8058\n",
      "\n",
      "\tEpoch:168\tTrain Loss:0.1637\tRecon Loss:1.8347\tTriplet Loss:0.0880\tStatic Loss:0.1546\t\n",
      "Val Loss:0.2537\tRecon Loss:1.9413\tTriplet Loss:0.1169\tStatic Loss:0.2505\n",
      "\n",
      "\tTime:48.9513\n",
      "\n",
      "Test Loss:0.8515\tRecon Loss:5.8467\tTriplet Loss:0.4162\tStatic Loss:0.8451\n",
      "\n",
      "\tEpoch:169\tTrain Loss:0.1658\tRecon Loss:1.8453\tTriplet Loss:0.0871\tStatic Loss:0.1569\t\n",
      "Val Loss:0.2486\tRecon Loss:1.9510\tTriplet Loss:0.1239\tStatic Loss:0.2440\n",
      "\n",
      "\tTime:48.3727\n",
      "\n",
      "Test Loss:0.8319\tRecon Loss:5.8450\tTriplet Loss:0.4299\tStatic Loss:0.8219\n",
      "\n",
      "\tEpoch:170\tTrain Loss:0.1709\tRecon Loss:1.8469\tTriplet Loss:0.0905\tStatic Loss:0.1622\t\n",
      "Val Loss:0.2512\tRecon Loss:1.9409\tTriplet Loss:0.1272\tStatic Loss:0.2467\n",
      "\n",
      "\tTime:49.7309\n",
      "\n",
      "Test Loss:0.8117\tRecon Loss:5.8428\tTriplet Loss:0.3979\tStatic Loss:0.8028\n",
      "\n",
      "\tEpoch:171\tTrain Loss:0.1670\tRecon Loss:1.8351\tTriplet Loss:0.0830\tStatic Loss:0.1587\t\n",
      "Val Loss:0.2494\tRecon Loss:1.9584\tTriplet Loss:0.1234\tStatic Loss:0.2449\n",
      "\n",
      "\tTime:49.7794\n",
      "\n",
      "Test Loss:0.8184\tRecon Loss:5.7985\tTriplet Loss:0.3957\tStatic Loss:0.8109\n",
      "\n",
      "\tEpoch:172\tTrain Loss:0.1660\tRecon Loss:1.8699\tTriplet Loss:0.0887\tStatic Loss:0.1567\t\n",
      "Val Loss:0.2487\tRecon Loss:1.9485\tTriplet Loss:0.1226\tStatic Loss:0.2443\n",
      "\n",
      "\tTime:50.1304\n",
      "\n",
      "Test Loss:0.8197\tRecon Loss:5.7874\tTriplet Loss:0.4249\tStatic Loss:0.8095\n",
      "\n",
      "\tEpoch:173\tTrain Loss:0.1659\tRecon Loss:1.8360\tTriplet Loss:0.0854\tStatic Loss:0.1572\t\n",
      "Val Loss:0.2484\tRecon Loss:1.9518\tTriplet Loss:0.1288\tStatic Loss:0.2434\n",
      "\n",
      "\tTime:49.5111\n",
      "\n",
      "Test Loss:0.8024\tRecon Loss:5.7868\tTriplet Loss:0.4019\tStatic Loss:0.7926\n",
      "\n",
      "\tEpoch:174\tTrain Loss:0.1678\tRecon Loss:1.8658\tTriplet Loss:0.0876\tStatic Loss:0.1588\t\n",
      "Val Loss:0.2475\tRecon Loss:2.0068\tTriplet Loss:0.1213\tStatic Loss:0.2425\n",
      "\n",
      "\tTime:49.0531\n",
      "\n",
      "Test Loss:0.8022\tRecon Loss:5.9526\tTriplet Loss:0.4156\tStatic Loss:0.7894\n",
      "\n",
      "\tEpoch:175\tTrain Loss:0.1640\tRecon Loss:1.8454\tTriplet Loss:0.0835\tStatic Loss:0.1553\t\n",
      "Val Loss:0.2494\tRecon Loss:1.9361\tTriplet Loss:0.1276\tStatic Loss:0.2447\n",
      "\n",
      "\tTime:48.8567\n",
      "\n",
      "Test Loss:0.8095\tRecon Loss:5.8121\tTriplet Loss:0.4039\tStatic Loss:0.8000\n",
      "\n",
      "\tEpoch:176\tTrain Loss:0.1643\tRecon Loss:1.8405\tTriplet Loss:0.0878\tStatic Loss:0.1552\t\n",
      "Val Loss:0.2504\tRecon Loss:1.9527\tTriplet Loss:0.1364\tStatic Loss:0.2448\n",
      "\n",
      "\tTime:48.6361\n",
      "\n",
      "Test Loss:0.8203\tRecon Loss:5.8092\tTriplet Loss:0.4488\tStatic Loss:0.8076\n",
      "\n",
      "\tEpoch:177\tTrain Loss:0.1638\tRecon Loss:1.8387\tTriplet Loss:0.0863\tStatic Loss:0.1548\t\n",
      "Val Loss:0.2523\tRecon Loss:1.9381\tTriplet Loss:0.1253\tStatic Loss:0.2481\n",
      "\n",
      "\tTime:48.9360\n",
      "\n",
      "Test Loss:0.8250\tRecon Loss:5.7973\tTriplet Loss:0.4113\tStatic Loss:0.8167\n",
      "\n",
      "\tEpoch:178\tTrain Loss:0.1645\tRecon Loss:1.8509\tTriplet Loss:0.0846\tStatic Loss:0.1556\t\n",
      "Val Loss:0.2538\tRecon Loss:2.0046\tTriplet Loss:0.1273\tStatic Loss:0.2489\n",
      "\n",
      "\tTime:48.7806\n",
      "\n",
      "Test Loss:0.8436\tRecon Loss:5.9827\tTriplet Loss:0.4237\tStatic Loss:0.8342\n",
      "\n",
      "\tEpoch:179\tTrain Loss:0.1911\tRecon Loss:1.8903\tTriplet Loss:0.1051\tStatic Loss:0.1827\t\n",
      "Val Loss:0.2567\tRecon Loss:1.9890\tTriplet Loss:0.1430\tStatic Loss:0.2507\n",
      "\n",
      "\tTime:48.4668\n",
      "\n",
      "Test Loss:0.8517\tRecon Loss:5.9304\tTriplet Loss:0.4387\tStatic Loss:0.8422\n",
      "\n",
      "\tEpoch:180\tTrain Loss:0.1825\tRecon Loss:1.8553\tTriplet Loss:0.0988\tStatic Loss:0.1742\t\n",
      "Val Loss:0.2548\tRecon Loss:1.9425\tTriplet Loss:0.1463\tStatic Loss:0.2487\n",
      "\n",
      "\tTime:48.0322\n",
      "\n",
      "Test Loss:0.8508\tRecon Loss:5.8013\tTriplet Loss:0.4637\tStatic Loss:0.8400\n",
      "\n",
      "\tEpoch:181\tTrain Loss:0.1739\tRecon Loss:1.8378\tTriplet Loss:0.0967\tStatic Loss:0.1650\t\n",
      "Val Loss:0.2527\tRecon Loss:1.9475\tTriplet Loss:0.1325\tStatic Loss:0.2477\n",
      "\n",
      "\tTime:49.1075\n",
      "\n",
      "Test Loss:0.8207\tRecon Loss:5.8111\tTriplet Loss:0.4244\tStatic Loss:0.8104\n",
      "\n",
      "\tEpoch:182\tTrain Loss:0.1843\tRecon Loss:1.8611\tTriplet Loss:0.0991\tStatic Loss:0.1761\t\n",
      "Val Loss:0.2461\tRecon Loss:2.0126\tTriplet Loss:0.1156\tStatic Loss:0.2414\n",
      "\n",
      "\tTime:48.2520\n",
      "\n",
      "Test Loss:0.8306\tRecon Loss:5.8945\tTriplet Loss:0.4200\tStatic Loss:0.8210\n",
      "\n",
      "\tEpoch:183\tTrain Loss:0.1715\tRecon Loss:1.8377\tTriplet Loss:0.0952\tStatic Loss:0.1624\t\n",
      "Val Loss:0.2448\tRecon Loss:1.9645\tTriplet Loss:0.1157\tStatic Loss:0.2405\n",
      "\n",
      "\tTime:49.0213\n",
      "\n",
      "Test Loss:0.8188\tRecon Loss:5.8495\tTriplet Loss:0.4225\tStatic Loss:0.8081\n",
      "\n",
      "\tEpoch:184\tTrain Loss:0.1697\tRecon Loss:1.8439\tTriplet Loss:0.0926\tStatic Loss:0.1606\t\n",
      "Val Loss:0.2452\tRecon Loss:1.9420\tTriplet Loss:0.1088\tStatic Loss:0.2419\n",
      "\n",
      "\tTime:49.1882\n",
      "\n",
      "Test Loss:0.8127\tRecon Loss:5.8500\tTriplet Loss:0.4002\tStatic Loss:0.8036\n",
      "\n",
      "\tEpoch:185\tTrain Loss:0.1668\tRecon Loss:1.8403\tTriplet Loss:0.0874\tStatic Loss:0.1580\t\n",
      "Val Loss:0.2503\tRecon Loss:1.9499\tTriplet Loss:0.1236\tStatic Loss:0.2459\n",
      "\n",
      "\tTime:48.7511\n",
      "\n",
      "Test Loss:0.8513\tRecon Loss:5.8508\tTriplet Loss:0.4372\tStatic Loss:0.8427\n",
      "\n",
      "\tEpoch:186\tTrain Loss:0.1657\tRecon Loss:1.8378\tTriplet Loss:0.0868\tStatic Loss:0.1569\t\n",
      "Val Loss:0.2492\tRecon Loss:1.9330\tTriplet Loss:0.1239\tStatic Loss:0.2449\n",
      "\n",
      "\tTime:47.7332\n",
      "\n",
      "Test Loss:0.8144\tRecon Loss:5.8048\tTriplet Loss:0.4087\tStatic Loss:0.8051\n",
      "\n",
      "\tEpoch:187\tTrain Loss:0.1654\tRecon Loss:1.8312\tTriplet Loss:0.0918\tStatic Loss:0.1561\t\n",
      "Val Loss:0.2531\tRecon Loss:1.9187\tTriplet Loss:0.1166\tStatic Loss:0.2501\n",
      "\n",
      "\tTime:48.7366\n",
      "\n",
      "Test Loss:0.8528\tRecon Loss:5.7795\tTriplet Loss:0.4386\tStatic Loss:0.8449\n",
      "\n",
      "\tEpoch:188\tTrain Loss:0.1637\tRecon Loss:1.8345\tTriplet Loss:0.0829\tStatic Loss:0.1551\t\n",
      "Val Loss:0.2481\tRecon Loss:1.9467\tTriplet Loss:0.1247\tStatic Loss:0.2434\n",
      "\n",
      "\tTime:48.4146\n",
      "\n",
      "Test Loss:0.8102\tRecon Loss:5.8891\tTriplet Loss:0.4147\tStatic Loss:0.7990\n",
      "\n",
      "\tEpoch:189\tTrain Loss:0.1653\tRecon Loss:1.8262\tTriplet Loss:0.0891\tStatic Loss:0.1563\t\n",
      "Val Loss:0.2542\tRecon Loss:1.9794\tTriplet Loss:0.1209\tStatic Loss:0.2503\n",
      "\n",
      "\tTime:48.9716\n",
      "\n",
      "Test Loss:0.8370\tRecon Loss:5.8965\tTriplet Loss:0.4132\tStatic Loss:0.8288\n",
      "\n",
      "\tEpoch:190\tTrain Loss:0.1653\tRecon Loss:1.8898\tTriplet Loss:0.0908\tStatic Loss:0.1555\t\n",
      "Val Loss:0.2475\tRecon Loss:1.9512\tTriplet Loss:0.1287\tStatic Loss:0.2424\n",
      "\n",
      "\tTime:48.5108\n",
      "\n",
      "Test Loss:0.8078\tRecon Loss:5.8721\tTriplet Loss:0.4066\tStatic Loss:0.7973\n",
      "\n",
      "\tEpoch:191\tTrain Loss:0.1637\tRecon Loss:1.8372\tTriplet Loss:0.0878\tStatic Loss:0.1545\t\n",
      "Val Loss:0.2521\tRecon Loss:1.9558\tTriplet Loss:0.1329\tStatic Loss:0.2470\n",
      "\n",
      "\tTime:48.4482\n",
      "\n",
      "Test Loss:0.8330\tRecon Loss:5.9134\tTriplet Loss:0.4284\tStatic Loss:0.8226\n",
      "\n",
      "\tEpoch:192\tTrain Loss:0.1792\tRecon Loss:1.8758\tTriplet Loss:0.0946\tStatic Loss:0.1707\t\n",
      "Val Loss:0.2550\tRecon Loss:1.9804\tTriplet Loss:0.1286\tStatic Loss:0.2503\n",
      "\n",
      "\tTime:49.1491\n",
      "\n",
      "Test Loss:0.8323\tRecon Loss:5.9957\tTriplet Loss:0.4201\tStatic Loss:0.8219\n",
      "\n",
      "\tEpoch:193\tTrain Loss:0.1735\tRecon Loss:1.8855\tTriplet Loss:0.0960\tStatic Loss:0.1642\t\n",
      "Val Loss:0.2445\tRecon Loss:1.9597\tTriplet Loss:0.1309\tStatic Loss:0.2387\n",
      "\n",
      "\tTime:48.3744\n",
      "\n",
      "Test Loss:0.8077\tRecon Loss:5.8882\tTriplet Loss:0.3936\tStatic Loss:0.7983\n",
      "\n",
      "\tEpoch:194\tTrain Loss:0.1684\tRecon Loss:1.8375\tTriplet Loss:0.0884\tStatic Loss:0.1597\t\n",
      "Val Loss:0.2482\tRecon Loss:1.9563\tTriplet Loss:0.1156\tStatic Loss:0.2444\n",
      "\n",
      "\tTime:48.2015\n",
      "\n",
      "Test Loss:0.8254\tRecon Loss:5.8213\tTriplet Loss:0.4416\tStatic Loss:0.8138\n",
      "\n",
      "\tEpoch:195\tTrain Loss:0.1642\tRecon Loss:1.8300\tTriplet Loss:0.0829\tStatic Loss:0.1556\t\n",
      "Val Loss:0.2553\tRecon Loss:1.9891\tTriplet Loss:0.1140\tStatic Loss:0.2521\n",
      "\n",
      "\tTime:48.4605\n",
      "\n",
      "Test Loss:0.8438\tRecon Loss:5.8966\tTriplet Loss:0.4084\tStatic Loss:0.8369\n",
      "\n",
      "\tEpoch:196\tTrain Loss:0.1641\tRecon Loss:1.8442\tTriplet Loss:0.0878\tStatic Loss:0.1550\t\n",
      "Val Loss:0.2478\tRecon Loss:1.9482\tTriplet Loss:0.1238\tStatic Loss:0.2432\n",
      "\n",
      "\tTime:48.5428\n",
      "\n",
      "Test Loss:0.8108\tRecon Loss:5.9499\tTriplet Loss:0.4071\tStatic Loss:0.7997\n",
      "\n",
      "\tEpoch:197\tTrain Loss:0.1737\tRecon Loss:1.8535\tTriplet Loss:0.0910\tStatic Loss:0.1652\t\n",
      "Val Loss:0.2529\tRecon Loss:1.9618\tTriplet Loss:0.1208\tStatic Loss:0.2490\n",
      "\n",
      "\tTime:48.8319\n",
      "\n",
      "Test Loss:0.8273\tRecon Loss:6.0519\tTriplet Loss:0.3884\tStatic Loss:0.8189\n",
      "\n",
      "\tEpoch:198\tTrain Loss:0.1657\tRecon Loss:1.8384\tTriplet Loss:0.0915\tStatic Loss:0.1564\t\n",
      "Val Loss:0.2464\tRecon Loss:1.9381\tTriplet Loss:0.1197\tStatic Loss:0.2421\n",
      "\n",
      "\tTime:48.5229\n",
      "\n",
      "Test Loss:0.8238\tRecon Loss:5.8431\tTriplet Loss:0.4139\tStatic Loss:0.8146\n",
      "\n",
      "\tEpoch:199\tTrain Loss:0.1680\tRecon Loss:1.8392\tTriplet Loss:0.0851\tStatic Loss:0.1596\t\n",
      "Val Loss:0.2487\tRecon Loss:1.9596\tTriplet Loss:0.1334\tStatic Loss:0.2431\n",
      "\n",
      "\tTime:48.5194\n",
      "\n",
      "Test Loss:0.7957\tRecon Loss:5.8564\tTriplet Loss:0.3822\tStatic Loss:0.7865\n",
      "\n",
      "\t\n",
      "Unc Est in Static characteristics:0.0000\tUnc Est in Streamflow, dynamic:0.0000\t\n",
      "\n",
      "\tATT_NL_0\n",
      "Epoch:0\tTrain Loss:0.5482\tRecon Loss:4.1101\tTriplet Loss:0.3820\tStatic Loss:0.5293\t\n",
      "Val Loss:0.4252\tRecon Loss:4.0382\tTriplet Loss:0.2561\tStatic Loss:0.4059\n",
      "\n",
      "\tTime:48.8201\n",
      "\n",
      "Test Loss:1.2581\tRecon Loss:11.9746\tTriplet Loss:0.8456\tStatic Loss:1.1921\n",
      "\n",
      "\tEpoch:1\tTrain Loss:0.3923\tRecon Loss:3.9678\tTriplet Loss:0.2356\tStatic Loss:0.3722\t\n",
      "Val Loss:0.3811\tRecon Loss:4.0235\tTriplet Loss:0.2176\tStatic Loss:0.3610\n",
      "\n",
      "\tTime:48.8914\n",
      "\n",
      "Test Loss:1.1526\tRecon Loss:11.9191\tTriplet Loss:0.7001\tStatic Loss:1.0902\n",
      "\n",
      "\tEpoch:2\tTrain Loss:0.3594\tRecon Loss:3.9574\tTriplet Loss:0.2115\tStatic Loss:0.3382\t\n",
      "Val Loss:0.3560\tRecon Loss:4.0141\tTriplet Loss:0.2024\tStatic Loss:0.3348\n",
      "\n",
      "\tTime:48.5896\n",
      "\n",
      "Test Loss:1.0716\tRecon Loss:11.9166\tTriplet Loss:0.6700\tStatic Loss:1.0033\n",
      "\n",
      "\tEpoch:3\tTrain Loss:0.3383\tRecon Loss:3.8662\tTriplet Loss:0.1919\tStatic Loss:0.3176\t\n",
      "Val Loss:0.3441\tRecon Loss:3.7828\tTriplet Loss:0.1843\tStatic Loss:0.3257\n",
      "\n",
      "\tTime:48.3146\n",
      "\n",
      "Test Loss:1.0869\tRecon Loss:11.2905\tTriplet Loss:0.6199\tStatic Loss:1.0316\n",
      "\n",
      "\tEpoch:4\tTrain Loss:0.3192\tRecon Loss:3.5209\tTriplet Loss:0.1753\tStatic Loss:0.3015\t\n",
      "Val Loss:0.3240\tRecon Loss:3.2615\tTriplet Loss:0.1699\tStatic Loss:0.3100\n",
      "\n",
      "\tTime:48.3899\n",
      "\n",
      "Test Loss:1.0206\tRecon Loss:10.1203\tTriplet Loss:0.5975\tStatic Loss:0.9719\n",
      "\n",
      "\tEpoch:5\tTrain Loss:0.3004\tRecon Loss:2.4481\tTriplet Loss:0.1755\tStatic Loss:0.2914\t\n",
      "Val Loss:0.3129\tRecon Loss:2.1693\tTriplet Loss:0.1729\tStatic Loss:0.3084\n",
      "\n",
      "\tTime:49.0930\n",
      "\n",
      "Test Loss:0.9951\tRecon Loss:6.5318\tTriplet Loss:0.6063\tStatic Loss:0.9786\n",
      "\n",
      "\tEpoch:6\tTrain Loss:0.2885\tRecon Loss:2.0459\tTriplet Loss:0.1702\tStatic Loss:0.2827\t\n",
      "Val Loss:0.3082\tRecon Loss:2.0207\tTriplet Loss:0.1773\tStatic Loss:0.3042\n",
      "\n",
      "\tTime:49.3489\n",
      "\n",
      "Test Loss:0.9606\tRecon Loss:6.0110\tTriplet Loss:0.5649\tStatic Loss:0.9497\n",
      "\n",
      "\tEpoch:7\tTrain Loss:0.2811\tRecon Loss:2.0638\tTriplet Loss:0.1644\tStatic Loss:0.2749\t\n",
      "Val Loss:0.3208\tRecon Loss:2.7143\tTriplet Loss:0.1665\tStatic Loss:0.3123\n",
      "\n",
      "\tTime:49.2357\n",
      "\n",
      "Test Loss:1.0274\tRecon Loss:7.9812\tTriplet Loss:0.6194\tStatic Loss:0.9987\n",
      "\n",
      "\tEpoch:8\tTrain Loss:0.2752\tRecon Loss:1.9816\tTriplet Loss:0.1587\tStatic Loss:0.2698\t\n",
      "Val Loss:0.3033\tRecon Loss:2.0346\tTriplet Loss:0.1706\tStatic Loss:0.2993\n",
      "\n",
      "\tTime:48.9866\n",
      "\n",
      "Test Loss:0.9771\tRecon Loss:6.0488\tTriplet Loss:0.5762\tStatic Loss:0.9665\n",
      "\n",
      "\tEpoch:9\tTrain Loss:0.2700\tRecon Loss:1.9175\tTriplet Loss:0.1576\tStatic Loss:0.2648\t\n",
      "Val Loss:0.2969\tRecon Loss:1.9624\tTriplet Loss:0.1648\tStatic Loss:0.2935\n",
      "\n",
      "\tTime:50.3020\n",
      "\n",
      "Test Loss:0.9650\tRecon Loss:5.8751\tTriplet Loss:0.5823\tStatic Loss:0.9541\n",
      "\n",
      "\tEpoch:10\tTrain Loss:0.2636\tRecon Loss:1.9310\tTriplet Loss:0.1487\tStatic Loss:0.2584\t\n",
      "Val Loss:0.2939\tRecon Loss:1.9593\tTriplet Loss:0.1661\tStatic Loss:0.2900\n",
      "\n",
      "\tTime:50.2402\n",
      "\n",
      "Test Loss:0.9526\tRecon Loss:5.8285\tTriplet Loss:0.5589\tStatic Loss:0.9432\n",
      "\n",
      "\tEpoch:11\tTrain Loss:0.2600\tRecon Loss:1.8981\tTriplet Loss:0.1451\tStatic Loss:0.2551\t\n",
      "Val Loss:0.2873\tRecon Loss:2.2600\tTriplet Loss:0.1573\tStatic Loss:0.2806\n",
      "\n",
      "\tTime:49.2062\n",
      "\n",
      "Test Loss:0.9322\tRecon Loss:6.8111\tTriplet Loss:0.6009\tStatic Loss:0.9065\n",
      "\n",
      "\tEpoch:12\tTrain Loss:0.2552\tRecon Loss:1.8950\tTriplet Loss:0.1378\tStatic Loss:0.2505\t\n",
      "Val Loss:0.2863\tRecon Loss:1.9358\tTriplet Loss:0.1619\tStatic Loss:0.2822\n",
      "\n",
      "\tTime:49.9387\n",
      "\n",
      "Test Loss:0.9275\tRecon Loss:5.7658\tTriplet Loss:0.5578\tStatic Loss:0.9161\n",
      "\n",
      "\tEpoch:13\tTrain Loss:0.2531\tRecon Loss:2.0720\tTriplet Loss:0.1379\tStatic Loss:0.2465\t\n",
      "Val Loss:0.2859\tRecon Loss:1.9490\tTriplet Loss:0.1512\tStatic Loss:0.2827\n",
      "\n",
      "\tTime:48.7280\n",
      "\n",
      "Test Loss:0.9434\tRecon Loss:5.7689\tTriplet Loss:0.5440\tStatic Loss:0.9351\n",
      "\n",
      "\tEpoch:14\tTrain Loss:0.2483\tRecon Loss:1.8857\tTriplet Loss:0.1355\tStatic Loss:0.2433\t\n",
      "Val Loss:0.2843\tRecon Loss:1.9561\tTriplet Loss:0.1552\tStatic Loss:0.2805\n",
      "\n",
      "\tTime:49.1105\n",
      "\n",
      "Test Loss:0.9287\tRecon Loss:5.8621\tTriplet Loss:0.5682\tStatic Loss:0.9154\n",
      "\n",
      "\tEpoch:15\tTrain Loss:0.2454\tRecon Loss:1.8896\tTriplet Loss:0.1386\tStatic Loss:0.2397\t\n",
      "Val Loss:0.2798\tRecon Loss:1.9412\tTriplet Loss:0.1475\tStatic Loss:0.2765\n",
      "\n",
      "\tTime:49.3201\n",
      "\n",
      "Test Loss:0.8970\tRecon Loss:5.9089\tTriplet Loss:0.5699\tStatic Loss:0.8796\n",
      "\n",
      "\tEpoch:16\tTrain Loss:0.2424\tRecon Loss:1.8948\tTriplet Loss:0.1334\tStatic Loss:0.2368\t\n",
      "Val Loss:0.2809\tRecon Loss:1.9351\tTriplet Loss:0.1576\tStatic Loss:0.2766\n",
      "\n",
      "\tTime:50.2296\n",
      "\n",
      "Test Loss:0.9162\tRecon Loss:5.9385\tTriplet Loss:0.5632\tStatic Loss:0.9012\n",
      "\n",
      "\tEpoch:17\tTrain Loss:0.2406\tRecon Loss:2.0275\tTriplet Loss:0.1339\tStatic Loss:0.2334\t\n",
      "Val Loss:0.2778\tRecon Loss:1.9322\tTriplet Loss:0.1632\tStatic Loss:0.2727\n",
      "\n",
      "\tTime:50.0632\n",
      "\n",
      "Test Loss:0.8814\tRecon Loss:5.8904\tTriplet Loss:0.5081\tStatic Loss:0.8686\n",
      "\n",
      "\tEpoch:18\tTrain Loss:0.2352\tRecon Loss:1.8767\tTriplet Loss:0.1308\tStatic Loss:0.2292\t\n",
      "Val Loss:0.2786\tRecon Loss:1.9280\tTriplet Loss:0.1503\tStatic Loss:0.2750\n",
      "\n",
      "\tTime:49.4164\n",
      "\n",
      "Test Loss:0.8978\tRecon Loss:5.7708\tTriplet Loss:0.5230\tStatic Loss:0.8866\n",
      "\n",
      "\tEpoch:19\tTrain Loss:0.2369\tRecon Loss:1.8634\tTriplet Loss:0.1250\tStatic Loss:0.2319\t\n",
      "Val Loss:0.2791\tRecon Loss:1.9582\tTriplet Loss:0.1395\tStatic Loss:0.2762\n",
      "\n",
      "\tTime:49.2724\n",
      "\n",
      "Test Loss:0.9070\tRecon Loss:5.8433\tTriplet Loss:0.5514\tStatic Loss:0.8932\n",
      "\n",
      "\tEpoch:20\tTrain Loss:0.2311\tRecon Loss:1.8874\tTriplet Loss:0.1226\tStatic Loss:0.2254\t\n",
      "Val Loss:0.2763\tRecon Loss:1.9894\tTriplet Loss:0.1572\tStatic Loss:0.2711\n",
      "\n",
      "\tTime:50.1830\n",
      "\n",
      "Test Loss:0.8868\tRecon Loss:6.0188\tTriplet Loss:0.5418\tStatic Loss:0.8700\n",
      "\n",
      "\tEpoch:21\tTrain Loss:0.2295\tRecon Loss:1.8783\tTriplet Loss:0.1271\tStatic Loss:0.2232\t\n",
      "Val Loss:0.2763\tRecon Loss:1.9523\tTriplet Loss:0.1428\tStatic Loss:0.2729\n",
      "\n",
      "\tTime:49.3469\n",
      "\n",
      "Test Loss:0.9026\tRecon Loss:5.8175\tTriplet Loss:0.5263\tStatic Loss:0.8911\n",
      "\n",
      "\tEpoch:22\tTrain Loss:0.2270\tRecon Loss:1.8652\tTriplet Loss:0.1222\tStatic Loss:0.2211\t\n",
      "Val Loss:0.2764\tRecon Loss:1.9633\tTriplet Loss:0.1461\tStatic Loss:0.2726\n",
      "\n",
      "\tTime:48.5161\n",
      "\n",
      "Test Loss:0.9029\tRecon Loss:5.8859\tTriplet Loss:0.5564\tStatic Loss:0.8877\n",
      "\n",
      "\tEpoch:23\tTrain Loss:0.2240\tRecon Loss:1.8616\tTriplet Loss:0.1161\tStatic Loss:0.2184\t\n",
      "Val Loss:0.2747\tRecon Loss:1.9360\tTriplet Loss:0.1604\tStatic Loss:0.2695\n",
      "\n",
      "\tTime:49.6611\n",
      "\n",
      "Test Loss:0.8791\tRecon Loss:5.8027\tTriplet Loss:0.5518\tStatic Loss:0.8626\n",
      "\n",
      "\tEpoch:24\tTrain Loss:0.2244\tRecon Loss:1.8936\tTriplet Loss:0.1261\tStatic Loss:0.2175\t\n",
      "Val Loss:0.2747\tRecon Loss:1.9506\tTriplet Loss:0.1426\tStatic Loss:0.2711\n",
      "\n",
      "\tTime:49.2113\n",
      "\n",
      "Test Loss:0.8686\tRecon Loss:5.8517\tTriplet Loss:0.5451\tStatic Loss:0.8511\n",
      "\n",
      "\tEpoch:25\tTrain Loss:0.2204\tRecon Loss:1.8645\tTriplet Loss:0.1216\tStatic Loss:0.2139\t\n",
      "Val Loss:0.2723\tRecon Loss:1.9780\tTriplet Loss:0.1453\tStatic Loss:0.2680\n",
      "\n",
      "\tTime:49.3406\n",
      "\n",
      "Test Loss:0.8919\tRecon Loss:5.9656\tTriplet Loss:0.5243\tStatic Loss:0.8779\n",
      "\n",
      "\tEpoch:26\tTrain Loss:0.2193\tRecon Loss:1.8571\tTriplet Loss:0.1211\tStatic Loss:0.2127\t\n",
      "Val Loss:0.2690\tRecon Loss:1.9704\tTriplet Loss:0.1491\tStatic Loss:0.2640\n",
      "\n",
      "\tTime:50.2513\n",
      "\n",
      "Test Loss:0.8677\tRecon Loss:5.8731\tTriplet Loss:0.5202\tStatic Loss:0.8524\n",
      "\n",
      "\tEpoch:27\tTrain Loss:0.2175\tRecon Loss:1.8808\tTriplet Loss:0.1113\tStatic Loss:0.2115\t\n",
      "Val Loss:0.2700\tRecon Loss:2.0182\tTriplet Loss:0.1524\tStatic Loss:0.2642\n",
      "\n",
      "\tTime:48.5184\n",
      "\n",
      "Test Loss:0.8636\tRecon Loss:5.9623\tTriplet Loss:0.5210\tStatic Loss:0.8469\n",
      "\n",
      "\tEpoch:28\tTrain Loss:0.2174\tRecon Loss:1.8955\tTriplet Loss:0.1168\tStatic Loss:0.2107\t\n",
      "Val Loss:0.2737\tRecon Loss:1.9409\tTriplet Loss:0.1494\tStatic Loss:0.2694\n",
      "\n",
      "\tTime:49.0027\n",
      "\n",
      "Test Loss:0.8817\tRecon Loss:5.8570\tTriplet Loss:0.5319\tStatic Loss:0.8669\n",
      "\n",
      "\tEpoch:29\tTrain Loss:0.2151\tRecon Loss:1.8744\tTriplet Loss:0.1123\tStatic Loss:0.2088\t\n",
      "Val Loss:0.2724\tRecon Loss:1.9374\tTriplet Loss:0.1470\tStatic Loss:0.2683\n",
      "\n",
      "\tTime:49.0272\n",
      "\n",
      "Test Loss:0.8826\tRecon Loss:5.8729\tTriplet Loss:0.5263\tStatic Loss:0.8684\n",
      "\n",
      "\tEpoch:30\tTrain Loss:0.2143\tRecon Loss:1.8592\tTriplet Loss:0.1105\tStatic Loss:0.2083\t\n",
      "Val Loss:0.2779\tRecon Loss:1.9779\tTriplet Loss:0.1478\tStatic Loss:0.2739\n",
      "\n",
      "\tTime:49.7980\n",
      "\n",
      "Test Loss:0.9055\tRecon Loss:5.9625\tTriplet Loss:0.5211\tStatic Loss:0.8933\n",
      "\n",
      "\tEpoch:31\tTrain Loss:0.2121\tRecon Loss:1.8596\tTriplet Loss:0.1098\tStatic Loss:0.2058\t\n",
      "Val Loss:0.2668\tRecon Loss:1.9293\tTriplet Loss:0.1469\tStatic Loss:0.2621\n",
      "\n",
      "\tTime:49.0336\n",
      "\n",
      "Test Loss:0.8737\tRecon Loss:5.7471\tTriplet Loss:0.5390\tStatic Loss:0.8584\n",
      "\n",
      "\tEpoch:32\tTrain Loss:0.2107\tRecon Loss:1.8648\tTriplet Loss:0.1132\tStatic Loss:0.2039\t\n",
      "Val Loss:0.2694\tRecon Loss:1.9306\tTriplet Loss:0.1489\tStatic Loss:0.2648\n",
      "\n",
      "\tTime:49.1902\n",
      "\n",
      "Test Loss:0.8675\tRecon Loss:5.7681\tTriplet Loss:0.4989\tStatic Loss:0.8554\n",
      "\n",
      "\tEpoch:33\tTrain Loss:0.2106\tRecon Loss:1.9669\tTriplet Loss:0.1093\tStatic Loss:0.2031\t\n",
      "Val Loss:0.2743\tRecon Loss:1.9442\tTriplet Loss:0.1492\tStatic Loss:0.2701\n",
      "\n",
      "\tTime:49.0130\n",
      "\n",
      "Test Loss:0.8810\tRecon Loss:5.7684\tTriplet Loss:0.5281\tStatic Loss:0.8675\n",
      "\n",
      "\tEpoch:34\tTrain Loss:0.2108\tRecon Loss:1.8618\tTriplet Loss:0.1120\tStatic Loss:0.2041\t\n",
      "Val Loss:0.2673\tRecon Loss:1.9689\tTriplet Loss:0.1480\tStatic Loss:0.2622\n",
      "\n",
      "\tTime:49.0452\n",
      "\n",
      "Test Loss:0.8741\tRecon Loss:5.8705\tTriplet Loss:0.5487\tStatic Loss:0.8567\n",
      "\n",
      "\tEpoch:35\tTrain Loss:0.2096\tRecon Loss:1.8541\tTriplet Loss:0.1152\tStatic Loss:0.2026\t\n",
      "Val Loss:0.2669\tRecon Loss:1.9657\tTriplet Loss:0.1457\tStatic Loss:0.2620\n",
      "\n",
      "\tTime:49.1524\n",
      "\n",
      "Test Loss:0.8618\tRecon Loss:6.0515\tTriplet Loss:0.4853\tStatic Loss:0.8476\n",
      "\n",
      "\tEpoch:36\tTrain Loss:0.2073\tRecon Loss:1.8638\tTriplet Loss:0.1110\tStatic Loss:0.2004\t\n",
      "Val Loss:0.2743\tRecon Loss:2.0657\tTriplet Loss:0.1494\tStatic Loss:0.2689\n",
      "\n",
      "\tTime:49.5503\n",
      "\n",
      "Test Loss:0.9038\tRecon Loss:6.4101\tTriplet Loss:0.5252\tStatic Loss:0.8866\n",
      "\n",
      "\tEpoch:37\tTrain Loss:0.2068\tRecon Loss:1.8769\tTriplet Loss:0.1163\tStatic Loss:0.1991\t\n",
      "Val Loss:0.2694\tRecon Loss:1.9289\tTriplet Loss:0.1480\tStatic Loss:0.2650\n",
      "\n",
      "\tTime:49.4554\n",
      "\n",
      "Test Loss:0.8815\tRecon Loss:5.7810\tTriplet Loss:0.5391\tStatic Loss:0.8667\n",
      "\n",
      "\tEpoch:38\tTrain Loss:0.2052\tRecon Loss:1.8675\tTriplet Loss:0.1108\tStatic Loss:0.1980\t\n",
      "Val Loss:0.2735\tRecon Loss:1.9695\tTriplet Loss:0.1469\tStatic Loss:0.2691\n",
      "\n",
      "\tTime:49.4327\n",
      "\n",
      "Test Loss:0.8709\tRecon Loss:5.9551\tTriplet Loss:0.4867\tStatic Loss:0.8585\n",
      "\n",
      "\tEpoch:39\tTrain Loss:0.2058\tRecon Loss:1.8530\tTriplet Loss:0.1078\tStatic Loss:0.1991\t\n",
      "Val Loss:0.2669\tRecon Loss:1.9526\tTriplet Loss:0.1397\tStatic Loss:0.2627\n",
      "\n",
      "\tTime:49.4351\n",
      "\n",
      "Test Loss:0.8706\tRecon Loss:5.9686\tTriplet Loss:0.5220\tStatic Loss:0.8545\n",
      "\n",
      "\tEpoch:40\tTrain Loss:0.2044\tRecon Loss:1.8581\tTriplet Loss:0.1114\tStatic Loss:0.1972\t\n",
      "Val Loss:0.2721\tRecon Loss:1.9046\tTriplet Loss:0.1456\tStatic Loss:0.2685\n",
      "\n",
      "\tTime:49.9307\n",
      "\n",
      "Test Loss:0.8893\tRecon Loss:5.7624\tTriplet Loss:0.5115\tStatic Loss:0.8783\n",
      "\n",
      "\tEpoch:41\tTrain Loss:0.2022\tRecon Loss:1.8539\tTriplet Loss:0.0991\tStatic Loss:0.1960\t\n",
      "Val Loss:0.2699\tRecon Loss:1.9449\tTriplet Loss:0.1470\tStatic Loss:0.2654\n",
      "\n",
      "\tTime:49.1187\n",
      "\n",
      "Test Loss:0.8832\tRecon Loss:5.8476\tTriplet Loss:0.5131\tStatic Loss:0.8705\n",
      "\n",
      "\tEpoch:42\tTrain Loss:0.2017\tRecon Loss:1.8601\tTriplet Loss:0.1101\tStatic Loss:0.1943\t\n",
      "Val Loss:0.2697\tRecon Loss:1.9899\tTriplet Loss:0.1493\tStatic Loss:0.2645\n",
      "\n",
      "\tTime:49.1745\n",
      "\n",
      "Test Loss:0.8513\tRecon Loss:6.0163\tTriplet Loss:0.5150\tStatic Loss:0.8333\n",
      "\n",
      "\tEpoch:43\tTrain Loss:0.2013\tRecon Loss:1.8536\tTriplet Loss:0.1119\tStatic Loss:0.1937\t\n",
      "Val Loss:0.2699\tRecon Loss:1.9358\tTriplet Loss:0.1456\tStatic Loss:0.2657\n",
      "\n",
      "\tTime:49.6704\n",
      "\n",
      "Test Loss:0.8814\tRecon Loss:5.7485\tTriplet Loss:0.5538\tStatic Loss:0.8655\n",
      "\n",
      "\tEpoch:44\tTrain Loss:0.2022\tRecon Loss:1.8477\tTriplet Loss:0.1038\tStatic Loss:0.1956\t\n",
      "Val Loss:0.2749\tRecon Loss:1.9409\tTriplet Loss:0.1538\tStatic Loss:0.2704\n",
      "\n",
      "\tTime:49.1740\n",
      "\n",
      "Test Loss:0.8859\tRecon Loss:5.8758\tTriplet Loss:0.5169\tStatic Loss:0.8729\n",
      "\n",
      "\tEpoch:45\tTrain Loss:0.2005\tRecon Loss:1.8528\tTriplet Loss:0.1074\tStatic Loss:0.1933\t\n",
      "Val Loss:0.2738\tRecon Loss:1.9758\tTriplet Loss:0.1462\tStatic Loss:0.2696\n",
      "\n",
      "\tTime:48.1634\n",
      "\n",
      "Test Loss:0.8753\tRecon Loss:5.8981\tTriplet Loss:0.5126\tStatic Loss:0.8613\n",
      "\n",
      "\tEpoch:46\tTrain Loss:0.2014\tRecon Loss:1.8785\tTriplet Loss:0.1071\tStatic Loss:0.1940\t\n",
      "Val Loss:0.2695\tRecon Loss:1.9521\tTriplet Loss:0.1451\tStatic Loss:0.2651\n",
      "\n",
      "\tTime:48.4760\n",
      "\n",
      "Test Loss:0.8600\tRecon Loss:5.8268\tTriplet Loss:0.5167\tStatic Loss:0.8447\n",
      "\n",
      "\tEpoch:47\tTrain Loss:0.1999\tRecon Loss:1.8599\tTriplet Loss:0.1046\tStatic Loss:0.1929\t\n",
      "Val Loss:0.2844\tRecon Loss:1.9537\tTriplet Loss:0.1480\tStatic Loss:0.2814\n",
      "\n",
      "\tTime:48.2545\n",
      "\n",
      "Test Loss:0.8969\tRecon Loss:5.8770\tTriplet Loss:0.5257\tStatic Loss:0.8843\n",
      "\n",
      "\tEpoch:48\tTrain Loss:0.2014\tRecon Loss:1.8528\tTriplet Loss:0.1088\tStatic Loss:0.1941\t\n",
      "Val Loss:0.2716\tRecon Loss:1.9368\tTriplet Loss:0.1357\tStatic Loss:0.2685\n",
      "\n",
      "\tTime:48.9203\n",
      "\n",
      "Test Loss:0.8562\tRecon Loss:5.8801\tTriplet Loss:0.5278\tStatic Loss:0.8388\n",
      "\n",
      "\tEpoch:49\tTrain Loss:0.1974\tRecon Loss:1.8448\tTriplet Loss:0.1056\tStatic Loss:0.1901\t\n",
      "Val Loss:0.2675\tRecon Loss:1.9173\tTriplet Loss:0.1545\tStatic Loss:0.2623\n",
      "\n",
      "\tTime:49.9838\n",
      "\n",
      "Test Loss:0.8624\tRecon Loss:5.8626\tTriplet Loss:0.5206\tStatic Loss:0.8466\n",
      "\n",
      "\tEpoch:50\tTrain Loss:0.1997\tRecon Loss:1.8591\tTriplet Loss:0.1056\tStatic Loss:0.1925\t\n",
      "Val Loss:0.2747\tRecon Loss:1.9372\tTriplet Loss:0.1406\tStatic Loss:0.2715\n",
      "\n",
      "\tTime:49.9960\n",
      "\n",
      "Test Loss:0.8630\tRecon Loss:5.9449\tTriplet Loss:0.5032\tStatic Loss:0.8482\n",
      "\n",
      "\tEpoch:51\tTrain Loss:0.1987\tRecon Loss:1.8492\tTriplet Loss:0.1088\tStatic Loss:0.1912\t\n",
      "Val Loss:0.2809\tRecon Loss:2.0588\tTriplet Loss:0.1307\tStatic Loss:0.2781\n",
      "\n",
      "\tTime:50.0826\n",
      "\n",
      "Test Loss:0.8762\tRecon Loss:6.0931\tTriplet Loss:0.5142\tStatic Loss:0.8603\n",
      "\n",
      "\tEpoch:52\tTrain Loss:0.1948\tRecon Loss:1.8674\tTriplet Loss:0.1030\tStatic Loss:0.1873\t\n",
      "Val Loss:0.2692\tRecon Loss:1.9314\tTriplet Loss:0.1534\tStatic Loss:0.2641\n",
      "\n",
      "\tTime:50.2370\n",
      "\n",
      "Test Loss:0.8653\tRecon Loss:5.7834\tTriplet Loss:0.5181\tStatic Loss:0.8509\n",
      "\n",
      "\tEpoch:53\tTrain Loss:0.1953\tRecon Loss:1.8482\tTriplet Loss:0.1050\tStatic Loss:0.1878\t\n",
      "Val Loss:0.2717\tRecon Loss:1.9711\tTriplet Loss:0.1439\tStatic Loss:0.2674\n",
      "\n",
      "\tTime:49.5905\n",
      "\n",
      "Test Loss:0.8816\tRecon Loss:5.8916\tTriplet Loss:0.5391\tStatic Loss:0.8658\n",
      "\n",
      "\tEpoch:54\tTrain Loss:0.1954\tRecon Loss:1.8508\tTriplet Loss:0.1092\tStatic Loss:0.1875\t\n",
      "Val Loss:0.2747\tRecon Loss:1.9676\tTriplet Loss:0.1531\tStatic Loss:0.2700\n",
      "\n",
      "\tTime:49.5742\n",
      "\n",
      "Test Loss:0.8957\tRecon Loss:6.0223\tTriplet Loss:0.4893\tStatic Loss:0.8851\n",
      "\n",
      "\tEpoch:55\tTrain Loss:0.1934\tRecon Loss:1.8448\tTriplet Loss:0.1021\tStatic Loss:0.1860\t\n",
      "Val Loss:0.2639\tRecon Loss:1.9357\tTriplet Loss:0.1360\tStatic Loss:0.2600\n",
      "\n",
      "\tTime:49.3081\n",
      "\n",
      "Test Loss:0.8658\tRecon Loss:5.9480\tTriplet Loss:0.5030\tStatic Loss:0.8512\n",
      "\n",
      "\tEpoch:56\tTrain Loss:0.1928\tRecon Loss:1.8374\tTriplet Loss:0.1051\tStatic Loss:0.1852\t\n",
      "Val Loss:0.2699\tRecon Loss:1.9676\tTriplet Loss:0.1532\tStatic Loss:0.2646\n",
      "\n",
      "\tTime:49.5815\n",
      "\n",
      "Test Loss:0.8558\tRecon Loss:5.8449\tTriplet Loss:0.5130\tStatic Loss:0.8402\n",
      "\n",
      "\tEpoch:57\tTrain Loss:0.1961\tRecon Loss:1.8442\tTriplet Loss:0.1085\tStatic Loss:0.1883\t\n",
      "Val Loss:0.2691\tRecon Loss:1.9808\tTriplet Loss:0.1476\tStatic Loss:0.2641\n",
      "\n",
      "\tTime:49.5650\n",
      "\n",
      "Test Loss:0.8831\tRecon Loss:5.9951\tTriplet Loss:0.5054\tStatic Loss:0.8697\n",
      "\n",
      "\tEpoch:58\tTrain Loss:0.1940\tRecon Loss:1.8522\tTriplet Loss:0.1053\tStatic Loss:0.1863\t\n",
      "Val Loss:0.2745\tRecon Loss:2.0547\tTriplet Loss:0.1489\tStatic Loss:0.2692\n",
      "\n",
      "\tTime:48.9976\n",
      "\n",
      "Test Loss:0.9012\tRecon Loss:6.1527\tTriplet Loss:0.5270\tStatic Loss:0.8861\n",
      "\n",
      "\tEpoch:59\tTrain Loss:0.1977\tRecon Loss:1.8489\tTriplet Loss:0.1008\tStatic Loss:0.1909\t\n",
      "Val Loss:0.2703\tRecon Loss:1.9692\tTriplet Loss:0.1440\tStatic Loss:0.2659\n",
      "\n",
      "\tTime:48.5201\n",
      "\n",
      "Test Loss:0.8759\tRecon Loss:5.9107\tTriplet Loss:0.5313\tStatic Loss:0.8600\n",
      "\n",
      "\tEpoch:60\tTrain Loss:0.1935\tRecon Loss:1.8448\tTriplet Loss:0.1073\tStatic Loss:0.1856\t\n",
      "Val Loss:0.2691\tRecon Loss:1.9518\tTriplet Loss:0.1355\tStatic Loss:0.2657\n",
      "\n",
      "\tTime:48.8264\n",
      "\n",
      "Test Loss:0.8680\tRecon Loss:5.9333\tTriplet Loss:0.5023\tStatic Loss:0.8539\n",
      "\n",
      "\tEpoch:61\tTrain Loss:0.1920\tRecon Loss:1.8464\tTriplet Loss:0.1073\tStatic Loss:0.1839\t\n",
      "Val Loss:0.2631\tRecon Loss:1.9595\tTriplet Loss:0.1355\tStatic Loss:0.2589\n",
      "\n",
      "\tTime:49.3826\n",
      "\n",
      "Test Loss:0.8567\tRecon Loss:5.9133\tTriplet Loss:0.4970\tStatic Loss:0.8421\n",
      "\n",
      "\tEpoch:62\tTrain Loss:0.2035\tRecon Loss:1.8678\tTriplet Loss:0.1090\tStatic Loss:0.1963\t\n",
      "Val Loss:0.2664\tRecon Loss:1.9526\tTriplet Loss:0.1474\tStatic Loss:0.2615\n",
      "\n",
      "\tTime:49.5777\n",
      "\n",
      "Test Loss:0.8553\tRecon Loss:5.9977\tTriplet Loss:0.5157\tStatic Loss:0.8379\n",
      "\n",
      "\tEpoch:63\tTrain Loss:0.1929\tRecon Loss:1.8435\tTriplet Loss:0.0993\tStatic Loss:0.1857\t\n",
      "Val Loss:0.2657\tRecon Loss:1.9408\tTriplet Loss:0.1450\tStatic Loss:0.2611\n",
      "\n",
      "\tTime:48.5124\n",
      "\n",
      "Test Loss:0.8657\tRecon Loss:5.9488\tTriplet Loss:0.5004\tStatic Loss:0.8514\n",
      "\n",
      "\tEpoch:64\tTrain Loss:0.1897\tRecon Loss:1.8408\tTriplet Loss:0.1028\tStatic Loss:0.1819\t\n",
      "Val Loss:0.2642\tRecon Loss:1.9403\tTriplet Loss:0.1503\tStatic Loss:0.2589\n",
      "\n",
      "\tTime:49.0669\n",
      "\n",
      "Test Loss:0.8795\tRecon Loss:5.9196\tTriplet Loss:0.5352\tStatic Loss:0.8636\n",
      "\n",
      "\tEpoch:65\tTrain Loss:0.1892\tRecon Loss:1.8484\tTriplet Loss:0.1014\tStatic Loss:0.1814\t\n",
      "Val Loss:0.2679\tRecon Loss:1.9903\tTriplet Loss:0.1383\tStatic Loss:0.2637\n",
      "\n",
      "\tTime:48.9705\n",
      "\n",
      "Test Loss:0.8573\tRecon Loss:6.0793\tTriplet Loss:0.5194\tStatic Loss:0.8389\n",
      "\n",
      "\tEpoch:66\tTrain Loss:0.1903\tRecon Loss:1.8477\tTriplet Loss:0.1031\tStatic Loss:0.1825\t\n",
      "Val Loss:0.2672\tRecon Loss:1.9474\tTriplet Loss:0.1438\tStatic Loss:0.2627\n",
      "\n",
      "\tTime:49.0340\n",
      "\n",
      "Test Loss:0.8943\tRecon Loss:6.0154\tTriplet Loss:0.5115\tStatic Loss:0.8813\n",
      "\n",
      "\tEpoch:67\tTrain Loss:0.1912\tRecon Loss:1.8415\tTriplet Loss:0.0997\tStatic Loss:0.1839\t\n",
      "Val Loss:0.2599\tRecon Loss:1.9418\tTriplet Loss:0.1431\tStatic Loss:0.2548\n",
      "\n",
      "\tTime:48.5601\n",
      "\n",
      "Test Loss:0.8594\tRecon Loss:5.8496\tTriplet Loss:0.5328\tStatic Loss:0.8422\n",
      "\n",
      "\tEpoch:68\tTrain Loss:0.1917\tRecon Loss:1.8439\tTriplet Loss:0.1057\tStatic Loss:0.1837\t\n",
      "Val Loss:0.2663\tRecon Loss:2.0466\tTriplet Loss:0.1481\tStatic Loss:0.2604\n",
      "\n",
      "\tTime:49.6143\n",
      "\n",
      "Test Loss:0.8722\tRecon Loss:6.0412\tTriplet Loss:0.4939\tStatic Loss:0.8583\n",
      "\n",
      "\tEpoch:69\tTrain Loss:0.2004\tRecon Loss:1.8730\tTriplet Loss:0.1073\tStatic Loss:0.1930\t\n",
      "Val Loss:0.2713\tRecon Loss:1.9576\tTriplet Loss:0.1484\tStatic Loss:0.2667\n",
      "\n",
      "\tTime:49.3172\n",
      "\n",
      "Test Loss:0.8625\tRecon Loss:5.9020\tTriplet Loss:0.5339\tStatic Loss:0.8450\n",
      "\n",
      "\tEpoch:70\tTrain Loss:0.1939\tRecon Loss:1.8400\tTriplet Loss:0.1008\tStatic Loss:0.1867\t\n",
      "Val Loss:0.2682\tRecon Loss:1.9686\tTriplet Loss:0.1369\tStatic Loss:0.2643\n",
      "\n",
      "\tTime:49.8287\n",
      "\n",
      "Test Loss:0.8824\tRecon Loss:6.0683\tTriplet Loss:0.5102\tStatic Loss:0.8678\n",
      "\n",
      "\tEpoch:71\tTrain Loss:0.1924\tRecon Loss:1.8584\tTriplet Loss:0.1032\tStatic Loss:0.1847\t\n",
      "Val Loss:0.2651\tRecon Loss:1.9330\tTriplet Loss:0.1378\tStatic Loss:0.2611\n",
      "\n",
      "\tTime:49.8823\n",
      "\n",
      "Test Loss:0.8935\tRecon Loss:6.0997\tTriplet Loss:0.5215\tStatic Loss:0.8787\n",
      "\n",
      "\tEpoch:72\tTrain Loss:0.1893\tRecon Loss:1.8430\tTriplet Loss:0.0989\tStatic Loss:0.1818\t\n",
      "Val Loss:0.2655\tRecon Loss:1.9330\tTriplet Loss:0.1456\tStatic Loss:0.2608\n",
      "\n",
      "\tTime:49.1836\n",
      "\n",
      "Test Loss:0.8765\tRecon Loss:5.9881\tTriplet Loss:0.4879\tStatic Loss:0.8642\n",
      "\n",
      "\tEpoch:73\tTrain Loss:0.1920\tRecon Loss:1.8530\tTriplet Loss:0.1021\tStatic Loss:0.1843\t\n",
      "Val Loss:0.2680\tRecon Loss:1.9240\tTriplet Loss:0.1418\tStatic Loss:0.2640\n",
      "\n",
      "\tTime:49.0217\n",
      "\n",
      "Test Loss:0.9025\tRecon Loss:5.9283\tTriplet Loss:0.5240\tStatic Loss:0.8901\n",
      "\n",
      "\tEpoch:74\tTrain Loss:0.1868\tRecon Loss:1.8324\tTriplet Loss:0.0994\tStatic Loss:0.1791\t\n",
      "Val Loss:0.2664\tRecon Loss:1.9744\tTriplet Loss:0.1464\tStatic Loss:0.2613\n",
      "\n",
      "\tTime:50.0619\n",
      "\n",
      "Test Loss:0.8595\tRecon Loss:5.9799\tTriplet Loss:0.4830\tStatic Loss:0.8459\n",
      "\n",
      "\tEpoch:75\tTrain Loss:0.1875\tRecon Loss:1.8490\tTriplet Loss:0.1039\tStatic Loss:0.1793\t\n",
      "Val Loss:0.2683\tRecon Loss:1.9594\tTriplet Loss:0.1324\tStatic Loss:0.2650\n",
      "\n",
      "\tTime:49.9784\n",
      "\n",
      "Test Loss:0.8958\tRecon Loss:5.9944\tTriplet Loss:0.5485\tStatic Loss:0.8796\n",
      "\n",
      "\tEpoch:76\tTrain Loss:0.1864\tRecon Loss:1.8417\tTriplet Loss:0.0984\tStatic Loss:0.1787\t\n",
      "Val Loss:0.2798\tRecon Loss:1.9810\tTriplet Loss:0.1478\tStatic Loss:0.2760\n",
      "\n",
      "\tTime:50.3142\n",
      "\n",
      "Test Loss:0.9221\tRecon Loss:5.9855\tTriplet Loss:0.4917\tStatic Loss:0.9145\n",
      "\n",
      "\tEpoch:77\tTrain Loss:0.1891\tRecon Loss:1.8415\tTriplet Loss:0.1043\tStatic Loss:0.1811\t\n",
      "Val Loss:0.2687\tRecon Loss:1.9393\tTriplet Loss:0.1450\tStatic Loss:0.2644\n",
      "\n",
      "\tTime:49.7147\n",
      "\n",
      "Test Loss:0.8645\tRecon Loss:5.9053\tTriplet Loss:0.5357\tStatic Loss:0.8470\n",
      "\n",
      "\tEpoch:78\tTrain Loss:0.1961\tRecon Loss:1.8567\tTriplet Loss:0.1103\tStatic Loss:0.1881\t\n",
      "Val Loss:0.2691\tRecon Loss:1.9656\tTriplet Loss:0.1465\tStatic Loss:0.2644\n",
      "\n",
      "\tTime:49.7146\n",
      "\n",
      "Test Loss:0.8873\tRecon Loss:6.0843\tTriplet Loss:0.5111\tStatic Loss:0.8729\n",
      "\n",
      "\tEpoch:79\tTrain Loss:0.1887\tRecon Loss:1.8385\tTriplet Loss:0.1050\tStatic Loss:0.1806\t\n",
      "Val Loss:0.2719\tRecon Loss:1.9564\tTriplet Loss:0.1411\tStatic Loss:0.2682\n",
      "\n",
      "\tTime:49.3513\n",
      "\n",
      "Test Loss:0.8656\tRecon Loss:5.9193\tTriplet Loss:0.5175\tStatic Loss:0.8499\n",
      "\n",
      "\tEpoch:80\tTrain Loss:0.1885\tRecon Loss:1.8556\tTriplet Loss:0.1023\tStatic Loss:0.1805\t\n",
      "Val Loss:0.2706\tRecon Loss:2.0263\tTriplet Loss:0.1421\tStatic Loss:0.2659\n",
      "\n",
      "\tTime:49.6062\n",
      "\n",
      "Test Loss:0.8921\tRecon Loss:6.4464\tTriplet Loss:0.4818\tStatic Loss:0.8776\n",
      "\n",
      "\tEpoch:81\tTrain Loss:0.1862\tRecon Loss:1.8389\tTriplet Loss:0.0991\tStatic Loss:0.1784\t\n",
      "Val Loss:0.2673\tRecon Loss:1.9321\tTriplet Loss:0.1377\tStatic Loss:0.2636\n",
      "\n",
      "\tTime:49.3237\n",
      "\n",
      "Test Loss:0.8727\tRecon Loss:5.9594\tTriplet Loss:0.4571\tStatic Loss:0.8634\n",
      "\n",
      "\tEpoch:82\tTrain Loss:0.1898\tRecon Loss:1.8415\tTriplet Loss:0.0972\tStatic Loss:0.1826\t\n",
      "Val Loss:0.2666\tRecon Loss:1.9673\tTriplet Loss:0.1392\tStatic Loss:0.2623\n",
      "\n",
      "\tTime:49.9515\n",
      "\n",
      "Test Loss:0.8671\tRecon Loss:6.1117\tTriplet Loss:0.4905\tStatic Loss:0.8523\n",
      "\n",
      "\tEpoch:83\tTrain Loss:0.1855\tRecon Loss:1.8398\tTriplet Loss:0.0966\tStatic Loss:0.1779\t\n",
      "Val Loss:0.2713\tRecon Loss:1.9366\tTriplet Loss:0.1476\tStatic Loss:0.2670\n",
      "\n",
      "\tTime:50.1243\n",
      "\n",
      "Test Loss:0.8888\tRecon Loss:5.9609\tTriplet Loss:0.5556\tStatic Loss:0.8714\n",
      "\n",
      "\tEpoch:84\tTrain Loss:0.1868\tRecon Loss:1.8361\tTriplet Loss:0.1021\tStatic Loss:0.1788\t\n",
      "Val Loss:0.2687\tRecon Loss:1.9489\tTriplet Loss:0.1544\tStatic Loss:0.2633\n",
      "\n",
      "\tTime:49.3089\n",
      "\n",
      "Test Loss:0.8911\tRecon Loss:6.0945\tTriplet Loss:0.5002\tStatic Loss:0.8781\n",
      "\n",
      "\tEpoch:85\tTrain Loss:0.1838\tRecon Loss:1.8348\tTriplet Loss:0.0998\tStatic Loss:0.1757\t\n",
      "Val Loss:0.2703\tRecon Loss:1.9548\tTriplet Loss:0.1416\tStatic Loss:0.2663\n",
      "\n",
      "\tTime:49.1707\n",
      "\n",
      "Test Loss:0.8930\tRecon Loss:6.1083\tTriplet Loss:0.5052\tStatic Loss:0.8796\n",
      "\n",
      "\tEpoch:86\tTrain Loss:0.1838\tRecon Loss:1.8396\tTriplet Loss:0.1010\tStatic Loss:0.1755\t\n",
      "Val Loss:0.2716\tRecon Loss:1.9479\tTriplet Loss:0.1397\tStatic Loss:0.2680\n",
      "\n",
      "\tTime:49.4876\n",
      "\n",
      "Test Loss:0.9059\tRecon Loss:6.0808\tTriplet Loss:0.5065\tStatic Loss:0.8941\n",
      "\n",
      "\tEpoch:87\tTrain Loss:0.1884\tRecon Loss:1.8575\tTriplet Loss:0.0984\tStatic Loss:0.1808\t\n",
      "Val Loss:0.2740\tRecon Loss:1.9822\tTriplet Loss:0.1500\tStatic Loss:0.2694\n",
      "\n",
      "\tTime:49.1877\n",
      "\n",
      "Test Loss:0.9405\tRecon Loss:6.2146\tTriplet Loss:0.5288\tStatic Loss:0.9290\n",
      "\n",
      "\tEpoch:88\tTrain Loss:0.1845\tRecon Loss:1.8409\tTriplet Loss:0.1030\tStatic Loss:0.1761\t\n",
      "Val Loss:0.2740\tRecon Loss:1.9445\tTriplet Loss:0.1438\tStatic Loss:0.2703\n",
      "\n",
      "\tTime:49.3734\n",
      "\n",
      "Test Loss:0.9118\tRecon Loss:6.0276\tTriplet Loss:0.5008\tStatic Loss:0.9017\n",
      "\n",
      "\tEpoch:89\tTrain Loss:0.1853\tRecon Loss:1.8336\tTriplet Loss:0.1036\tStatic Loss:0.1770\t\n",
      "Val Loss:0.2644\tRecon Loss:1.9634\tTriplet Loss:0.1363\tStatic Loss:0.2602\n",
      "\n",
      "\tTime:48.7008\n",
      "\n",
      "Test Loss:0.8747\tRecon Loss:5.8817\tTriplet Loss:0.4908\tStatic Loss:0.8631\n",
      "\n",
      "\tEpoch:90\tTrain Loss:0.1857\tRecon Loss:1.8379\tTriplet Loss:0.1015\tStatic Loss:0.1776\t\n",
      "Val Loss:0.2728\tRecon Loss:1.9822\tTriplet Loss:0.1367\tStatic Loss:0.2693\n",
      "\n",
      "\tTime:49.4868\n",
      "\n",
      "Test Loss:0.9251\tRecon Loss:6.1410\tTriplet Loss:0.5050\tStatic Loss:0.9149\n",
      "\n",
      "\tEpoch:91\tTrain Loss:0.1913\tRecon Loss:1.8654\tTriplet Loss:0.1026\tStatic Loss:0.1834\t\n",
      "Val Loss:0.2748\tRecon Loss:1.9518\tTriplet Loss:0.1533\tStatic Loss:0.2702\n",
      "\n",
      "\tTime:50.1849\n",
      "\n",
      "Test Loss:0.9050\tRecon Loss:6.0534\tTriplet Loss:0.4844\tStatic Loss:0.8956\n",
      "\n",
      "\tEpoch:92\tTrain Loss:0.1870\tRecon Loss:1.8404\tTriplet Loss:0.1027\tStatic Loss:0.1789\t\n",
      "Val Loss:0.2692\tRecon Loss:1.9369\tTriplet Loss:0.1362\tStatic Loss:0.2658\n",
      "\n",
      "\tTime:49.1403\n",
      "\n",
      "Test Loss:0.9025\tRecon Loss:6.0225\tTriplet Loss:0.5367\tStatic Loss:0.8879\n",
      "\n",
      "\tEpoch:93\tTrain Loss:0.1835\tRecon Loss:1.8371\tTriplet Loss:0.0984\tStatic Loss:0.1754\t\n",
      "Val Loss:0.2731\tRecon Loss:1.9518\tTriplet Loss:0.1480\tStatic Loss:0.2688\n",
      "\n",
      "\tTime:49.2307\n",
      "\n",
      "Test Loss:0.8987\tRecon Loss:6.0353\tTriplet Loss:0.5121\tStatic Loss:0.8860\n",
      "\n",
      "\tEpoch:94\tTrain Loss:0.1827\tRecon Loss:1.8386\tTriplet Loss:0.0985\tStatic Loss:0.1745\t\n",
      "Val Loss:0.2690\tRecon Loss:1.9846\tTriplet Loss:0.1406\tStatic Loss:0.2647\n",
      "\n",
      "\tTime:48.4293\n",
      "\n",
      "Test Loss:0.8884\tRecon Loss:5.9662\tTriplet Loss:0.5028\tStatic Loss:0.8762\n",
      "\n",
      "\tEpoch:95\tTrain Loss:0.1858\tRecon Loss:1.8380\tTriplet Loss:0.0972\tStatic Loss:0.1782\t\n",
      "Val Loss:0.2707\tRecon Loss:2.0306\tTriplet Loss:0.1440\tStatic Loss:0.2658\n",
      "\n",
      "\tTime:49.9963\n",
      "\n",
      "Test Loss:0.9150\tRecon Loss:6.1860\tTriplet Loss:0.5058\tStatic Loss:0.9032\n",
      "\n",
      "\tEpoch:96\tTrain Loss:0.1846\tRecon Loss:1.8432\tTriplet Loss:0.0999\tStatic Loss:0.1764\t\n",
      "Val Loss:0.2678\tRecon Loss:1.9569\tTriplet Loss:0.1357\tStatic Loss:0.2641\n",
      "\n",
      "\tTime:48.7735\n",
      "\n",
      "Test Loss:0.9087\tRecon Loss:5.9180\tTriplet Loss:0.4868\tStatic Loss:0.9008\n",
      "\n",
      "\tEpoch:97\tTrain Loss:0.1798\tRecon Loss:1.8322\tTriplet Loss:0.0961\tStatic Loss:0.1717\t\n",
      "Val Loss:0.2684\tRecon Loss:1.9688\tTriplet Loss:0.1474\tStatic Loss:0.2635\n",
      "\n",
      "\tTime:49.6039\n",
      "\n",
      "Test Loss:0.9059\tRecon Loss:6.0605\tTriplet Loss:0.5061\tStatic Loss:0.8943\n",
      "\n",
      "\tEpoch:98\tTrain Loss:0.1820\tRecon Loss:1.8513\tTriplet Loss:0.1016\tStatic Loss:0.1733\t\n",
      "Val Loss:0.2667\tRecon Loss:1.9815\tTriplet Loss:0.1414\tStatic Loss:0.2620\n",
      "\n",
      "\tTime:48.9477\n",
      "\n",
      "Test Loss:0.8813\tRecon Loss:6.0587\tTriplet Loss:0.5317\tStatic Loss:0.8645\n",
      "\n",
      "\tEpoch:99\tTrain Loss:0.1802\tRecon Loss:1.8363\tTriplet Loss:0.0995\tStatic Loss:0.1717\t\n",
      "Val Loss:0.2869\tRecon Loss:1.9543\tTriplet Loss:0.1377\tStatic Loss:0.2852\n",
      "\n",
      "\tTime:48.1605\n",
      "\n",
      "Test Loss:0.9342\tRecon Loss:5.9148\tTriplet Loss:0.5008\tStatic Loss:0.9277\n",
      "\n",
      "\tEpoch:100\tTrain Loss:0.1930\tRecon Loss:1.8484\tTriplet Loss:0.1068\tStatic Loss:0.1851\t\n",
      "Val Loss:0.2714\tRecon Loss:1.9495\tTriplet Loss:0.1447\tStatic Loss:0.2673\n",
      "\n",
      "\tTime:48.5548\n",
      "\n",
      "Test Loss:0.9043\tRecon Loss:6.1797\tTriplet Loss:0.5040\tStatic Loss:0.8916\n",
      "\n",
      "\tEpoch:101\tTrain Loss:0.1834\tRecon Loss:1.8303\tTriplet Loss:0.1053\tStatic Loss:0.1748\t\n",
      "Val Loss:0.2652\tRecon Loss:1.9424\tTriplet Loss:0.1372\tStatic Loss:0.2612\n",
      "\n",
      "\tTime:49.2525\n",
      "\n",
      "Test Loss:0.8917\tRecon Loss:5.9191\tTriplet Loss:0.4915\tStatic Loss:0.8814\n",
      "\n",
      "\tEpoch:102\tTrain Loss:0.1813\tRecon Loss:1.8302\tTriplet Loss:0.1008\tStatic Loss:0.1729\t\n",
      "Val Loss:0.2729\tRecon Loss:1.9886\tTriplet Loss:0.1318\tStatic Loss:0.2698\n",
      "\n",
      "\tTime:49.3459\n",
      "\n",
      "Test Loss:0.9199\tRecon Loss:6.2720\tTriplet Loss:0.5328\tStatic Loss:0.9051\n",
      "\n",
      "\tEpoch:103\tTrain Loss:0.1835\tRecon Loss:1.8422\tTriplet Loss:0.1024\tStatic Loss:0.1751\t\n",
      "Val Loss:0.2736\tRecon Loss:1.9943\tTriplet Loss:0.1524\tStatic Loss:0.2685\n",
      "\n",
      "\tTime:49.2755\n",
      "\n",
      "Test Loss:0.9032\tRecon Loss:6.0567\tTriplet Loss:0.5117\tStatic Loss:0.8909\n",
      "\n",
      "\tEpoch:104\tTrain Loss:0.1802\tRecon Loss:1.8412\tTriplet Loss:0.1000\tStatic Loss:0.1716\t\n",
      "Val Loss:0.2714\tRecon Loss:1.9733\tTriplet Loss:0.1414\tStatic Loss:0.2674\n",
      "\n",
      "\tTime:49.4883\n",
      "\n",
      "Test Loss:0.9003\tRecon Loss:6.0345\tTriplet Loss:0.4670\tStatic Loss:0.8923\n",
      "\n",
      "\tEpoch:105\tTrain Loss:0.1806\tRecon Loss:1.8475\tTriplet Loss:0.0988\tStatic Loss:0.1721\t\n",
      "Val Loss:0.2709\tRecon Loss:1.9722\tTriplet Loss:0.1461\tStatic Loss:0.2664\n",
      "\n",
      "\tTime:48.9444\n",
      "\n",
      "Test Loss:0.9188\tRecon Loss:5.9940\tTriplet Loss:0.5089\tStatic Loss:0.9091\n",
      "\n",
      "\tEpoch:106\tTrain Loss:0.1951\tRecon Loss:1.8857\tTriplet Loss:0.1044\tStatic Loss:0.1873\t\n",
      "Val Loss:0.2658\tRecon Loss:1.9715\tTriplet Loss:0.1404\tStatic Loss:0.2613\n",
      "\n",
      "\tTime:49.6663\n",
      "\n",
      "Test Loss:0.8755\tRecon Loss:6.0982\tTriplet Loss:0.5256\tStatic Loss:0.8582\n",
      "\n",
      "\tEpoch:107\tTrain Loss:0.1855\tRecon Loss:1.8319\tTriplet Loss:0.1039\tStatic Loss:0.1772\t\n",
      "Val Loss:0.2662\tRecon Loss:1.9322\tTriplet Loss:0.1287\tStatic Loss:0.2633\n",
      "\n",
      "\tTime:48.6326\n",
      "\n",
      "Test Loss:0.9045\tRecon Loss:6.0073\tTriplet Loss:0.5295\tStatic Loss:0.8910\n",
      "\n",
      "\tEpoch:108\tTrain Loss:0.1798\tRecon Loss:1.8272\tTriplet Loss:0.1029\tStatic Loss:0.1710\t\n",
      "Val Loss:0.2697\tRecon Loss:1.9726\tTriplet Loss:0.1377\tStatic Loss:0.2659\n",
      "\n",
      "\tTime:48.2836\n",
      "\n",
      "Test Loss:0.8988\tRecon Loss:6.1746\tTriplet Loss:0.5114\tStatic Loss:0.8847\n",
      "\n",
      "\tEpoch:109\tTrain Loss:0.1780\tRecon Loss:1.8281\tTriplet Loss:0.0993\tStatic Loss:0.1694\t\n",
      "Val Loss:0.2670\tRecon Loss:1.9756\tTriplet Loss:0.1369\tStatic Loss:0.2629\n",
      "\n",
      "\tTime:47.5068\n",
      "\n",
      "Test Loss:0.8998\tRecon Loss:5.9671\tTriplet Loss:0.4905\tStatic Loss:0.8900\n",
      "\n",
      "\tEpoch:110\tTrain Loss:0.1798\tRecon Loss:1.8327\tTriplet Loss:0.0991\tStatic Loss:0.1713\t\n",
      "Val Loss:0.2657\tRecon Loss:2.0132\tTriplet Loss:0.1398\tStatic Loss:0.2608\n",
      "\n",
      "\tTime:48.8941\n",
      "\n",
      "Test Loss:0.8773\tRecon Loss:6.2403\tTriplet Loss:0.4988\tStatic Loss:0.8616\n",
      "\n",
      "\tEpoch:111\tTrain Loss:0.1854\tRecon Loss:1.8429\tTriplet Loss:0.1006\tStatic Loss:0.1773\t\n",
      "Val Loss:0.2702\tRecon Loss:1.9583\tTriplet Loss:0.1392\tStatic Loss:0.2665\n",
      "\n",
      "\tTime:49.5189\n",
      "\n",
      "Test Loss:0.8893\tRecon Loss:5.9111\tTriplet Loss:0.4823\tStatic Loss:0.8797\n",
      "\n",
      "\tEpoch:112\tTrain Loss:0.1869\tRecon Loss:1.8383\tTriplet Loss:0.1027\tStatic Loss:0.1788\t\n",
      "Val Loss:0.2860\tRecon Loss:1.9726\tTriplet Loss:0.1499\tStatic Loss:0.2827\n",
      "\n",
      "\tTime:48.7741\n",
      "\n",
      "Test Loss:0.9519\tRecon Loss:6.1365\tTriplet Loss:0.5540\tStatic Loss:0.9398\n",
      "\n",
      "\tEpoch:113\tTrain Loss:0.1913\tRecon Loss:1.8467\tTriplet Loss:0.1067\tStatic Loss:0.1832\t\n",
      "Val Loss:0.2660\tRecon Loss:1.9135\tTriplet Loss:0.1284\tStatic Loss:0.2633\n",
      "\n",
      "\tTime:48.3973\n",
      "\n",
      "Test Loss:0.8993\tRecon Loss:5.9995\tTriplet Loss:0.4796\tStatic Loss:0.8903\n",
      "\n",
      "\tEpoch:114\tTrain Loss:0.1822\tRecon Loss:1.8372\tTriplet Loss:0.0985\tStatic Loss:0.1740\t\n",
      "Val Loss:0.2642\tRecon Loss:1.9473\tTriplet Loss:0.1308\tStatic Loss:0.2607\n",
      "\n",
      "\tTime:49.0219\n",
      "\n",
      "Test Loss:0.8579\tRecon Loss:5.9759\tTriplet Loss:0.5053\tStatic Loss:0.8419\n",
      "\n",
      "\tEpoch:115\tTrain Loss:0.1828\tRecon Loss:1.8543\tTriplet Loss:0.1023\tStatic Loss:0.1741\t\n",
      "Val Loss:0.2679\tRecon Loss:1.9804\tTriplet Loss:0.1396\tStatic Loss:0.2636\n",
      "\n",
      "\tTime:48.2368\n",
      "\n",
      "Test Loss:0.8848\tRecon Loss:6.0043\tTriplet Loss:0.4944\tStatic Loss:0.8727\n",
      "\n",
      "\tEpoch:116\tTrain Loss:0.1837\tRecon Loss:1.8391\tTriplet Loss:0.1060\tStatic Loss:0.1749\t\n",
      "Val Loss:0.2641\tRecon Loss:1.9184\tTriplet Loss:0.1308\tStatic Loss:0.2608\n",
      "\n",
      "\tTime:47.6216\n",
      "\n",
      "Test Loss:0.8826\tRecon Loss:5.8774\tTriplet Loss:0.4804\tStatic Loss:0.8729\n",
      "\n",
      "\tEpoch:117\tTrain Loss:0.1841\tRecon Loss:1.8394\tTriplet Loss:0.1023\tStatic Loss:0.1757\t\n",
      "Val Loss:0.2702\tRecon Loss:1.9488\tTriplet Loss:0.1324\tStatic Loss:0.2672\n",
      "\n",
      "\tTime:48.1721\n",
      "\n",
      "Test Loss:0.9008\tRecon Loss:6.0042\tTriplet Loss:0.4892\tStatic Loss:0.8909\n",
      "\n",
      "\tEpoch:118\tTrain Loss:0.1785\tRecon Loss:1.8363\tTriplet Loss:0.0949\tStatic Loss:0.1703\t\n",
      "Val Loss:0.2676\tRecon Loss:1.9520\tTriplet Loss:0.1364\tStatic Loss:0.2639\n",
      "\n",
      "\tTime:48.2399\n",
      "\n",
      "Test Loss:0.8941\tRecon Loss:6.0027\tTriplet Loss:0.4992\tStatic Loss:0.8825\n",
      "\n",
      "\tEpoch:119\tTrain Loss:0.1781\tRecon Loss:1.8274\tTriplet Loss:0.0953\tStatic Loss:0.1698\t\n",
      "Val Loss:0.2686\tRecon Loss:1.9613\tTriplet Loss:0.1481\tStatic Loss:0.2637\n",
      "\n",
      "\tTime:48.2831\n",
      "\n",
      "Test Loss:0.8773\tRecon Loss:6.1655\tTriplet Loss:0.4754\tStatic Loss:0.8646\n",
      "\n",
      "\tEpoch:120\tTrain Loss:0.1775\tRecon Loss:1.8320\tTriplet Loss:0.0973\tStatic Loss:0.1689\t\n",
      "Val Loss:0.2679\tRecon Loss:1.9674\tTriplet Loss:0.1398\tStatic Loss:0.2637\n",
      "\n",
      "\tTime:47.5956\n",
      "\n",
      "Test Loss:0.9022\tRecon Loss:6.0954\tTriplet Loss:0.5079\tStatic Loss:0.8897\n",
      "\n",
      "\tEpoch:121\tTrain Loss:0.1777\tRecon Loss:1.8329\tTriplet Loss:0.0986\tStatic Loss:0.1690\t\n",
      "Val Loss:0.2700\tRecon Loss:1.9413\tTriplet Loss:0.1495\tStatic Loss:0.2654\n",
      "\n",
      "\tTime:48.3972\n",
      "\n",
      "Test Loss:0.9200\tRecon Loss:5.8625\tTriplet Loss:0.4932\tStatic Loss:0.9133\n",
      "\n",
      "\tEpoch:122\tTrain Loss:0.1754\tRecon Loss:1.8400\tTriplet Loss:0.0994\tStatic Loss:0.1664\t\n",
      "Val Loss:0.2679\tRecon Loss:1.9346\tTriplet Loss:0.1363\tStatic Loss:0.2644\n",
      "\n",
      "\tTime:48.1150\n",
      "\n",
      "Test Loss:0.9136\tRecon Loss:5.9873\tTriplet Loss:0.4830\tStatic Loss:0.9059\n",
      "\n",
      "\tEpoch:123\tTrain Loss:0.1874\tRecon Loss:1.8403\tTriplet Loss:0.1070\tStatic Loss:0.1790\t\n",
      "Val Loss:0.2624\tRecon Loss:1.9660\tTriplet Loss:0.1336\tStatic Loss:0.2583\n",
      "\n",
      "\tTime:48.5796\n",
      "\n",
      "Test Loss:0.8644\tRecon Loss:5.9984\tTriplet Loss:0.4674\tStatic Loss:0.8527\n",
      "\n",
      "\tEpoch:124\tTrain Loss:0.1762\tRecon Loss:1.8368\tTriplet Loss:0.0973\tStatic Loss:0.1675\t\n",
      "Val Loss:0.2602\tRecon Loss:1.9384\tTriplet Loss:0.1324\tStatic Loss:0.2562\n",
      "\n",
      "\tTime:49.0144\n",
      "\n",
      "Test Loss:0.8730\tRecon Loss:6.1305\tTriplet Loss:0.4979\tStatic Loss:0.8579\n",
      "\n",
      "\tEpoch:125\tTrain Loss:0.1795\tRecon Loss:1.8505\tTriplet Loss:0.0955\tStatic Loss:0.1712\t\n",
      "Val Loss:0.2672\tRecon Loss:1.9344\tTriplet Loss:0.1430\tStatic Loss:0.2630\n",
      "\n",
      "\tTime:48.9891\n",
      "\n",
      "Test Loss:0.9052\tRecon Loss:6.0935\tTriplet Loss:0.4726\tStatic Loss:0.8966\n",
      "\n",
      "\tEpoch:126\tTrain Loss:0.1760\tRecon Loss:1.8410\tTriplet Loss:0.0955\tStatic Loss:0.1675\t\n",
      "Val Loss:0.2695\tRecon Loss:1.9526\tTriplet Loss:0.1458\tStatic Loss:0.2651\n",
      "\n",
      "\tTime:48.1467\n",
      "\n",
      "Test Loss:0.9009\tRecon Loss:6.0315\tTriplet Loss:0.4938\tStatic Loss:0.8903\n",
      "\n",
      "\tEpoch:127\tTrain Loss:0.1893\tRecon Loss:1.8643\tTriplet Loss:0.1089\tStatic Loss:0.1806\t\n",
      "Val Loss:0.2592\tRecon Loss:1.9588\tTriplet Loss:0.1295\tStatic Loss:0.2552\n",
      "\n",
      "\tTime:47.9181\n",
      "\n",
      "Test Loss:0.8896\tRecon Loss:6.1058\tTriplet Loss:0.5025\tStatic Loss:0.8762\n",
      "\n",
      "\tEpoch:128\tTrain Loss:0.1801\tRecon Loss:1.8344\tTriplet Loss:0.0989\tStatic Loss:0.1717\t\n",
      "Val Loss:0.2660\tRecon Loss:1.9434\tTriplet Loss:0.1229\tStatic Loss:0.2635\n",
      "\n",
      "\tTime:47.5396\n",
      "\n",
      "Test Loss:0.9038\tRecon Loss:5.9107\tTriplet Loss:0.4907\tStatic Loss:0.8951\n",
      "\n",
      "\tEpoch:129\tTrain Loss:0.1769\tRecon Loss:1.8371\tTriplet Loss:0.1001\tStatic Loss:0.1680\t\n",
      "Val Loss:0.2721\tRecon Loss:2.0081\tTriplet Loss:0.1389\tStatic Loss:0.2680\n",
      "\n",
      "\tTime:47.8698\n",
      "\n",
      "Test Loss:0.9536\tRecon Loss:6.2125\tTriplet Loss:0.5067\tStatic Loss:0.9457\n",
      "\n",
      "\tEpoch:130\tTrain Loss:0.1763\tRecon Loss:1.8355\tTriplet Loss:0.0993\tStatic Loss:0.1674\t\n",
      "Val Loss:0.2709\tRecon Loss:1.9715\tTriplet Loss:0.1417\tStatic Loss:0.2668\n",
      "\n",
      "\tTime:48.0054\n",
      "\n",
      "Test Loss:0.8863\tRecon Loss:6.0596\tTriplet Loss:0.4841\tStatic Loss:0.8747\n",
      "\n",
      "\tEpoch:131\tTrain Loss:0.1855\tRecon Loss:1.8493\tTriplet Loss:0.1004\tStatic Loss:0.1774\t\n",
      "Val Loss:0.2705\tRecon Loss:1.9453\tTriplet Loss:0.1236\tStatic Loss:0.2684\n",
      "\n",
      "\tTime:48.1934\n",
      "\n",
      "Test Loss:0.8876\tRecon Loss:6.0588\tTriplet Loss:0.4968\tStatic Loss:0.8750\n",
      "\n",
      "\tEpoch:132\tTrain Loss:0.1825\tRecon Loss:1.8438\tTriplet Loss:0.1047\tStatic Loss:0.1737\t\n",
      "Val Loss:0.2656\tRecon Loss:1.9706\tTriplet Loss:0.1272\tStatic Loss:0.2624\n",
      "\n",
      "\tTime:47.6915\n",
      "\n",
      "Test Loss:0.8875\tRecon Loss:6.0179\tTriplet Loss:0.4986\tStatic Loss:0.8751\n",
      "\n",
      "\tEpoch:133\tTrain Loss:0.1796\tRecon Loss:1.8301\tTriplet Loss:0.1002\tStatic Loss:0.1710\t\n",
      "Val Loss:0.2870\tRecon Loss:2.0245\tTriplet Loss:0.1449\tStatic Loss:0.2838\n",
      "\n",
      "\tTime:48.6702\n",
      "\n",
      "Test Loss:0.9790\tRecon Loss:6.1657\tTriplet Loss:0.5446\tStatic Loss:0.9705\n",
      "\n",
      "\tEpoch:134\tTrain Loss:0.1937\tRecon Loss:1.8638\tTriplet Loss:0.1128\tStatic Loss:0.1851\t\n",
      "Val Loss:0.2649\tRecon Loss:1.9398\tTriplet Loss:0.1434\tStatic Loss:0.2603\n",
      "\n",
      "\tTime:48.3332\n",
      "\n",
      "Test Loss:0.8846\tRecon Loss:6.0219\tTriplet Loss:0.4869\tStatic Loss:0.8730\n",
      "\n",
      "\tEpoch:135\tTrain Loss:0.1805\tRecon Loss:1.8378\tTriplet Loss:0.1013\tStatic Loss:0.1718\t\n",
      "Val Loss:0.2667\tRecon Loss:1.9672\tTriplet Loss:0.1438\tStatic Loss:0.2619\n",
      "\n",
      "\tTime:48.7459\n",
      "\n",
      "Test Loss:0.8788\tRecon Loss:6.1396\tTriplet Loss:0.4952\tStatic Loss:0.8646\n",
      "\n",
      "\tEpoch:136\tTrain Loss:0.1839\tRecon Loss:1.8463\tTriplet Loss:0.1015\tStatic Loss:0.1755\t\n",
      "Val Loss:0.2586\tRecon Loss:1.9612\tTriplet Loss:0.1199\tStatic Loss:0.2554\n",
      "\n",
      "\tTime:48.5035\n",
      "\n",
      "Test Loss:0.8759\tRecon Loss:6.0726\tTriplet Loss:0.4817\tStatic Loss:0.8633\n",
      "\n",
      "\tEpoch:137\tTrain Loss:0.1785\tRecon Loss:1.8279\tTriplet Loss:0.1058\tStatic Loss:0.1692\t\n",
      "Val Loss:0.2620\tRecon Loss:1.9576\tTriplet Loss:0.1287\tStatic Loss:0.2583\n",
      "\n",
      "\tTime:47.7612\n",
      "\n",
      "Test Loss:0.8809\tRecon Loss:6.0841\tTriplet Loss:0.4833\tStatic Loss:0.8686\n",
      "\n",
      "\tEpoch:138\tTrain Loss:0.1756\tRecon Loss:1.8318\tTriplet Loss:0.1001\tStatic Loss:0.1666\t\n",
      "Val Loss:0.2592\tRecon Loss:1.9862\tTriplet Loss:0.1290\tStatic Loss:0.2549\n",
      "\n",
      "\tTime:48.7254\n",
      "\n",
      "Test Loss:0.8718\tRecon Loss:6.2434\tTriplet Loss:0.5126\tStatic Loss:0.8540\n",
      "\n",
      "\tEpoch:139\tTrain Loss:0.1763\tRecon Loss:1.8362\tTriplet Loss:0.1029\tStatic Loss:0.1670\t\n",
      "Val Loss:0.2607\tRecon Loss:1.9941\tTriplet Loss:0.1355\tStatic Loss:0.2559\n",
      "\n",
      "\tTime:48.8098\n",
      "\n",
      "Test Loss:0.8953\tRecon Loss:6.0168\tTriplet Loss:0.4970\tStatic Loss:0.8839\n",
      "\n",
      "\tEpoch:140\tTrain Loss:0.1728\tRecon Loss:1.8388\tTriplet Loss:0.1002\tStatic Loss:0.1634\t\n",
      "Val Loss:0.2642\tRecon Loss:1.9777\tTriplet Loss:0.1486\tStatic Loss:0.2587\n",
      "\n",
      "\tTime:48.9908\n",
      "\n",
      "Test Loss:0.8934\tRecon Loss:6.0745\tTriplet Loss:0.5183\tStatic Loss:0.8791\n",
      "\n",
      "\tEpoch:141\tTrain Loss:0.1773\tRecon Loss:1.8506\tTriplet Loss:0.0975\tStatic Loss:0.1686\t\n",
      "Val Loss:0.2666\tRecon Loss:2.0393\tTriplet Loss:0.1318\tStatic Loss:0.2624\n",
      "\n",
      "\tTime:49.1545\n",
      "\n",
      "Test Loss:0.8988\tRecon Loss:6.1857\tTriplet Loss:0.4951\tStatic Loss:0.8863\n",
      "\n",
      "\tEpoch:142\tTrain Loss:0.1805\tRecon Loss:1.8358\tTriplet Loss:0.0995\tStatic Loss:0.1720\t\n",
      "Val Loss:0.2619\tRecon Loss:1.9593\tTriplet Loss:0.1294\tStatic Loss:0.2582\n",
      "\n",
      "\tTime:48.3792\n",
      "\n",
      "Test Loss:0.8941\tRecon Loss:6.0708\tTriplet Loss:0.4821\tStatic Loss:0.8835\n",
      "\n",
      "\tEpoch:143\tTrain Loss:0.1752\tRecon Loss:1.8362\tTriplet Loss:0.0952\tStatic Loss:0.1665\t\n",
      "Val Loss:0.2672\tRecon Loss:2.0050\tTriplet Loss:0.1300\tStatic Loss:0.2635\n",
      "\n",
      "\tTime:47.8519\n",
      "\n",
      "Test Loss:0.8871\tRecon Loss:6.1587\tTriplet Loss:0.4706\tStatic Loss:0.8760\n",
      "\n",
      "\tEpoch:144\tTrain Loss:0.1734\tRecon Loss:1.8294\tTriplet Loss:0.0994\tStatic Loss:0.1642\t\n",
      "Val Loss:0.2614\tRecon Loss:1.9544\tTriplet Loss:0.1456\tStatic Loss:0.2560\n",
      "\n",
      "\tTime:48.5400\n",
      "\n",
      "Test Loss:0.8977\tRecon Loss:6.0649\tTriplet Loss:0.5225\tStatic Loss:0.8836\n",
      "\n",
      "\tEpoch:145\tTrain Loss:0.1750\tRecon Loss:1.8394\tTriplet Loss:0.0986\tStatic Loss:0.1660\t\n",
      "Val Loss:0.2647\tRecon Loss:1.9831\tTriplet Loss:0.1332\tStatic Loss:0.2607\n",
      "\n",
      "\tTime:48.2242\n",
      "\n",
      "Test Loss:0.8949\tRecon Loss:6.0002\tTriplet Loss:0.4597\tStatic Loss:0.8873\n",
      "\n",
      "\tEpoch:146\tTrain Loss:0.1742\tRecon Loss:1.8338\tTriplet Loss:0.1000\tStatic Loss:0.1650\t\n",
      "Val Loss:0.2638\tRecon Loss:1.9567\tTriplet Loss:0.1349\tStatic Loss:0.2598\n",
      "\n",
      "\tTime:49.3474\n",
      "\n",
      "Test Loss:0.8897\tRecon Loss:5.9301\tTriplet Loss:0.4941\tStatic Loss:0.8789\n",
      "\n",
      "\tEpoch:147\tTrain Loss:0.1821\tRecon Loss:1.8363\tTriplet Loss:0.1003\tStatic Loss:0.1737\t\n",
      "Val Loss:0.2731\tRecon Loss:1.9353\tTriplet Loss:0.1478\tStatic Loss:0.2690\n",
      "\n",
      "\tTime:49.3966\n",
      "\n",
      "Test Loss:0.9234\tRecon Loss:6.1520\tTriplet Loss:0.4812\tStatic Loss:0.9153\n",
      "\n",
      "\tEpoch:148\tTrain Loss:0.1850\tRecon Loss:1.8369\tTriplet Loss:0.1057\tStatic Loss:0.1764\t\n",
      "Val Loss:0.2758\tRecon Loss:1.9492\tTriplet Loss:0.1181\tStatic Loss:0.2749\n",
      "\n",
      "\tTime:49.6495\n",
      "\n",
      "Test Loss:0.9077\tRecon Loss:6.0851\tTriplet Loss:0.4998\tStatic Loss:0.8967\n",
      "\n",
      "\tEpoch:149\tTrain Loss:0.1764\tRecon Loss:1.8294\tTriplet Loss:0.0968\tStatic Loss:0.1678\t\n",
      "Val Loss:0.2588\tRecon Loss:1.9312\tTriplet Loss:0.1302\tStatic Loss:0.2550\n",
      "\n",
      "\tTime:49.5596\n",
      "\n",
      "Test Loss:0.8736\tRecon Loss:5.9158\tTriplet Loss:0.5043\tStatic Loss:0.8602\n",
      "\n",
      "\tEpoch:150\tTrain Loss:0.1775\tRecon Loss:1.8361\tTriplet Loss:0.0993\tStatic Loss:0.1687\t\n",
      "Val Loss:0.2721\tRecon Loss:2.0280\tTriplet Loss:0.1253\tStatic Loss:0.2692\n",
      "\n",
      "\tTime:49.8163\n",
      "\n",
      "Test Loss:0.9370\tRecon Loss:6.3885\tTriplet Loss:0.4972\tStatic Loss:0.9264\n",
      "\n",
      "\tEpoch:151\tTrain Loss:0.1830\tRecon Loss:1.8530\tTriplet Loss:0.1005\tStatic Loss:0.1745\t\n",
      "Val Loss:0.2634\tRecon Loss:1.9245\tTriplet Loss:0.1310\tStatic Loss:0.2601\n",
      "\n",
      "\tTime:49.8302\n",
      "\n",
      "Test Loss:0.9060\tRecon Loss:6.0411\tTriplet Loss:0.4953\tStatic Loss:0.8957\n",
      "\n",
      "\tEpoch:152\tTrain Loss:0.1719\tRecon Loss:1.8224\tTriplet Loss:0.0964\tStatic Loss:0.1629\t\n",
      "Val Loss:0.2603\tRecon Loss:1.9132\tTriplet Loss:0.1398\tStatic Loss:0.2558\n",
      "\n",
      "\tTime:50.4476\n",
      "\n",
      "Test Loss:0.8898\tRecon Loss:6.0276\tTriplet Loss:0.4552\tStatic Loss:0.8819\n",
      "\n",
      "\tEpoch:153\tTrain Loss:0.1718\tRecon Loss:1.8304\tTriplet Loss:0.0958\tStatic Loss:0.1628\t\n",
      "Val Loss:0.2612\tRecon Loss:1.9309\tTriplet Loss:0.1332\tStatic Loss:0.2573\n",
      "\n",
      "\tTime:50.3827\n",
      "\n",
      "Test Loss:0.8917\tRecon Loss:5.9537\tTriplet Loss:0.4969\tStatic Loss:0.8805\n",
      "\n",
      "\tEpoch:154\tTrain Loss:0.1705\tRecon Loss:1.8322\tTriplet Loss:0.0953\tStatic Loss:0.1615\t\n",
      "Val Loss:0.2667\tRecon Loss:1.9438\tTriplet Loss:0.1326\tStatic Loss:0.2634\n",
      "\n",
      "\tTime:50.3027\n",
      "\n",
      "Test Loss:0.8966\tRecon Loss:5.9578\tTriplet Loss:0.5121\tStatic Loss:0.8844\n",
      "\n",
      "\tEpoch:155\tTrain Loss:0.1740\tRecon Loss:1.8370\tTriplet Loss:0.0947\tStatic Loss:0.1653\t\n",
      "Val Loss:0.2630\tRecon Loss:2.0555\tTriplet Loss:0.1367\tStatic Loss:0.2577\n",
      "\n",
      "\tTime:49.7545\n",
      "\n",
      "Test Loss:0.8902\tRecon Loss:6.4429\tTriplet Loss:0.4911\tStatic Loss:0.8746\n",
      "\n",
      "\tEpoch:156\tTrain Loss:0.1725\tRecon Loss:1.8306\tTriplet Loss:0.0960\tStatic Loss:0.1636\t\n",
      "Val Loss:0.2590\tRecon Loss:1.9333\tTriplet Loss:0.1335\tStatic Loss:0.2548\n",
      "\n",
      "\tTime:49.8649\n",
      "\n",
      "Test Loss:0.9007\tRecon Loss:5.9662\tTriplet Loss:0.4774\tStatic Loss:0.8924\n",
      "\n",
      "\tEpoch:157\tTrain Loss:0.1706\tRecon Loss:1.8301\tTriplet Loss:0.0957\tStatic Loss:0.1615\t\n",
      "Val Loss:0.2590\tRecon Loss:1.9694\tTriplet Loss:0.1343\tStatic Loss:0.2543\n",
      "\n",
      "\tTime:50.2563\n",
      "\n",
      "Test Loss:0.8788\tRecon Loss:6.2024\tTriplet Loss:0.5078\tStatic Loss:0.8626\n",
      "\n",
      "\tEpoch:158\tTrain Loss:0.1816\tRecon Loss:1.8467\tTriplet Loss:0.0980\tStatic Loss:0.1733\t\n",
      "Val Loss:0.2829\tRecon Loss:1.9531\tTriplet Loss:0.1434\tStatic Loss:0.2802\n",
      "\n",
      "\tTime:48.3961\n",
      "\n",
      "Test Loss:0.9193\tRecon Loss:6.0076\tTriplet Loss:0.5191\tStatic Loss:0.9084\n",
      "\n",
      "\tEpoch:159\tTrain Loss:0.1842\tRecon Loss:1.8459\tTriplet Loss:0.1058\tStatic Loss:0.1754\t\n",
      "Val Loss:0.2663\tRecon Loss:1.9770\tTriplet Loss:0.1329\tStatic Loss:0.2625\n",
      "\n",
      "\tTime:47.9228\n",
      "\n",
      "Test Loss:0.8928\tRecon Loss:6.1140\tTriplet Loss:0.5002\tStatic Loss:0.8799\n",
      "\n",
      "\tEpoch:160\tTrain Loss:0.1741\tRecon Loss:1.8307\tTriplet Loss:0.0993\tStatic Loss:0.1650\t\n",
      "Val Loss:0.2634\tRecon Loss:1.9649\tTriplet Loss:0.1272\tStatic Loss:0.2601\n",
      "\n",
      "\tTime:48.4388\n",
      "\n",
      "Test Loss:0.8771\tRecon Loss:6.0890\tTriplet Loss:0.4663\tStatic Loss:0.8661\n",
      "\n",
      "\tEpoch:161\tTrain Loss:0.1777\tRecon Loss:1.8329\tTriplet Loss:0.0978\tStatic Loss:0.1692\t\n",
      "Val Loss:0.2650\tRecon Loss:1.9137\tTriplet Loss:0.1409\tStatic Loss:0.2609\n",
      "\n",
      "\tTime:48.9571\n",
      "\n",
      "Test Loss:0.9095\tRecon Loss:5.9427\tTriplet Loss:0.4955\tStatic Loss:0.9006\n",
      "\n",
      "\tEpoch:162\tTrain Loss:0.1738\tRecon Loss:1.8265\tTriplet Loss:0.0964\tStatic Loss:0.1650\t\n",
      "Val Loss:0.2635\tRecon Loss:1.9535\tTriplet Loss:0.1406\tStatic Loss:0.2588\n",
      "\n",
      "\tTime:49.2961\n",
      "\n",
      "Test Loss:0.8732\tRecon Loss:5.9282\tTriplet Loss:0.4839\tStatic Loss:0.8616\n",
      "\n",
      "\tEpoch:163\tTrain Loss:0.1748\tRecon Loss:1.8307\tTriplet Loss:0.0969\tStatic Loss:0.1660\t\n",
      "Val Loss:0.2623\tRecon Loss:2.0171\tTriplet Loss:0.1328\tStatic Loss:0.2577\n",
      "\n",
      "\tTime:48.7467\n",
      "\n",
      "Test Loss:0.8895\tRecon Loss:6.3879\tTriplet Loss:0.5014\tStatic Loss:0.8734\n",
      "\n",
      "\tEpoch:164\tTrain Loss:0.1721\tRecon Loss:1.8348\tTriplet Loss:0.1001\tStatic Loss:0.1626\t\n",
      "Val Loss:0.2628\tRecon Loss:1.9613\tTriplet Loss:0.1318\tStatic Loss:0.2589\n",
      "\n",
      "\tTime:48.6730\n",
      "\n",
      "Test Loss:0.9149\tRecon Loss:6.1919\tTriplet Loss:0.4911\tStatic Loss:0.9045\n",
      "\n",
      "\tEpoch:165\tTrain Loss:0.1818\tRecon Loss:1.8437\tTriplet Loss:0.1017\tStatic Loss:0.1732\t\n",
      "Val Loss:0.2585\tRecon Loss:1.9601\tTriplet Loss:0.1285\tStatic Loss:0.2545\n",
      "\n",
      "\tTime:48.9288\n",
      "\n",
      "Test Loss:0.8620\tRecon Loss:5.9775\tTriplet Loss:0.4691\tStatic Loss:0.8501\n",
      "\n",
      "\tEpoch:166\tTrain Loss:0.1752\tRecon Loss:1.8289\tTriplet Loss:0.0963\tStatic Loss:0.1665\t\n",
      "Val Loss:0.2588\tRecon Loss:1.9635\tTriplet Loss:0.1160\tStatic Loss:0.2560\n",
      "\n",
      "\tTime:48.4505\n",
      "\n",
      "Test Loss:0.8797\tRecon Loss:6.0985\tTriplet Loss:0.4708\tStatic Loss:0.8684\n",
      "\n",
      "\tEpoch:167\tTrain Loss:0.1697\tRecon Loss:1.8282\tTriplet Loss:0.0951\tStatic Loss:0.1605\t\n",
      "Val Loss:0.2619\tRecon Loss:1.9983\tTriplet Loss:0.1188\tStatic Loss:0.2589\n",
      "\n",
      "\tTime:49.3122\n",
      "\n",
      "Test Loss:0.8890\tRecon Loss:6.2129\tTriplet Loss:0.5270\tStatic Loss:0.8720\n",
      "\n",
      "\tEpoch:168\tTrain Loss:0.1754\tRecon Loss:1.8277\tTriplet Loss:0.0973\tStatic Loss:0.1667\t\n",
      "Val Loss:0.2582\tRecon Loss:1.9492\tTriplet Loss:0.1274\tStatic Loss:0.2544\n",
      "\n",
      "\tTime:49.5362\n",
      "\n",
      "Test Loss:0.8678\tRecon Loss:6.0439\tTriplet Loss:0.4567\tStatic Loss:0.8571\n",
      "\n",
      "\tEpoch:169\tTrain Loss:0.1781\tRecon Loss:1.8369\tTriplet Loss:0.0980\tStatic Loss:0.1695\t\n",
      "Val Loss:0.2703\tRecon Loss:1.9729\tTriplet Loss:0.1389\tStatic Loss:0.2664\n",
      "\n",
      "\tTime:49.5001\n",
      "\n",
      "Test Loss:0.8821\tRecon Loss:6.3731\tTriplet Loss:0.5166\tStatic Loss:0.8637\n",
      "\n",
      "\tEpoch:170\tTrain Loss:0.1922\tRecon Loss:1.8516\tTriplet Loss:0.1114\tStatic Loss:0.1837\t\n",
      "Val Loss:0.2606\tRecon Loss:1.9405\tTriplet Loss:0.1320\tStatic Loss:0.2566\n",
      "\n",
      "\tTime:48.8584\n",
      "\n",
      "Test Loss:0.8710\tRecon Loss:6.0347\tTriplet Loss:0.4948\tStatic Loss:0.8570\n",
      "\n",
      "\tEpoch:171\tTrain Loss:0.1812\tRecon Loss:1.8258\tTriplet Loss:0.1092\tStatic Loss:0.1719\t\n",
      "Val Loss:0.2619\tRecon Loss:1.9579\tTriplet Loss:0.1294\tStatic Loss:0.2582\n",
      "\n",
      "\tTime:49.3446\n",
      "\n",
      "Test Loss:0.8900\tRecon Loss:5.8704\tTriplet Loss:0.4942\tStatic Loss:0.8798\n",
      "\n",
      "\tEpoch:172\tTrain Loss:0.1802\tRecon Loss:1.8242\tTriplet Loss:0.1004\tStatic Loss:0.1717\t\n",
      "Val Loss:0.2661\tRecon Loss:1.9862\tTriplet Loss:0.1439\tStatic Loss:0.2611\n",
      "\n",
      "\tTime:49.3490\n",
      "\n",
      "Test Loss:0.8537\tRecon Loss:6.1772\tTriplet Loss:0.4868\tStatic Loss:0.8371\n",
      "\n",
      "\tEpoch:173\tTrain Loss:0.1821\tRecon Loss:1.9921\tTriplet Loss:0.0980\tStatic Loss:0.1724\t\n",
      "Val Loss:0.2678\tRecon Loss:2.1280\tTriplet Loss:0.1363\tStatic Loss:0.2624\n",
      "\n",
      "\tTime:49.1001\n",
      "\n",
      "Test Loss:0.8976\tRecon Loss:6.7047\tTriplet Loss:0.4648\tStatic Loss:0.8829\n",
      "\n",
      "\tEpoch:174\tTrain Loss:0.1762\tRecon Loss:1.8576\tTriplet Loss:0.0987\tStatic Loss:0.1672\t\n",
      "Val Loss:0.2689\tRecon Loss:2.0191\tTriplet Loss:0.1315\tStatic Loss:0.2651\n",
      "\n",
      "\tTime:49.8544\n",
      "\n",
      "Test Loss:0.8726\tRecon Loss:5.9980\tTriplet Loss:0.4953\tStatic Loss:0.8590\n",
      "\n",
      "\tEpoch:175\tTrain Loss:0.1746\tRecon Loss:1.8397\tTriplet Loss:0.0989\tStatic Loss:0.1656\t\n",
      "Val Loss:0.2708\tRecon Loss:2.1157\tTriplet Loss:0.1383\tStatic Loss:0.2656\n",
      "\n",
      "\tTime:49.0954\n",
      "\n",
      "Test Loss:0.9101\tRecon Loss:6.9393\tTriplet Loss:0.4555\tStatic Loss:0.8952\n",
      "\n",
      "\tEpoch:176\tTrain Loss:0.1726\tRecon Loss:1.8440\tTriplet Loss:0.0962\tStatic Loss:0.1635\t\n",
      "Val Loss:0.2610\tRecon Loss:1.9700\tTriplet Loss:0.1291\tStatic Loss:0.2570\n",
      "\n",
      "\tTime:48.7187\n",
      "\n",
      "Test Loss:0.8763\tRecon Loss:5.9951\tTriplet Loss:0.5180\tStatic Loss:0.8610\n",
      "\n",
      "\tEpoch:177\tTrain Loss:0.1703\tRecon Loss:1.8306\tTriplet Loss:0.0966\tStatic Loss:0.1611\t\n",
      "Val Loss:0.2550\tRecon Loss:1.9617\tTriplet Loss:0.1313\tStatic Loss:0.2503\n",
      "\n",
      "\tTime:48.6037\n",
      "\n",
      "Test Loss:0.8802\tRecon Loss:6.0782\tTriplet Loss:0.4867\tStatic Loss:0.8676\n",
      "\n",
      "\tEpoch:178\tTrain Loss:0.1733\tRecon Loss:1.8426\tTriplet Loss:0.0965\tStatic Loss:0.1642\t\n",
      "Val Loss:0.2586\tRecon Loss:1.9621\tTriplet Loss:0.1147\tStatic Loss:0.2560\n",
      "\n",
      "\tTime:48.9023\n",
      "\n",
      "Test Loss:0.8638\tRecon Loss:5.9528\tTriplet Loss:0.4875\tStatic Loss:0.8506\n",
      "\n",
      "\tEpoch:179\tTrain Loss:0.1744\tRecon Loss:1.8414\tTriplet Loss:0.1047\tStatic Loss:0.1647\t\n",
      "Val Loss:0.2585\tRecon Loss:2.0778\tTriplet Loss:0.1272\tStatic Loss:0.2535\n",
      "\n",
      "\tTime:49.6907\n",
      "\n",
      "Test Loss:0.8426\tRecon Loss:6.3275\tTriplet Loss:0.4900\tStatic Loss:0.8231\n",
      "\n",
      "\tEpoch:180\tTrain Loss:0.1728\tRecon Loss:1.8309\tTriplet Loss:0.0983\tStatic Loss:0.1637\t\n",
      "Val Loss:0.2621\tRecon Loss:2.0184\tTriplet Loss:0.1294\tStatic Loss:0.2578\n",
      "\n",
      "\tTime:50.0057\n",
      "\n",
      "Test Loss:0.8815\tRecon Loss:6.1676\tTriplet Loss:0.4674\tStatic Loss:0.8701\n",
      "\n",
      "\tEpoch:181\tTrain Loss:0.1717\tRecon Loss:1.8322\tTriplet Loss:0.0976\tStatic Loss:0.1625\t\n",
      "Val Loss:0.2640\tRecon Loss:1.9659\tTriplet Loss:0.1372\tStatic Loss:0.2597\n",
      "\n",
      "\tTime:49.6000\n",
      "\n",
      "Test Loss:0.8745\tRecon Loss:6.0932\tTriplet Loss:0.5141\tStatic Loss:0.8584\n",
      "\n",
      "\tEpoch:182\tTrain Loss:0.1693\tRecon Loss:1.8255\tTriplet Loss:0.0974\tStatic Loss:0.1600\t\n",
      "Val Loss:0.2604\tRecon Loss:1.9836\tTriplet Loss:0.1199\tStatic Loss:0.2572\n",
      "\n",
      "\tTime:48.8010\n",
      "\n",
      "Test Loss:0.8741\tRecon Loss:6.0200\tTriplet Loss:0.4687\tStatic Loss:0.8632\n",
      "\n",
      "\tEpoch:183\tTrain Loss:0.1671\tRecon Loss:1.8334\tTriplet Loss:0.0940\tStatic Loss:0.1577\t\n",
      "Val Loss:0.2579\tRecon Loss:2.0163\tTriplet Loss:0.1203\tStatic Loss:0.2541\n",
      "\n",
      "\tTime:49.3031\n",
      "\n",
      "Test Loss:0.8531\tRecon Loss:6.1175\tTriplet Loss:0.4632\tStatic Loss:0.8394\n",
      "\n",
      "\tEpoch:184\tTrain Loss:0.1697\tRecon Loss:1.8317\tTriplet Loss:0.0963\tStatic Loss:0.1605\t\n",
      "Val Loss:0.2640\tRecon Loss:1.9589\tTriplet Loss:0.1274\tStatic Loss:0.2607\n",
      "\n",
      "\tTime:49.9852\n",
      "\n",
      "Test Loss:0.8928\tRecon Loss:5.9959\tTriplet Loss:0.4672\tStatic Loss:0.8843\n",
      "\n",
      "\tEpoch:185\tTrain Loss:0.1680\tRecon Loss:1.8290\tTriplet Loss:0.0947\tStatic Loss:0.1587\t\n",
      "Val Loss:0.2642\tRecon Loss:1.9809\tTriplet Loss:0.1233\tStatic Loss:0.2611\n",
      "\n",
      "\tTime:49.7851\n",
      "\n",
      "Test Loss:0.9024\tRecon Loss:6.0725\tTriplet Loss:0.5029\tStatic Loss:0.8907\n",
      "\n",
      "\tEpoch:186\tTrain Loss:0.1699\tRecon Loss:1.8373\tTriplet Loss:0.0968\tStatic Loss:0.1605\t\n",
      "Val Loss:0.2636\tRecon Loss:1.9897\tTriplet Loss:0.1385\tStatic Loss:0.2589\n",
      "\n",
      "\tTime:49.6154\n",
      "\n",
      "Test Loss:0.8886\tRecon Loss:5.9842\tTriplet Loss:0.4903\tStatic Loss:0.8775\n",
      "\n",
      "\tEpoch:187\tTrain Loss:0.1716\tRecon Loss:1.8340\tTriplet Loss:0.0992\tStatic Loss:0.1622\t\n",
      "Val Loss:0.2609\tRecon Loss:1.9885\tTriplet Loss:0.1242\tStatic Loss:0.2573\n",
      "\n",
      "\tTime:49.6021\n",
      "\n",
      "Test Loss:0.8646\tRecon Loss:5.9827\tTriplet Loss:0.4755\tStatic Loss:0.8523\n",
      "\n",
      "\tEpoch:188\tTrain Loss:0.1747\tRecon Loss:1.8330\tTriplet Loss:0.1027\tStatic Loss:0.1653\t\n",
      "Val Loss:0.2722\tRecon Loss:2.0596\tTriplet Loss:0.1311\tStatic Loss:0.2684\n",
      "\n",
      "\tTime:49.6642\n",
      "\n",
      "Test Loss:0.9143\tRecon Loss:6.4549\tTriplet Loss:0.4686\tStatic Loss:0.9035\n",
      "\n",
      "\tEpoch:189\tTrain Loss:0.1791\tRecon Loss:1.8417\tTriplet Loss:0.1010\tStatic Loss:0.1702\t\n",
      "Val Loss:0.2653\tRecon Loss:1.9739\tTriplet Loss:0.1302\tStatic Loss:0.2618\n",
      "\n",
      "\tTime:48.7664\n",
      "\n",
      "Test Loss:0.8960\tRecon Loss:6.0213\tTriplet Loss:0.4647\tStatic Loss:0.8878\n",
      "\n",
      "\tEpoch:190\tTrain Loss:0.1803\tRecon Loss:1.8417\tTriplet Loss:0.1045\tStatic Loss:0.1713\t\n",
      "Val Loss:0.2667\tRecon Loss:1.9851\tTriplet Loss:0.1241\tStatic Loss:0.2638\n",
      "\n",
      "\tTime:48.8039\n",
      "\n",
      "Test Loss:0.8764\tRecon Loss:6.0626\tTriplet Loss:0.4764\tStatic Loss:0.8646\n",
      "\n",
      "\tEpoch:191\tTrain Loss:0.1747\tRecon Loss:1.8237\tTriplet Loss:0.1047\tStatic Loss:0.1652\t\n",
      "Val Loss:0.2572\tRecon Loss:1.9648\tTriplet Loss:0.1145\tStatic Loss:0.2544\n",
      "\n",
      "\tTime:48.6945\n",
      "\n",
      "Test Loss:0.8567\tRecon Loss:5.8844\tTriplet Loss:0.4711\tStatic Loss:0.8449\n",
      "\n",
      "\tEpoch:192\tTrain Loss:0.1707\tRecon Loss:1.8266\tTriplet Loss:0.0994\tStatic Loss:0.1613\t\n",
      "Val Loss:0.2609\tRecon Loss:1.9601\tTriplet Loss:0.1240\tStatic Loss:0.2576\n",
      "\n",
      "\tTime:48.7173\n",
      "\n",
      "Test Loss:0.8936\tRecon Loss:5.8839\tTriplet Loss:0.5021\tStatic Loss:0.8828\n",
      "\n",
      "\tEpoch:193\tTrain Loss:0.1731\tRecon Loss:1.8641\tTriplet Loss:0.0961\tStatic Loss:0.1638\t\n",
      "Val Loss:0.2598\tRecon Loss:1.9432\tTriplet Loss:0.1426\tStatic Loss:0.2547\n",
      "\n",
      "\tTime:48.1688\n",
      "\n",
      "Test Loss:0.8665\tRecon Loss:5.9017\tTriplet Loss:0.4579\tStatic Loss:0.8570\n",
      "\n",
      "\tEpoch:194\tTrain Loss:0.1786\tRecon Loss:1.8434\tTriplet Loss:0.1018\tStatic Loss:0.1697\t\n",
      "Val Loss:0.2607\tRecon Loss:1.9315\tTriplet Loss:0.1322\tStatic Loss:0.2568\n",
      "\n",
      "\tTime:48.3734\n",
      "\n",
      "Test Loss:0.8839\tRecon Loss:5.8957\tTriplet Loss:0.4951\tStatic Loss:0.8726\n",
      "\n",
      "\tEpoch:195\tTrain Loss:0.1735\tRecon Loss:1.8291\tTriplet Loss:0.0936\tStatic Loss:0.1649\t\n",
      "Val Loss:0.2551\tRecon Loss:1.9324\tTriplet Loss:0.1173\tStatic Loss:0.2521\n",
      "\n",
      "\tTime:49.7024\n",
      "\n",
      "Test Loss:0.8523\tRecon Loss:6.0444\tTriplet Loss:0.4569\tStatic Loss:0.8400\n",
      "\n",
      "\tEpoch:196\tTrain Loss:0.1681\tRecon Loss:1.8259\tTriplet Loss:0.0934\tStatic Loss:0.1590\t\n",
      "Val Loss:0.2689\tRecon Loss:1.9391\tTriplet Loss:0.1391\tStatic Loss:0.2652\n",
      "\n",
      "\tTime:49.5305\n",
      "\n",
      "Test Loss:0.8756\tRecon Loss:5.9218\tTriplet Loss:0.4683\tStatic Loss:0.8659\n",
      "\n",
      "\tEpoch:197\tTrain Loss:0.1728\tRecon Loss:1.8318\tTriplet Loss:0.1026\tStatic Loss:0.1632\t\n",
      "Val Loss:0.2596\tRecon Loss:1.9429\tTriplet Loss:0.1271\tStatic Loss:0.2560\n",
      "\n",
      "\tTime:49.4153\n",
      "\n",
      "Test Loss:0.8630\tRecon Loss:6.0640\tTriplet Loss:0.4723\tStatic Loss:0.8501\n",
      "\n",
      "\tEpoch:198\tTrain Loss:0.1725\tRecon Loss:1.8402\tTriplet Loss:0.0984\tStatic Loss:0.1633\t\n",
      "Val Loss:0.2605\tRecon Loss:1.9220\tTriplet Loss:0.1247\tStatic Loss:0.2575\n",
      "\n",
      "\tTime:49.8046\n",
      "\n",
      "Test Loss:0.8886\tRecon Loss:5.9469\tTriplet Loss:0.4691\tStatic Loss:0.8800\n",
      "\n",
      "\tEpoch:199\tTrain Loss:0.1690\tRecon Loss:1.8215\tTriplet Loss:0.0987\tStatic Loss:0.1595\t\n",
      "Val Loss:0.2670\tRecon Loss:1.9626\tTriplet Loss:0.1375\tStatic Loss:0.2630\n",
      "\n",
      "\tTime:48.8359\n",
      "\n",
      "Test Loss:0.8920\tRecon Loss:6.0137\tTriplet Loss:0.5029\tStatic Loss:0.8797\n",
      "\n",
      "\t\n",
      "Unc Est in Static characteristics:0.0000\tUnc Est in Streamflow, dynamic:0.0000\t\n",
      "\n",
      "\tATT_NL_3\n",
      "Epoch:0\tTrain Loss:0.5419\tRecon Loss:4.1106\tTriplet Loss:0.3746\tStatic Loss:0.5229\t\n",
      "Val Loss:0.4184\tRecon Loss:4.0247\tTriplet Loss:0.2440\tStatic Loss:0.3997\n",
      "\n",
      "\tTime:49.5954\n",
      "\n",
      "Test Loss:1.2934\tRecon Loss:11.9421\tTriplet Loss:0.8488\tStatic Loss:1.2314\n",
      "\n",
      "\tEpoch:1\tTrain Loss:0.3844\tRecon Loss:3.9625\tTriplet Loss:0.2434\tStatic Loss:0.3627\t\n",
      "Val Loss:0.3737\tRecon Loss:4.0142\tTriplet Loss:0.2227\tStatic Loss:0.3524\n",
      "\n",
      "\tTime:48.7239\n",
      "\n",
      "Test Loss:1.1529\tRecon Loss:11.9015\tTriplet Loss:0.6760\tStatic Loss:1.0931\n",
      "\n",
      "\tEpoch:2\tTrain Loss:0.3482\tRecon Loss:3.9494\tTriplet Loss:0.2062\tStatic Loss:0.3264\t\n",
      "Val Loss:0.3487\tRecon Loss:3.9933\tTriplet Loss:0.1882\tStatic Loss:0.3283\n",
      "\n",
      "\tTime:49.0461\n",
      "\n",
      "Test Loss:1.0934\tRecon Loss:11.8300\tTriplet Loss:0.5955\tStatic Loss:1.0358\n",
      "\n",
      "\tEpoch:3\tTrain Loss:0.3291\tRecon Loss:3.9165\tTriplet Loss:0.1914\tStatic Loss:0.3070\t\n",
      "Val Loss:0.3312\tRecon Loss:3.8861\tTriplet Loss:0.1831\tStatic Loss:0.3105\n",
      "\n",
      "\tTime:48.5888\n",
      "\n",
      "Test Loss:1.0371\tRecon Loss:11.5571\tTriplet Loss:0.5647\tStatic Loss:0.9791\n",
      "\n",
      "\tEpoch:4\tTrain Loss:0.3118\tRecon Loss:3.7063\tTriplet Loss:0.1744\tStatic Loss:0.2915\t\n",
      "Val Loss:0.3182\tRecon Loss:3.3566\tTriplet Loss:0.1691\tStatic Loss:0.3028\n",
      "\n",
      "\tTime:48.5042\n",
      "\n",
      "Test Loss:1.0072\tRecon Loss:10.1664\tTriplet Loss:0.5892\tStatic Loss:0.9574\n",
      "\n",
      "\tEpoch:5\tTrain Loss:0.2959\tRecon Loss:3.0112\tTriplet Loss:0.1651\tStatic Loss:0.2818\t\n",
      "Val Loss:0.3228\tRecon Loss:3.7013\tTriplet Loss:0.1801\tStatic Loss:0.3033\n",
      "\n",
      "\tTime:49.7307\n",
      "\n",
      "Test Loss:1.0372\tRecon Loss:10.6416\tTriplet Loss:0.6070\tStatic Loss:0.9842\n",
      "\n",
      "\tEpoch:6\tTrain Loss:0.2849\tRecon Loss:2.5328\tTriplet Loss:0.1676\tStatic Loss:0.2742\t\n",
      "Val Loss:0.3003\tRecon Loss:2.5566\tTriplet Loss:0.1756\tStatic Loss:0.2902\n",
      "\n",
      "\tTime:49.1368\n",
      "\n",
      "Test Loss:0.9631\tRecon Loss:7.7455\tTriplet Loss:0.6004\tStatic Loss:0.9315\n",
      "\n",
      "\tEpoch:7\tTrain Loss:0.2737\tRecon Loss:2.1612\tTriplet Loss:0.1554\tStatic Loss:0.2667\t\n",
      "Val Loss:0.2934\tRecon Loss:2.0794\tTriplet Loss:0.1709\tStatic Loss:0.2878\n",
      "\n",
      "\tTime:48.8581\n",
      "\n",
      "Test Loss:0.9050\tRecon Loss:6.2804\tTriplet Loss:0.5495\tStatic Loss:0.8867\n",
      "\n",
      "\tEpoch:8\tTrain Loss:0.2661\tRecon Loss:2.0159\tTriplet Loss:0.1476\tStatic Loss:0.2605\t\n",
      "Val Loss:0.2885\tRecon Loss:2.0204\tTriplet Loss:0.1705\tStatic Loss:0.2829\n",
      "\n",
      "\tTime:48.5425\n",
      "\n",
      "Test Loss:0.9261\tRecon Loss:5.9943\tTriplet Loss:0.5405\tStatic Loss:0.9140\n",
      "\n",
      "\tEpoch:9\tTrain Loss:0.2653\tRecon Loss:2.4064\tTriplet Loss:0.1476\tStatic Loss:0.2556\t\n",
      "Val Loss:0.2947\tRecon Loss:2.5393\tTriplet Loss:0.1625\tStatic Loss:0.2855\n",
      "\n",
      "\tTime:48.6281\n",
      "\n",
      "Test Loss:0.9312\tRecon Loss:7.7218\tTriplet Loss:0.5198\tStatic Loss:0.9045\n",
      "\n",
      "\tEpoch:10\tTrain Loss:0.2578\tRecon Loss:2.0179\tTriplet Loss:0.1532\tStatic Loss:0.2507\t\n",
      "Val Loss:0.2853\tRecon Loss:1.9759\tTriplet Loss:0.1640\tStatic Loss:0.2806\n",
      "\n",
      "\tTime:48.4302\n",
      "\n",
      "Test Loss:0.8897\tRecon Loss:5.9408\tTriplet Loss:0.5175\tStatic Loss:0.8765\n",
      "\n",
      "\tEpoch:11\tTrain Loss:0.2527\tRecon Loss:1.9301\tTriplet Loss:0.1445\tStatic Loss:0.2467\t\n",
      "Val Loss:0.2851\tRecon Loss:1.9650\tTriplet Loss:0.1633\tStatic Loss:0.2805\n",
      "\n",
      "\tTime:48.4734\n",
      "\n",
      "Test Loss:0.8799\tRecon Loss:5.9298\tTriplet Loss:0.5002\tStatic Loss:0.8674\n",
      "\n",
      "\tEpoch:12\tTrain Loss:0.2528\tRecon Loss:2.2428\tTriplet Loss:0.1455\tStatic Loss:0.2436\t\n",
      "Val Loss:0.2822\tRecon Loss:2.1068\tTriplet Loss:0.1601\tStatic Loss:0.2762\n",
      "\n",
      "\tTime:48.3734\n",
      "\n",
      "Test Loss:0.8758\tRecon Loss:6.3605\tTriplet Loss:0.5322\tStatic Loss:0.8553\n",
      "\n",
      "\tEpoch:13\tTrain Loss:0.2589\tRecon Loss:2.2072\tTriplet Loss:0.1445\tStatic Loss:0.2508\t\n",
      "Val Loss:0.3744\tRecon Loss:4.3255\tTriplet Loss:0.1958\tStatic Loss:0.3528\n",
      "\n",
      "\tTime:47.7822\n",
      "\n",
      "Test Loss:1.1332\tRecon Loss:12.4371\tTriplet Loss:0.6154\tStatic Loss:1.0719\n",
      "\n",
      "\tEpoch:14\tTrain Loss:0.2842\tRecon Loss:3.3789\tTriplet Loss:0.1666\tStatic Loss:0.2650\t\n",
      "Val Loss:0.2936\tRecon Loss:2.4555\tTriplet Loss:0.1742\tStatic Loss:0.2839\n",
      "\n",
      "\tTime:48.3201\n",
      "\n",
      "Test Loss:0.9435\tRecon Loss:7.5249\tTriplet Loss:0.5646\tStatic Loss:0.9155\n",
      "\n",
      "\tEpoch:15\tTrain Loss:0.2519\tRecon Loss:2.0972\tTriplet Loss:0.1561\tStatic Loss:0.2430\t\n",
      "Val Loss:0.2869\tRecon Loss:2.0425\tTriplet Loss:0.1652\tStatic Loss:0.2815\n",
      "\n",
      "\tTime:48.1152\n",
      "\n",
      "Test Loss:0.8873\tRecon Loss:6.0750\tTriplet Loss:0.5305\tStatic Loss:0.8710\n",
      "\n",
      "\tEpoch:16\tTrain Loss:0.2442\tRecon Loss:1.9750\tTriplet Loss:0.1451\tStatic Loss:0.2368\t\n",
      "Val Loss:0.2881\tRecon Loss:2.0737\tTriplet Loss:0.1737\tStatic Loss:0.2817\n",
      "\n",
      "\tTime:47.9847\n",
      "\n",
      "Test Loss:0.8834\tRecon Loss:6.2649\tTriplet Loss:0.5550\tStatic Loss:0.8624\n",
      "\n",
      "\tEpoch:17\tTrain Loss:0.2571\tRecon Loss:3.3948\tTriplet Loss:0.1449\tStatic Loss:0.2369\t\n",
      "Val Loss:0.2910\tRecon Loss:3.2708\tTriplet Loss:0.1636\tStatic Loss:0.2739\n",
      "\n",
      "\tTime:48.3569\n",
      "\n",
      "Test Loss:0.9332\tRecon Loss:9.7699\tTriplet Loss:0.5083\tStatic Loss:0.8873\n",
      "\n",
      "\tEpoch:18\tTrain Loss:0.2423\tRecon Loss:2.4442\tTriplet Loss:0.1290\tStatic Loss:0.2316\t\n",
      "Val Loss:0.2855\tRecon Loss:2.0471\tTriplet Loss:0.1578\tStatic Loss:0.2807\n",
      "\n",
      "\tTime:49.0178\n",
      "\n",
      "Test Loss:0.9211\tRecon Loss:6.1196\tTriplet Loss:0.5248\tStatic Loss:0.9087\n",
      "\n",
      "\tEpoch:19\tTrain Loss:0.2358\tRecon Loss:2.0119\tTriplet Loss:0.1347\tStatic Loss:0.2281\t\n",
      "Val Loss:0.2828\tRecon Loss:2.0120\tTriplet Loss:0.1634\tStatic Loss:0.2775\n",
      "\n",
      "\tTime:50.1397\n",
      "\n",
      "Test Loss:0.9024\tRecon Loss:5.9883\tTriplet Loss:0.4699\tStatic Loss:0.8948\n",
      "\n",
      "\tEpoch:20\tTrain Loss:0.2336\tRecon Loss:2.1133\tTriplet Loss:0.1242\tStatic Loss:0.2257\t\n",
      "Val Loss:0.2781\tRecon Loss:2.4048\tTriplet Loss:0.1577\tStatic Loss:0.2689\n",
      "\n",
      "\tTime:49.5355\n",
      "\n",
      "Test Loss:0.8747\tRecon Loss:7.2862\tTriplet Loss:0.4947\tStatic Loss:0.8486\n",
      "\n",
      "\tEpoch:21\tTrain Loss:0.2309\tRecon Loss:2.2102\tTriplet Loss:0.1310\tStatic Loss:0.2211\t\n",
      "Val Loss:0.2758\tRecon Loss:2.0172\tTriplet Loss:0.1591\tStatic Loss:0.2701\n",
      "\n",
      "\tTime:50.0155\n",
      "\n",
      "Test Loss:0.8590\tRecon Loss:6.0646\tTriplet Loss:0.4734\tStatic Loss:0.8455\n",
      "\n",
      "\tEpoch:22\tTrain Loss:0.2258\tRecon Loss:1.9342\tTriplet Loss:0.1260\tStatic Loss:0.2187\t\n",
      "Val Loss:0.2736\tRecon Loss:2.0179\tTriplet Loss:0.1429\tStatic Loss:0.2692\n",
      "\n",
      "\tTime:50.3738\n",
      "\n",
      "Test Loss:0.8710\tRecon Loss:6.0343\tTriplet Loss:0.5057\tStatic Loss:0.8559\n",
      "\n",
      "\tEpoch:23\tTrain Loss:0.2305\tRecon Loss:2.3201\tTriplet Loss:0.1285\tStatic Loss:0.2198\t\n",
      "Val Loss:0.2712\tRecon Loss:1.9932\tTriplet Loss:0.1531\tStatic Loss:0.2658\n",
      "\n",
      "\tTime:50.1423\n",
      "\n",
      "Test Loss:0.8819\tRecon Loss:6.0242\tTriplet Loss:0.5259\tStatic Loss:0.8661\n",
      "\n",
      "\tEpoch:24\tTrain Loss:0.2222\tRecon Loss:1.9160\tTriplet Loss:0.1229\tStatic Loss:0.2152\t\n",
      "Val Loss:0.2741\tRecon Loss:1.9421\tTriplet Loss:0.1539\tStatic Loss:0.2694\n",
      "\n",
      "\tTime:50.5760\n",
      "\n",
      "Test Loss:0.8651\tRecon Loss:5.8204\tTriplet Loss:0.4743\tStatic Loss:0.8546\n",
      "\n",
      "\tEpoch:25\tTrain Loss:0.2233\tRecon Loss:2.1842\tTriplet Loss:0.1207\tStatic Loss:0.2139\t\n",
      "Val Loss:0.2723\tRecon Loss:1.9755\tTriplet Loss:0.1520\tStatic Loss:0.2673\n",
      "\n",
      "\tTime:50.1774\n",
      "\n",
      "Test Loss:0.8548\tRecon Loss:5.9444\tTriplet Loss:0.5154\tStatic Loss:0.8378\n",
      "\n",
      "\tEpoch:26\tTrain Loss:0.2195\tRecon Loss:1.9115\tTriplet Loss:0.1268\tStatic Loss:0.2118\t\n",
      "Val Loss:0.2728\tRecon Loss:1.9419\tTriplet Loss:0.1507\tStatic Loss:0.2683\n",
      "\n",
      "\tTime:51.0197\n",
      "\n",
      "Test Loss:0.8694\tRecon Loss:5.9259\tTriplet Loss:0.4840\tStatic Loss:0.8574\n",
      "\n",
      "\tEpoch:27\tTrain Loss:0.2208\tRecon Loss:2.1475\tTriplet Loss:0.1266\tStatic Loss:0.2109\t\n",
      "Val Loss:0.2790\tRecon Loss:2.1481\tTriplet Loss:0.1655\tStatic Loss:0.2717\n",
      "\n",
      "\tTime:49.8540\n",
      "\n",
      "Test Loss:0.8712\tRecon Loss:6.5613\tTriplet Loss:0.5105\tStatic Loss:0.8503\n",
      "\n",
      "\tEpoch:28\tTrain Loss:0.2173\tRecon Loss:1.9241\tTriplet Loss:0.1172\tStatic Loss:0.2102\t\n",
      "Val Loss:0.2686\tRecon Loss:1.9588\tTriplet Loss:0.1433\tStatic Loss:0.2642\n",
      "\n",
      "\tTime:49.1939\n",
      "\n",
      "Test Loss:0.8584\tRecon Loss:5.8295\tTriplet Loss:0.4672\tStatic Loss:0.8478\n",
      "\n",
      "\tEpoch:29\tTrain Loss:0.2155\tRecon Loss:1.8868\tTriplet Loss:0.1211\tStatic Loss:0.2082\t\n",
      "Val Loss:0.2700\tRecon Loss:1.9146\tTriplet Loss:0.1540\tStatic Loss:0.2651\n",
      "\n",
      "\tTime:48.3290\n",
      "\n",
      "Test Loss:0.8423\tRecon Loss:5.7966\tTriplet Loss:0.4828\tStatic Loss:0.8287\n",
      "\n",
      "\tEpoch:30\tTrain Loss:0.2139\tRecon Loss:1.8799\tTriplet Loss:0.1156\tStatic Loss:0.2070\t\n",
      "Val Loss:0.2683\tRecon Loss:2.0576\tTriplet Loss:0.1423\tStatic Loss:0.2630\n",
      "\n",
      "\tTime:48.7946\n",
      "\n",
      "Test Loss:0.8561\tRecon Loss:6.2395\tTriplet Loss:0.4920\tStatic Loss:0.8387\n",
      "\n",
      "\tEpoch:31\tTrain Loss:0.2130\tRecon Loss:1.9613\tTriplet Loss:0.1138\tStatic Loss:0.2054\t\n",
      "Val Loss:0.2655\tRecon Loss:1.9297\tTriplet Loss:0.1444\tStatic Loss:0.2610\n",
      "\n",
      "\tTime:48.7814\n",
      "\n",
      "Test Loss:0.8322\tRecon Loss:5.8327\tTriplet Loss:0.4676\tStatic Loss:0.8187\n",
      "\n",
      "\tEpoch:32\tTrain Loss:0.2101\tRecon Loss:1.8709\tTriplet Loss:0.1126\tStatic Loss:0.2033\t\n",
      "Val Loss:0.2652\tRecon Loss:1.9311\tTriplet Loss:0.1445\tStatic Loss:0.2606\n",
      "\n",
      "\tTime:48.9541\n",
      "\n",
      "Test Loss:0.8386\tRecon Loss:5.7971\tTriplet Loss:0.4498\tStatic Loss:0.8279\n",
      "\n",
      "\tEpoch:33\tTrain Loss:0.2108\tRecon Loss:1.8944\tTriplet Loss:0.1130\tStatic Loss:0.2038\t\n",
      "Val Loss:0.2647\tRecon Loss:1.9447\tTriplet Loss:0.1425\tStatic Loss:0.2601\n",
      "\n",
      "\tTime:49.1736\n",
      "\n",
      "Test Loss:0.8254\tRecon Loss:5.8629\tTriplet Loss:0.4798\tStatic Loss:0.8096\n",
      "\n",
      "\tEpoch:34\tTrain Loss:0.2080\tRecon Loss:1.8990\tTriplet Loss:0.1092\tStatic Loss:0.2010\t\n",
      "Val Loss:0.2663\tRecon Loss:1.9593\tTriplet Loss:0.1493\tStatic Loss:0.2611\n",
      "\n",
      "\tTime:48.8618\n",
      "\n",
      "Test Loss:0.8283\tRecon Loss:5.8263\tTriplet Loss:0.4827\tStatic Loss:0.8129\n",
      "\n",
      "\tEpoch:35\tTrain Loss:0.2098\tRecon Loss:2.0507\tTriplet Loss:0.1058\tStatic Loss:0.2018\t\n",
      "Val Loss:0.2617\tRecon Loss:1.9357\tTriplet Loss:0.1399\tStatic Loss:0.2571\n",
      "\n",
      "\tTime:49.1407\n",
      "\n",
      "Test Loss:0.8382\tRecon Loss:5.8533\tTriplet Loss:0.4549\tStatic Loss:0.8263\n",
      "\n",
      "\tEpoch:36\tTrain Loss:0.2056\tRecon Loss:1.8741\tTriplet Loss:0.1146\tStatic Loss:0.1980\t\n",
      "Val Loss:0.2646\tRecon Loss:1.9200\tTriplet Loss:0.1409\tStatic Loss:0.2605\n",
      "\n",
      "\tTime:48.3793\n",
      "\n",
      "Test Loss:0.8636\tRecon Loss:5.8020\tTriplet Loss:0.4785\tStatic Loss:0.8528\n",
      "\n",
      "\tEpoch:37\tTrain Loss:0.2063\tRecon Loss:1.8952\tTriplet Loss:0.1153\tStatic Loss:0.1985\t\n",
      "Val Loss:0.2615\tRecon Loss:1.9198\tTriplet Loss:0.1377\tStatic Loss:0.2573\n",
      "\n",
      "\tTime:48.8807\n",
      "\n",
      "Test Loss:0.8372\tRecon Loss:5.8346\tTriplet Loss:0.4497\tStatic Loss:0.8260\n",
      "\n",
      "\tEpoch:38\tTrain Loss:0.2242\tRecon Loss:2.8708\tTriplet Loss:0.1178\tStatic Loss:0.2084\t\n",
      "Val Loss:0.2815\tRecon Loss:3.9415\tTriplet Loss:0.1350\tStatic Loss:0.2596\n",
      "\n",
      "\tTime:48.7642\n",
      "\n",
      "Test Loss:0.8848\tRecon Loss:11.6910\tTriplet Loss:0.4645\tStatic Loss:0.8187\n",
      "\n",
      "\tEpoch:39\tTrain Loss:0.2145\tRecon Loss:2.9003\tTriplet Loss:0.1156\tStatic Loss:0.1976\t\n",
      "Val Loss:0.2648\tRecon Loss:2.1291\tTriplet Loss:0.1426\tStatic Loss:0.2584\n",
      "\n",
      "\tTime:49.4780\n",
      "\n",
      "Test Loss:0.8458\tRecon Loss:6.4098\tTriplet Loss:0.4752\tStatic Loss:0.8273\n",
      "\n",
      "\tEpoch:40\tTrain Loss:0.2058\tRecon Loss:1.9833\tTriplet Loss:0.1112\tStatic Loss:0.1975\t\n",
      "Val Loss:0.2587\tRecon Loss:2.0036\tTriplet Loss:0.1385\tStatic Loss:0.2533\n",
      "\n",
      "\tTime:48.7080\n",
      "\n",
      "Test Loss:0.8189\tRecon Loss:6.0101\tTriplet Loss:0.4545\tStatic Loss:0.8034\n",
      "\n",
      "\tEpoch:41\tTrain Loss:0.2086\tRecon Loss:1.9123\tTriplet Loss:0.1147\tStatic Loss:0.2009\t\n",
      "Val Loss:0.2612\tRecon Loss:1.9876\tTriplet Loss:0.1432\tStatic Loss:0.2557\n",
      "\n",
      "\tTime:48.2774\n",
      "\n",
      "Test Loss:0.8433\tRecon Loss:5.9827\tTriplet Loss:0.4671\tStatic Loss:0.8295\n",
      "\n",
      "\tEpoch:42\tTrain Loss:0.2022\tRecon Loss:1.9185\tTriplet Loss:0.1101\tStatic Loss:0.1942\t\n",
      "Val Loss:0.2619\tRecon Loss:1.9564\tTriplet Loss:0.1415\tStatic Loss:0.2570\n",
      "\n",
      "\tTime:48.7224\n",
      "\n",
      "Test Loss:0.8479\tRecon Loss:5.8566\tTriplet Loss:0.4554\tStatic Loss:0.8371\n",
      "\n",
      "\tEpoch:43\tTrain Loss:0.2013\tRecon Loss:1.8927\tTriplet Loss:0.1101\tStatic Loss:0.1935\t\n",
      "Val Loss:0.2593\tRecon Loss:1.9414\tTriplet Loss:0.1329\tStatic Loss:0.2551\n",
      "\n",
      "\tTime:49.1338\n",
      "\n",
      "Test Loss:0.8282\tRecon Loss:5.8957\tTriplet Loss:0.4802\tStatic Loss:0.8124\n",
      "\n",
      "\tEpoch:44\tTrain Loss:0.1989\tRecon Loss:1.8996\tTriplet Loss:0.1105\tStatic Loss:0.1907\t\n",
      "Val Loss:0.2622\tRecon Loss:1.9442\tTriplet Loss:0.1378\tStatic Loss:0.2578\n",
      "\n",
      "\tTime:49.1494\n",
      "\n",
      "Test Loss:0.8174\tRecon Loss:5.8519\tTriplet Loss:0.4717\tStatic Loss:0.8017\n",
      "\n",
      "\tEpoch:45\tTrain Loss:0.1983\tRecon Loss:1.8780\tTriplet Loss:0.1050\tStatic Loss:0.1908\t\n",
      "Val Loss:0.2614\tRecon Loss:1.9314\tTriplet Loss:0.1411\tStatic Loss:0.2567\n",
      "\n",
      "\tTime:49.2128\n",
      "\n",
      "Test Loss:0.8145\tRecon Loss:5.8116\tTriplet Loss:0.4921\tStatic Loss:0.7967\n",
      "\n",
      "\tEpoch:46\tTrain Loss:0.1997\tRecon Loss:1.9243\tTriplet Loss:0.1058\tStatic Loss:0.1918\t\n",
      "Val Loss:0.2676\tRecon Loss:2.5080\tTriplet Loss:0.1407\tStatic Loss:0.2579\n",
      "\n",
      "\tTime:48.3413\n",
      "\n",
      "Test Loss:0.8560\tRecon Loss:7.4700\tTriplet Loss:0.4739\tStatic Loss:0.8281\n",
      "\n",
      "\tEpoch:47\tTrain Loss:0.2001\tRecon Loss:2.0384\tTriplet Loss:0.1071\tStatic Loss:0.1910\t\n",
      "Val Loss:0.2641\tRecon Loss:2.0249\tTriplet Loss:0.1369\tStatic Loss:0.2592\n",
      "\n",
      "\tTime:48.6375\n",
      "\n",
      "Test Loss:0.8218\tRecon Loss:6.1251\tTriplet Loss:0.4287\tStatic Loss:0.8081\n",
      "\n",
      "\tEpoch:48\tTrain Loss:0.2020\tRecon Loss:2.0809\tTriplet Loss:0.1128\tStatic Loss:0.1921\t\n",
      "Val Loss:0.2613\tRecon Loss:2.0263\tTriplet Loss:0.1420\tStatic Loss:0.2556\n",
      "\n",
      "\tTime:48.5949\n",
      "\n",
      "Test Loss:0.8342\tRecon Loss:6.1184\tTriplet Loss:0.4711\tStatic Loss:0.8177\n",
      "\n",
      "\tEpoch:49\tTrain Loss:0.2028\tRecon Loss:2.2045\tTriplet Loss:0.1070\tStatic Loss:0.1923\t\n",
      "Val Loss:0.2629\tRecon Loss:2.3169\tTriplet Loss:0.1331\tStatic Loss:0.2553\n",
      "\n",
      "\tTime:49.1313\n",
      "\n",
      "Test Loss:0.8215\tRecon Loss:6.9169\tTriplet Loss:0.4644\tStatic Loss:0.7963\n",
      "\n",
      "\tEpoch:50\tTrain Loss:0.2007\tRecon Loss:2.2129\tTriplet Loss:0.1103\tStatic Loss:0.1897\t\n",
      "Val Loss:0.2635\tRecon Loss:2.1176\tTriplet Loss:0.1392\tStatic Loss:0.2574\n",
      "\n",
      "\tTime:49.0818\n",
      "\n",
      "Test Loss:0.8287\tRecon Loss:6.3268\tTriplet Loss:0.4759\tStatic Loss:0.8090\n",
      "\n",
      "\tEpoch:51\tTrain Loss:0.1954\tRecon Loss:1.9532\tTriplet Loss:0.1059\tStatic Loss:0.1868\t\n",
      "Val Loss:0.2623\tRecon Loss:1.9695\tTriplet Loss:0.1413\tStatic Loss:0.2574\n",
      "\n",
      "\tTime:48.5446\n",
      "\n",
      "Test Loss:0.8393\tRecon Loss:5.9253\tTriplet Loss:0.4694\tStatic Loss:0.8254\n",
      "\n",
      "\tEpoch:52\tTrain Loss:0.1945\tRecon Loss:1.9177\tTriplet Loss:0.1030\tStatic Loss:0.1864\t\n",
      "Val Loss:0.2604\tRecon Loss:1.9730\tTriplet Loss:0.1509\tStatic Loss:0.2542\n",
      "\n",
      "\tTime:48.9676\n",
      "\n",
      "Test Loss:0.8388\tRecon Loss:5.9011\tTriplet Loss:0.4514\tStatic Loss:0.8269\n",
      "\n",
      "\tEpoch:53\tTrain Loss:0.1960\tRecon Loss:1.9228\tTriplet Loss:0.1086\tStatic Loss:0.1875\t\n",
      "Val Loss:0.2593\tRecon Loss:1.9570\tTriplet Loss:0.1354\tStatic Loss:0.2547\n",
      "\n",
      "\tTime:48.0295\n",
      "\n",
      "Test Loss:0.8193\tRecon Loss:5.9573\tTriplet Loss:0.4552\tStatic Loss:0.8043\n",
      "\n",
      "\tEpoch:54\tTrain Loss:0.1934\tRecon Loss:1.8832\tTriplet Loss:0.1021\tStatic Loss:0.1857\t\n",
      "Val Loss:0.2629\tRecon Loss:1.9363\tTriplet Loss:0.1399\tStatic Loss:0.2585\n",
      "\n",
      "\tTime:48.6087\n",
      "\n",
      "Test Loss:0.8386\tRecon Loss:5.8516\tTriplet Loss:0.4427\tStatic Loss:0.8280\n",
      "\n",
      "\tEpoch:55\tTrain Loss:0.1953\tRecon Loss:1.8817\tTriplet Loss:0.1072\tStatic Loss:0.1873\t\n",
      "Val Loss:0.2611\tRecon Loss:1.9574\tTriplet Loss:0.1484\tStatic Loss:0.2555\n",
      "\n",
      "\tTime:48.7970\n",
      "\n",
      "Test Loss:0.8070\tRecon Loss:6.0091\tTriplet Loss:0.4687\tStatic Loss:0.7889\n",
      "\n",
      "\tEpoch:56\tTrain Loss:0.2639\tRecon Loss:3.4055\tTriplet Loss:0.1533\tStatic Loss:0.2436\t\n",
      "Val Loss:0.2831\tRecon Loss:3.1013\tTriplet Loss:0.1674\tStatic Loss:0.2665\n",
      "\n",
      "\tTime:49.6991\n",
      "\n",
      "Test Loss:0.8845\tRecon Loss:9.3796\tTriplet Loss:0.5193\tStatic Loss:0.8361\n",
      "\n",
      "\tEpoch:57\tTrain Loss:0.2334\tRecon Loss:2.6115\tTriplet Loss:0.1445\tStatic Loss:0.2185\t\n",
      "Val Loss:0.2734\tRecon Loss:2.4192\tTriplet Loss:0.1489\tStatic Loss:0.2643\n",
      "\n",
      "\tTime:48.9343\n",
      "\n",
      "Test Loss:0.8705\tRecon Loss:7.2492\tTriplet Loss:0.5053\tStatic Loss:0.8432\n",
      "\n",
      "\tEpoch:58\tTrain Loss:0.2156\tRecon Loss:2.1423\tTriplet Loss:0.1272\tStatic Loss:0.2052\t\n",
      "Val Loss:0.2659\tRecon Loss:2.1481\tTriplet Loss:0.1419\tStatic Loss:0.2595\n",
      "\n",
      "\tTime:50.5473\n",
      "\n",
      "Test Loss:0.8337\tRecon Loss:6.5605\tTriplet Loss:0.4632\tStatic Loss:0.8135\n",
      "\n",
      "\tEpoch:59\tTrain Loss:0.2094\tRecon Loss:2.0604\tTriplet Loss:0.1215\tStatic Loss:0.1997\t\n",
      "Val Loss:0.2616\tRecon Loss:2.0762\tTriplet Loss:0.1449\tStatic Loss:0.2552\n",
      "\n",
      "\tTime:49.9844\n",
      "\n",
      "Test Loss:0.8234\tRecon Loss:6.2966\tTriplet Loss:0.4870\tStatic Loss:0.8023\n",
      "\n",
      "\tEpoch:60\tTrain Loss:0.2043\tRecon Loss:2.0279\tTriplet Loss:0.1169\tStatic Loss:0.1948\t\n",
      "Val Loss:0.2597\tRecon Loss:2.0581\tTriplet Loss:0.1389\tStatic Loss:0.2538\n",
      "\n",
      "\tTime:50.0506\n",
      "\n",
      "Test Loss:0.8294\tRecon Loss:6.2609\tTriplet Loss:0.5149\tStatic Loss:0.8065\n",
      "\n",
      "\tEpoch:61\tTrain Loss:0.2000\tRecon Loss:1.9804\tTriplet Loss:0.1129\tStatic Loss:0.1909\t\n",
      "Val Loss:0.2573\tRecon Loss:2.0314\tTriplet Loss:0.1377\tStatic Loss:0.2515\n",
      "\n",
      "\tTime:49.8208\n",
      "\n",
      "Test Loss:0.8105\tRecon Loss:6.2034\tTriplet Loss:0.4944\tStatic Loss:0.7882\n",
      "\n",
      "\tEpoch:62\tTrain Loss:0.2001\tRecon Loss:1.9554\tTriplet Loss:0.1104\tStatic Loss:0.1916\t\n",
      "Val Loss:0.2571\tRecon Loss:2.0077\tTriplet Loss:0.1353\tStatic Loss:0.2518\n",
      "\n",
      "\tTime:50.3084\n",
      "\n",
      "Test Loss:0.8141\tRecon Loss:6.0780\tTriplet Loss:0.4678\tStatic Loss:0.7961\n",
      "\n",
      "\tEpoch:63\tTrain Loss:0.1978\tRecon Loss:1.9486\tTriplet Loss:0.1114\tStatic Loss:0.1890\t\n",
      "Val Loss:0.2587\tRecon Loss:2.0019\tTriplet Loss:0.1377\tStatic Loss:0.2534\n",
      "\n",
      "\tTime:49.8537\n",
      "\n",
      "Test Loss:0.8258\tRecon Loss:6.0477\tTriplet Loss:0.4619\tStatic Loss:0.8100\n",
      "\n",
      "\tEpoch:64\tTrain Loss:0.1980\tRecon Loss:1.9689\tTriplet Loss:0.1130\tStatic Loss:0.1888\t\n",
      "Val Loss:0.2589\tRecon Loss:2.0365\tTriplet Loss:0.1430\tStatic Loss:0.2527\n",
      "\n",
      "\tTime:49.5882\n",
      "\n",
      "Test Loss:0.8243\tRecon Loss:6.2853\tTriplet Loss:0.4383\tStatic Loss:0.8082\n",
      "\n",
      "\tEpoch:65\tTrain Loss:0.1948\tRecon Loss:1.9287\tTriplet Loss:0.1076\tStatic Loss:0.1862\t\n",
      "Val Loss:0.2577\tRecon Loss:1.9866\tTriplet Loss:0.1450\tStatic Loss:0.2517\n",
      "\n",
      "\tTime:49.4878\n",
      "\n",
      "Test Loss:0.8202\tRecon Loss:5.9623\tTriplet Loss:0.4276\tStatic Loss:0.8080\n",
      "\n",
      "\tEpoch:66\tTrain Loss:0.1936\tRecon Loss:1.9164\tTriplet Loss:0.1121\tStatic Loss:0.1845\t\n",
      "Val Loss:0.2554\tRecon Loss:1.9697\tTriplet Loss:0.1435\tStatic Loss:0.2494\n",
      "\n",
      "\tTime:48.7249\n",
      "\n",
      "Test Loss:0.8129\tRecon Loss:5.9340\tTriplet Loss:0.4430\tStatic Loss:0.7987\n",
      "\n",
      "\tEpoch:67\tTrain Loss:0.1932\tRecon Loss:1.9300\tTriplet Loss:0.1071\tStatic Loss:0.1845\t\n",
      "Val Loss:0.2612\tRecon Loss:1.9899\tTriplet Loss:0.1418\tStatic Loss:0.2559\n",
      "\n",
      "\tTime:49.7902\n",
      "\n",
      "Test Loss:0.8340\tRecon Loss:5.9631\tTriplet Loss:0.4639\tStatic Loss:0.8197\n",
      "\n",
      "\tEpoch:68\tTrain Loss:0.1910\tRecon Loss:1.9055\tTriplet Loss:0.1079\tStatic Loss:0.1822\t\n",
      "Val Loss:0.2563\tRecon Loss:1.9835\tTriplet Loss:0.1381\tStatic Loss:0.2509\n",
      "\n",
      "\tTime:48.4269\n",
      "\n",
      "Test Loss:0.8006\tRecon Loss:5.9571\tTriplet Loss:0.4491\tStatic Loss:0.7842\n",
      "\n",
      "\tEpoch:69\tTrain Loss:0.1910\tRecon Loss:1.9060\tTriplet Loss:0.1082\tStatic Loss:0.1822\t\n",
      "Val Loss:0.2567\tRecon Loss:1.9698\tTriplet Loss:0.1359\tStatic Loss:0.2517\n",
      "\n",
      "\tTime:48.8579\n",
      "\n",
      "Test Loss:0.8095\tRecon Loss:5.9289\tTriplet Loss:0.4483\tStatic Loss:0.7944\n",
      "\n",
      "\tEpoch:70\tTrain Loss:0.1905\tRecon Loss:1.9028\tTriplet Loss:0.1050\tStatic Loss:0.1819\t\n",
      "Val Loss:0.2584\tRecon Loss:1.9896\tTriplet Loss:0.1317\tStatic Loss:0.2538\n",
      "\n",
      "\tTime:49.2034\n",
      "\n",
      "Test Loss:0.8103\tRecon Loss:5.9724\tTriplet Loss:0.4405\tStatic Loss:0.7957\n",
      "\n",
      "\tEpoch:71\tTrain Loss:0.1909\tRecon Loss:1.8986\tTriplet Loss:0.1078\tStatic Loss:0.1821\t\n",
      "Val Loss:0.2578\tRecon Loss:1.9502\tTriplet Loss:0.1271\tStatic Loss:0.2539\n",
      "\n",
      "\tTime:49.2137\n",
      "\n",
      "Test Loss:0.8097\tRecon Loss:6.0169\tTriplet Loss:0.4367\tStatic Loss:0.7949\n",
      "\n",
      "\tEpoch:72\tTrain Loss:0.1913\tRecon Loss:1.9184\tTriplet Loss:0.1069\tStatic Loss:0.1825\t\n",
      "Val Loss:0.2552\tRecon Loss:1.9589\tTriplet Loss:0.1383\tStatic Loss:0.2498\n",
      "\n",
      "\tTime:48.8734\n",
      "\n",
      "Test Loss:0.8145\tRecon Loss:5.8519\tTriplet Loss:0.4753\tStatic Loss:0.7980\n",
      "\n",
      "\tEpoch:73\tTrain Loss:0.1899\tRecon Loss:1.8948\tTriplet Loss:0.1066\tStatic Loss:0.1811\t\n",
      "Val Loss:0.2569\tRecon Loss:1.9681\tTriplet Loss:0.1312\tStatic Loss:0.2524\n",
      "\n",
      "\tTime:49.0997\n",
      "\n",
      "Test Loss:0.8331\tRecon Loss:5.9660\tTriplet Loss:0.4493\tStatic Loss:0.8201\n",
      "\n",
      "\tEpoch:74\tTrain Loss:0.1872\tRecon Loss:1.9100\tTriplet Loss:0.1030\tStatic Loss:0.1784\t\n",
      "Val Loss:0.2574\tRecon Loss:1.9592\tTriplet Loss:0.1343\tStatic Loss:0.2527\n",
      "\n",
      "\tTime:48.9231\n",
      "\n",
      "Test Loss:0.8289\tRecon Loss:5.8214\tTriplet Loss:0.4605\tStatic Loss:0.8158\n",
      "\n",
      "\tEpoch:75\tTrain Loss:0.1861\tRecon Loss:1.8785\tTriplet Loss:0.1021\tStatic Loss:0.1775\t\n",
      "Val Loss:0.2562\tRecon Loss:1.9500\tTriplet Loss:0.1251\tStatic Loss:0.2523\n",
      "\n",
      "\tTime:49.1010\n",
      "\n",
      "Test Loss:0.8164\tRecon Loss:5.8292\tTriplet Loss:0.4520\tStatic Loss:0.8027\n",
      "\n",
      "\tEpoch:76\tTrain Loss:0.1864\tRecon Loss:1.8981\tTriplet Loss:0.1041\tStatic Loss:0.1775\t\n",
      "Val Loss:0.2656\tRecon Loss:1.9589\tTriplet Loss:0.1394\tStatic Loss:0.2613\n",
      "\n",
      "\tTime:50.1260\n",
      "\n",
      "Test Loss:0.8172\tRecon Loss:5.8789\tTriplet Loss:0.4721\tStatic Loss:0.8011\n",
      "\n",
      "\tEpoch:77\tTrain Loss:0.1881\tRecon Loss:1.8862\tTriplet Loss:0.1065\tStatic Loss:0.1793\t\n",
      "Val Loss:0.2630\tRecon Loss:1.9653\tTriplet Loss:0.1348\tStatic Loss:0.2588\n",
      "\n",
      "\tTime:48.9979\n",
      "\n",
      "Test Loss:0.8261\tRecon Loss:5.8298\tTriplet Loss:0.4562\tStatic Loss:0.8131\n",
      "\n",
      "\tEpoch:78\tTrain Loss:0.1860\tRecon Loss:1.8733\tTriplet Loss:0.1025\tStatic Loss:0.1775\t\n",
      "Val Loss:0.2599\tRecon Loss:1.9384\tTriplet Loss:0.1330\tStatic Loss:0.2558\n",
      "\n",
      "\tTime:49.7656\n",
      "\n",
      "Test Loss:0.7928\tRecon Loss:5.9146\tTriplet Loss:0.4482\tStatic Loss:0.7761\n",
      "\n",
      "\tEpoch:79\tTrain Loss:0.1868\tRecon Loss:1.8888\tTriplet Loss:0.1048\tStatic Loss:0.1780\t\n",
      "Val Loss:0.2580\tRecon Loss:1.9505\tTriplet Loss:0.1358\tStatic Loss:0.2532\n",
      "\n",
      "\tTime:49.3295\n",
      "\n",
      "Test Loss:0.8056\tRecon Loss:5.8829\tTriplet Loss:0.4439\tStatic Loss:0.7910\n",
      "\n",
      "\tEpoch:80\tTrain Loss:0.1887\tRecon Loss:1.9225\tTriplet Loss:0.1044\tStatic Loss:0.1798\t\n",
      "Val Loss:0.2614\tRecon Loss:1.9545\tTriplet Loss:0.1289\tStatic Loss:0.2577\n",
      "\n",
      "\tTime:49.5854\n",
      "\n",
      "Test Loss:0.8102\tRecon Loss:5.7954\tTriplet Loss:0.4653\tStatic Loss:0.7948\n",
      "\n",
      "\tEpoch:81\tTrain Loss:0.1863\tRecon Loss:1.8678\tTriplet Loss:0.1073\tStatic Loss:0.1773\t\n",
      "Val Loss:0.2658\tRecon Loss:2.0975\tTriplet Loss:0.1290\tStatic Loss:0.2612\n",
      "\n",
      "\tTime:49.8109\n",
      "\n",
      "Test Loss:0.8227\tRecon Loss:6.3875\tTriplet Loss:0.4408\tStatic Loss:0.8052\n",
      "\n",
      "\tEpoch:82\tTrain Loss:0.1847\tRecon Loss:1.8926\tTriplet Loss:0.1055\tStatic Loss:0.1755\t\n",
      "Val Loss:0.2612\tRecon Loss:1.9738\tTriplet Loss:0.1256\tStatic Loss:0.2577\n",
      "\n",
      "\tTime:49.4078\n",
      "\n",
      "Test Loss:0.8262\tRecon Loss:5.9956\tTriplet Loss:0.4635\tStatic Loss:0.8108\n",
      "\n",
      "\tEpoch:83\tTrain Loss:0.1840\tRecon Loss:1.8743\tTriplet Loss:0.1002\tStatic Loss:0.1755\t\n",
      "Val Loss:0.2570\tRecon Loss:1.9524\tTriplet Loss:0.1358\tStatic Loss:0.2522\n",
      "\n",
      "\tTime:49.8501\n",
      "\n",
      "Test Loss:0.8098\tRecon Loss:5.8541\tTriplet Loss:0.4669\tStatic Loss:0.7937\n",
      "\n",
      "\tEpoch:84\tTrain Loss:0.1839\tRecon Loss:1.9171\tTriplet Loss:0.1043\tStatic Loss:0.1745\t\n",
      "Val Loss:0.2625\tRecon Loss:1.9432\tTriplet Loss:0.1406\tStatic Loss:0.2579\n",
      "\n",
      "\tTime:49.8138\n",
      "\n",
      "Test Loss:0.8302\tRecon Loss:5.8262\tTriplet Loss:0.4598\tStatic Loss:0.8173\n",
      "\n",
      "\tEpoch:85\tTrain Loss:0.1827\tRecon Loss:1.8696\tTriplet Loss:0.0969\tStatic Loss:0.1744\t\n",
      "Val Loss:0.2618\tRecon Loss:1.9718\tTriplet Loss:0.1381\tStatic Loss:0.2570\n",
      "\n",
      "\tTime:50.4591\n",
      "\n",
      "Test Loss:0.8088\tRecon Loss:5.8441\tTriplet Loss:0.4514\tStatic Loss:0.7942\n",
      "\n",
      "\tEpoch:86\tTrain Loss:0.1832\tRecon Loss:1.8721\tTriplet Loss:0.0985\tStatic Loss:0.1748\t\n",
      "Val Loss:0.2616\tRecon Loss:1.9371\tTriplet Loss:0.1293\tStatic Loss:0.2581\n",
      "\n",
      "\tTime:49.1194\n",
      "\n",
      "Test Loss:0.7967\tRecon Loss:5.7987\tTriplet Loss:0.4441\tStatic Loss:0.7819\n",
      "\n",
      "\tEpoch:87\tTrain Loss:0.1856\tRecon Loss:1.8887\tTriplet Loss:0.0982\tStatic Loss:0.1773\t\n",
      "Val Loss:0.2724\tRecon Loss:2.1009\tTriplet Loss:0.1386\tStatic Loss:0.2675\n",
      "\n",
      "\tTime:48.8143\n",
      "\n",
      "Test Loss:0.8763\tRecon Loss:6.3707\tTriplet Loss:0.4491\tStatic Loss:0.8641\n",
      "\n",
      "\tEpoch:88\tTrain Loss:0.1896\tRecon Loss:1.8762\tTriplet Loss:0.1029\tStatic Loss:0.1814\t\n",
      "Val Loss:0.2606\tRecon Loss:1.9291\tTriplet Loss:0.1442\tStatic Loss:0.2555\n",
      "\n",
      "\tTime:48.8640\n",
      "\n",
      "Test Loss:0.7982\tRecon Loss:5.7662\tTriplet Loss:0.4610\tStatic Loss:0.7822\n",
      "\n",
      "\tEpoch:89\tTrain Loss:0.1850\tRecon Loss:1.8671\tTriplet Loss:0.1011\tStatic Loss:0.1766\t\n",
      "Val Loss:0.2669\tRecon Loss:1.9410\tTriplet Loss:0.1373\tStatic Loss:0.2631\n",
      "\n",
      "\tTime:48.7153\n",
      "\n",
      "Test Loss:0.8443\tRecon Loss:5.7541\tTriplet Loss:0.4662\tStatic Loss:0.8330\n",
      "\n",
      "\tEpoch:90\tTrain Loss:0.1832\tRecon Loss:1.8638\tTriplet Loss:0.1000\tStatic Loss:0.1747\t\n",
      "Val Loss:0.2606\tRecon Loss:1.9523\tTriplet Loss:0.1311\tStatic Loss:0.2566\n",
      "\n",
      "\tTime:49.1705\n",
      "\n",
      "Test Loss:0.8253\tRecon Loss:5.8279\tTriplet Loss:0.4448\tStatic Loss:0.8134\n",
      "\n",
      "\tEpoch:91\tTrain Loss:0.1812\tRecon Loss:1.8604\tTriplet Loss:0.1021\tStatic Loss:0.1723\t\n",
      "Val Loss:0.2606\tRecon Loss:1.9507\tTriplet Loss:0.1283\tStatic Loss:0.2570\n",
      "\n",
      "\tTime:48.7522\n",
      "\n",
      "Test Loss:0.8191\tRecon Loss:5.8483\tTriplet Loss:0.4227\tStatic Loss:0.8085\n",
      "\n",
      "\tEpoch:92\tTrain Loss:0.1823\tRecon Loss:1.8649\tTriplet Loss:0.1025\tStatic Loss:0.1735\t\n",
      "Val Loss:0.2612\tRecon Loss:1.9303\tTriplet Loss:0.1266\tStatic Loss:0.2580\n",
      "\n",
      "\tTime:51.3923\n",
      "\n",
      "Test Loss:0.8328\tRecon Loss:5.7570\tTriplet Loss:0.4590\tStatic Loss:0.8209\n",
      "\n",
      "\tEpoch:93\tTrain Loss:0.1822\tRecon Loss:1.9024\tTriplet Loss:0.0994\tStatic Loss:0.1732\t\n",
      "Val Loss:0.2588\tRecon Loss:1.9200\tTriplet Loss:0.1281\tStatic Loss:0.2553\n",
      "\n",
      "\tTime:49.9701\n",
      "\n",
      "Test Loss:0.8228\tRecon Loss:5.7814\tTriplet Loss:0.4563\tStatic Loss:0.8099\n",
      "\n",
      "\tEpoch:94\tTrain Loss:0.1887\tRecon Loss:1.8845\tTriplet Loss:0.1040\tStatic Loss:0.1802\t\n",
      "Val Loss:0.2576\tRecon Loss:1.9256\tTriplet Loss:0.1313\tStatic Loss:0.2536\n",
      "\n",
      "\tTime:49.9649\n",
      "\n",
      "Test Loss:0.8018\tRecon Loss:5.7892\tTriplet Loss:0.4436\tStatic Loss:0.7878\n",
      "\n",
      "\tEpoch:95\tTrain Loss:0.1831\tRecon Loss:1.8632\tTriplet Loss:0.1010\tStatic Loss:0.1745\t\n",
      "Val Loss:0.2607\tRecon Loss:1.9247\tTriplet Loss:0.1297\tStatic Loss:0.2572\n",
      "\n",
      "\tTime:49.7916\n",
      "\n",
      "Test Loss:0.8353\tRecon Loss:5.8439\tTriplet Loss:0.4344\tStatic Loss:0.8252\n",
      "\n",
      "\tEpoch:96\tTrain Loss:0.1809\tRecon Loss:1.8868\tTriplet Loss:0.0980\tStatic Loss:0.1721\t\n",
      "Val Loss:0.2607\tRecon Loss:1.9423\tTriplet Loss:0.1325\tStatic Loss:0.2567\n",
      "\n",
      "\tTime:49.4525\n",
      "\n",
      "Test Loss:0.8191\tRecon Loss:5.7819\tTriplet Loss:0.4315\tStatic Loss:0.8082\n",
      "\n",
      "\tEpoch:97\tTrain Loss:0.1821\tRecon Loss:1.8571\tTriplet Loss:0.1028\tStatic Loss:0.1732\t\n",
      "Val Loss:0.2603\tRecon Loss:1.9190\tTriplet Loss:0.1315\tStatic Loss:0.2566\n",
      "\n",
      "\tTime:50.1287\n",
      "\n",
      "Test Loss:0.8224\tRecon Loss:5.8654\tTriplet Loss:0.4706\tStatic Loss:0.8071\n",
      "\n",
      "\tEpoch:98\tTrain Loss:0.1805\tRecon Loss:1.8579\tTriplet Loss:0.1030\tStatic Loss:0.1715\t\n",
      "Val Loss:0.2626\tRecon Loss:1.9217\tTriplet Loss:0.1357\tStatic Loss:0.2587\n",
      "\n",
      "\tTime:48.6549\n",
      "\n",
      "Test Loss:0.8178\tRecon Loss:5.7814\tTriplet Loss:0.4472\tStatic Loss:0.8052\n",
      "\n",
      "\tEpoch:99\tTrain Loss:0.1806\tRecon Loss:1.9494\tTriplet Loss:0.0987\tStatic Loss:0.1711\t\n",
      "Val Loss:0.2616\tRecon Loss:1.9635\tTriplet Loss:0.1350\tStatic Loss:0.2573\n",
      "\n",
      "\tTime:48.6933\n",
      "\n",
      "Test Loss:0.8019\tRecon Loss:5.9061\tTriplet Loss:0.4306\tStatic Loss:0.7880\n",
      "\n",
      "\tEpoch:100\tTrain Loss:0.1784\tRecon Loss:1.8904\tTriplet Loss:0.0992\tStatic Loss:0.1692\t\n",
      "Val Loss:0.2627\tRecon Loss:1.9760\tTriplet Loss:0.1376\tStatic Loss:0.2581\n",
      "\n",
      "\tTime:48.3961\n",
      "\n",
      "Test Loss:0.8150\tRecon Loss:5.9166\tTriplet Loss:0.4291\tStatic Loss:0.8026\n",
      "\n",
      "\tEpoch:101\tTrain Loss:0.1788\tRecon Loss:1.8891\tTriplet Loss:0.0976\tStatic Loss:0.1698\t\n",
      "Val Loss:0.2587\tRecon Loss:1.9580\tTriplet Loss:0.1316\tStatic Loss:0.2544\n",
      "\n",
      "\tTime:48.1813\n",
      "\n",
      "Test Loss:0.8133\tRecon Loss:5.8054\tTriplet Loss:0.4528\tStatic Loss:0.7994\n",
      "\n",
      "\tEpoch:102\tTrain Loss:0.1892\tRecon Loss:1.8654\tTriplet Loss:0.1070\tStatic Loss:0.1807\t\n",
      "Val Loss:0.2738\tRecon Loss:1.9435\tTriplet Loss:0.1259\tStatic Loss:0.2719\n",
      "\n",
      "\tTime:48.6761\n",
      "\n",
      "Test Loss:0.8874\tRecon Loss:5.9693\tTriplet Loss:0.4840\tStatic Loss:0.8769\n",
      "\n",
      "\tEpoch:103\tTrain Loss:0.1864\tRecon Loss:1.8630\tTriplet Loss:0.1063\tStatic Loss:0.1776\t\n",
      "Val Loss:0.2628\tRecon Loss:1.9271\tTriplet Loss:0.1276\tStatic Loss:0.2596\n",
      "\n",
      "\tTime:48.8840\n",
      "\n",
      "Test Loss:0.8253\tRecon Loss:5.8193\tTriplet Loss:0.4645\tStatic Loss:0.8114\n",
      "\n",
      "\tEpoch:104\tTrain Loss:0.1820\tRecon Loss:1.8559\tTriplet Loss:0.1058\tStatic Loss:0.1729\t\n",
      "Val Loss:0.2556\tRecon Loss:1.9364\tTriplet Loss:0.1211\tStatic Loss:0.2523\n",
      "\n",
      "\tTime:49.0056\n",
      "\n",
      "Test Loss:0.8202\tRecon Loss:5.7968\tTriplet Loss:0.4525\tStatic Loss:0.8073\n",
      "\n",
      "\tEpoch:105\tTrain Loss:0.1772\tRecon Loss:1.8534\tTriplet Loss:0.0960\tStatic Loss:0.1686\t\n",
      "Val Loss:0.2608\tRecon Loss:1.9785\tTriplet Loss:0.1365\tStatic Loss:0.2561\n",
      "\n",
      "\tTime:49.4704\n",
      "\n",
      "Test Loss:0.8437\tRecon Loss:5.9648\tTriplet Loss:0.4510\tStatic Loss:0.8317\n",
      "\n",
      "\tEpoch:106\tTrain Loss:0.1781\tRecon Loss:1.8458\tTriplet Loss:0.0987\tStatic Loss:0.1694\t\n",
      "Val Loss:0.2583\tRecon Loss:1.9183\tTriplet Loss:0.1342\tStatic Loss:0.2542\n",
      "\n",
      "\tTime:49.1212\n",
      "\n",
      "Test Loss:0.8118\tRecon Loss:5.7167\tTriplet Loss:0.4423\tStatic Loss:0.7997\n",
      "\n",
      "\tEpoch:107\tTrain Loss:0.1843\tRecon Loss:1.8635\tTriplet Loss:0.1014\tStatic Loss:0.1758\t\n",
      "Val Loss:0.2612\tRecon Loss:1.9399\tTriplet Loss:0.1321\tStatic Loss:0.2574\n",
      "\n",
      "\tTime:48.8173\n",
      "\n",
      "Test Loss:0.8302\tRecon Loss:5.8111\tTriplet Loss:0.4695\tStatic Loss:0.8165\n",
      "\n",
      "\tEpoch:108\tTrain Loss:0.1818\tRecon Loss:1.8869\tTriplet Loss:0.0973\tStatic Loss:0.1732\t\n",
      "Val Loss:0.2601\tRecon Loss:1.9216\tTriplet Loss:0.1339\tStatic Loss:0.2561\n",
      "\n",
      "\tTime:49.3274\n",
      "\n",
      "Test Loss:0.8409\tRecon Loss:5.7623\tTriplet Loss:0.4444\tStatic Loss:0.8314\n",
      "\n",
      "\tEpoch:109\tTrain Loss:0.1778\tRecon Loss:1.8494\tTriplet Loss:0.0975\tStatic Loss:0.1691\t\n",
      "Val Loss:0.2576\tRecon Loss:1.9238\tTriplet Loss:0.1406\tStatic Loss:0.2526\n",
      "\n",
      "\tTime:49.6675\n",
      "\n",
      "Test Loss:0.8005\tRecon Loss:5.7738\tTriplet Loss:0.4600\tStatic Loss:0.7849\n",
      "\n",
      "\tEpoch:110\tTrain Loss:0.1772\tRecon Loss:1.8632\tTriplet Loss:0.0984\tStatic Loss:0.1683\t\n",
      "Val Loss:0.2609\tRecon Loss:1.9095\tTriplet Loss:0.1374\tStatic Loss:0.2567\n",
      "\n",
      "\tTime:49.2601\n",
      "\n",
      "Test Loss:0.8083\tRecon Loss:5.7661\tTriplet Loss:0.4530\tStatic Loss:0.7942\n",
      "\n",
      "\tEpoch:111\tTrain Loss:0.1754\tRecon Loss:1.8449\tTriplet Loss:0.0954\tStatic Loss:0.1667\t\n",
      "Val Loss:0.2607\tRecon Loss:1.9129\tTriplet Loss:0.1313\tStatic Loss:0.2571\n",
      "\n",
      "\tTime:49.9980\n",
      "\n",
      "Test Loss:0.8234\tRecon Loss:5.7770\tTriplet Loss:0.4541\tStatic Loss:0.8107\n",
      "\n",
      "\tEpoch:112\tTrain Loss:0.1757\tRecon Loss:1.8486\tTriplet Loss:0.0972\tStatic Loss:0.1668\t\n",
      "Val Loss:0.2606\tRecon Loss:1.9320\tTriplet Loss:0.1377\tStatic Loss:0.2562\n",
      "\n",
      "\tTime:49.6504\n",
      "\n",
      "Test Loss:0.8175\tRecon Loss:5.8238\tTriplet Loss:0.4166\tStatic Loss:0.8075\n",
      "\n",
      "\tEpoch:113\tTrain Loss:0.1759\tRecon Loss:1.8510\tTriplet Loss:0.0968\tStatic Loss:0.1671\t\n",
      "Val Loss:0.2628\tRecon Loss:1.9304\tTriplet Loss:0.1274\tStatic Loss:0.2597\n",
      "\n",
      "\tTime:49.2777\n",
      "\n",
      "Test Loss:0.8318\tRecon Loss:5.8425\tTriplet Loss:0.4706\tStatic Loss:0.8178\n",
      "\n",
      "\tEpoch:114\tTrain Loss:0.1753\tRecon Loss:1.8585\tTriplet Loss:0.0961\tStatic Loss:0.1664\t\n",
      "Val Loss:0.2666\tRecon Loss:1.9381\tTriplet Loss:0.1302\tStatic Loss:0.2635\n",
      "\n",
      "\tTime:48.7453\n",
      "\n",
      "Test Loss:0.8292\tRecon Loss:5.8233\tTriplet Loss:0.4342\tStatic Loss:0.8188\n",
      "\n",
      "\tEpoch:115\tTrain Loss:0.1754\tRecon Loss:1.8474\tTriplet Loss:0.1014\tStatic Loss:0.1661\t\n",
      "Val Loss:0.2612\tRecon Loss:1.9491\tTriplet Loss:0.1211\tStatic Loss:0.2584\n",
      "\n",
      "\tTime:48.7239\n",
      "\n",
      "Test Loss:0.8278\tRecon Loss:5.7944\tTriplet Loss:0.4591\tStatic Loss:0.8150\n",
      "\n",
      "\tEpoch:116\tTrain Loss:0.1756\tRecon Loss:1.8598\tTriplet Loss:0.0980\tStatic Loss:0.1665\t\n",
      "Val Loss:0.2588\tRecon Loss:1.9337\tTriplet Loss:0.1233\tStatic Loss:0.2556\n",
      "\n",
      "\tTime:48.8973\n",
      "\n",
      "Test Loss:0.8015\tRecon Loss:5.8693\tTriplet Loss:0.4455\tStatic Loss:0.7864\n",
      "\n",
      "\tEpoch:117\tTrain Loss:0.1749\tRecon Loss:1.8562\tTriplet Loss:0.0952\tStatic Loss:0.1660\t\n",
      "Val Loss:0.2608\tRecon Loss:1.9119\tTriplet Loss:0.1255\tStatic Loss:0.2578\n",
      "\n",
      "\tTime:50.0712\n",
      "\n",
      "Test Loss:0.8261\tRecon Loss:5.7607\tTriplet Loss:0.4627\tStatic Loss:0.8131\n",
      "\n",
      "\tEpoch:118\tTrain Loss:0.1765\tRecon Loss:1.8612\tTriplet Loss:0.0973\tStatic Loss:0.1676\t\n",
      "Val Loss:0.2634\tRecon Loss:1.9765\tTriplet Loss:0.1246\tStatic Loss:0.2601\n",
      "\n",
      "\tTime:50.5096\n",
      "\n",
      "Test Loss:0.8238\tRecon Loss:6.0883\tTriplet Loss:0.4411\tStatic Loss:0.8094\n",
      "\n",
      "\tEpoch:119\tTrain Loss:0.1748\tRecon Loss:1.8424\tTriplet Loss:0.0970\tStatic Loss:0.1659\t\n",
      "Val Loss:0.2606\tRecon Loss:1.9154\tTriplet Loss:0.1283\tStatic Loss:0.2573\n",
      "\n",
      "\tTime:49.5528\n",
      "\n",
      "Test Loss:0.8090\tRecon Loss:5.7588\tTriplet Loss:0.4450\tStatic Loss:0.7959\n",
      "\n",
      "\tEpoch:120\tTrain Loss:0.1754\tRecon Loss:1.8507\tTriplet Loss:0.1001\tStatic Loss:0.1662\t\n",
      "Val Loss:0.2622\tRecon Loss:1.9456\tTriplet Loss:0.1263\tStatic Loss:0.2590\n",
      "\n",
      "\tTime:48.8530\n",
      "\n",
      "Test Loss:0.8353\tRecon Loss:5.7999\tTriplet Loss:0.4362\tStatic Loss:0.8256\n",
      "\n",
      "\tEpoch:121\tTrain Loss:0.1772\tRecon Loss:1.8631\tTriplet Loss:0.1009\tStatic Loss:0.1680\t\n",
      "Val Loss:0.2644\tRecon Loss:1.9194\tTriplet Loss:0.1408\tStatic Loss:0.2603\n",
      "\n",
      "\tTime:48.7645\n",
      "\n",
      "Test Loss:0.8176\tRecon Loss:5.8293\tTriplet Loss:0.4388\tStatic Loss:0.8054\n",
      "\n",
      "\tEpoch:122\tTrain Loss:0.1849\tRecon Loss:1.8620\tTriplet Loss:0.0995\tStatic Loss:0.1766\t\n",
      "Val Loss:0.2619\tRecon Loss:1.9444\tTriplet Loss:0.1350\tStatic Loss:0.2577\n",
      "\n",
      "\tTime:49.0223\n",
      "\n",
      "Test Loss:0.8072\tRecon Loss:5.8002\tTriplet Loss:0.4395\tStatic Loss:0.7940\n",
      "\n",
      "\tEpoch:123\tTrain Loss:0.1767\tRecon Loss:1.8382\tTriplet Loss:0.0972\tStatic Loss:0.1681\t\n",
      "Val Loss:0.2657\tRecon Loss:1.9098\tTriplet Loss:0.1392\tStatic Loss:0.2619\n",
      "\n",
      "\tTime:49.1773\n",
      "\n",
      "Test Loss:0.8357\tRecon Loss:5.7577\tTriplet Loss:0.4489\tStatic Loss:0.8252\n",
      "\n",
      "\tEpoch:124\tTrain Loss:0.1754\tRecon Loss:1.8427\tTriplet Loss:0.0968\tStatic Loss:0.1665\t\n",
      "Val Loss:0.2632\tRecon Loss:1.9091\tTriplet Loss:0.1302\tStatic Loss:0.2600\n",
      "\n",
      "\tTime:49.5015\n",
      "\n",
      "Test Loss:0.8321\tRecon Loss:5.7633\tTriplet Loss:0.4075\tStatic Loss:0.8252\n",
      "\n",
      "\tEpoch:125\tTrain Loss:0.1805\tRecon Loss:1.8431\tTriplet Loss:0.0991\tStatic Loss:0.1720\t\n",
      "Val Loss:0.2893\tRecon Loss:2.0230\tTriplet Loss:0.1286\tStatic Loss:0.2880\n",
      "\n",
      "\tTime:49.3679\n",
      "\n",
      "Test Loss:0.9361\tRecon Loss:6.0347\tTriplet Loss:0.4906\tStatic Loss:0.9297\n",
      "\n",
      "\tEpoch:126\tTrain Loss:0.1961\tRecon Loss:1.8630\tTriplet Loss:0.1010\tStatic Loss:0.1890\t\n",
      "Val Loss:0.2648\tRecon Loss:1.9173\tTriplet Loss:0.1288\tStatic Loss:0.2619\n",
      "\n",
      "\tTime:49.0295\n",
      "\n",
      "Test Loss:0.8318\tRecon Loss:5.7687\tTriplet Loss:0.4337\tStatic Loss:0.8222\n",
      "\n",
      "\tEpoch:127\tTrain Loss:0.1836\tRecon Loss:1.8409\tTriplet Loss:0.1028\tStatic Loss:0.1751\t\n",
      "Val Loss:0.2602\tRecon Loss:1.9459\tTriplet Loss:0.1225\tStatic Loss:0.2571\n",
      "\n",
      "\tTime:49.7168\n",
      "\n",
      "Test Loss:0.8450\tRecon Loss:5.7607\tTriplet Loss:0.4468\tStatic Loss:0.8357\n",
      "\n",
      "\tEpoch:128\tTrain Loss:0.1796\tRecon Loss:1.8494\tTriplet Loss:0.0989\tStatic Loss:0.1709\t\n",
      "Val Loss:0.2605\tRecon Loss:1.9542\tTriplet Loss:0.1331\tStatic Loss:0.2564\n",
      "\n",
      "\tTime:48.8025\n",
      "\n",
      "Test Loss:0.8287\tRecon Loss:5.8421\tTriplet Loss:0.4636\tStatic Loss:0.8151\n",
      "\n",
      "\tEpoch:129\tTrain Loss:0.1782\tRecon Loss:1.8355\tTriplet Loss:0.0947\tStatic Loss:0.1700\t\n",
      "Val Loss:0.2575\tRecon Loss:1.9042\tTriplet Loss:0.1247\tStatic Loss:0.2543\n",
      "\n",
      "\tTime:48.6401\n",
      "\n",
      "Test Loss:0.8188\tRecon Loss:5.7696\tTriplet Loss:0.4430\tStatic Loss:0.8069\n",
      "\n",
      "\tEpoch:130\tTrain Loss:0.1777\tRecon Loss:1.8344\tTriplet Loss:0.1005\tStatic Loss:0.1688\t\n",
      "Val Loss:0.2628\tRecon Loss:1.9081\tTriplet Loss:0.1334\tStatic Loss:0.2592\n",
      "\n",
      "\tTime:48.2562\n",
      "\n",
      "Test Loss:0.8015\tRecon Loss:5.7108\tTriplet Loss:0.4814\tStatic Loss:0.7844\n",
      "\n",
      "\tEpoch:131\tTrain Loss:0.1771\tRecon Loss:1.8356\tTriplet Loss:0.0986\tStatic Loss:0.1684\t\n",
      "Val Loss:0.2600\tRecon Loss:1.9299\tTriplet Loss:0.1273\tStatic Loss:0.2565\n",
      "\n",
      "\tTime:48.6954\n",
      "\n",
      "Test Loss:0.8434\tRecon Loss:5.8655\tTriplet Loss:0.4707\tStatic Loss:0.8304\n",
      "\n",
      "\tEpoch:132\tTrain Loss:0.1764\tRecon Loss:1.8343\tTriplet Loss:0.0960\tStatic Loss:0.1678\t\n",
      "Val Loss:0.2634\tRecon Loss:1.9037\tTriplet Loss:0.1278\tStatic Loss:0.2606\n",
      "\n",
      "\tTime:49.5815\n",
      "\n",
      "Test Loss:0.8324\tRecon Loss:5.7255\tTriplet Loss:0.4521\tStatic Loss:0.8215\n",
      "\n",
      "\tEpoch:133\tTrain Loss:0.1737\tRecon Loss:1.8349\tTriplet Loss:0.0910\tStatic Loss:0.1654\t\n",
      "Val Loss:0.2608\tRecon Loss:1.9340\tTriplet Loss:0.1231\tStatic Loss:0.2578\n",
      "\n",
      "\tTime:49.4209\n",
      "\n",
      "Test Loss:0.8296\tRecon Loss:5.7893\tTriplet Loss:0.4620\tStatic Loss:0.8168\n",
      "\n",
      "\tEpoch:134\tTrain Loss:0.1752\tRecon Loss:1.8490\tTriplet Loss:0.0890\tStatic Loss:0.1671\t\n",
      "Val Loss:0.2699\tRecon Loss:1.9288\tTriplet Loss:0.1396\tStatic Loss:0.2663\n",
      "\n",
      "\tTime:49.5205\n",
      "\n",
      "Test Loss:0.8337\tRecon Loss:5.8063\tTriplet Loss:0.4714\tStatic Loss:0.8202\n",
      "\n",
      "\tEpoch:135\tTrain Loss:0.1779\tRecon Loss:1.8537\tTriplet Loss:0.0949\tStatic Loss:0.1694\t\n",
      "Val Loss:0.2610\tRecon Loss:1.9063\tTriplet Loss:0.1309\tStatic Loss:0.2576\n",
      "\n",
      "\tTime:50.0281\n",
      "\n",
      "Test Loss:0.8321\tRecon Loss:5.7341\tTriplet Loss:0.4436\tStatic Loss:0.8219\n",
      "\n",
      "\tEpoch:136\tTrain Loss:0.1775\tRecon Loss:1.8493\tTriplet Loss:0.0981\tStatic Loss:0.1687\t\n",
      "Val Loss:0.2630\tRecon Loss:1.9174\tTriplet Loss:0.1185\tStatic Loss:0.2610\n",
      "\n",
      "\tTime:50.9968\n",
      "\n",
      "Test Loss:0.8677\tRecon Loss:5.7987\tTriplet Loss:0.4541\tStatic Loss:0.8598\n",
      "\n",
      "\tEpoch:137\tTrain Loss:0.1801\tRecon Loss:1.8426\tTriplet Loss:0.1015\tStatic Loss:0.1714\t\n",
      "Val Loss:0.2719\tRecon Loss:1.9175\tTriplet Loss:0.1374\tStatic Loss:0.2689\n",
      "\n",
      "\tTime:49.7580\n",
      "\n",
      "Test Loss:0.8238\tRecon Loss:5.7435\tTriplet Loss:0.4468\tStatic Loss:0.8123\n",
      "\n",
      "\tEpoch:138\tTrain Loss:0.1805\tRecon Loss:1.8462\tTriplet Loss:0.0981\tStatic Loss:0.1721\t\n",
      "Val Loss:0.2578\tRecon Loss:1.8897\tTriplet Loss:0.1326\tStatic Loss:0.2540\n",
      "\n",
      "\tTime:50.6356\n",
      "\n",
      "Test Loss:0.8280\tRecon Loss:5.6811\tTriplet Loss:0.4526\tStatic Loss:0.8170\n",
      "\n",
      "\tEpoch:139\tTrain Loss:0.1772\tRecon Loss:1.8341\tTriplet Loss:0.0960\tStatic Loss:0.1687\t\n",
      "Val Loss:0.2576\tRecon Loss:1.9100\tTriplet Loss:0.1279\tStatic Loss:0.2541\n",
      "\n",
      "\tTime:49.1898\n",
      "\n",
      "Test Loss:0.8112\tRecon Loss:5.7305\tTriplet Loss:0.4379\tStatic Loss:0.7994\n",
      "\n",
      "\tEpoch:140\tTrain Loss:0.1763\tRecon Loss:1.8270\tTriplet Loss:0.0988\tStatic Loss:0.1675\t\n",
      "Val Loss:0.2565\tRecon Loss:1.9011\tTriplet Loss:0.1276\tStatic Loss:0.2529\n",
      "\n",
      "\tTime:49.3477\n",
      "\n",
      "Test Loss:0.8102\tRecon Loss:5.6919\tTriplet Loss:0.4412\tStatic Loss:0.7983\n",
      "\n",
      "\tEpoch:141\tTrain Loss:0.1733\tRecon Loss:1.8291\tTriplet Loss:0.0944\tStatic Loss:0.1646\t\n",
      "Val Loss:0.2641\tRecon Loss:1.8916\tTriplet Loss:0.1291\tStatic Loss:0.2614\n",
      "\n",
      "\tTime:50.4383\n",
      "\n",
      "Test Loss:0.8445\tRecon Loss:5.7058\tTriplet Loss:0.4655\tStatic Loss:0.8337\n",
      "\n",
      "\tEpoch:142\tTrain Loss:0.1753\tRecon Loss:1.8460\tTriplet Loss:0.1001\tStatic Loss:0.1661\t\n",
      "Val Loss:0.2623\tRecon Loss:1.8928\tTriplet Loss:0.1297\tStatic Loss:0.2592\n",
      "\n",
      "\tTime:50.6140\n",
      "\n",
      "Test Loss:0.8350\tRecon Loss:5.7119\tTriplet Loss:0.4586\tStatic Loss:0.8239\n",
      "\n",
      "\tEpoch:143\tTrain Loss:0.1792\tRecon Loss:1.8542\tTriplet Loss:0.0942\tStatic Loss:0.1709\t\n",
      "Val Loss:0.2599\tRecon Loss:1.9248\tTriplet Loss:0.1228\tStatic Loss:0.2570\n",
      "\n",
      "\tTime:50.5241\n",
      "\n",
      "Test Loss:0.8289\tRecon Loss:5.7195\tTriplet Loss:0.4420\tStatic Loss:0.8187\n",
      "\n",
      "\tEpoch:144\tTrain Loss:0.1720\tRecon Loss:1.8373\tTriplet Loss:0.0950\tStatic Loss:0.1630\t\n",
      "Val Loss:0.2593\tRecon Loss:1.9300\tTriplet Loss:0.1253\tStatic Loss:0.2560\n",
      "\n",
      "\tTime:50.1158\n",
      "\n",
      "Test Loss:0.8260\tRecon Loss:5.7992\tTriplet Loss:0.4295\tStatic Loss:0.8159\n",
      "\n",
      "\tEpoch:145\tTrain Loss:0.1702\tRecon Loss:1.8359\tTriplet Loss:0.0942\tStatic Loss:0.1611\t\n",
      "Val Loss:0.2641\tRecon Loss:1.9163\tTriplet Loss:0.1258\tStatic Loss:0.2614\n",
      "\n",
      "\tTime:48.9881\n",
      "\n",
      "Test Loss:0.8114\tRecon Loss:5.6969\tTriplet Loss:0.4008\tStatic Loss:0.8037\n",
      "\n",
      "\tEpoch:146\tTrain Loss:0.1743\tRecon Loss:1.8327\tTriplet Loss:0.0902\tStatic Loss:0.1661\t\n",
      "Val Loss:0.2614\tRecon Loss:1.8980\tTriplet Loss:0.1348\tStatic Loss:0.2577\n",
      "\n",
      "\tTime:49.4128\n",
      "\n",
      "Test Loss:0.8173\tRecon Loss:5.6951\tTriplet Loss:0.4396\tStatic Loss:0.8062\n",
      "\n",
      "\tEpoch:147\tTrain Loss:0.1721\tRecon Loss:1.8341\tTriplet Loss:0.0923\tStatic Loss:0.1635\t\n",
      "Val Loss:0.2617\tRecon Loss:1.9207\tTriplet Loss:0.1316\tStatic Loss:0.2581\n",
      "\n",
      "\tTime:49.3043\n",
      "\n",
      "Test Loss:0.8186\tRecon Loss:5.7945\tTriplet Loss:0.4329\tStatic Loss:0.8075\n",
      "\n",
      "\tEpoch:148\tTrain Loss:0.1793\tRecon Loss:1.8497\tTriplet Loss:0.1003\tStatic Loss:0.1705\t\n",
      "Val Loss:0.2605\tRecon Loss:1.9124\tTriplet Loss:0.1352\tStatic Loss:0.2565\n",
      "\n",
      "\tTime:49.5276\n",
      "\n",
      "Test Loss:0.8203\tRecon Loss:5.7359\tTriplet Loss:0.4159\tStatic Loss:0.8116\n",
      "\n",
      "\tEpoch:149\tTrain Loss:0.1851\tRecon Loss:1.8664\tTriplet Loss:0.1017\tStatic Loss:0.1767\t\n",
      "Val Loss:0.2721\tRecon Loss:1.9538\tTriplet Loss:0.1355\tStatic Loss:0.2689\n",
      "\n",
      "\tTime:48.8563\n",
      "\n",
      "Test Loss:0.8646\tRecon Loss:5.8052\tTriplet Loss:0.4744\tStatic Loss:0.8542\n",
      "\n",
      "\tEpoch:150\tTrain Loss:0.1818\tRecon Loss:1.8484\tTriplet Loss:0.1025\tStatic Loss:0.1730\t\n",
      "Val Loss:0.2538\tRecon Loss:1.9076\tTriplet Loss:0.1153\tStatic Loss:0.2511\n",
      "\n",
      "\tTime:48.5452\n",
      "\n",
      "Test Loss:0.8130\tRecon Loss:5.7753\tTriplet Loss:0.4552\tStatic Loss:0.7991\n",
      "\n",
      "\tEpoch:151\tTrain Loss:0.1794\tRecon Loss:1.8430\tTriplet Loss:0.0964\tStatic Loss:0.1710\t\n",
      "Val Loss:0.2594\tRecon Loss:1.9193\tTriplet Loss:0.1388\tStatic Loss:0.2548\n",
      "\n",
      "\tTime:49.6368\n",
      "\n",
      "Test Loss:0.8237\tRecon Loss:5.7421\tTriplet Loss:0.4201\tStatic Loss:0.8149\n",
      "\n",
      "\tEpoch:152\tTrain Loss:0.1713\tRecon Loss:1.8467\tTriplet Loss:0.0955\tStatic Loss:0.1621\t\n",
      "Val Loss:0.2585\tRecon Loss:1.9156\tTriplet Loss:0.1219\tStatic Loss:0.2556\n",
      "\n",
      "\tTime:49.2726\n",
      "\n",
      "Test Loss:0.8234\tRecon Loss:5.8628\tTriplet Loss:0.4249\tStatic Loss:0.8129\n",
      "\n",
      "\tEpoch:153\tTrain Loss:0.1990\tRecon Loss:1.8772\tTriplet Loss:0.1096\tStatic Loss:0.1912\t\n",
      "Val Loss:0.2577\tRecon Loss:1.9135\tTriplet Loss:0.1345\tStatic Loss:0.2534\n",
      "\n",
      "\tTime:48.2193\n",
      "\n",
      "Test Loss:0.8205\tRecon Loss:5.7734\tTriplet Loss:0.4548\tStatic Loss:0.8075\n",
      "\n",
      "\tEpoch:154\tTrain Loss:0.1879\tRecon Loss:1.8521\tTriplet Loss:0.1044\tStatic Loss:0.1796\t\n",
      "Val Loss:0.2609\tRecon Loss:1.9125\tTriplet Loss:0.1336\tStatic Loss:0.2571\n",
      "\n",
      "\tTime:48.6689\n",
      "\n",
      "Test Loss:0.8362\tRecon Loss:5.7282\tTriplet Loss:0.4462\tStatic Loss:0.8262\n",
      "\n",
      "\tEpoch:155\tTrain Loss:0.1896\tRecon Loss:1.8473\tTriplet Loss:0.1068\tStatic Loss:0.1813\t\n",
      "Val Loss:0.2645\tRecon Loss:1.9326\tTriplet Loss:0.1308\tStatic Loss:0.2612\n",
      "\n",
      "\tTime:49.2731\n",
      "\n",
      "Test Loss:0.8486\tRecon Loss:5.7979\tTriplet Loss:0.4555\tStatic Loss:0.8384\n",
      "\n",
      "\tEpoch:156\tTrain Loss:0.1772\tRecon Loss:1.8303\tTriplet Loss:0.0964\tStatic Loss:0.1687\t\n",
      "Val Loss:0.2547\tRecon Loss:1.9022\tTriplet Loss:0.1286\tStatic Loss:0.2508\n",
      "\n",
      "\tTime:50.2447\n",
      "\n",
      "Test Loss:0.8119\tRecon Loss:5.7014\tTriplet Loss:0.4260\tStatic Loss:0.8016\n",
      "\n",
      "\tEpoch:157\tTrain Loss:0.1715\tRecon Loss:1.8247\tTriplet Loss:0.0933\tStatic Loss:0.1628\t\n",
      "Val Loss:0.2603\tRecon Loss:1.9235\tTriplet Loss:0.1310\tStatic Loss:0.2565\n",
      "\n",
      "\tTime:49.7929\n",
      "\n",
      "Test Loss:0.8228\tRecon Loss:5.7324\tTriplet Loss:0.4343\tStatic Loss:0.8126\n",
      "\n",
      "\tEpoch:158\tTrain Loss:0.1746\tRecon Loss:1.8246\tTriplet Loss:0.0959\tStatic Loss:0.1660\t\n",
      "Val Loss:0.2570\tRecon Loss:1.9046\tTriplet Loss:0.1392\tStatic Loss:0.2523\n",
      "\n",
      "\tTime:49.0375\n",
      "\n",
      "Test Loss:0.8274\tRecon Loss:5.6853\tTriplet Loss:0.4733\tStatic Loss:0.8142\n",
      "\n",
      "\tEpoch:159\tTrain Loss:0.1717\tRecon Loss:1.8293\tTriplet Loss:0.0964\tStatic Loss:0.1626\t\n",
      "Val Loss:0.2612\tRecon Loss:1.9082\tTriplet Loss:0.1398\tStatic Loss:0.2569\n",
      "\n",
      "\tTime:49.6173\n",
      "\n",
      "Test Loss:0.8458\tRecon Loss:5.8177\tTriplet Loss:0.4440\tStatic Loss:0.8363\n",
      "\n",
      "\tEpoch:160\tTrain Loss:0.1797\tRecon Loss:1.8414\tTriplet Loss:0.1006\tStatic Loss:0.1710\t\n",
      "Val Loss:0.2623\tRecon Loss:1.9542\tTriplet Loss:0.1237\tStatic Loss:0.2593\n",
      "\n",
      "\tTime:50.2006\n",
      "\n",
      "Test Loss:0.8278\tRecon Loss:5.7626\tTriplet Loss:0.4467\tStatic Loss:0.8166\n",
      "\n",
      "\tEpoch:161\tTrain Loss:0.1710\tRecon Loss:1.8305\tTriplet Loss:0.0950\tStatic Loss:0.1620\t\n",
      "Val Loss:0.2550\tRecon Loss:1.9130\tTriplet Loss:0.1282\tStatic Loss:0.2511\n",
      "\n",
      "\tTime:50.2760\n",
      "\n",
      "Test Loss:0.8231\tRecon Loss:5.7571\tTriplet Loss:0.4382\tStatic Loss:0.8122\n",
      "\n",
      "\tEpoch:162\tTrain Loss:0.1690\tRecon Loss:1.8268\tTriplet Loss:0.0919\tStatic Loss:0.1601\t\n",
      "Val Loss:0.2554\tRecon Loss:1.9278\tTriplet Loss:0.1243\tStatic Loss:0.2517\n",
      "\n",
      "\tTime:49.2285\n",
      "\n",
      "Test Loss:0.8115\tRecon Loss:5.7371\tTriplet Loss:0.4551\tStatic Loss:0.7978\n",
      "\n",
      "\tEpoch:163\tTrain Loss:0.1687\tRecon Loss:1.8350\tTriplet Loss:0.0872\tStatic Loss:0.1601\t\n",
      "Val Loss:0.2594\tRecon Loss:1.9410\tTriplet Loss:0.1426\tStatic Loss:0.2543\n",
      "\n",
      "\tTime:49.5619\n",
      "\n",
      "Test Loss:0.8295\tRecon Loss:5.7508\tTriplet Loss:0.4115\tStatic Loss:0.8221\n",
      "\n",
      "\tEpoch:164\tTrain Loss:0.1704\tRecon Loss:2.0118\tTriplet Loss:0.0944\tStatic Loss:0.1596\t\n",
      "Val Loss:0.2632\tRecon Loss:1.9665\tTriplet Loss:0.1192\tStatic Loss:0.2606\n",
      "\n",
      "\tTime:49.2112\n",
      "\n",
      "Test Loss:0.8172\tRecon Loss:5.9274\tTriplet Loss:0.4297\tStatic Loss:0.8049\n",
      "\n",
      "\tEpoch:165\tTrain Loss:0.1780\tRecon Loss:1.8787\tTriplet Loss:0.0983\tStatic Loss:0.1689\t\n",
      "Val Loss:0.2589\tRecon Loss:1.9271\tTriplet Loss:0.1328\tStatic Loss:0.2549\n",
      "\n",
      "\tTime:50.0486\n",
      "\n",
      "Test Loss:0.8204\tRecon Loss:5.8097\tTriplet Loss:0.4633\tStatic Loss:0.8063\n",
      "\n",
      "\tEpoch:166\tTrain Loss:0.1703\tRecon Loss:1.8492\tTriplet Loss:0.0944\tStatic Loss:0.1611\t\n",
      "Val Loss:0.2567\tRecon Loss:1.9397\tTriplet Loss:0.1284\tStatic Loss:0.2527\n",
      "\n",
      "\tTime:50.8358\n",
      "\n",
      "Test Loss:0.8086\tRecon Loss:5.8385\tTriplet Loss:0.4229\tStatic Loss:0.7969\n",
      "\n",
      "\tEpoch:167\tTrain Loss:0.1683\tRecon Loss:1.8403\tTriplet Loss:0.0927\tStatic Loss:0.1592\t\n",
      "Val Loss:0.2566\tRecon Loss:1.9283\tTriplet Loss:0.1240\tStatic Loss:0.2532\n",
      "\n",
      "\tTime:49.6890\n",
      "\n",
      "Test Loss:0.8363\tRecon Loss:5.8225\tTriplet Loss:0.4605\tStatic Loss:0.8241\n",
      "\n",
      "\tEpoch:168\tTrain Loss:0.1676\tRecon Loss:1.8336\tTriplet Loss:0.0893\tStatic Loss:0.1587\t\n",
      "Val Loss:0.2571\tRecon Loss:1.9345\tTriplet Loss:0.1323\tStatic Loss:0.2528\n",
      "\n",
      "\tTime:49.7067\n",
      "\n",
      "Test Loss:0.8196\tRecon Loss:5.8084\tTriplet Loss:0.4451\tStatic Loss:0.8071\n",
      "\n",
      "\tEpoch:169\tTrain Loss:0.1733\tRecon Loss:1.8406\tTriplet Loss:0.0990\tStatic Loss:0.1640\t\n",
      "Val Loss:0.2580\tRecon Loss:1.9305\tTriplet Loss:0.1220\tStatic Loss:0.2549\n",
      "\n",
      "\tTime:49.6920\n",
      "\n",
      "Test Loss:0.8369\tRecon Loss:5.7300\tTriplet Loss:0.4411\tStatic Loss:0.8276\n",
      "\n",
      "\tEpoch:170\tTrain Loss:0.1831\tRecon Loss:1.8503\tTriplet Loss:0.0982\tStatic Loss:0.1749\t\n",
      "Val Loss:0.2579\tRecon Loss:1.9167\tTriplet Loss:0.1202\tStatic Loss:0.2551\n",
      "\n",
      "\tTime:48.8194\n",
      "\n",
      "Test Loss:0.8534\tRecon Loss:5.7197\tTriplet Loss:0.4621\tStatic Loss:0.8439\n",
      "\n",
      "\tEpoch:171\tTrain Loss:0.1802\tRecon Loss:1.8403\tTriplet Loss:0.1023\tStatic Loss:0.1714\t\n",
      "Val Loss:0.2514\tRecon Loss:1.8971\tTriplet Loss:0.1206\tStatic Loss:0.2480\n",
      "\n",
      "\tTime:50.4887\n",
      "\n",
      "Test Loss:0.8087\tRecon Loss:5.7582\tTriplet Loss:0.4528\tStatic Loss:0.7948\n",
      "\n",
      "\tEpoch:172\tTrain Loss:0.1748\tRecon Loss:1.8414\tTriplet Loss:0.0928\tStatic Loss:0.1664\t\n",
      "Val Loss:0.2551\tRecon Loss:1.9187\tTriplet Loss:0.1218\tStatic Loss:0.2518\n",
      "\n",
      "\tTime:49.4771\n",
      "\n",
      "Test Loss:0.8086\tRecon Loss:5.8157\tTriplet Loss:0.4229\tStatic Loss:0.7971\n",
      "\n",
      "\tEpoch:173\tTrain Loss:0.1811\tRecon Loss:1.8403\tTriplet Loss:0.0995\tStatic Loss:0.1727\t\n",
      "Val Loss:0.2608\tRecon Loss:1.9517\tTriplet Loss:0.1351\tStatic Loss:0.2564\n",
      "\n",
      "\tTime:48.9776\n",
      "\n",
      "Test Loss:0.8480\tRecon Loss:5.7814\tTriplet Loss:0.4455\tStatic Loss:0.8389\n",
      "\n",
      "\tEpoch:174\tTrain Loss:0.1785\tRecon Loss:1.8290\tTriplet Loss:0.1012\tStatic Loss:0.1697\t\n",
      "Val Loss:0.2590\tRecon Loss:1.9158\tTriplet Loss:0.1218\tStatic Loss:0.2561\n",
      "\n",
      "\tTime:49.2443\n",
      "\n",
      "Test Loss:0.8402\tRecon Loss:5.7549\tTriplet Loss:0.4412\tStatic Loss:0.8309\n",
      "\n",
      "\tEpoch:175\tTrain Loss:0.1742\tRecon Loss:1.8356\tTriplet Loss:0.0950\tStatic Loss:0.1655\t\n",
      "Val Loss:0.2608\tRecon Loss:1.8921\tTriplet Loss:0.1319\tStatic Loss:0.2574\n",
      "\n",
      "\tTime:49.4426\n",
      "\n",
      "Test Loss:0.8489\tRecon Loss:5.7324\tTriplet Loss:0.4309\tStatic Loss:0.8418\n",
      "\n",
      "\tEpoch:176\tTrain Loss:0.1699\tRecon Loss:1.8374\tTriplet Loss:0.0882\tStatic Loss:0.1613\t\n",
      "Val Loss:0.2572\tRecon Loss:1.8973\tTriplet Loss:0.1195\tStatic Loss:0.2546\n",
      "\n",
      "\tTime:49.3888\n",
      "\n",
      "Test Loss:0.8219\tRecon Loss:5.7454\tTriplet Loss:0.4374\tStatic Loss:0.8111\n",
      "\n",
      "\tEpoch:177\tTrain Loss:0.1681\tRecon Loss:1.8217\tTriplet Loss:0.0926\tStatic Loss:0.1592\t\n",
      "Val Loss:0.2582\tRecon Loss:1.8995\tTriplet Loss:0.1325\tStatic Loss:0.2543\n",
      "\n",
      "\tTime:48.8224\n",
      "\n",
      "Test Loss:0.8278\tRecon Loss:5.7469\tTriplet Loss:0.4438\tStatic Loss:0.8170\n",
      "\n",
      "\tEpoch:178\tTrain Loss:0.1688\tRecon Loss:1.8388\tTriplet Loss:0.0930\tStatic Loss:0.1597\t\n",
      "Val Loss:0.2581\tRecon Loss:1.9026\tTriplet Loss:0.1234\tStatic Loss:0.2551\n",
      "\n",
      "\tTime:49.6801\n",
      "\n",
      "Test Loss:0.8331\tRecon Loss:5.7499\tTriplet Loss:0.4058\tStatic Loss:0.8267\n",
      "\n",
      "\tEpoch:179\tTrain Loss:0.1681\tRecon Loss:1.8315\tTriplet Loss:0.0911\tStatic Loss:0.1591\t\n",
      "Val Loss:0.2611\tRecon Loss:1.9581\tTriplet Loss:0.1239\tStatic Loss:0.2578\n",
      "\n",
      "\tTime:49.5617\n",
      "\n",
      "Test Loss:0.8269\tRecon Loss:5.9899\tTriplet Loss:0.4451\tStatic Loss:0.8134\n",
      "\n",
      "\tEpoch:180\tTrain Loss:0.1678\tRecon Loss:1.8364\tTriplet Loss:0.0866\tStatic Loss:0.1593\t\n",
      "Val Loss:0.2631\tRecon Loss:1.9307\tTriplet Loss:0.1195\tStatic Loss:0.2607\n",
      "\n",
      "\tTime:48.6820\n",
      "\n",
      "Test Loss:0.8475\tRecon Loss:5.9120\tTriplet Loss:0.4572\tStatic Loss:0.8359\n",
      "\n",
      "\tEpoch:181\tTrain Loss:0.1744\tRecon Loss:1.8348\tTriplet Loss:0.0980\tStatic Loss:0.1654\t\n",
      "Val Loss:0.2568\tRecon Loss:1.9262\tTriplet Loss:0.1247\tStatic Loss:0.2533\n",
      "\n",
      "\tTime:49.2864\n",
      "\n",
      "Test Loss:0.8329\tRecon Loss:5.7758\tTriplet Loss:0.4594\tStatic Loss:0.8209\n",
      "\n",
      "\tEpoch:182\tTrain Loss:0.1712\tRecon Loss:1.8320\tTriplet Loss:0.0939\tStatic Loss:0.1624\t\n",
      "Val Loss:0.2542\tRecon Loss:1.9098\tTriplet Loss:0.1358\tStatic Loss:0.2494\n",
      "\n",
      "\tTime:48.2030\n",
      "\n",
      "Test Loss:0.8180\tRecon Loss:5.7968\tTriplet Loss:0.4492\tStatic Loss:0.8051\n",
      "\n",
      "\tEpoch:183\tTrain Loss:0.1707\tRecon Loss:1.8372\tTriplet Loss:0.0967\tStatic Loss:0.1614\t\n",
      "Val Loss:0.2580\tRecon Loss:1.9213\tTriplet Loss:0.1283\tStatic Loss:0.2543\n",
      "\n",
      "\tTime:49.6513\n",
      "\n",
      "Test Loss:0.8208\tRecon Loss:5.7930\tTriplet Loss:0.4458\tStatic Loss:0.8085\n",
      "\n",
      "\tEpoch:184\tTrain Loss:0.1687\tRecon Loss:1.8351\tTriplet Loss:0.0864\tStatic Loss:0.1603\t\n",
      "Val Loss:0.2570\tRecon Loss:1.9074\tTriplet Loss:0.1270\tStatic Loss:0.2535\n",
      "\n",
      "\tTime:50.0543\n",
      "\n",
      "Test Loss:0.8137\tRecon Loss:5.7373\tTriplet Loss:0.4275\tStatic Loss:0.8030\n",
      "\n",
      "\tEpoch:185\tTrain Loss:0.1729\tRecon Loss:1.8317\tTriplet Loss:0.0996\tStatic Loss:0.1636\t\n",
      "Val Loss:0.2594\tRecon Loss:1.9409\tTriplet Loss:0.1211\tStatic Loss:0.2564\n",
      "\n",
      "\tTime:48.2878\n",
      "\n",
      "Test Loss:0.8243\tRecon Loss:5.8995\tTriplet Loss:0.4388\tStatic Loss:0.8121\n",
      "\n",
      "\tEpoch:186\tTrain Loss:0.1762\tRecon Loss:1.8329\tTriplet Loss:0.0951\tStatic Loss:0.1677\t\n",
      "Val Loss:0.2595\tRecon Loss:1.9054\tTriplet Loss:0.1328\tStatic Loss:0.2557\n",
      "\n",
      "\tTime:48.6417\n",
      "\n",
      "Test Loss:0.8219\tRecon Loss:5.7819\tTriplet Loss:0.4218\tStatic Loss:0.8123\n",
      "\n",
      "\tEpoch:187\tTrain Loss:0.1723\tRecon Loss:1.8251\tTriplet Loss:0.0987\tStatic Loss:0.1631\t\n",
      "Val Loss:0.2595\tRecon Loss:1.9061\tTriplet Loss:0.1265\tStatic Loss:0.2563\n",
      "\n",
      "\tTime:48.3557\n",
      "\n",
      "Test Loss:0.8167\tRecon Loss:5.7491\tTriplet Loss:0.4258\tStatic Loss:0.8065\n",
      "\n",
      "\tEpoch:188\tTrain Loss:0.1695\tRecon Loss:1.8297\tTriplet Loss:0.0938\tStatic Loss:0.1605\t\n",
      "Val Loss:0.2575\tRecon Loss:1.9007\tTriplet Loss:0.1195\tStatic Loss:0.2548\n",
      "\n",
      "\tTime:44.4288\n",
      "\n",
      "Test Loss:0.8178\tRecon Loss:5.7520\tTriplet Loss:0.4420\tStatic Loss:0.8061\n",
      "\n",
      "\tEpoch:189\tTrain Loss:0.1662\tRecon Loss:1.8270\tTriplet Loss:0.0950\tStatic Loss:0.1567\t\n",
      "Val Loss:0.2559\tRecon Loss:1.9081\tTriplet Loss:0.1302\tStatic Loss:0.2519\n",
      "\n",
      "\tTime:46.8776\n",
      "\n",
      "Test Loss:0.8232\tRecon Loss:5.7344\tTriplet Loss:0.4491\tStatic Loss:0.8115\n",
      "\n",
      "\tEpoch:190\tTrain Loss:0.1680\tRecon Loss:1.8223\tTriplet Loss:0.0937\tStatic Loss:0.1589\t\n",
      "Val Loss:0.2559\tRecon Loss:1.9027\tTriplet Loss:0.1237\tStatic Loss:0.2527\n",
      "\n",
      "\tTime:49.2033\n",
      "\n",
      "Test Loss:0.8216\tRecon Loss:5.7777\tTriplet Loss:0.4390\tStatic Loss:0.8103\n",
      "\n",
      "\tEpoch:191\tTrain Loss:0.1666\tRecon Loss:1.8413\tTriplet Loss:0.0908\tStatic Loss:0.1575\t\n",
      "Val Loss:0.2583\tRecon Loss:1.9060\tTriplet Loss:0.1196\tStatic Loss:0.2557\n",
      "\n",
      "\tTime:49.2405\n",
      "\n",
      "Test Loss:0.8363\tRecon Loss:5.8002\tTriplet Loss:0.4637\tStatic Loss:0.8239\n",
      "\n",
      "\tEpoch:192\tTrain Loss:0.1677\tRecon Loss:1.8266\tTriplet Loss:0.0939\tStatic Loss:0.1585\t\n",
      "Val Loss:0.2575\tRecon Loss:1.9105\tTriplet Loss:0.1279\tStatic Loss:0.2539\n",
      "\n",
      "\tTime:48.8371\n",
      "\n",
      "Test Loss:0.8203\tRecon Loss:5.7196\tTriplet Loss:0.4111\tStatic Loss:0.8122\n",
      "\n",
      "\tEpoch:193\tTrain Loss:0.1693\tRecon Loss:1.8270\tTriplet Loss:0.0950\tStatic Loss:0.1602\t\n",
      "Val Loss:0.2612\tRecon Loss:1.9003\tTriplet Loss:0.1359\tStatic Loss:0.2574\n",
      "\n",
      "\tTime:48.9834\n",
      "\n",
      "Test Loss:0.8480\tRecon Loss:5.7436\tTriplet Loss:0.4389\tStatic Loss:0.8400\n",
      "\n",
      "\tEpoch:194\tTrain Loss:0.1670\tRecon Loss:1.8312\tTriplet Loss:0.0898\tStatic Loss:0.1580\t\n",
      "Val Loss:0.2587\tRecon Loss:1.8961\tTriplet Loss:0.1239\tStatic Loss:0.2559\n",
      "\n",
      "\tTime:49.7907\n",
      "\n",
      "Test Loss:0.8268\tRecon Loss:5.7044\tTriplet Loss:0.4447\tStatic Loss:0.8163\n",
      "\n",
      "\tEpoch:195\tTrain Loss:0.1666\tRecon Loss:1.8318\tTriplet Loss:0.0953\tStatic Loss:0.1571\t\n",
      "Val Loss:0.2570\tRecon Loss:1.9107\tTriplet Loss:0.1312\tStatic Loss:0.2531\n",
      "\n",
      "\tTime:49.0481\n",
      "\n",
      "Test Loss:0.8344\tRecon Loss:5.7264\tTriplet Loss:0.4410\tStatic Loss:0.8248\n",
      "\n",
      "\tEpoch:196\tTrain Loss:0.1664\tRecon Loss:1.8224\tTriplet Loss:0.0907\tStatic Loss:0.1574\t\n",
      "Val Loss:0.2590\tRecon Loss:1.9143\tTriplet Loss:0.1210\tStatic Loss:0.2563\n",
      "\n",
      "\tTime:48.9993\n",
      "\n",
      "Test Loss:0.8206\tRecon Loss:5.7689\tTriplet Loss:0.4191\tStatic Loss:0.8112\n",
      "\n",
      "\tEpoch:197\tTrain Loss:0.1673\tRecon Loss:1.8322\tTriplet Loss:0.0895\tStatic Loss:0.1584\t\n",
      "Val Loss:0.2568\tRecon Loss:1.9103\tTriplet Loss:0.1308\tStatic Loss:0.2528\n",
      "\n",
      "\tTime:49.1263\n",
      "\n",
      "Test Loss:0.8337\tRecon Loss:5.7921\tTriplet Loss:0.4372\tStatic Loss:0.8238\n",
      "\n",
      "\tEpoch:198\tTrain Loss:0.1663\tRecon Loss:1.8368\tTriplet Loss:0.0937\tStatic Loss:0.1569\t\n",
      "Val Loss:0.2621\tRecon Loss:1.9200\tTriplet Loss:0.1361\tStatic Loss:0.2582\n",
      "\n",
      "\tTime:48.3670\n",
      "\n",
      "Test Loss:0.8302\tRecon Loss:5.7882\tTriplet Loss:0.4449\tStatic Loss:0.8191\n",
      "\n",
      "\tEpoch:199\tTrain Loss:0.1906\tRecon Loss:1.8865\tTriplet Loss:0.1031\tStatic Loss:0.1824\t\n",
      "Val Loss:0.2504\tRecon Loss:1.8883\tTriplet Loss:0.1233\tStatic Loss:0.2467\n",
      "\n",
      "\tTime:48.8665\n",
      "\n",
      "Test Loss:0.8054\tRecon Loss:5.7359\tTriplet Loss:0.4695\tStatic Loss:0.7897\n",
      "\n",
      "\t\n",
      "Unc Est in Static characteristics:0.0007\tUnc Est in Streamflow, dynamic:0.0004\t\n",
      "\n",
      "\tATT_NL_3\n",
      "Epoch:0\tTrain Loss:0.5575\tRecon Loss:4.0877\tTriplet Loss:0.3909\tStatic Loss:0.5388\t\n",
      "Val Loss:0.4147\tRecon Loss:4.0267\tTriplet Loss:0.2437\tStatic Loss:0.3956\n",
      "\n",
      "\tTime:48.8719\n",
      "\n",
      "Test Loss:1.2361\tRecon Loss:11.9585\tTriplet Loss:0.8138\tStatic Loss:1.1712\n",
      "\n",
      "\tEpoch:1\tTrain Loss:0.3785\tRecon Loss:3.9593\tTriplet Loss:0.2226\tStatic Loss:0.3582\t\n",
      "Val Loss:0.3683\tRecon Loss:4.0177\tTriplet Loss:0.1970\tStatic Loss:0.3489\n",
      "\n",
      "\tTime:49.0648\n",
      "\n",
      "Test Loss:1.1166\tRecon Loss:11.8799\tTriplet Loss:0.6214\tStatic Loss:1.0585\n",
      "\n",
      "\tEpoch:2\tTrain Loss:0.3456\tRecon Loss:3.9536\tTriplet Loss:0.1878\tStatic Loss:0.3253\t\n",
      "Val Loss:0.3419\tRecon Loss:4.0146\tTriplet Loss:0.1608\tStatic Loss:0.3233\n",
      "\n",
      "\tTime:49.9264\n",
      "\n",
      "Test Loss:1.0572\tRecon Loss:11.8793\tTriplet Loss:0.5629\tStatic Loss:0.9984\n",
      "\n",
      "\tEpoch:3\tTrain Loss:0.3280\tRecon Loss:3.9380\tTriplet Loss:0.1701\tStatic Loss:0.3077\t\n",
      "Val Loss:0.3316\tRecon Loss:3.9959\tTriplet Loss:0.1571\tStatic Loss:0.3124\n",
      "\n",
      "\tTime:49.6807\n",
      "\n",
      "Test Loss:1.0377\tRecon Loss:11.8221\tTriplet Loss:0.5179\tStatic Loss:0.9819\n",
      "\n",
      "\tEpoch:4\tTrain Loss:0.3143\tRecon Loss:3.9234\tTriplet Loss:0.1594\tStatic Loss:0.2937\t\n",
      "Val Loss:0.3241\tRecon Loss:3.9778\tTriplet Loss:0.1643\tStatic Loss:0.3036\n",
      "\n",
      "\tTime:50.9371\n",
      "\n",
      "Test Loss:1.0153\tRecon Loss:11.7874\tTriplet Loss:0.4976\tStatic Loss:0.9594\n",
      "\n",
      "\tEpoch:5\tTrain Loss:0.3031\tRecon Loss:3.8502\tTriplet Loss:0.1485\tStatic Loss:0.2831\t\n",
      "Val Loss:0.3140\tRecon Loss:3.8743\tTriplet Loss:0.1552\tStatic Loss:0.2943\n",
      "\n",
      "\tTime:50.3348\n",
      "\n",
      "Test Loss:0.9803\tRecon Loss:11.4561\tTriplet Loss:0.5115\tStatic Loss:0.9224\n",
      "\n",
      "\tEpoch:6\tTrain Loss:0.2925\tRecon Loss:3.7508\tTriplet Loss:0.1495\tStatic Loss:0.2722\t\n",
      "Val Loss:0.3102\tRecon Loss:3.7211\tTriplet Loss:0.1506\tStatic Loss:0.2921\n",
      "\n",
      "\tTime:48.7065\n",
      "\n",
      "Test Loss:0.9647\tRecon Loss:11.1090\tTriplet Loss:0.4871\tStatic Loss:0.9110\n",
      "\n",
      "\tEpoch:7\tTrain Loss:0.2793\tRecon Loss:2.9319\tTriplet Loss:0.1451\tStatic Loss:0.2662\t\n",
      "Val Loss:0.2932\tRecon Loss:2.5853\tTriplet Loss:0.1490\tStatic Loss:0.2847\n",
      "\n",
      "\tTime:48.7289\n",
      "\n",
      "Test Loss:0.9356\tRecon Loss:7.4631\tTriplet Loss:0.5224\tStatic Loss:0.9116\n",
      "\n",
      "\tEpoch:8\tTrain Loss:0.2677\tRecon Loss:2.2815\tTriplet Loss:0.1473\tStatic Loss:0.2596\t\n",
      "Val Loss:0.2843\tRecon Loss:2.1870\tTriplet Loss:0.1475\tStatic Loss:0.2789\n",
      "\n",
      "\tTime:47.0524\n",
      "\n",
      "Test Loss:0.8948\tRecon Loss:6.4045\tTriplet Loss:0.4878\tStatic Loss:0.8804\n",
      "\n",
      "\tEpoch:9\tTrain Loss:0.2614\tRecon Loss:2.0980\tTriplet Loss:0.1403\tStatic Loss:0.2552\t\n",
      "Val Loss:0.2833\tRecon Loss:2.0921\tTriplet Loss:0.1420\tStatic Loss:0.2794\n",
      "\n",
      "\tTime:48.9267\n",
      "\n",
      "Test Loss:0.9180\tRecon Loss:6.1627\tTriplet Loss:0.5129\tStatic Loss:0.9061\n",
      "\n",
      "\tEpoch:10\tTrain Loss:0.2553\tRecon Loss:2.0102\tTriplet Loss:0.1319\tStatic Loss:0.2501\t\n",
      "Val Loss:0.2855\tRecon Loss:2.1192\tTriplet Loss:0.1519\tStatic Loss:0.2805\n",
      "\n",
      "\tTime:48.6587\n",
      "\n",
      "Test Loss:0.9251\tRecon Loss:6.1588\tTriplet Loss:0.5023\tStatic Loss:0.9151\n",
      "\n",
      "\tEpoch:11\tTrain Loss:0.2506\tRecon Loss:1.9537\tTriplet Loss:0.1329\tStatic Loss:0.2454\t\n",
      "Val Loss:0.2763\tRecon Loss:2.0350\tTriplet Loss:0.1478\tStatic Loss:0.2715\n",
      "\n",
      "\tTime:47.3299\n",
      "\n",
      "Test Loss:0.8593\tRecon Loss:5.9536\tTriplet Loss:0.5037\tStatic Loss:0.8439\n",
      "\n",
      "\tEpoch:12\tTrain Loss:0.2464\tRecon Loss:1.9304\tTriplet Loss:0.1291\tStatic Loss:0.2412\t\n",
      "Val Loss:0.2734\tRecon Loss:1.9700\tTriplet Loss:0.1384\tStatic Loss:0.2700\n",
      "\n",
      "\tTime:48.0979\n",
      "\n",
      "Test Loss:0.8869\tRecon Loss:5.8953\tTriplet Loss:0.4835\tStatic Loss:0.8772\n",
      "\n",
      "\tEpoch:13\tTrain Loss:0.2436\tRecon Loss:1.9140\tTriplet Loss:0.1313\tStatic Loss:0.2382\t\n",
      "Val Loss:0.2840\tRecon Loss:1.9894\tTriplet Loss:0.1374\tStatic Loss:0.2816\n",
      "\n",
      "\tTime:47.4446\n",
      "\n",
      "Test Loss:0.8878\tRecon Loss:5.8622\tTriplet Loss:0.4616\tStatic Loss:0.8807\n",
      "\n",
      "\tEpoch:14\tTrain Loss:0.2416\tRecon Loss:1.9144\tTriplet Loss:0.1229\tStatic Loss:0.2367\t\n",
      "Val Loss:0.2750\tRecon Loss:2.0405\tTriplet Loss:0.1444\tStatic Loss:0.2704\n",
      "\n",
      "\tTime:48.9412\n",
      "\n",
      "Test Loss:0.8786\tRecon Loss:5.9393\tTriplet Loss:0.4668\tStatic Loss:0.8692\n",
      "\n",
      "\tEpoch:15\tTrain Loss:0.2375\tRecon Loss:1.9241\tTriplet Loss:0.1224\tStatic Loss:0.2321\t\n",
      "Val Loss:0.2765\tRecon Loss:1.9917\tTriplet Loss:0.1420\tStatic Loss:0.2728\n",
      "\n",
      "\tTime:48.7548\n",
      "\n",
      "Test Loss:0.8624\tRecon Loss:5.8488\tTriplet Loss:0.4547\tStatic Loss:0.8533\n",
      "\n",
      "\tEpoch:16\tTrain Loss:0.2368\tRecon Loss:1.9116\tTriplet Loss:0.1261\tStatic Loss:0.2312\t\n",
      "Val Loss:0.2726\tRecon Loss:1.9751\tTriplet Loss:0.1454\tStatic Loss:0.2683\n",
      "\n",
      "\tTime:48.8355\n",
      "\n",
      "Test Loss:0.8535\tRecon Loss:5.8597\tTriplet Loss:0.4799\tStatic Loss:0.8408\n",
      "\n",
      "\tEpoch:17\tTrain Loss:0.2340\tRecon Loss:1.8885\tTriplet Loss:0.1221\tStatic Loss:0.2286\t\n",
      "Val Loss:0.2758\tRecon Loss:1.9503\tTriplet Loss:0.1362\tStatic Loss:0.2730\n",
      "\n",
      "\tTime:48.9665\n",
      "\n",
      "Test Loss:0.8494\tRecon Loss:5.7876\tTriplet Loss:0.4689\tStatic Loss:0.8381\n",
      "\n",
      "\tEpoch:18\tTrain Loss:0.2294\tRecon Loss:1.8790\tTriplet Loss:0.1223\tStatic Loss:0.2236\t\n",
      "Val Loss:0.2714\tRecon Loss:1.9649\tTriplet Loss:0.1404\tStatic Loss:0.2676\n",
      "\n",
      "\tTime:48.4246\n",
      "\n",
      "Test Loss:0.8385\tRecon Loss:5.7505\tTriplet Loss:0.4628\tStatic Loss:0.8269\n",
      "\n",
      "\tEpoch:19\tTrain Loss:0.2339\tRecon Loss:1.9388\tTriplet Loss:0.1167\tStatic Loss:0.2286\t\n",
      "Val Loss:0.2783\tRecon Loss:1.9552\tTriplet Loss:0.1365\tStatic Loss:0.2757\n",
      "\n",
      "\tTime:48.4631\n",
      "\n",
      "Test Loss:0.8653\tRecon Loss:5.8541\tTriplet Loss:0.4731\tStatic Loss:0.8546\n",
      "\n",
      "\tEpoch:20\tTrain Loss:0.2277\tRecon Loss:1.8695\tTriplet Loss:0.1163\tStatic Loss:0.2224\t\n",
      "Val Loss:0.2680\tRecon Loss:1.9561\tTriplet Loss:0.1295\tStatic Loss:0.2650\n",
      "\n",
      "\tTime:48.5984\n",
      "\n",
      "Test Loss:0.8440\tRecon Loss:5.7626\tTriplet Loss:0.4422\tStatic Loss:0.8350\n",
      "\n",
      "\tEpoch:21\tTrain Loss:0.2252\tRecon Loss:1.9546\tTriplet Loss:0.1127\tStatic Loss:0.2191\t\n",
      "Val Loss:0.2675\tRecon Loss:1.9347\tTriplet Loss:0.1425\tStatic Loss:0.2633\n",
      "\n",
      "\tTime:48.4742\n",
      "\n",
      "Test Loss:0.8358\tRecon Loss:5.7704\tTriplet Loss:0.4611\tStatic Loss:0.8239\n",
      "\n",
      "\tEpoch:22\tTrain Loss:0.2232\tRecon Loss:1.8618\tTriplet Loss:0.1152\tStatic Loss:0.2176\t\n",
      "Val Loss:0.2687\tRecon Loss:1.9420\tTriplet Loss:0.1270\tStatic Loss:0.2662\n",
      "\n",
      "\tTime:47.6029\n",
      "\n",
      "Test Loss:0.8469\tRecon Loss:5.7320\tTriplet Loss:0.4119\tStatic Loss:0.8416\n",
      "\n",
      "\tEpoch:23\tTrain Loss:0.2199\tRecon Loss:1.8722\tTriplet Loss:0.1104\tStatic Loss:0.2143\t\n",
      "Val Loss:0.2720\tRecon Loss:2.0190\tTriplet Loss:0.1355\tStatic Loss:0.2682\n",
      "\n",
      "\tTime:47.9932\n",
      "\n",
      "Test Loss:0.8454\tRecon Loss:5.9215\tTriplet Loss:0.4695\tStatic Loss:0.8323\n",
      "\n",
      "\tEpoch:24\tTrain Loss:0.2202\tRecon Loss:1.8861\tTriplet Loss:0.1162\tStatic Loss:0.2139\t\n",
      "Val Loss:0.2729\tRecon Loss:1.9894\tTriplet Loss:0.1327\tStatic Loss:0.2697\n",
      "\n",
      "\tTime:47.2370\n",
      "\n",
      "Test Loss:0.8431\tRecon Loss:5.8561\tTriplet Loss:0.4354\tStatic Loss:0.8337\n",
      "\n",
      "\tEpoch:25\tTrain Loss:0.2172\tRecon Loss:1.8702\tTriplet Loss:0.1116\tStatic Loss:0.2113\t\n",
      "Val Loss:0.2635\tRecon Loss:1.9561\tTriplet Loss:0.1382\tStatic Loss:0.2591\n",
      "\n",
      "\tTime:48.1692\n",
      "\n",
      "Test Loss:0.8281\tRecon Loss:5.8358\tTriplet Loss:0.4269\tStatic Loss:0.8181\n",
      "\n",
      "\tEpoch:26\tTrain Loss:0.2162\tRecon Loss:1.9740\tTriplet Loss:0.1112\tStatic Loss:0.2091\t\n",
      "Val Loss:0.2642\tRecon Loss:1.9319\tTriplet Loss:0.1444\tStatic Loss:0.2596\n",
      "\n",
      "\tTime:47.0883\n",
      "\n",
      "Test Loss:0.8326\tRecon Loss:5.6926\tTriplet Loss:0.4299\tStatic Loss:0.8243\n",
      "\n",
      "\tEpoch:27\tTrain Loss:0.2156\tRecon Loss:1.8646\tTriplet Loss:0.1068\tStatic Loss:0.2100\t\n",
      "Val Loss:0.2632\tRecon Loss:1.9387\tTriplet Loss:0.1275\tStatic Loss:0.2600\n",
      "\n",
      "\tTime:48.5775\n",
      "\n",
      "Test Loss:0.8306\tRecon Loss:5.7302\tTriplet Loss:0.4503\tStatic Loss:0.8197\n",
      "\n",
      "\tEpoch:28\tTrain Loss:0.2139\tRecon Loss:1.8699\tTriplet Loss:0.1124\tStatic Loss:0.2074\t\n",
      "Val Loss:0.2652\tRecon Loss:1.9185\tTriplet Loss:0.1353\tStatic Loss:0.2616\n",
      "\n",
      "\tTime:48.0231\n",
      "\n",
      "Test Loss:0.8336\tRecon Loss:5.7111\tTriplet Loss:0.4181\tStatic Loss:0.8264\n",
      "\n",
      "\tEpoch:29\tTrain Loss:0.2104\tRecon Loss:1.8593\tTriplet Loss:0.1092\tStatic Loss:0.2040\t\n",
      "Val Loss:0.2718\tRecon Loss:1.9184\tTriplet Loss:0.1366\tStatic Loss:0.2689\n",
      "\n",
      "\tTime:48.1361\n",
      "\n",
      "Test Loss:0.8382\tRecon Loss:5.7413\tTriplet Loss:0.4285\tStatic Loss:0.8301\n",
      "\n",
      "\tEpoch:30\tTrain Loss:0.2136\tRecon Loss:1.8826\tTriplet Loss:0.1094\tStatic Loss:0.2073\t\n",
      "Val Loss:0.2642\tRecon Loss:1.9151\tTriplet Loss:0.1318\tStatic Loss:0.2609\n",
      "\n",
      "\tTime:48.9183\n",
      "\n",
      "Test Loss:0.8541\tRecon Loss:5.7209\tTriplet Loss:0.4412\tStatic Loss:0.8468\n",
      "\n",
      "\tEpoch:31\tTrain Loss:0.2108\tRecon Loss:1.8739\tTriplet Loss:0.1072\tStatic Loss:0.2045\t\n",
      "Val Loss:0.2629\tRecon Loss:1.9494\tTriplet Loss:0.1419\tStatic Loss:0.2581\n",
      "\n",
      "\tTime:48.5252\n",
      "\n",
      "Test Loss:0.8214\tRecon Loss:5.8921\tTriplet Loss:0.4533\tStatic Loss:0.8075\n",
      "\n",
      "\tEpoch:32\tTrain Loss:0.2090\tRecon Loss:1.8681\tTriplet Loss:0.1157\tStatic Loss:0.2018\t\n",
      "Val Loss:0.2710\tRecon Loss:1.9229\tTriplet Loss:0.1335\tStatic Loss:0.2682\n",
      "\n",
      "\tTime:50.3687\n",
      "\n",
      "Test Loss:0.8493\tRecon Loss:5.8090\tTriplet Loss:0.4347\tStatic Loss:0.8412\n",
      "\n",
      "\tEpoch:33\tTrain Loss:0.2067\tRecon Loss:1.8716\tTriplet Loss:0.1076\tStatic Loss:0.2000\t\n",
      "Val Loss:0.2630\tRecon Loss:1.9104\tTriplet Loss:0.1559\tStatic Loss:0.2572\n",
      "\n",
      "\tTime:51.4352\n",
      "\n",
      "Test Loss:0.8122\tRecon Loss:5.7206\tTriplet Loss:0.4243\tStatic Loss:0.8019\n",
      "\n",
      "\tEpoch:34\tTrain Loss:0.2117\tRecon Loss:1.8829\tTriplet Loss:0.1147\tStatic Loss:0.2047\t\n",
      "Val Loss:0.2642\tRecon Loss:1.9415\tTriplet Loss:0.1279\tStatic Loss:0.2611\n",
      "\n",
      "\tTime:51.2859\n",
      "\n",
      "Test Loss:0.8379\tRecon Loss:5.9048\tTriplet Loss:0.4479\tStatic Loss:0.8262\n",
      "\n",
      "\tEpoch:35\tTrain Loss:0.2064\tRecon Loss:1.8675\tTriplet Loss:0.1043\tStatic Loss:0.2000\t\n",
      "Val Loss:0.2688\tRecon Loss:1.9203\tTriplet Loss:0.1380\tStatic Loss:0.2654\n",
      "\n",
      "\tTime:50.5280\n",
      "\n",
      "Test Loss:0.8522\tRecon Loss:5.7610\tTriplet Loss:0.4237\tStatic Loss:0.8459\n",
      "\n",
      "\tEpoch:36\tTrain Loss:0.2057\tRecon Loss:1.8525\tTriplet Loss:0.1094\tStatic Loss:0.1989\t\n",
      "Val Loss:0.2620\tRecon Loss:1.9304\tTriplet Loss:0.1400\tStatic Loss:0.2575\n",
      "\n",
      "\tTime:50.4199\n",
      "\n",
      "Test Loss:0.8036\tRecon Loss:5.7397\tTriplet Loss:0.4513\tStatic Loss:0.7895\n",
      "\n",
      "\tEpoch:37\tTrain Loss:0.2107\tRecon Loss:1.8899\tTriplet Loss:0.1159\tStatic Loss:0.2034\t\n",
      "Val Loss:0.2606\tRecon Loss:1.9479\tTriplet Loss:0.1331\tStatic Loss:0.2565\n",
      "\n",
      "\tTime:48.5676\n",
      "\n",
      "Test Loss:0.8277\tRecon Loss:5.8286\tTriplet Loss:0.4634\tStatic Loss:0.8141\n",
      "\n",
      "\tEpoch:38\tTrain Loss:0.2031\tRecon Loss:1.8488\tTriplet Loss:0.1083\tStatic Loss:0.1961\t\n",
      "Val Loss:0.2589\tRecon Loss:1.9216\tTriplet Loss:0.1329\tStatic Loss:0.2549\n",
      "\n",
      "\tTime:49.4989\n",
      "\n",
      "Test Loss:0.8049\tRecon Loss:5.7147\tTriplet Loss:0.4450\tStatic Loss:0.7917\n",
      "\n",
      "\tEpoch:39\tTrain Loss:0.2013\tRecon Loss:1.8602\tTriplet Loss:0.1060\tStatic Loss:0.1943\t\n",
      "Val Loss:0.2588\tRecon Loss:1.9255\tTriplet Loss:0.1352\tStatic Loss:0.2544\n",
      "\n",
      "\tTime:48.9608\n",
      "\n",
      "Test Loss:0.8438\tRecon Loss:5.7491\tTriplet Loss:0.4372\tStatic Loss:0.8354\n",
      "\n",
      "\tEpoch:40\tTrain Loss:0.2013\tRecon Loss:1.8943\tTriplet Loss:0.1071\tStatic Loss:0.1938\t\n",
      "Val Loss:0.2635\tRecon Loss:1.9152\tTriplet Loss:0.1363\tStatic Loss:0.2597\n",
      "\n",
      "\tTime:49.6457\n",
      "\n",
      "Test Loss:0.8393\tRecon Loss:5.7320\tTriplet Loss:0.4526\tStatic Loss:0.8290\n",
      "\n",
      "\tEpoch:41\tTrain Loss:0.1998\tRecon Loss:1.8504\tTriplet Loss:0.1064\tStatic Loss:0.1926\t\n",
      "Val Loss:0.2623\tRecon Loss:1.9176\tTriplet Loss:0.1321\tStatic Loss:0.2588\n",
      "\n",
      "\tTime:49.5052\n",
      "\n",
      "Test Loss:0.8354\tRecon Loss:5.7124\tTriplet Loss:0.4662\tStatic Loss:0.8236\n",
      "\n",
      "\tEpoch:42\tTrain Loss:0.2003\tRecon Loss:1.8508\tTriplet Loss:0.1068\tStatic Loss:0.1931\t\n",
      "Val Loss:0.2616\tRecon Loss:1.9144\tTriplet Loss:0.1422\tStatic Loss:0.2571\n",
      "\n",
      "\tTime:49.0799\n",
      "\n",
      "Test Loss:0.8349\tRecon Loss:5.7666\tTriplet Loss:0.4204\tStatic Loss:0.8271\n",
      "\n",
      "\tEpoch:43\tTrain Loss:0.1965\tRecon Loss:1.8659\tTriplet Loss:0.1047\tStatic Loss:0.1890\t\n",
      "Val Loss:0.2601\tRecon Loss:1.9046\tTriplet Loss:0.1353\tStatic Loss:0.2561\n",
      "\n",
      "\tTime:48.4909\n",
      "\n",
      "Test Loss:0.8319\tRecon Loss:5.6987\tTriplet Loss:0.4435\tStatic Loss:0.8221\n",
      "\n",
      "\tEpoch:44\tTrain Loss:0.1991\tRecon Loss:1.8612\tTriplet Loss:0.1042\tStatic Loss:0.1919\t\n",
      "Val Loss:0.2615\tRecon Loss:1.9177\tTriplet Loss:0.1330\tStatic Loss:0.2578\n",
      "\n",
      "\tTime:48.5178\n",
      "\n",
      "Test Loss:0.8349\tRecon Loss:5.7499\tTriplet Loss:0.4441\tStatic Loss:0.8249\n",
      "\n",
      "\tEpoch:45\tTrain Loss:0.1983\tRecon Loss:1.8642\tTriplet Loss:0.1096\tStatic Loss:0.1905\t\n",
      "Val Loss:0.2642\tRecon Loss:1.9507\tTriplet Loss:0.1334\tStatic Loss:0.2605\n",
      "\n",
      "\tTime:49.2030\n",
      "\n",
      "Test Loss:0.8414\tRecon Loss:5.8524\tTriplet Loss:0.4465\tStatic Loss:0.8308\n",
      "\n",
      "\tEpoch:46\tTrain Loss:0.1991\tRecon Loss:1.8603\tTriplet Loss:0.1077\tStatic Loss:0.1917\t\n",
      "Val Loss:0.2639\tRecon Loss:1.9177\tTriplet Loss:0.1399\tStatic Loss:0.2597\n",
      "\n",
      "\tTime:48.3357\n",
      "\n",
      "Test Loss:0.8359\tRecon Loss:5.7234\tTriplet Loss:0.4164\tStatic Loss:0.8290\n",
      "\n",
      "\tEpoch:47\tTrain Loss:0.1952\tRecon Loss:1.8562\tTriplet Loss:0.1083\tStatic Loss:0.1873\t\n",
      "Val Loss:0.2678\tRecon Loss:1.9649\tTriplet Loss:0.1277\tStatic Loss:0.2649\n",
      "\n",
      "\tTime:48.9297\n",
      "\n",
      "Test Loss:0.8610\tRecon Loss:5.9312\tTriplet Loss:0.4493\tStatic Loss:0.8515\n",
      "\n",
      "\tEpoch:48\tTrain Loss:0.2037\tRecon Loss:1.8849\tTriplet Loss:0.1091\tStatic Loss:0.1963\t\n",
      "Val Loss:0.2623\tRecon Loss:1.9583\tTriplet Loss:0.1432\tStatic Loss:0.2573\n",
      "\n",
      "\tTime:51.4794\n",
      "\n",
      "Test Loss:0.8262\tRecon Loss:5.7887\tTriplet Loss:0.4581\tStatic Loss:0.8134\n",
      "\n",
      "\tEpoch:49\tTrain Loss:0.1990\tRecon Loss:1.8803\tTriplet Loss:0.1062\tStatic Loss:0.1915\t\n",
      "Val Loss:0.2583\tRecon Loss:1.9651\tTriplet Loss:0.1250\tStatic Loss:0.2546\n",
      "\n",
      "\tTime:50.8826\n",
      "\n",
      "Test Loss:0.8439\tRecon Loss:5.7969\tTriplet Loss:0.4613\tStatic Loss:0.8326\n",
      "\n",
      "\tEpoch:50\tTrain Loss:0.2108\tRecon Loss:1.8899\tTriplet Loss:0.1162\tStatic Loss:0.2035\t\n",
      "Val Loss:0.2720\tRecon Loss:1.9320\tTriplet Loss:0.1359\tStatic Loss:0.2690\n",
      "\n",
      "\tTime:49.4045\n",
      "\n",
      "Test Loss:0.8411\tRecon Loss:5.7515\tTriplet Loss:0.4714\tStatic Loss:0.8289\n",
      "\n",
      "\tEpoch:51\tTrain Loss:0.2022\tRecon Loss:1.8623\tTriplet Loss:0.1155\tStatic Loss:0.1943\t\n",
      "Val Loss:0.2651\tRecon Loss:1.9276\tTriplet Loss:0.1320\tStatic Loss:0.2617\n",
      "\n",
      "\tTime:49.3165\n",
      "\n",
      "Test Loss:0.8379\tRecon Loss:5.7468\tTriplet Loss:0.4566\tStatic Loss:0.8269\n",
      "\n",
      "\tEpoch:52\tTrain Loss:0.2027\tRecon Loss:1.8557\tTriplet Loss:0.1142\tStatic Loss:0.1951\t\n",
      "Val Loss:0.2619\tRecon Loss:1.8995\tTriplet Loss:0.1284\tStatic Loss:0.2588\n",
      "\n",
      "\tTime:48.0891\n",
      "\n",
      "Test Loss:0.8499\tRecon Loss:5.6859\tTriplet Loss:0.4471\tStatic Loss:0.8419\n",
      "\n",
      "\tEpoch:53\tTrain Loss:0.2018\tRecon Loss:1.8742\tTriplet Loss:0.1080\tStatic Loss:0.1945\t\n",
      "Val Loss:0.2580\tRecon Loss:1.9249\tTriplet Loss:0.1353\tStatic Loss:0.2536\n",
      "\n",
      "\tTime:48.3677\n",
      "\n",
      "Test Loss:0.8420\tRecon Loss:5.7451\tTriplet Loss:0.4757\tStatic Loss:0.8296\n",
      "\n",
      "\tEpoch:54\tTrain Loss:0.1971\tRecon Loss:1.9311\tTriplet Loss:0.1064\tStatic Loss:0.1888\t\n",
      "Val Loss:0.2606\tRecon Loss:1.9599\tTriplet Loss:0.1253\tStatic Loss:0.2571\n",
      "\n",
      "\tTime:48.8146\n",
      "\n",
      "Test Loss:0.8403\tRecon Loss:5.7725\tTriplet Loss:0.4480\tStatic Loss:0.8302\n",
      "\n",
      "\tEpoch:55\tTrain Loss:0.1925\tRecon Loss:1.8470\tTriplet Loss:0.1095\tStatic Loss:0.1843\t\n",
      "Val Loss:0.2618\tRecon Loss:1.9338\tTriplet Loss:0.1295\tStatic Loss:0.2583\n",
      "\n",
      "\tTime:49.3851\n",
      "\n",
      "Test Loss:0.8573\tRecon Loss:5.7465\tTriplet Loss:0.4830\tStatic Loss:0.8458\n",
      "\n",
      "\tEpoch:56\tTrain Loss:0.1920\tRecon Loss:1.8549\tTriplet Loss:0.1033\tStatic Loss:0.1842\t\n",
      "Val Loss:0.2561\tRecon Loss:1.9330\tTriplet Loss:0.1294\tStatic Loss:0.2520\n",
      "\n",
      "\tTime:54.1334\n",
      "\n",
      "Test Loss:0.8056\tRecon Loss:5.7061\tTriplet Loss:0.4245\tStatic Loss:0.7947\n",
      "\n",
      "\tEpoch:57\tTrain Loss:0.2081\tRecon Loss:1.9370\tTriplet Loss:0.1118\tStatic Loss:0.2004\t\n",
      "Val Loss:0.2753\tRecon Loss:1.9723\tTriplet Loss:0.1397\tStatic Loss:0.2719\n",
      "\n",
      "\tTime:49.9112\n",
      "\n",
      "Test Loss:0.8751\tRecon Loss:5.9297\tTriplet Loss:0.4804\tStatic Loss:0.8640\n",
      "\n",
      "\tEpoch:58\tTrain Loss:0.2035\tRecon Loss:1.8681\tTriplet Loss:0.1104\tStatic Loss:0.1961\t\n",
      "Val Loss:0.2643\tRecon Loss:1.9334\tTriplet Loss:0.1385\tStatic Loss:0.2602\n",
      "\n",
      "\tTime:51.0934\n",
      "\n",
      "Test Loss:0.8758\tRecon Loss:5.7516\tTriplet Loss:0.4286\tStatic Loss:0.8717\n",
      "\n",
      "\tEpoch:59\tTrain Loss:0.2017\tRecon Loss:1.8564\tTriplet Loss:0.1117\tStatic Loss:0.1941\t\n",
      "Val Loss:0.2600\tRecon Loss:1.9147\tTriplet Loss:0.1268\tStatic Loss:0.2568\n",
      "\n",
      "\tTime:50.4207\n",
      "\n",
      "Test Loss:0.8269\tRecon Loss:5.7438\tTriplet Loss:0.4506\tStatic Loss:0.8154\n",
      "\n",
      "\tEpoch:60\tTrain Loss:0.1977\tRecon Loss:1.8683\tTriplet Loss:0.1079\tStatic Loss:0.1900\t\n",
      "Val Loss:0.2619\tRecon Loss:1.9374\tTriplet Loss:0.1328\tStatic Loss:0.2580\n",
      "\n",
      "\tTime:51.7765\n",
      "\n",
      "Test Loss:0.8225\tRecon Loss:5.7470\tTriplet Loss:0.4244\tStatic Loss:0.8130\n",
      "\n",
      "\tEpoch:61\tTrain Loss:0.1929\tRecon Loss:1.8479\tTriplet Loss:0.1053\tStatic Loss:0.1851\t\n",
      "Val Loss:0.2636\tRecon Loss:1.9170\tTriplet Loss:0.1296\tStatic Loss:0.2604\n",
      "\n",
      "\tTime:52.6092\n",
      "\n",
      "Test Loss:0.8517\tRecon Loss:5.7091\tTriplet Loss:0.4272\tStatic Loss:0.8455\n",
      "\n",
      "\tEpoch:62\tTrain Loss:0.1922\tRecon Loss:1.8550\tTriplet Loss:0.1008\tStatic Loss:0.1847\t\n",
      "Val Loss:0.2613\tRecon Loss:1.9280\tTriplet Loss:0.1422\tStatic Loss:0.2566\n",
      "\n",
      "\tTime:51.6599\n",
      "\n",
      "Test Loss:0.8210\tRecon Loss:5.7324\tTriplet Loss:0.4549\tStatic Loss:0.8085\n",
      "\n",
      "\tEpoch:63\tTrain Loss:0.1927\tRecon Loss:1.8560\tTriplet Loss:0.0978\tStatic Loss:0.1856\t\n",
      "Val Loss:0.2579\tRecon Loss:1.9237\tTriplet Loss:0.1261\tStatic Loss:0.2545\n",
      "\n",
      "\tTime:51.0271\n",
      "\n",
      "Test Loss:0.8231\tRecon Loss:5.8118\tTriplet Loss:0.4568\tStatic Loss:0.8099\n",
      "\n",
      "\tEpoch:64\tTrain Loss:0.1925\tRecon Loss:1.8453\tTriplet Loss:0.1015\tStatic Loss:0.1851\t\n",
      "Val Loss:0.2622\tRecon Loss:1.9406\tTriplet Loss:0.1192\tStatic Loss:0.2597\n",
      "\n",
      "\tTime:51.9390\n",
      "\n",
      "Test Loss:0.8439\tRecon Loss:5.8590\tTriplet Loss:0.4439\tStatic Loss:0.8337\n",
      "\n",
      "\tEpoch:65\tTrain Loss:0.1888\tRecon Loss:1.8559\tTriplet Loss:0.0953\tStatic Loss:0.1815\t\n",
      "Val Loss:0.2617\tRecon Loss:1.9173\tTriplet Loss:0.1238\tStatic Loss:0.2590\n",
      "\n",
      "\tTime:51.3128\n",
      "\n",
      "Test Loss:0.8360\tRecon Loss:5.7689\tTriplet Loss:0.4143\tStatic Loss:0.8288\n",
      "\n",
      "\tEpoch:66\tTrain Loss:0.1891\tRecon Loss:1.8536\tTriplet Loss:0.1028\tStatic Loss:0.1810\t\n",
      "Val Loss:0.2630\tRecon Loss:1.9708\tTriplet Loss:0.1370\tStatic Loss:0.2585\n",
      "\n",
      "\tTime:50.3648\n",
      "\n",
      "Test Loss:0.8477\tRecon Loss:5.9037\tTriplet Loss:0.4458\tStatic Loss:0.8373\n",
      "\n",
      "\tEpoch:67\tTrain Loss:0.1910\tRecon Loss:1.8474\tTriplet Loss:0.1032\tStatic Loss:0.1833\t\n",
      "Val Loss:0.2627\tRecon Loss:1.9190\tTriplet Loss:0.1360\tStatic Loss:0.2588\n",
      "\n",
      "\tTime:50.0912\n",
      "\n",
      "Test Loss:0.8300\tRecon Loss:5.7423\tTriplet Loss:0.4610\tStatic Loss:0.8178\n",
      "\n",
      "\tEpoch:68\tTrain Loss:0.1909\tRecon Loss:1.8538\tTriplet Loss:0.1035\tStatic Loss:0.1830\t\n",
      "Val Loss:0.2623\tRecon Loss:1.9456\tTriplet Loss:0.1398\tStatic Loss:0.2577\n",
      "\n",
      "\tTime:49.3848\n",
      "\n",
      "Test Loss:0.8338\tRecon Loss:5.8254\tTriplet Loss:0.4087\tStatic Loss:0.8264\n",
      "\n",
      "\tEpoch:69\tTrain Loss:0.1956\tRecon Loss:1.8547\tTriplet Loss:0.1092\tStatic Loss:0.1876\t\n",
      "Val Loss:0.2603\tRecon Loss:1.9526\tTriplet Loss:0.1403\tStatic Loss:0.2553\n",
      "\n",
      "\tTime:49.9728\n",
      "\n",
      "Test Loss:0.8309\tRecon Loss:5.8063\tTriplet Loss:0.4604\tStatic Loss:0.8182\n",
      "\n",
      "\tEpoch:70\tTrain Loss:0.1953\tRecon Loss:1.8544\tTriplet Loss:0.1077\tStatic Loss:0.1875\t\n",
      "Val Loss:0.2595\tRecon Loss:1.9213\tTriplet Loss:0.1353\tStatic Loss:0.2553\n",
      "\n",
      "\tTime:50.8917\n",
      "\n",
      "Test Loss:0.8355\tRecon Loss:5.7819\tTriplet Loss:0.4416\tStatic Loss:0.8254\n",
      "\n",
      "\tEpoch:71\tTrain Loss:0.1945\tRecon Loss:1.8589\tTriplet Loss:0.1097\tStatic Loss:0.1863\t\n",
      "Val Loss:0.2587\tRecon Loss:1.9195\tTriplet Loss:0.1389\tStatic Loss:0.2541\n",
      "\n",
      "\tTime:50.0957\n",
      "\n",
      "Test Loss:0.8278\tRecon Loss:5.7591\tTriplet Loss:0.4237\tStatic Loss:0.8189\n",
      "\n",
      "\tEpoch:72\tTrain Loss:0.1898\tRecon Loss:1.8538\tTriplet Loss:0.1045\tStatic Loss:0.1817\t\n",
      "Val Loss:0.2534\tRecon Loss:1.9741\tTriplet Loss:0.1247\tStatic Loss:0.2491\n",
      "\n",
      "\tTime:50.4590\n",
      "\n",
      "Test Loss:0.8106\tRecon Loss:5.9675\tTriplet Loss:0.4448\tStatic Loss:0.7956\n",
      "\n",
      "\tEpoch:73\tTrain Loss:0.2021\tRecon Loss:1.8895\tTriplet Loss:0.1110\tStatic Loss:0.1943\t\n",
      "Val Loss:0.2639\tRecon Loss:1.9365\tTriplet Loss:0.1253\tStatic Loss:0.2611\n",
      "\n",
      "\tTime:50.2749\n",
      "\n",
      "Test Loss:0.8430\tRecon Loss:5.7756\tTriplet Loss:0.4491\tStatic Loss:0.8330\n",
      "\n",
      "\tEpoch:74\tTrain Loss:0.1934\tRecon Loss:1.8445\tTriplet Loss:0.1038\tStatic Loss:0.1858\t\n",
      "Val Loss:0.2618\tRecon Loss:1.9581\tTriplet Loss:0.1342\tStatic Loss:0.2576\n",
      "\n",
      "\tTime:50.7149\n",
      "\n",
      "Test Loss:0.8293\tRecon Loss:5.8667\tTriplet Loss:0.4410\tStatic Loss:0.8177\n",
      "\n",
      "\tEpoch:75\tTrain Loss:0.1928\tRecon Loss:1.8537\tTriplet Loss:0.1061\tStatic Loss:0.1849\t\n",
      "Val Loss:0.2588\tRecon Loss:1.9228\tTriplet Loss:0.1223\tStatic Loss:0.2558\n",
      "\n",
      "\tTime:51.0174\n",
      "\n",
      "Test Loss:0.8340\tRecon Loss:5.7025\tTriplet Loss:0.4288\tStatic Loss:0.8259\n",
      "\n",
      "\tEpoch:76\tTrain Loss:0.1885\tRecon Loss:1.8485\tTriplet Loss:0.1015\tStatic Loss:0.1807\t\n",
      "Val Loss:0.2554\tRecon Loss:1.9369\tTriplet Loss:0.1223\tStatic Loss:0.2518\n",
      "\n",
      "\tTime:50.8790\n",
      "\n",
      "Test Loss:0.8203\tRecon Loss:5.7520\tTriplet Loss:0.4455\tStatic Loss:0.8084\n",
      "\n",
      "\tEpoch:77\tTrain Loss:0.1884\tRecon Loss:1.8571\tTriplet Loss:0.1014\tStatic Loss:0.1804\t\n",
      "Val Loss:0.2634\tRecon Loss:1.9256\tTriplet Loss:0.1365\tStatic Loss:0.2594\n",
      "\n",
      "\tTime:50.4311\n",
      "\n",
      "Test Loss:0.8252\tRecon Loss:5.7510\tTriplet Loss:0.4518\tStatic Loss:0.8132\n",
      "\n",
      "\tEpoch:78\tTrain Loss:0.1896\tRecon Loss:1.8592\tTriplet Loss:0.0999\tStatic Loss:0.1819\t\n",
      "Val Loss:0.2773\tRecon Loss:2.0150\tTriplet Loss:0.1453\tStatic Loss:0.2731\n",
      "\n",
      "\tTime:51.6404\n",
      "\n",
      "Test Loss:0.8712\tRecon Loss:5.8856\tTriplet Loss:0.4767\tStatic Loss:0.8605\n",
      "\n",
      "\tEpoch:79\tTrain Loss:0.1920\tRecon Loss:1.8533\tTriplet Loss:0.1042\tStatic Loss:0.1842\t\n",
      "Val Loss:0.2575\tRecon Loss:1.9228\tTriplet Loss:0.1286\tStatic Loss:0.2538\n",
      "\n",
      "\tTime:51.1412\n",
      "\n",
      "Test Loss:0.8176\tRecon Loss:5.7562\tTriplet Loss:0.4319\tStatic Loss:0.8068\n",
      "\n",
      "\tEpoch:80\tTrain Loss:0.1873\tRecon Loss:1.8415\tTriplet Loss:0.1008\tStatic Loss:0.1794\t\n",
      "Val Loss:0.2549\tRecon Loss:1.9441\tTriplet Loss:0.1311\tStatic Loss:0.2504\n",
      "\n",
      "\tTime:51.6168\n",
      "\n",
      "Test Loss:0.8157\tRecon Loss:5.7385\tTriplet Loss:0.4249\tStatic Loss:0.8055\n",
      "\n",
      "\tEpoch:81\tTrain Loss:0.1865\tRecon Loss:1.8534\tTriplet Loss:0.1012\tStatic Loss:0.1784\t\n",
      "Val Loss:0.2555\tRecon Loss:1.9238\tTriplet Loss:0.1246\tStatic Loss:0.2519\n",
      "\n",
      "\tTime:50.1906\n",
      "\n",
      "Test Loss:0.8290\tRecon Loss:5.7494\tTriplet Loss:0.4353\tStatic Loss:0.8192\n",
      "\n",
      "\tEpoch:82\tTrain Loss:0.1833\tRecon Loss:1.8379\tTriplet Loss:0.1014\tStatic Loss:0.1750\t\n",
      "Val Loss:0.2597\tRecon Loss:1.9222\tTriplet Loss:0.1295\tStatic Loss:0.2561\n",
      "\n",
      "\tTime:50.6466\n",
      "\n",
      "Test Loss:0.8292\tRecon Loss:5.7554\tTriplet Loss:0.4069\tStatic Loss:0.8222\n",
      "\n",
      "\tEpoch:83\tTrain Loss:0.1834\tRecon Loss:1.8410\tTriplet Loss:0.1000\tStatic Loss:0.1752\t\n",
      "Val Loss:0.2562\tRecon Loss:1.9236\tTriplet Loss:0.1173\tStatic Loss:0.2534\n",
      "\n",
      "\tTime:51.4289\n",
      "\n",
      "Test Loss:0.8176\tRecon Loss:5.7708\tTriplet Loss:0.4291\tStatic Loss:0.8069\n",
      "\n",
      "\tEpoch:84\tTrain Loss:0.1823\tRecon Loss:1.8536\tTriplet Loss:0.0940\tStatic Loss:0.1744\t\n",
      "Val Loss:0.2553\tRecon Loss:1.9448\tTriplet Loss:0.1236\tStatic Loss:0.2516\n",
      "\n",
      "\tTime:50.5854\n",
      "\n",
      "Test Loss:0.8131\tRecon Loss:5.7558\tTriplet Loss:0.4138\tStatic Loss:0.8037\n",
      "\n",
      "\tEpoch:85\tTrain Loss:0.1822\tRecon Loss:1.8670\tTriplet Loss:0.0961\tStatic Loss:0.1740\t\n",
      "Val Loss:0.2619\tRecon Loss:1.9479\tTriplet Loss:0.1293\tStatic Loss:0.2583\n",
      "\n",
      "\tTime:49.6821\n",
      "\n",
      "Test Loss:0.8370\tRecon Loss:5.8025\tTriplet Loss:0.4342\tStatic Loss:0.8276\n",
      "\n",
      "\tEpoch:86\tTrain Loss:0.1850\tRecon Loss:1.8703\tTriplet Loss:0.1049\tStatic Loss:0.1762\t\n",
      "Val Loss:0.2642\tRecon Loss:1.9357\tTriplet Loss:0.1461\tStatic Loss:0.2593\n",
      "\n",
      "\tTime:50.8951\n",
      "\n",
      "Test Loss:0.8359\tRecon Loss:5.7785\tTriplet Loss:0.4357\tStatic Loss:0.8265\n",
      "\n",
      "\tEpoch:87\tTrain Loss:0.1829\tRecon Loss:1.8391\tTriplet Loss:0.0933\tStatic Loss:0.1753\t\n",
      "Val Loss:0.2553\tRecon Loss:1.9449\tTriplet Loss:0.1224\tStatic Loss:0.2517\n",
      "\n",
      "\tTime:51.4697\n",
      "\n",
      "Test Loss:0.8246\tRecon Loss:5.8220\tTriplet Loss:0.4160\tStatic Loss:0.8154\n",
      "\n",
      "\tEpoch:88\tTrain Loss:0.1819\tRecon Loss:1.8457\tTriplet Loss:0.0978\tStatic Loss:0.1736\t\n",
      "Val Loss:0.2621\tRecon Loss:1.9454\tTriplet Loss:0.1238\tStatic Loss:0.2590\n",
      "\n",
      "\tTime:51.3102\n",
      "\n",
      "Test Loss:0.8446\tRecon Loss:5.7603\tTriplet Loss:0.4094\tStatic Loss:0.8389\n",
      "\n",
      "\tEpoch:89\tTrain Loss:0.1824\tRecon Loss:1.8527\tTriplet Loss:0.0986\tStatic Loss:0.1741\t\n",
      "Val Loss:0.2670\tRecon Loss:1.9303\tTriplet Loss:0.1334\tStatic Loss:0.2638\n",
      "\n",
      "\tTime:51.5673\n",
      "\n",
      "Test Loss:0.8658\tRecon Loss:5.7376\tTriplet Loss:0.4500\tStatic Loss:0.8587\n",
      "\n",
      "\tEpoch:90\tTrain Loss:0.1825\tRecon Loss:1.8506\tTriplet Loss:0.1025\tStatic Loss:0.1738\t\n",
      "Val Loss:0.2702\tRecon Loss:2.0198\tTriplet Loss:0.1255\tStatic Loss:0.2672\n",
      "\n",
      "\tTime:51.5766\n",
      "\n",
      "Test Loss:0.8909\tRecon Loss:5.9580\tTriplet Loss:0.4381\tStatic Loss:0.8855\n",
      "\n",
      "\tEpoch:91\tTrain Loss:0.1824\tRecon Loss:1.8443\tTriplet Loss:0.1051\tStatic Loss:0.1735\t\n",
      "Val Loss:0.2656\tRecon Loss:1.9404\tTriplet Loss:0.1313\tStatic Loss:0.2623\n",
      "\n",
      "\tTime:51.9806\n",
      "\n",
      "Test Loss:0.8346\tRecon Loss:5.7784\tTriplet Loss:0.4236\tStatic Loss:0.8263\n",
      "\n",
      "\tEpoch:92\tTrain Loss:0.1817\tRecon Loss:1.8477\tTriplet Loss:0.0962\tStatic Loss:0.1736\t\n",
      "Val Loss:0.2626\tRecon Loss:1.9611\tTriplet Loss:0.1243\tStatic Loss:0.2594\n",
      "\n",
      "\tTime:52.2427\n",
      "\n",
      "Test Loss:0.8521\tRecon Loss:5.7349\tTriplet Loss:0.4518\tStatic Loss:0.8433\n",
      "\n",
      "\tEpoch:93\tTrain Loss:0.1879\tRecon Loss:1.8561\tTriplet Loss:0.1014\tStatic Loss:0.1799\t\n",
      "Val Loss:0.2604\tRecon Loss:1.9655\tTriplet Loss:0.1434\tStatic Loss:0.2551\n",
      "\n",
      "\tTime:51.2277\n",
      "\n",
      "Test Loss:0.8425\tRecon Loss:5.8603\tTriplet Loss:0.4433\tStatic Loss:0.8322\n",
      "\n",
      "\tEpoch:94\tTrain Loss:0.1822\tRecon Loss:1.8418\tTriplet Loss:0.1006\tStatic Loss:0.1738\t\n",
      "Val Loss:0.2547\tRecon Loss:1.9413\tTriplet Loss:0.1260\tStatic Loss:0.2507\n",
      "\n",
      "\tTime:52.2783\n",
      "\n",
      "Test Loss:0.8288\tRecon Loss:5.8046\tTriplet Loss:0.4708\tStatic Loss:0.8148\n",
      "\n",
      "\tEpoch:95\tTrain Loss:0.1802\tRecon Loss:1.8426\tTriplet Loss:0.0981\tStatic Loss:0.1718\t\n",
      "Val Loss:0.2601\tRecon Loss:1.9663\tTriplet Loss:0.1278\tStatic Loss:0.2563\n",
      "\n",
      "\tTime:51.8743\n",
      "\n",
      "Test Loss:0.8409\tRecon Loss:5.9100\tTriplet Loss:0.4386\tStatic Loss:0.8304\n",
      "\n",
      "\tEpoch:96\tTrain Loss:0.1830\tRecon Loss:1.8513\tTriplet Loss:0.0949\tStatic Loss:0.1752\t\n",
      "Val Loss:0.2596\tRecon Loss:2.0468\tTriplet Loss:0.1255\tStatic Loss:0.2551\n",
      "\n",
      "\tTime:50.4337\n",
      "\n",
      "Test Loss:0.8366\tRecon Loss:5.9749\tTriplet Loss:0.4196\tStatic Loss:0.8269\n",
      "\n",
      "\tEpoch:97\tTrain Loss:0.1816\tRecon Loss:1.8590\tTriplet Loss:0.1012\tStatic Loss:0.1729\t\n",
      "Val Loss:0.2638\tRecon Loss:1.9552\tTriplet Loss:0.1330\tStatic Loss:0.2599\n",
      "\n",
      "\tTime:50.7964\n",
      "\n",
      "Test Loss:0.8350\tRecon Loss:5.8080\tTriplet Loss:0.4146\tStatic Loss:0.8273\n",
      "\n",
      "\tEpoch:98\tTrain Loss:0.1782\tRecon Loss:1.8443\tTriplet Loss:0.0953\tStatic Loss:0.1698\t\n",
      "Val Loss:0.2619\tRecon Loss:1.9659\tTriplet Loss:0.1260\tStatic Loss:0.2585\n",
      "\n",
      "\tTime:51.6136\n",
      "\n",
      "Test Loss:0.8509\tRecon Loss:5.8227\tTriplet Loss:0.4164\tStatic Loss:0.8446\n",
      "\n",
      "\tEpoch:99\tTrain Loss:0.1799\tRecon Loss:1.8434\tTriplet Loss:0.0964\tStatic Loss:0.1716\t\n",
      "Val Loss:0.2585\tRecon Loss:1.9406\tTriplet Loss:0.1255\tStatic Loss:0.2549\n",
      "\n",
      "\tTime:50.9848\n",
      "\n",
      "Test Loss:0.8315\tRecon Loss:5.7985\tTriplet Loss:0.4320\tStatic Loss:0.8218\n",
      "\n",
      "\tEpoch:100\tTrain Loss:0.1801\tRecon Loss:1.8451\tTriplet Loss:0.1004\tStatic Loss:0.1715\t\n",
      "Val Loss:0.2531\tRecon Loss:1.9356\tTriplet Loss:0.1151\tStatic Loss:0.2500\n",
      "\n",
      "\tTime:50.8849\n",
      "\n",
      "Test Loss:0.8486\tRecon Loss:5.7461\tTriplet Loss:0.4097\tStatic Loss:0.8435\n",
      "\n",
      "\tEpoch:101\tTrain Loss:0.1835\tRecon Loss:1.8577\tTriplet Loss:0.1079\tStatic Loss:0.1743\t\n",
      "Val Loss:0.2592\tRecon Loss:1.9484\tTriplet Loss:0.1291\tStatic Loss:0.2553\n",
      "\n",
      "\tTime:52.1381\n",
      "\n",
      "Test Loss:0.8563\tRecon Loss:5.8546\tTriplet Loss:0.4280\tStatic Loss:0.8492\n",
      "\n",
      "\tEpoch:102\tTrain Loss:0.1773\tRecon Loss:1.8373\tTriplet Loss:0.1028\tStatic Loss:0.1682\t\n",
      "Val Loss:0.2606\tRecon Loss:1.9441\tTriplet Loss:0.1276\tStatic Loss:0.2571\n",
      "\n",
      "\tTime:51.9154\n",
      "\n",
      "Test Loss:0.8287\tRecon Loss:5.7874\tTriplet Loss:0.4256\tStatic Loss:0.8194\n",
      "\n",
      "\tEpoch:103\tTrain Loss:0.1958\tRecon Loss:1.8889\tTriplet Loss:0.1076\tStatic Loss:0.1876\t\n",
      "Val Loss:0.2675\tRecon Loss:1.9968\tTriplet Loss:0.1303\tStatic Loss:0.2639\n",
      "\n",
      "\tTime:52.0486\n",
      "\n",
      "Test Loss:0.8529\tRecon Loss:5.8926\tTriplet Loss:0.4511\tStatic Loss:0.8427\n",
      "\n",
      "\tEpoch:104\tTrain Loss:0.1879\tRecon Loss:1.8556\tTriplet Loss:0.1019\tStatic Loss:0.1798\t\n",
      "Val Loss:0.2581\tRecon Loss:1.9406\tTriplet Loss:0.1300\tStatic Loss:0.2540\n",
      "\n",
      "\tTime:52.1420\n",
      "\n",
      "Test Loss:0.8210\tRecon Loss:5.7233\tTriplet Loss:0.4114\tStatic Loss:0.8130\n",
      "\n",
      "\tEpoch:105\tTrain Loss:0.1786\tRecon Loss:1.8343\tTriplet Loss:0.0931\tStatic Loss:0.1706\t\n",
      "Val Loss:0.2589\tRecon Loss:1.9509\tTriplet Loss:0.1247\tStatic Loss:0.2554\n",
      "\n",
      "\tTime:51.3241\n",
      "\n",
      "Test Loss:0.8424\tRecon Loss:5.8010\tTriplet Loss:0.4418\tStatic Loss:0.8329\n",
      "\n",
      "\tEpoch:106\tTrain Loss:0.1808\tRecon Loss:1.8541\tTriplet Loss:0.1008\tStatic Loss:0.1720\t\n",
      "Val Loss:0.2593\tRecon Loss:1.9349\tTriplet Loss:0.1225\tStatic Loss:0.2562\n",
      "\n",
      "\tTime:51.0821\n",
      "\n",
      "Test Loss:0.8243\tRecon Loss:5.7744\tTriplet Loss:0.4198\tStatic Loss:0.8152\n",
      "\n",
      "\tEpoch:107\tTrain Loss:0.1919\tRecon Loss:1.8608\tTriplet Loss:0.0973\tStatic Loss:0.1847\t\n",
      "Val Loss:0.2635\tRecon Loss:1.9227\tTriplet Loss:0.1283\tStatic Loss:0.2605\n",
      "\n",
      "\tTime:51.6153\n",
      "\n",
      "Test Loss:0.8530\tRecon Loss:5.7828\tTriplet Loss:0.4043\tStatic Loss:0.8485\n",
      "\n",
      "\tEpoch:108\tTrain Loss:0.1981\tRecon Loss:1.8536\tTriplet Loss:0.1127\tStatic Loss:0.1901\t\n",
      "Val Loss:0.2741\tRecon Loss:1.9264\tTriplet Loss:0.1413\tStatic Loss:0.2708\n",
      "\n",
      "\tTime:50.0134\n",
      "\n",
      "Test Loss:0.8535\tRecon Loss:5.7825\tTriplet Loss:0.4822\tStatic Loss:0.8413\n",
      "\n",
      "\tEpoch:109\tTrain Loss:0.1988\tRecon Loss:1.8623\tTriplet Loss:0.1112\tStatic Loss:0.1910\t\n",
      "Val Loss:0.2544\tRecon Loss:1.9272\tTriplet Loss:0.1370\tStatic Loss:0.2494\n",
      "\n",
      "\tTime:50.3950\n",
      "\n",
      "Test Loss:0.8052\tRecon Loss:5.7013\tTriplet Loss:0.4349\tStatic Loss:0.7932\n",
      "\n",
      "\tEpoch:110\tTrain Loss:0.1843\tRecon Loss:1.8457\tTriplet Loss:0.1009\tStatic Loss:0.1760\t\n",
      "Val Loss:0.2585\tRecon Loss:2.0090\tTriplet Loss:0.1296\tStatic Loss:0.2539\n",
      "\n",
      "\tTime:50.9076\n",
      "\n",
      "Test Loss:0.8387\tRecon Loss:5.8991\tTriplet Loss:0.4170\tStatic Loss:0.8302\n",
      "\n",
      "\tEpoch:111\tTrain Loss:0.1833\tRecon Loss:1.8549\tTriplet Loss:0.1029\tStatic Loss:0.1746\t\n",
      "Val Loss:0.2608\tRecon Loss:1.9335\tTriplet Loss:0.1242\tStatic Loss:0.2577\n",
      "\n",
      "\tTime:51.4469\n",
      "\n",
      "Test Loss:0.8279\tRecon Loss:5.7925\tTriplet Loss:0.4266\tStatic Loss:0.8184\n",
      "\n",
      "\tEpoch:112\tTrain Loss:0.1846\tRecon Loss:1.8463\tTriplet Loss:0.1006\tStatic Loss:0.1764\t\n",
      "Val Loss:0.2656\tRecon Loss:1.9149\tTriplet Loss:0.1422\tStatic Loss:0.2614\n",
      "\n",
      "\tTime:51.5170\n",
      "\n",
      "Test Loss:0.8259\tRecon Loss:5.7197\tTriplet Loss:0.4249\tStatic Loss:0.8171\n",
      "\n",
      "\tEpoch:113\tTrain Loss:0.1822\tRecon Loss:1.8386\tTriplet Loss:0.0980\tStatic Loss:0.1740\t\n",
      "Val Loss:0.2564\tRecon Loss:1.9255\tTriplet Loss:0.1210\tStatic Loss:0.2532\n",
      "\n",
      "\tTime:51.0386\n",
      "\n",
      "Test Loss:0.8353\tRecon Loss:5.7906\tTriplet Loss:0.4214\tStatic Loss:0.8271\n",
      "\n",
      "\tEpoch:114\tTrain Loss:0.1794\tRecon Loss:1.8374\tTriplet Loss:0.0978\tStatic Loss:0.1709\t\n",
      "Val Loss:0.2576\tRecon Loss:1.9400\tTriplet Loss:0.1158\tStatic Loss:0.2549\n",
      "\n",
      "\tTime:51.8974\n",
      "\n",
      "Test Loss:0.8248\tRecon Loss:5.7527\tTriplet Loss:0.4529\tStatic Loss:0.8128\n",
      "\n",
      "\tEpoch:115\tTrain Loss:0.1838\tRecon Loss:1.8563\tTriplet Loss:0.0975\tStatic Loss:0.1757\t\n",
      "Val Loss:0.2607\tRecon Loss:1.9595\tTriplet Loss:0.1265\tStatic Loss:0.2572\n",
      "\n",
      "\tTime:51.6605\n",
      "\n",
      "Test Loss:0.8212\tRecon Loss:5.7567\tTriplet Loss:0.4303\tStatic Loss:0.8109\n",
      "\n",
      "\tEpoch:116\tTrain Loss:0.1797\tRecon Loss:1.8457\tTriplet Loss:0.0976\tStatic Loss:0.1712\t\n",
      "Val Loss:0.2541\tRecon Loss:1.9659\tTriplet Loss:0.1173\tStatic Loss:0.2506\n",
      "\n",
      "\tTime:50.9997\n",
      "\n",
      "Test Loss:0.8350\tRecon Loss:5.7748\tTriplet Loss:0.4266\tStatic Loss:0.8264\n",
      "\n",
      "\tEpoch:117\tTrain Loss:0.1792\tRecon Loss:1.8528\tTriplet Loss:0.0958\tStatic Loss:0.1708\t\n",
      "Val Loss:0.2578\tRecon Loss:1.9294\tTriplet Loss:0.1222\tStatic Loss:0.2546\n",
      "\n",
      "\tTime:51.9292\n",
      "\n",
      "Test Loss:0.8432\tRecon Loss:5.7703\tTriplet Loss:0.4343\tStatic Loss:0.8349\n",
      "\n",
      "\tEpoch:118\tTrain Loss:0.1767\tRecon Loss:1.8363\tTriplet Loss:0.0983\tStatic Loss:0.1680\t\n",
      "Val Loss:0.2634\tRecon Loss:1.9501\tTriplet Loss:0.1405\tStatic Loss:0.2589\n",
      "\n",
      "\tTime:52.0786\n",
      "\n",
      "Test Loss:0.8644\tRecon Loss:5.8222\tTriplet Loss:0.4051\tStatic Loss:0.8607\n",
      "\n",
      "\tEpoch:119\tTrain Loss:0.1777\tRecon Loss:1.8396\tTriplet Loss:0.1014\tStatic Loss:0.1687\t\n",
      "Val Loss:0.2602\tRecon Loss:1.9497\tTriplet Loss:0.1246\tStatic Loss:0.2569\n",
      "\n",
      "\tTime:50.8567\n",
      "\n",
      "Test Loss:0.8510\tRecon Loss:5.8025\tTriplet Loss:0.4145\tStatic Loss:0.8451\n",
      "\n",
      "\tEpoch:120\tTrain Loss:0.1777\tRecon Loss:1.8386\tTriplet Loss:0.0955\tStatic Loss:0.1693\t\n",
      "Val Loss:0.2620\tRecon Loss:1.9431\tTriplet Loss:0.1293\tStatic Loss:0.2585\n",
      "\n",
      "\tTime:50.9494\n",
      "\n",
      "Test Loss:0.8593\tRecon Loss:5.8358\tTriplet Loss:0.4424\tStatic Loss:0.8513\n",
      "\n",
      "\tEpoch:121\tTrain Loss:0.1750\tRecon Loss:1.8483\tTriplet Loss:0.0950\tStatic Loss:0.1663\t\n",
      "Val Loss:0.2553\tRecon Loss:1.9359\tTriplet Loss:0.1178\tStatic Loss:0.2522\n",
      "\n",
      "\tTime:51.3057\n",
      "\n",
      "Test Loss:0.8288\tRecon Loss:5.7458\tTriplet Loss:0.4296\tStatic Loss:0.8196\n",
      "\n",
      "\tEpoch:122\tTrain Loss:0.1754\tRecon Loss:1.8364\tTriplet Loss:0.0969\tStatic Loss:0.1666\t\n",
      "Val Loss:0.2543\tRecon Loss:1.9613\tTriplet Loss:0.1168\tStatic Loss:0.2509\n",
      "\n",
      "\tTime:49.9969\n",
      "\n",
      "Test Loss:0.8273\tRecon Loss:5.8096\tTriplet Loss:0.4286\tStatic Loss:0.8173\n",
      "\n",
      "\tEpoch:123\tTrain Loss:0.1788\tRecon Loss:1.8531\tTriplet Loss:0.0984\tStatic Loss:0.1701\t\n",
      "Val Loss:0.2598\tRecon Loss:1.9343\tTriplet Loss:0.1266\tStatic Loss:0.2564\n",
      "\n",
      "\tTime:49.2144\n",
      "\n",
      "Test Loss:0.8373\tRecon Loss:5.7913\tTriplet Loss:0.4383\tStatic Loss:0.8277\n",
      "\n",
      "\tEpoch:124\tTrain Loss:0.1782\tRecon Loss:1.8442\tTriplet Loss:0.0909\tStatic Loss:0.1702\t\n",
      "Val Loss:0.2612\tRecon Loss:1.9525\tTriplet Loss:0.1282\tStatic Loss:0.2576\n",
      "\n",
      "\tTime:49.1811\n",
      "\n",
      "Test Loss:0.8455\tRecon Loss:5.8284\tTriplet Loss:0.4522\tStatic Loss:0.8350\n",
      "\n",
      "\tEpoch:125\tTrain Loss:0.1748\tRecon Loss:1.8374\tTriplet Loss:0.0941\tStatic Loss:0.1663\t\n",
      "Val Loss:0.2586\tRecon Loss:1.9378\tTriplet Loss:0.1306\tStatic Loss:0.2546\n",
      "\n",
      "\tTime:48.4172\n",
      "\n",
      "Test Loss:0.8353\tRecon Loss:5.7162\tTriplet Loss:0.4552\tStatic Loss:0.8245\n",
      "\n",
      "\tEpoch:126\tTrain Loss:0.1800\tRecon Loss:1.8526\tTriplet Loss:0.0999\tStatic Loss:0.1712\t\n",
      "Val Loss:0.2623\tRecon Loss:1.9408\tTriplet Loss:0.1242\tStatic Loss:0.2593\n",
      "\n",
      "\tTime:48.7179\n",
      "\n",
      "Test Loss:0.8593\tRecon Loss:5.8076\tTriplet Loss:0.4382\tStatic Loss:0.8519\n",
      "\n",
      "\tEpoch:127\tTrain Loss:0.1729\tRecon Loss:1.8402\tTriplet Loss:0.0926\tStatic Loss:0.1643\t\n",
      "Val Loss:0.2610\tRecon Loss:1.9674\tTriplet Loss:0.1234\tStatic Loss:0.2577\n",
      "\n",
      "\tTime:49.9979\n",
      "\n",
      "Test Loss:0.8337\tRecon Loss:5.8101\tTriplet Loss:0.4427\tStatic Loss:0.8230\n",
      "\n",
      "\tEpoch:128\tTrain Loss:0.1753\tRecon Loss:1.8377\tTriplet Loss:0.0950\tStatic Loss:0.1668\t\n",
      "Val Loss:0.2591\tRecon Loss:2.0405\tTriplet Loss:0.1244\tStatic Loss:0.2547\n",
      "\n",
      "\tTime:49.8192\n",
      "\n",
      "Test Loss:0.8567\tRecon Loss:6.0228\tTriplet Loss:0.4475\tStatic Loss:0.8460\n",
      "\n",
      "\tEpoch:129\tTrain Loss:0.1898\tRecon Loss:1.8649\tTriplet Loss:0.1015\tStatic Loss:0.1819\t\n",
      "Val Loss:0.2557\tRecon Loss:1.9267\tTriplet Loss:0.1227\tStatic Loss:0.2523\n",
      "\n",
      "\tTime:49.6979\n",
      "\n",
      "Test Loss:0.8095\tRecon Loss:5.7735\tTriplet Loss:0.4466\tStatic Loss:0.7961\n",
      "\n",
      "\tEpoch:130\tTrain Loss:0.1784\tRecon Loss:1.8400\tTriplet Loss:0.0972\tStatic Loss:0.1699\t\n",
      "Val Loss:0.2571\tRecon Loss:1.9596\tTriplet Loss:0.1340\tStatic Loss:0.2524\n",
      "\n",
      "\tTime:50.3470\n",
      "\n",
      "Test Loss:0.8305\tRecon Loss:5.7222\tTriplet Loss:0.3946\tStatic Loss:0.8252\n",
      "\n",
      "\tEpoch:131\tTrain Loss:0.1729\tRecon Loss:1.8326\tTriplet Loss:0.0922\tStatic Loss:0.1643\t\n",
      "Val Loss:0.2597\tRecon Loss:2.0162\tTriplet Loss:0.1294\tStatic Loss:0.2551\n",
      "\n",
      "\tTime:50.5374\n",
      "\n",
      "Test Loss:0.8542\tRecon Loss:5.9286\tTriplet Loss:0.4684\tStatic Loss:0.8421\n",
      "\n",
      "\tEpoch:132\tTrain Loss:0.1811\tRecon Loss:1.8511\tTriplet Loss:0.1015\tStatic Loss:0.1724\t\n",
      "Val Loss:0.2548\tRecon Loss:1.9669\tTriplet Loss:0.1250\tStatic Loss:0.2507\n",
      "\n",
      "\tTime:49.7000\n",
      "\n",
      "Test Loss:0.8362\tRecon Loss:5.7998\tTriplet Loss:0.4133\tStatic Loss:0.8288\n",
      "\n",
      "\tEpoch:133\tTrain Loss:0.1714\tRecon Loss:1.8313\tTriplet Loss:0.0992\tStatic Loss:0.1620\t\n",
      "Val Loss:0.2551\tRecon Loss:1.9819\tTriplet Loss:0.1204\tStatic Loss:0.2513\n",
      "\n",
      "\tTime:49.5660\n",
      "\n",
      "Test Loss:0.8372\tRecon Loss:5.7853\tTriplet Loss:0.4228\tStatic Loss:0.8292\n",
      "\n",
      "\tEpoch:134\tTrain Loss:0.1714\tRecon Loss:1.8456\tTriplet Loss:0.0902\tStatic Loss:0.1627\t\n",
      "Val Loss:0.2618\tRecon Loss:1.9591\tTriplet Loss:0.1230\tStatic Loss:0.2587\n",
      "\n",
      "\tTime:48.1026\n",
      "\n",
      "Test Loss:0.8510\tRecon Loss:5.8084\tTriplet Loss:0.4208\tStatic Loss:0.8445\n",
      "\n",
      "\tEpoch:135\tTrain Loss:0.1755\tRecon Loss:1.8466\tTriplet Loss:0.0944\tStatic Loss:0.1669\t\n",
      "Val Loss:0.2561\tRecon Loss:1.9779\tTriplet Loss:0.1301\tStatic Loss:0.2514\n",
      "\n",
      "\tTime:48.8226\n",
      "\n",
      "Test Loss:0.8401\tRecon Loss:5.9206\tTriplet Loss:0.4101\tStatic Loss:0.8323\n",
      "\n",
      "\tEpoch:136\tTrain Loss:0.1725\tRecon Loss:1.8439\tTriplet Loss:0.0943\tStatic Loss:0.1636\t\n",
      "Val Loss:0.2588\tRecon Loss:1.9766\tTriplet Loss:0.1311\tStatic Loss:0.2544\n",
      "\n",
      "\tTime:48.7875\n",
      "\n",
      "Test Loss:0.8307\tRecon Loss:5.8092\tTriplet Loss:0.3795\tStatic Loss:0.8260\n",
      "\n",
      "\tEpoch:137\tTrain Loss:0.1725\tRecon Loss:1.8524\tTriplet Loss:0.0913\tStatic Loss:0.1639\t\n",
      "Val Loss:0.2556\tRecon Loss:1.9423\tTriplet Loss:0.1225\tStatic Loss:0.2520\n",
      "\n",
      "\tTime:49.5219\n",
      "\n",
      "Test Loss:0.8402\tRecon Loss:5.7203\tTriplet Loss:0.4339\tStatic Loss:0.8320\n",
      "\n",
      "\tEpoch:138\tTrain Loss:0.1735\tRecon Loss:1.8413\tTriplet Loss:0.1001\tStatic Loss:0.1642\t\n",
      "Val Loss:0.2623\tRecon Loss:2.0545\tTriplet Loss:0.1297\tStatic Loss:0.2577\n",
      "\n",
      "\tTime:49.3910\n",
      "\n",
      "Test Loss:0.8659\tRecon Loss:6.0898\tTriplet Loss:0.4337\tStatic Loss:0.8569\n",
      "\n",
      "\tEpoch:139\tTrain Loss:0.1902\tRecon Loss:1.8714\tTriplet Loss:0.1013\tStatic Loss:0.1823\t\n",
      "Val Loss:0.2676\tRecon Loss:1.9914\tTriplet Loss:0.1418\tStatic Loss:0.2629\n",
      "\n",
      "\tTime:49.1071\n",
      "\n",
      "Test Loss:0.8543\tRecon Loss:5.8144\tTriplet Loss:0.4363\tStatic Loss:0.8465\n",
      "\n",
      "\tEpoch:140\tTrain Loss:0.1943\tRecon Loss:1.8544\tTriplet Loss:0.1071\tStatic Loss:0.1864\t\n",
      "Val Loss:0.2669\tRecon Loss:1.9294\tTriplet Loss:0.1331\tStatic Loss:0.2637\n",
      "\n",
      "\tTime:49.1887\n",
      "\n",
      "Test Loss:0.8922\tRecon Loss:5.8131\tTriplet Loss:0.4369\tStatic Loss:0.8885\n",
      "\n",
      "\tEpoch:141\tTrain Loss:0.1883\tRecon Loss:1.8424\tTriplet Loss:0.1035\tStatic Loss:0.1802\t\n",
      "Val Loss:0.2602\tRecon Loss:2.0287\tTriplet Loss:0.1313\tStatic Loss:0.2554\n",
      "\n",
      "\tTime:49.1652\n",
      "\n",
      "Test Loss:0.8522\tRecon Loss:5.9009\tTriplet Loss:0.4148\tStatic Loss:0.8455\n",
      "\n",
      "\tEpoch:142\tTrain Loss:0.1808\tRecon Loss:2.0136\tTriplet Loss:0.0996\tStatic Loss:0.1706\t\n",
      "Val Loss:0.2544\tRecon Loss:2.0053\tTriplet Loss:0.1299\tStatic Loss:0.2494\n",
      "\n",
      "\tTime:48.8410\n",
      "\n",
      "Test Loss:0.8468\tRecon Loss:5.9769\tTriplet Loss:0.4276\tStatic Loss:0.8374\n",
      "\n",
      "\tEpoch:143\tTrain Loss:0.1760\tRecon Loss:1.8834\tTriplet Loss:0.0985\tStatic Loss:0.1667\t\n",
      "Val Loss:0.2521\tRecon Loss:1.9500\tTriplet Loss:0.1241\tStatic Loss:0.2479\n",
      "\n",
      "\tTime:48.4140\n",
      "\n",
      "Test Loss:0.8485\tRecon Loss:5.8037\tTriplet Loss:0.4360\tStatic Loss:0.8402\n",
      "\n",
      "\tEpoch:144\tTrain Loss:0.1773\tRecon Loss:1.8761\tTriplet Loss:0.1004\tStatic Loss:0.1680\t\n",
      "Val Loss:0.2671\tRecon Loss:1.9733\tTriplet Loss:0.1249\tStatic Loss:0.2643\n",
      "\n",
      "\tTime:48.2790\n",
      "\n",
      "Test Loss:0.9027\tRecon Loss:5.8454\tTriplet Loss:0.4026\tStatic Loss:0.9033\n",
      "\n",
      "\tEpoch:145\tTrain Loss:0.1843\tRecon Loss:1.8902\tTriplet Loss:0.1071\tStatic Loss:0.1750\t\n",
      "Val Loss:0.2502\tRecon Loss:1.9288\tTriplet Loss:0.1126\tStatic Loss:0.2471\n",
      "\n",
      "\tTime:48.4374\n",
      "\n",
      "Test Loss:0.8361\tRecon Loss:5.7321\tTriplet Loss:0.4165\tStatic Loss:0.8291\n",
      "\n",
      "\tEpoch:146\tTrain Loss:0.1747\tRecon Loss:1.8529\tTriplet Loss:0.0975\tStatic Loss:0.1657\t\n",
      "Val Loss:0.2541\tRecon Loss:1.9504\tTriplet Loss:0.1280\tStatic Loss:0.2498\n",
      "\n",
      "\tTime:48.3336\n",
      "\n",
      "Test Loss:0.8628\tRecon Loss:5.7622\tTriplet Loss:0.4298\tStatic Loss:0.8571\n",
      "\n",
      "\tEpoch:147\tTrain Loss:0.1732\tRecon Loss:1.8472\tTriplet Loss:0.0906\tStatic Loss:0.1647\t\n",
      "Val Loss:0.2537\tRecon Loss:1.9415\tTriplet Loss:0.1347\tStatic Loss:0.2487\n",
      "\n",
      "\tTime:48.7208\n",
      "\n",
      "Test Loss:0.8397\tRecon Loss:5.7439\tTriplet Loss:0.4461\tStatic Loss:0.8300\n",
      "\n",
      "\tEpoch:148\tTrain Loss:0.1721\tRecon Loss:1.8446\tTriplet Loss:0.0952\tStatic Loss:0.1631\t\n",
      "Val Loss:0.2501\tRecon Loss:1.9281\tTriplet Loss:0.1185\tStatic Loss:0.2465\n",
      "\n",
      "\tTime:49.0436\n",
      "\n",
      "Test Loss:0.8272\tRecon Loss:5.7278\tTriplet Loss:0.4472\tStatic Loss:0.8162\n",
      "\n",
      "\tEpoch:149\tTrain Loss:0.1765\tRecon Loss:1.8551\tTriplet Loss:0.0953\tStatic Loss:0.1678\t\n",
      "Val Loss:0.2555\tRecon Loss:1.9571\tTriplet Loss:0.1211\tStatic Loss:0.2519\n",
      "\n",
      "\tTime:49.8127\n",
      "\n",
      "Test Loss:0.8466\tRecon Loss:5.7776\tTriplet Loss:0.4262\tStatic Loss:0.8394\n",
      "\n",
      "\tEpoch:150\tTrain Loss:0.1734\tRecon Loss:1.8383\tTriplet Loss:0.0964\tStatic Loss:0.1645\t\n",
      "Val Loss:0.2536\tRecon Loss:1.9794\tTriplet Loss:0.1322\tStatic Loss:0.2484\n",
      "\n",
      "\tTime:49.9612\n",
      "\n",
      "Test Loss:0.8290\tRecon Loss:5.9035\tTriplet Loss:0.4274\tStatic Loss:0.8184\n",
      "\n",
      "\tEpoch:151\tTrain Loss:0.1713\tRecon Loss:1.8427\tTriplet Loss:0.0911\tStatic Loss:0.1626\t\n",
      "Val Loss:0.2577\tRecon Loss:1.9918\tTriplet Loss:0.1250\tStatic Loss:0.2536\n",
      "\n",
      "\tTime:48.9425\n",
      "\n",
      "Test Loss:0.8532\tRecon Loss:5.8009\tTriplet Loss:0.4555\tStatic Loss:0.8434\n",
      "\n",
      "\tEpoch:152\tTrain Loss:0.1695\tRecon Loss:1.8384\tTriplet Loss:0.0924\tStatic Loss:0.1606\t\n",
      "Val Loss:0.2582\tRecon Loss:1.9557\tTriplet Loss:0.1253\tStatic Loss:0.2545\n",
      "\n",
      "\tTime:48.7187\n",
      "\n",
      "Test Loss:0.8542\tRecon Loss:5.7415\tTriplet Loss:0.4174\tStatic Loss:0.8490\n",
      "\n",
      "\tEpoch:153\tTrain Loss:0.1865\tRecon Loss:1.8666\tTriplet Loss:0.1026\tStatic Loss:0.1781\t\n",
      "Val Loss:0.2805\tRecon Loss:1.9543\tTriplet Loss:0.1316\tStatic Loss:0.2787\n",
      "\n",
      "\tTime:50.0033\n",
      "\n",
      "Test Loss:0.9314\tRecon Loss:5.8554\tTriplet Loss:0.4407\tStatic Loss:0.9312\n",
      "\n",
      "\tEpoch:154\tTrain Loss:0.1908\tRecon Loss:1.8586\tTriplet Loss:0.1043\tStatic Loss:0.1828\t\n",
      "Val Loss:0.2627\tRecon Loss:1.9083\tTriplet Loss:0.1327\tStatic Loss:0.2592\n",
      "\n",
      "\tTime:49.2481\n",
      "\n",
      "Test Loss:0.8588\tRecon Loss:5.7052\tTriplet Loss:0.4414\tStatic Loss:0.8521\n",
      "\n",
      "\tEpoch:155\tTrain Loss:0.1808\tRecon Loss:1.8407\tTriplet Loss:0.1000\tStatic Loss:0.1722\t\n",
      "Val Loss:0.2530\tRecon Loss:1.9555\tTriplet Loss:0.1303\tStatic Loss:0.2482\n",
      "\n",
      "\tTime:49.5947\n",
      "\n",
      "Test Loss:0.8313\tRecon Loss:5.7679\tTriplet Loss:0.4199\tStatic Loss:0.8231\n",
      "\n",
      "\tEpoch:156\tTrain Loss:0.1738\tRecon Loss:1.8494\tTriplet Loss:0.0931\tStatic Loss:0.1651\t\n",
      "Val Loss:0.2536\tRecon Loss:2.0006\tTriplet Loss:0.1202\tStatic Loss:0.2495\n",
      "\n",
      "\tTime:49.2472\n",
      "\n",
      "Test Loss:0.8216\tRecon Loss:5.7797\tTriplet Loss:0.4244\tStatic Loss:0.8118\n",
      "\n",
      "\tEpoch:157\tTrain Loss:0.1735\tRecon Loss:1.8395\tTriplet Loss:0.0914\tStatic Loss:0.1651\t\n",
      "Val Loss:0.2581\tRecon Loss:1.9651\tTriplet Loss:0.1266\tStatic Loss:0.2542\n",
      "\n",
      "\tTime:49.2739\n",
      "\n",
      "Test Loss:0.8357\tRecon Loss:5.7892\tTriplet Loss:0.4178\tStatic Loss:0.8280\n",
      "\n",
      "\tEpoch:158\tTrain Loss:0.1697\tRecon Loss:1.8413\tTriplet Loss:0.0905\tStatic Loss:0.1609\t\n",
      "Val Loss:0.2592\tRecon Loss:1.9805\tTriplet Loss:0.1260\tStatic Loss:0.2553\n",
      "\n",
      "\tTime:50.5792\n",
      "\n",
      "Test Loss:0.8483\tRecon Loss:5.8595\tTriplet Loss:0.4165\tStatic Loss:0.8413\n",
      "\n",
      "\tEpoch:159\tTrain Loss:0.1757\tRecon Loss:1.8515\tTriplet Loss:0.1016\tStatic Loss:0.1663\t\n",
      "Val Loss:0.2592\tRecon Loss:1.9216\tTriplet Loss:0.1257\tStatic Loss:0.2559\n",
      "\n",
      "\tTime:49.8082\n",
      "\n",
      "Test Loss:0.8369\tRecon Loss:5.7712\tTriplet Loss:0.4101\tStatic Loss:0.8302\n",
      "\n",
      "\tEpoch:160\tTrain Loss:0.1744\tRecon Loss:1.8558\tTriplet Loss:0.0976\tStatic Loss:0.1653\t\n",
      "Val Loss:0.2586\tRecon Loss:1.9845\tTriplet Loss:0.1279\tStatic Loss:0.2545\n",
      "\n",
      "\tTime:49.3593\n",
      "\n",
      "Test Loss:0.8558\tRecon Loss:5.8306\tTriplet Loss:0.4219\tStatic Loss:0.8495\n",
      "\n",
      "\tEpoch:161\tTrain Loss:0.1720\tRecon Loss:1.8467\tTriplet Loss:0.0895\tStatic Loss:0.1635\t\n",
      "Val Loss:0.2571\tRecon Loss:1.9246\tTriplet Loss:0.1305\tStatic Loss:0.2531\n",
      "\n",
      "\tTime:49.8924\n",
      "\n",
      "Test Loss:0.8350\tRecon Loss:5.7432\tTriplet Loss:0.4207\tStatic Loss:0.8274\n",
      "\n",
      "\tEpoch:162\tTrain Loss:0.1713\tRecon Loss:1.8366\tTriplet Loss:0.0939\tStatic Loss:0.1624\t\n",
      "Val Loss:0.2593\tRecon Loss:1.9358\tTriplet Loss:0.1271\tStatic Loss:0.2558\n",
      "\n",
      "\tTime:51.7549\n",
      "\n",
      "Test Loss:0.8552\tRecon Loss:5.7225\tTriplet Loss:0.4113\tStatic Loss:0.8510\n",
      "\n",
      "\tEpoch:163\tTrain Loss:0.1726\tRecon Loss:1.8483\tTriplet Loss:0.0940\tStatic Loss:0.1637\t\n",
      "Val Loss:0.2569\tRecon Loss:1.9556\tTriplet Loss:0.1316\tStatic Loss:0.2524\n",
      "\n",
      "\tTime:51.0235\n",
      "\n",
      "Test Loss:0.8318\tRecon Loss:5.7761\tTriplet Loss:0.4091\tStatic Loss:0.8246\n",
      "\n",
      "\tEpoch:164\tTrain Loss:0.1758\tRecon Loss:1.8569\tTriplet Loss:0.0924\tStatic Loss:0.1674\t\n",
      "Val Loss:0.2674\tRecon Loss:1.9624\tTriplet Loss:0.1189\tStatic Loss:0.2653\n",
      "\n",
      "\tTime:50.9537\n",
      "\n",
      "Test Loss:0.8617\tRecon Loss:5.8024\tTriplet Loss:0.4564\tStatic Loss:0.8528\n",
      "\n",
      "\tEpoch:165\tTrain Loss:0.1739\tRecon Loss:1.8385\tTriplet Loss:0.0973\tStatic Loss:0.1649\t\n",
      "Val Loss:0.2554\tRecon Loss:1.9162\tTriplet Loss:0.1311\tStatic Loss:0.2512\n",
      "\n",
      "\tTime:51.2638\n",
      "\n",
      "Test Loss:0.8419\tRecon Loss:5.7169\tTriplet Loss:0.4241\tStatic Loss:0.8349\n",
      "\n",
      "\tEpoch:166\tTrain Loss:0.1668\tRecon Loss:1.8253\tTriplet Loss:0.0925\tStatic Loss:0.1577\t\n",
      "Val Loss:0.2565\tRecon Loss:1.9382\tTriplet Loss:0.1259\tStatic Loss:0.2527\n",
      "\n",
      "\tTime:51.7529\n",
      "\n",
      "Test Loss:0.8353\tRecon Loss:5.7448\tTriplet Loss:0.4236\tStatic Loss:0.8274\n",
      "\n",
      "\tEpoch:167\tTrain Loss:0.1689\tRecon Loss:1.8425\tTriplet Loss:0.0903\tStatic Loss:0.1600\t\n",
      "Val Loss:0.2558\tRecon Loss:1.9706\tTriplet Loss:0.1167\tStatic Loss:0.2526\n",
      "\n",
      "\tTime:51.7570\n",
      "\n",
      "Test Loss:0.8401\tRecon Loss:5.7693\tTriplet Loss:0.4128\tStatic Loss:0.8335\n",
      "\n",
      "\tEpoch:168\tTrain Loss:0.1675\tRecon Loss:1.8362\tTriplet Loss:0.0962\tStatic Loss:0.1580\t\n",
      "Val Loss:0.2577\tRecon Loss:1.9464\tTriplet Loss:0.1177\tStatic Loss:0.2548\n",
      "\n",
      "\tTime:52.5128\n",
      "\n",
      "Test Loss:0.8662\tRecon Loss:5.7497\tTriplet Loss:0.4478\tStatic Loss:0.8592\n",
      "\n",
      "\tEpoch:169\tTrain Loss:0.1677\tRecon Loss:1.8467\tTriplet Loss:0.0895\tStatic Loss:0.1587\t\n",
      "Val Loss:0.2594\tRecon Loss:1.9719\tTriplet Loss:0.1156\tStatic Loss:0.2567\n",
      "\n",
      "\tTime:52.0931\n",
      "\n",
      "Test Loss:0.8725\tRecon Loss:5.8862\tTriplet Loss:0.4297\tStatic Loss:0.8666\n",
      "\n",
      "\tEpoch:170\tTrain Loss:0.1716\tRecon Loss:1.8465\tTriplet Loss:0.0936\tStatic Loss:0.1626\t\n",
      "Val Loss:0.2552\tRecon Loss:2.0040\tTriplet Loss:0.1253\tStatic Loss:0.2507\n",
      "\n",
      "\tTime:51.6993\n",
      "\n",
      "Test Loss:0.8257\tRecon Loss:5.8213\tTriplet Loss:0.4099\tStatic Loss:0.8173\n",
      "\n",
      "\tEpoch:171\tTrain Loss:0.1678\tRecon Loss:1.8455\tTriplet Loss:0.0933\tStatic Loss:0.1585\t\n",
      "Val Loss:0.2546\tRecon Loss:1.9290\tTriplet Loss:0.1249\tStatic Loss:0.2509\n",
      "\n",
      "\tTime:51.3138\n",
      "\n",
      "Test Loss:0.8268\tRecon Loss:5.7915\tTriplet Loss:0.4210\tStatic Loss:0.8177\n",
      "\n",
      "\tEpoch:172\tTrain Loss:0.1669\tRecon Loss:1.8349\tTriplet Loss:0.0926\tStatic Loss:0.1577\t\n",
      "Val Loss:0.2607\tRecon Loss:1.9486\tTriplet Loss:0.1292\tStatic Loss:0.2570\n",
      "\n",
      "\tTime:52.1188\n",
      "\n",
      "Test Loss:0.8431\tRecon Loss:5.7682\tTriplet Loss:0.4189\tStatic Loss:0.8362\n",
      "\n",
      "\tEpoch:173\tTrain Loss:0.1682\tRecon Loss:1.8460\tTriplet Loss:0.0924\tStatic Loss:0.1590\t\n",
      "Val Loss:0.2615\tRecon Loss:1.9709\tTriplet Loss:0.1277\tStatic Loss:0.2578\n",
      "\n",
      "\tTime:51.1584\n",
      "\n",
      "Test Loss:0.8596\tRecon Loss:5.8919\tTriplet Loss:0.4198\tStatic Loss:0.8532\n",
      "\n",
      "\tEpoch:174\tTrain Loss:0.1746\tRecon Loss:1.8501\tTriplet Loss:0.0935\tStatic Loss:0.1659\t\n",
      "Val Loss:0.2608\tRecon Loss:2.0103\tTriplet Loss:0.1211\tStatic Loss:0.2573\n",
      "\n",
      "\tTime:50.4916\n",
      "\n",
      "Test Loss:0.8541\tRecon Loss:5.9347\tTriplet Loss:0.4196\tStatic Loss:0.8468\n",
      "\n",
      "\tEpoch:175\tTrain Loss:0.1735\tRecon Loss:1.8569\tTriplet Loss:0.0932\tStatic Loss:0.1647\t\n",
      "Val Loss:0.2569\tRecon Loss:1.9757\tTriplet Loss:0.1267\tStatic Loss:0.2528\n",
      "\n",
      "\tTime:52.3523\n",
      "\n",
      "Test Loss:0.8394\tRecon Loss:5.8103\tTriplet Loss:0.4086\tStatic Loss:0.8327\n",
      "\n",
      "\tEpoch:176\tTrain Loss:0.1704\tRecon Loss:1.8420\tTriplet Loss:0.0934\tStatic Loss:0.1614\t\n",
      "Val Loss:0.2514\tRecon Loss:1.9403\tTriplet Loss:0.1248\tStatic Loss:0.2472\n",
      "\n",
      "\tTime:50.2802\n",
      "\n",
      "Test Loss:0.8248\tRecon Loss:5.7926\tTriplet Loss:0.4081\tStatic Loss:0.8167\n",
      "\n",
      "\tEpoch:177\tTrain Loss:0.1664\tRecon Loss:1.8382\tTriplet Loss:0.0858\tStatic Loss:0.1577\t\n",
      "Val Loss:0.2567\tRecon Loss:1.9251\tTriplet Loss:0.1228\tStatic Loss:0.2534\n",
      "\n",
      "\tTime:49.4733\n",
      "\n",
      "Test Loss:0.8316\tRecon Loss:5.7503\tTriplet Loss:0.4295\tStatic Loss:0.8226\n",
      "\n",
      "\tEpoch:178\tTrain Loss:0.1703\tRecon Loss:1.8395\tTriplet Loss:0.0956\tStatic Loss:0.1611\t\n",
      "Val Loss:0.2649\tRecon Loss:1.9502\tTriplet Loss:0.1287\tStatic Loss:0.2616\n",
      "\n",
      "\tTime:49.7990\n",
      "\n",
      "Test Loss:0.8620\tRecon Loss:5.7832\tTriplet Loss:0.4557\tStatic Loss:0.8534\n",
      "\n",
      "\tEpoch:179\tTrain Loss:0.1870\tRecon Loss:1.8912\tTriplet Loss:0.0998\tStatic Loss:0.1787\t\n",
      "Val Loss:0.2629\tRecon Loss:1.9649\tTriplet Loss:0.1328\tStatic Loss:0.2589\n",
      "\n",
      "\tTime:49.7990\n",
      "\n",
      "Test Loss:0.8384\tRecon Loss:5.7749\tTriplet Loss:0.4598\tStatic Loss:0.8269\n",
      "\n",
      "\tEpoch:180\tTrain Loss:0.1765\tRecon Loss:1.8383\tTriplet Loss:0.0947\tStatic Loss:0.1681\t\n",
      "Val Loss:0.2578\tRecon Loss:1.9451\tTriplet Loss:0.1244\tStatic Loss:0.2542\n",
      "\n",
      "\tTime:49.8588\n",
      "\n",
      "Test Loss:0.8327\tRecon Loss:5.7122\tTriplet Loss:0.4187\tStatic Loss:0.8253\n",
      "\n",
      "\tEpoch:181\tTrain Loss:0.1752\tRecon Loss:1.8444\tTriplet Loss:0.0904\tStatic Loss:0.1669\t\n",
      "Val Loss:0.2596\tRecon Loss:1.9757\tTriplet Loss:0.1211\tStatic Loss:0.2563\n",
      "\n",
      "\tTime:48.2725\n",
      "\n",
      "Test Loss:0.8699\tRecon Loss:5.8902\tTriplet Loss:0.4304\tStatic Loss:0.8636\n",
      "\n",
      "\tEpoch:182\tTrain Loss:0.1774\tRecon Loss:1.8396\tTriplet Loss:0.0976\tStatic Loss:0.1688\t\n",
      "Val Loss:0.2525\tRecon Loss:1.9336\tTriplet Loss:0.1221\tStatic Loss:0.2487\n",
      "\n",
      "\tTime:49.7490\n",
      "\n",
      "Test Loss:0.8115\tRecon Loss:5.7295\tTriplet Loss:0.4440\tStatic Loss:0.7991\n",
      "\n",
      "\tEpoch:183\tTrain Loss:0.1684\tRecon Loss:1.8376\tTriplet Loss:0.0919\tStatic Loss:0.1593\t\n",
      "Val Loss:0.2596\tRecon Loss:1.9657\tTriplet Loss:0.1257\tStatic Loss:0.2560\n",
      "\n",
      "\tTime:49.0467\n",
      "\n",
      "Test Loss:0.8584\tRecon Loss:5.7224\tTriplet Loss:0.4086\tStatic Loss:0.8548\n",
      "\n",
      "\tEpoch:184\tTrain Loss:0.1662\tRecon Loss:1.8413\tTriplet Loss:0.0923\tStatic Loss:0.1569\t\n",
      "Val Loss:0.2559\tRecon Loss:1.9264\tTriplet Loss:0.1202\tStatic Loss:0.2527\n",
      "\n",
      "\tTime:49.0509\n",
      "\n",
      "Test Loss:0.8187\tRecon Loss:5.7398\tTriplet Loss:0.4248\tStatic Loss:0.8088\n",
      "\n",
      "\tEpoch:185\tTrain Loss:0.1655\tRecon Loss:1.8375\tTriplet Loss:0.0906\tStatic Loss:0.1563\t\n",
      "Val Loss:0.2594\tRecon Loss:1.9428\tTriplet Loss:0.1352\tStatic Loss:0.2550\n",
      "\n",
      "\tTime:48.6931\n",
      "\n",
      "Test Loss:0.8396\tRecon Loss:5.7442\tTriplet Loss:0.4133\tStatic Loss:0.8332\n",
      "\n",
      "\tEpoch:186\tTrain Loss:0.1695\tRecon Loss:1.8391\tTriplet Loss:0.0967\tStatic Loss:0.1600\t\n",
      "Val Loss:0.2563\tRecon Loss:1.9307\tTriplet Loss:0.1284\tStatic Loss:0.2524\n",
      "\n",
      "\tTime:49.0513\n",
      "\n",
      "Test Loss:0.8341\tRecon Loss:5.7492\tTriplet Loss:0.4144\tStatic Loss:0.8269\n",
      "\n",
      "\tEpoch:187\tTrain Loss:0.1679\tRecon Loss:1.8402\tTriplet Loss:0.0932\tStatic Loss:0.1587\t\n",
      "Val Loss:0.2602\tRecon Loss:2.1535\tTriplet Loss:0.1359\tStatic Loss:0.2537\n",
      "\n",
      "\tTime:49.1374\n",
      "\n",
      "Test Loss:0.8485\tRecon Loss:6.5441\tTriplet Loss:0.4182\tStatic Loss:0.8345\n",
      "\n",
      "\tEpoch:188\tTrain Loss:0.1673\tRecon Loss:1.9097\tTriplet Loss:0.0911\tStatic Loss:0.1575\t\n",
      "Val Loss:0.2565\tRecon Loss:1.9640\tTriplet Loss:0.1243\tStatic Loss:0.2526\n",
      "\n",
      "\tTime:47.6271\n",
      "\n",
      "Test Loss:0.8391\tRecon Loss:5.7457\tTriplet Loss:0.4432\tStatic Loss:0.8296\n",
      "\n",
      "\tEpoch:189\tTrain Loss:0.1684\tRecon Loss:1.8416\tTriplet Loss:0.0935\tStatic Loss:0.1592\t\n",
      "Val Loss:0.2560\tRecon Loss:1.9160\tTriplet Loss:0.1180\tStatic Loss:0.2532\n",
      "\n",
      "\tTime:43.6974\n",
      "\n",
      "Test Loss:0.8238\tRecon Loss:5.7300\tTriplet Loss:0.4206\tStatic Loss:0.8150\n",
      "\n",
      "\tEpoch:190\tTrain Loss:0.1679\tRecon Loss:1.8346\tTriplet Loss:0.0927\tStatic Loss:0.1588\t\n",
      "Val Loss:0.2580\tRecon Loss:1.9788\tTriplet Loss:0.1258\tStatic Loss:0.2541\n",
      "\n",
      "\tTime:46.8957\n",
      "\n",
      "Test Loss:0.8321\tRecon Loss:5.8232\tTriplet Loss:0.4208\tStatic Loss:0.8233\n",
      "\n",
      "\tEpoch:191\tTrain Loss:0.1652\tRecon Loss:1.8518\tTriplet Loss:0.0903\tStatic Loss:0.1558\t\n",
      "Val Loss:0.2620\tRecon Loss:1.9610\tTriplet Loss:0.1252\tStatic Loss:0.2587\n",
      "\n",
      "\tTime:49.2056\n",
      "\n",
      "Test Loss:0.8710\tRecon Loss:5.7589\tTriplet Loss:0.4413\tStatic Loss:0.8651\n",
      "\n",
      "\tEpoch:192\tTrain Loss:0.1644\tRecon Loss:1.8469\tTriplet Loss:0.0896\tStatic Loss:0.1550\t\n",
      "Val Loss:0.2550\tRecon Loss:1.9670\tTriplet Loss:0.1347\tStatic Loss:0.2499\n",
      "\n",
      "\tTime:49.9900\n",
      "\n",
      "Test Loss:0.8460\tRecon Loss:5.7925\tTriplet Loss:0.4055\tStatic Loss:0.8406\n",
      "\n",
      "\tEpoch:193\tTrain Loss:0.1646\tRecon Loss:1.8386\tTriplet Loss:0.0901\tStatic Loss:0.1553\t\n",
      "Val Loss:0.2581\tRecon Loss:1.9415\tTriplet Loss:0.1425\tStatic Loss:0.2528\n",
      "\n",
      "\tTime:49.5739\n",
      "\n",
      "Test Loss:0.8372\tRecon Loss:5.7528\tTriplet Loss:0.3817\tStatic Loss:0.8336\n",
      "\n",
      "\tEpoch:194\tTrain Loss:0.1738\tRecon Loss:1.8534\tTriplet Loss:0.0961\tStatic Loss:0.1648\t\n",
      "Val Loss:0.2561\tRecon Loss:1.9387\tTriplet Loss:0.1237\tStatic Loss:0.2525\n",
      "\n",
      "\tTime:49.7564\n",
      "\n",
      "Test Loss:0.8148\tRecon Loss:5.8544\tTriplet Loss:0.4061\tStatic Loss:0.8052\n",
      "\n",
      "\tEpoch:195\tTrain Loss:0.1892\tRecon Loss:1.8620\tTriplet Loss:0.1075\tStatic Loss:0.1806\t\n",
      "Val Loss:0.3409\tRecon Loss:2.0962\tTriplet Loss:0.1822\tStatic Loss:0.3393\n",
      "\n",
      "\tTime:48.3627\n",
      "\n",
      "Test Loss:1.0599\tRecon Loss:6.2901\tTriplet Loss:0.6025\tStatic Loss:1.0533\n",
      "\n",
      "\tEpoch:196\tTrain Loss:0.2812\tRecon Loss:1.9966\tTriplet Loss:0.1922\tStatic Loss:0.2729\t\n",
      "Val Loss:0.2928\tRecon Loss:2.0117\tTriplet Loss:0.1826\tStatic Loss:0.2866\n",
      "\n",
      "\tTime:48.5627\n",
      "\n",
      "Test Loss:0.9550\tRecon Loss:6.0378\tTriplet Loss:0.6224\tStatic Loss:0.9374\n",
      "\n",
      "\tEpoch:197\tTrain Loss:0.2428\tRecon Loss:1.9005\tTriplet Loss:0.1642\tStatic Loss:0.2341\t\n",
      "Val Loss:0.2770\tRecon Loss:1.9631\tTriplet Loss:0.1679\tStatic Loss:0.2710\n",
      "\n",
      "\tTime:48.4818\n",
      "\n",
      "Test Loss:0.9283\tRecon Loss:5.8429\tTriplet Loss:0.5790\tStatic Loss:0.9140\n",
      "\n",
      "\tEpoch:198\tTrain Loss:0.2279\tRecon Loss:1.8754\tTriplet Loss:0.1603\tStatic Loss:0.2181\t\n",
      "Val Loss:0.2727\tRecon Loss:1.9629\tTriplet Loss:0.1744\tStatic Loss:0.2656\n",
      "\n",
      "\tTime:48.6646\n",
      "\n",
      "Test Loss:0.8939\tRecon Loss:5.8908\tTriplet Loss:0.5581\tStatic Loss:0.8775\n",
      "\n",
      "\tEpoch:199\tTrain Loss:0.2198\tRecon Loss:1.8660\tTriplet Loss:0.1490\tStatic Loss:0.2104\t\n",
      "Val Loss:0.2754\tRecon Loss:1.9665\tTriplet Loss:0.1688\tStatic Loss:0.2692\n",
      "\n",
      "\tTime:48.9037\n",
      "\n",
      "Test Loss:0.9321\tRecon Loss:5.8932\tTriplet Loss:0.5661\tStatic Loss:0.9191\n",
      "\n",
      "\t\n",
      "Unc Est in Static characteristics:0.0008\tUnc Est in Streamflow, dynamic:0.0004\t\n",
      "\n",
      "\t"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 122] Disk quota exceeded: 'DATA/RESULT/ATT_NL_3_1.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;66;03m# triplet_criterion = torch.nn.TripletMarginWithDistanceLoss(distance_function=torch.nn.PairwiseDistance(p=2.0, eps=1e-06), margin=alpha, reduction=\"none\")\u001b[39;00m\n\u001b[1;32m     12\u001b[0m         optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[0;32m---> 13\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend([a_model, \u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRESULT_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_model\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m])\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36mrun_model\u001b[0;34m(model_object, train_data, validation_data, test_data, model_save_path)\u001b[0m\n\u001b[1;32m    301\u001b[0m preds_std_reconstruction \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([model(input_data\u001b[38;5;241m.\u001b[39mto(device))[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m)])\u001b[38;5;241m.\u001b[39mstd(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mUnc Est in Static characteristics:\u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mUnc Est in Streamflow, dynamic:\u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(preds_std, preds_std_reconstruction), end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 303\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_save_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m min_val, total_recon_loss\u001b[38;5;241m/\u001b[39m((batch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m(year\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)), total_triplet_loss\u001b[38;5;241m/\u001b[39m((batch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m(year\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)), total_static_loss\u001b[38;5;241m/\u001b[39m((batch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m(year\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)), preds_std, preds_std_reconstruction\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py:377\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;124;03m\"\"\"save(obj, f, pickle_module=pickle, pickle_protocol=DEFAULT_PROTOCOL, _use_new_zipfile_serialization=True)\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \n\u001b[1;32m    343\u001b[0m \u001b[38;5;124;03mSaves an object to a disk file.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m    >>> torch.save(x, buffer)\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    375\u001b[0m _check_dill_version(pickle_module)\n\u001b[0;32m--> 377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m    379\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(opened_file) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py:231\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 231\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py:212\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 122] Disk quota exceeded: 'DATA/RESULT/ATT_NL_3_1.pt'"
     ]
    }
   ],
   "source": [
    "models = [\"ATT_NL_0\", \"ATT_NL_3\"] #KGSSL : ATT_NL, BIM: ATT_NL_3\n",
    "results = []\n",
    "\n",
    "for a_model in models:\n",
    "    for i in range(5):\n",
    "        print(a_model)\n",
    "        model = globals()[a_model](in_channels=len(input_channels), stat_channels=len(static_channels), code_dim=code_dim, device=device)\n",
    "        model = model.to(device)\n",
    "        criterion = torch.nn.MSELoss(reduction=\"none\")\n",
    "        triplet_criterion = torch.nn.TripletMarginLoss(margin=alpha, p=2.0, eps=1e-06, reduction=\"none\")\n",
    "        # triplet_criterion = torch.nn.TripletMarginWithDistanceLoss(distance_function=torch.nn.PairwiseDistance(p=2.0, eps=1e-06), margin=alpha, reduction=\"none\")\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        results.append([a_model, run_model(model, train_data, validation_data, test_data,os.path.join(RESULT_DIR, a_model+'_'+str(i)+'.pt') )])\n",
    "        \n",
    "print(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv('results1.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_model = \"ATT_NL_0\"\n",
    "\n",
    "# model.load_state_dict(torch.load(os.path.join(RESULT_DIR, a_model+'.pt')), strict=False)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:(531, 39, 365, 33)\tValidation Data:(531, 9, 365, 33)\tTest Data:(531, 19, 365, 33)\n",
      "recon weight:0.1\tstatic weight:10\ttriplet weight:1\tcorr_per:50\tcorr_std:1\tmodel:ATT_NL_0\n",
      "Epoch:0\tTrain Loss:1.0409\tRecon Loss:4.1464\tTriplet Loss:0.3989\tStatic Loss:1.0741\t\n",
      "Val Loss:0.9000\tRecon Loss:3.9999\tTriplet Loss:0.2564\tStatic Loss:0.9334\n",
      "\n",
      "\tTime:54.4322\n",
      "\n",
      "Test Loss:1.3625\tRecon Loss:11.9434\tTriplet Loss:0.8200\tStatic Loss:1.3109\n",
      "\n",
      "\tEpoch:1\tTrain Loss:0.8597\tRecon Loss:3.9762\tTriplet Loss:0.2519\tStatic Loss:0.8893\t\n",
      "Val Loss:0.8385\tRecon Loss:3.9724\tTriplet Loss:0.2183\tStatic Loss:0.8691\n",
      "\n",
      "\tTime:59.8261\n",
      "\n",
      "Test Loss:1.1840\tRecon Loss:11.8857\tTriplet Loss:0.7027\tStatic Loss:1.1251\n",
      "\n",
      "\tEpoch:2\tTrain Loss:0.8114\tRecon Loss:3.9711\tTriplet Loss:0.2122\tStatic Loss:0.8397\t\n",
      "Val Loss:0.8113\tRecon Loss:3.9589\tTriplet Loss:0.2113\tStatic Loss:0.8398\n",
      "\n",
      "\tTime:53.3018\n",
      "\n",
      "Test Loss:1.1772\tRecon Loss:11.8554\tTriplet Loss:0.6546\tStatic Loss:1.1227\n",
      "\n",
      "\tEpoch:3\tTrain Loss:0.7857\tRecon Loss:3.9569\tTriplet Loss:0.2000\tStatic Loss:0.8126\t\n",
      "Val Loss:0.7928\tRecon Loss:3.9006\tTriplet Loss:0.1963\tStatic Loss:0.8213\n",
      "\n",
      "\tTime:62.3474\n",
      "\n",
      "Test Loss:1.1167\tRecon Loss:11.6653\tTriplet Loss:0.5933\tStatic Loss:1.0636\n",
      "\n",
      "\tEpoch:4\tTrain Loss:0.7670\tRecon Loss:3.8779\tTriplet Loss:0.1876\tStatic Loss:0.7938\t\n",
      "Val Loss:0.7831\tRecon Loss:3.7892\tTriplet Loss:0.1873\tStatic Loss:0.8127\n",
      "\n",
      "\tTime:54.0068\n",
      "\n",
      "Test Loss:1.0958\tRecon Loss:11.3556\tTriplet Loss:0.5510\tStatic Loss:1.0476\n",
      "\n",
      "\tEpoch:5\tTrain Loss:0.7555\tRecon Loss:3.7560\tTriplet Loss:0.1722\tStatic Loss:0.7838\t\n",
      "Val Loss:0.7685\tRecon Loss:3.5568\tTriplet Loss:0.1817\tStatic Loss:0.7993\n",
      "\n",
      "\tTime:62.4529\n",
      "\n",
      "Test Loss:1.0809\tRecon Loss:10.6859\tTriplet Loss:0.5378\tStatic Loss:1.0392\n",
      "\n",
      "\tEpoch:6\tTrain Loss:0.7411\tRecon Loss:3.4952\tTriplet Loss:0.1679\tStatic Loss:0.7709\t\n",
      "Val Loss:0.7651\tRecon Loss:3.2802\tTriplet Loss:0.1667\tStatic Loss:0.7997\n",
      "\n",
      "\tTime:53.4210\n",
      "\n",
      "Test Loss:1.0756\tRecon Loss:9.9936\tTriplet Loss:0.5401\tStatic Loss:1.0400\n",
      "\n",
      "\tEpoch:7\tTrain Loss:0.7307\tRecon Loss:3.3785\tTriplet Loss:0.1636\tStatic Loss:0.7609\t\n",
      "Val Loss:0.7567\tRecon Loss:3.1941\tTriplet Loss:0.1658\tStatic Loss:0.7914\n",
      "\n",
      "\tTime:63.9593\n",
      "\n",
      "Test Loss:1.0504\tRecon Loss:9.6432\tTriplet Loss:0.5105\tStatic Loss:1.0184\n",
      "\n",
      "\tEpoch:8\tTrain Loss:0.7197\tRecon Loss:3.0872\tTriplet Loss:0.1513\tStatic Loss:0.7529\t\n",
      "Val Loss:0.7497\tRecon Loss:2.8680\tTriplet Loss:0.1677\tStatic Loss:0.7867\n",
      "\n",
      "\tTime:55.1149\n",
      "\n",
      "Test Loss:1.0421\tRecon Loss:8.7478\tTriplet Loss:0.4841\tStatic Loss:1.0208\n",
      "\n",
      "\tEpoch:9\tTrain Loss:0.7087\tRecon Loss:2.4288\tTriplet Loss:0.1462\tStatic Loss:0.7478\t\n",
      "Val Loss:0.7406\tRecon Loss:2.1664\tTriplet Loss:0.1546\tStatic Loss:0.7849\n",
      "\n",
      "\tTime:62.5503\n",
      "\n",
      "Test Loss:1.0257\tRecon Loss:6.7062\tTriplet Loss:0.4977\tStatic Loss:1.0217\n",
      "\n",
      "\tEpoch:10\tTrain Loss:0.7001\tRecon Loss:2.2146\tTriplet Loss:0.1464\tStatic Loss:0.7403\t\n",
      "Val Loss:0.7425\tRecon Loss:2.1095\tTriplet Loss:0.1709\tStatic Loss:0.7860\n",
      "\n",
      "\tTime:55.0117\n",
      "\n",
      "Test Loss:1.0386\tRecon Loss:6.4352\tTriplet Loss:0.4993\tStatic Loss:1.0386\n",
      "\n",
      "\tEpoch:11\tTrain Loss:0.7018\tRecon Loss:2.6775\tTriplet Loss:0.1444\tStatic Loss:0.7378\t\n",
      "Val Loss:0.7468\tRecon Loss:2.5695\tTriplet Loss:0.1647\tStatic Loss:0.7868\n",
      "\n",
      "\tTime:63.7116\n",
      "\n",
      "Test Loss:1.0323\tRecon Loss:7.7095\tTriplet Loss:0.4824\tStatic Loss:1.0205\n",
      "\n",
      "\tEpoch:12\tTrain Loss:0.6902\tRecon Loss:2.2605\tTriplet Loss:0.1379\tStatic Loss:0.7298\t\n",
      "Val Loss:0.7412\tRecon Loss:2.0715\tTriplet Loss:0.1504\tStatic Loss:0.7870\n",
      "\n",
      "\tTime:54.4623\n",
      "\n",
      "Test Loss:1.0320\tRecon Loss:6.3942\tTriplet Loss:0.4976\tStatic Loss:1.0318\n",
      "\n",
      "\tEpoch:13\tTrain Loss:0.6841\tRecon Loss:2.1392\tTriplet Loss:0.1354\tStatic Loss:0.7245\t\n",
      "Val Loss:0.7244\tRecon Loss:2.0273\tTriplet Loss:0.1447\tStatic Loss:0.7693\n",
      "\n",
      "\tTime:60.7188\n",
      "\n",
      "Test Loss:1.0277\tRecon Loss:6.1964\tTriplet Loss:0.4938\tStatic Loss:1.0294\n",
      "\n",
      "\tEpoch:14\tTrain Loss:0.6794\tRecon Loss:2.0965\tTriplet Loss:0.1377\tStatic Loss:0.7194\t\n",
      "Val Loss:0.7243\tRecon Loss:2.0093\tTriplet Loss:0.1554\tStatic Loss:0.7683\n",
      "\n",
      "\tTime:58.3425\n",
      "\n",
      "Test Loss:1.0466\tRecon Loss:6.2856\tTriplet Loss:0.4695\tStatic Loss:1.0519\n",
      "\n",
      "\tEpoch:15\tTrain Loss:0.6767\tRecon Loss:2.1306\tTriplet Loss:0.1321\tStatic Loss:0.7167\t\n",
      "Val Loss:0.7301\tRecon Loss:1.9876\tTriplet Loss:0.1620\tStatic Loss:0.7743\n",
      "\n",
      "\tTime:58.6481\n",
      "\n",
      "Test Loss:1.0331\tRecon Loss:6.1059\tTriplet Loss:0.4780\tStatic Loss:1.0378\n",
      "\n",
      "\tEpoch:16\tTrain Loss:0.6730\tRecon Loss:2.1299\tTriplet Loss:0.1308\tStatic Loss:0.7127\t\n",
      "Val Loss:0.7303\tRecon Loss:1.9934\tTriplet Loss:0.1532\tStatic Loss:0.7754\n",
      "\n",
      "\tTime:58.5500\n",
      "\n",
      "Test Loss:1.0467\tRecon Loss:6.1038\tTriplet Loss:0.4978\tStatic Loss:1.0510\n",
      "\n",
      "\tEpoch:17\tTrain Loss:0.6694\tRecon Loss:2.1513\tTriplet Loss:0.1275\tStatic Loss:0.7087\t\n",
      "Val Loss:0.7257\tRecon Loss:1.9935\tTriplet Loss:0.1553\tStatic Loss:0.7700\n",
      "\n",
      "\tTime:58.8389\n",
      "\n",
      "Test Loss:1.0313\tRecon Loss:6.1141\tTriplet Loss:0.5226\tStatic Loss:1.0313\n",
      "\n",
      "\tEpoch:18\tTrain Loss:0.6626\tRecon Loss:2.0916\tTriplet Loss:0.1250\tStatic Loss:0.7021\t\n",
      "Val Loss:0.7184\tRecon Loss:1.9492\tTriplet Loss:0.1505\tStatic Loss:0.7628\n",
      "\n",
      "\tTime:58.4260\n",
      "\n",
      "Test Loss:1.0546\tRecon Loss:6.0267\tTriplet Loss:0.4773\tStatic Loss:1.0626\n",
      "\n",
      "\tEpoch:19\tTrain Loss:0.6585\tRecon Loss:2.0114\tTriplet Loss:0.1253\tStatic Loss:0.6983\t\n",
      "Val Loss:0.7188\tRecon Loss:1.9748\tTriplet Loss:0.1477\tStatic Loss:0.7634\n",
      "\n",
      "\tTime:57.7589\n",
      "\n",
      "Test Loss:1.0174\tRecon Loss:6.1322\tTriplet Loss:0.4861\tStatic Loss:1.0193\n",
      "\n",
      "\tEpoch:20\tTrain Loss:0.6554\tRecon Loss:2.0058\tTriplet Loss:0.1230\tStatic Loss:0.6951\t\n",
      "Val Loss:0.7077\tRecon Loss:1.9655\tTriplet Loss:0.1548\tStatic Loss:0.7504\n",
      "\n",
      "\tTime:57.2854\n",
      "\n",
      "Test Loss:0.9659\tRecon Loss:6.0179\tTriplet Loss:0.4783\tStatic Loss:0.9641\n",
      "\n",
      "\tEpoch:21\tTrain Loss:0.6515\tRecon Loss:2.0201\tTriplet Loss:0.1196\tStatic Loss:0.6910\t\n",
      "Val Loss:0.7178\tRecon Loss:1.9493\tTriplet Loss:0.1613\tStatic Loss:0.7612\n",
      "\n",
      "\tTime:57.9674\n",
      "\n",
      "Test Loss:0.9981\tRecon Loss:6.0412\tTriplet Loss:0.4966\tStatic Loss:0.9978\n",
      "\n",
      "\tEpoch:22\tTrain Loss:0.6486\tRecon Loss:1.9869\tTriplet Loss:0.1178\tStatic Loss:0.6882\t\n",
      "Val Loss:0.7216\tRecon Loss:1.9693\tTriplet Loss:0.1487\tStatic Loss:0.7664\n",
      "\n",
      "\tTime:57.7856\n",
      "\n",
      "Test Loss:1.0430\tRecon Loss:6.0638\tTriplet Loss:0.4885\tStatic Loss:1.0482\n",
      "\n",
      "\tEpoch:23\tTrain Loss:0.6474\tRecon Loss:2.0862\tTriplet Loss:0.1183\tStatic Loss:0.6859\t\n",
      "Val Loss:0.7079\tRecon Loss:2.1109\tTriplet Loss:0.1492\tStatic Loss:0.7497\n",
      "\n",
      "\tTime:53.1465\n",
      "\n",
      "Test Loss:0.9686\tRecon Loss:6.5117\tTriplet Loss:0.4524\tStatic Loss:0.9648\n",
      "\n",
      "\tEpoch:24\tTrain Loss:0.6454\tRecon Loss:1.9874\tTriplet Loss:0.1167\tStatic Loss:0.6849\t\n",
      "Val Loss:0.7097\tRecon Loss:1.9246\tTriplet Loss:0.1546\tStatic Loss:0.7530\n",
      "\n",
      "\tTime:63.3272\n",
      "\n",
      "Test Loss:0.9823\tRecon Loss:6.0045\tTriplet Loss:0.4841\tStatic Loss:0.9819\n",
      "\n",
      "\tEpoch:25\tTrain Loss:0.6375\tRecon Loss:1.9797\tTriplet Loss:0.1129\tStatic Loss:0.6766\t\n",
      "Val Loss:0.7089\tRecon Loss:1.9371\tTriplet Loss:0.1596\tStatic Loss:0.7515\n",
      "\n",
      "\tTime:53.2796\n",
      "\n",
      "Test Loss:1.0586\tRecon Loss:5.9825\tTriplet Loss:0.4744\tStatic Loss:1.0678\n",
      "\n",
      "\tEpoch:26\tTrain Loss:0.6392\tRecon Loss:2.0697\tTriplet Loss:0.1205\tStatic Loss:0.6767\t\n",
      "Val Loss:0.7018\tRecon Loss:2.0089\tTriplet Loss:0.1457\tStatic Loss:0.7444\n",
      "\n",
      "\tTime:62.2967\n",
      "\n",
      "Test Loss:0.9811\tRecon Loss:6.2441\tTriplet Loss:0.4958\tStatic Loss:0.9770\n",
      "\n",
      "\tEpoch:27\tTrain Loss:0.6341\tRecon Loss:2.0693\tTriplet Loss:0.1156\tStatic Loss:0.6716\t\n",
      "Val Loss:0.7144\tRecon Loss:1.9516\tTriplet Loss:0.1500\tStatic Loss:0.7585\n",
      "\n",
      "\tTime:53.2387\n",
      "\n",
      "Test Loss:1.0233\tRecon Loss:6.1992\tTriplet Loss:0.4827\tStatic Loss:1.0256\n",
      "\n",
      "\tEpoch:28\tTrain Loss:0.6323\tRecon Loss:1.9681\tTriplet Loss:0.1125\tStatic Loss:0.6709\t\n",
      "Val Loss:0.7014\tRecon Loss:1.9318\tTriplet Loss:0.1635\tStatic Loss:0.7429\n",
      "\n",
      "\tTime:59.9302\n",
      "\n",
      "Test Loss:1.0485\tRecon Loss:5.9774\tTriplet Loss:0.4830\tStatic Loss:1.0557\n",
      "\n",
      "\tEpoch:29\tTrain Loss:0.6318\tRecon Loss:1.9596\tTriplet Loss:0.1125\tStatic Loss:0.6705\t\n",
      "Val Loss:0.7134\tRecon Loss:1.9276\tTriplet Loss:0.1551\tStatic Loss:0.7571\n",
      "\n",
      "\tTime:53.6249\n",
      "\n",
      "Test Loss:0.9896\tRecon Loss:5.9241\tTriplet Loss:0.4530\tStatic Loss:0.9939\n",
      "\n",
      "\tEpoch:30\tTrain Loss:0.6258\tRecon Loss:1.9736\tTriplet Loss:0.1114\tStatic Loss:0.6638\t\n",
      "Val Loss:0.7117\tRecon Loss:1.9367\tTriplet Loss:0.1571\tStatic Loss:0.7549\n",
      "\n",
      "\tTime:62.6760\n",
      "\n",
      "Test Loss:1.0150\tRecon Loss:5.9931\tTriplet Loss:0.4989\tStatic Loss:1.0168\n",
      "\n",
      "\tEpoch:31\tTrain Loss:0.6270\tRecon Loss:2.1480\tTriplet Loss:0.1115\tStatic Loss:0.6633\t\n",
      "Val Loss:0.7207\tRecon Loss:1.9358\tTriplet Loss:0.1533\tStatic Loss:0.7653\n",
      "\n",
      "\tTime:54.6113\n",
      "\n",
      "Test Loss:1.0517\tRecon Loss:5.9615\tTriplet Loss:0.4640\tStatic Loss:1.0614\n",
      "\n",
      "\tEpoch:32\tTrain Loss:0.6265\tRecon Loss:2.0013\tTriplet Loss:0.1107\tStatic Loss:0.6644\t\n",
      "Val Loss:0.7392\tRecon Loss:1.9515\tTriplet Loss:0.1738\tStatic Loss:0.7836\n",
      "\n",
      "\tTime:62.3714\n",
      "\n",
      "Test Loss:1.0473\tRecon Loss:6.0085\tTriplet Loss:0.5084\tStatic Loss:1.0516\n",
      "\n",
      "\tEpoch:33\tTrain Loss:0.6221\tRecon Loss:1.9847\tTriplet Loss:0.1089\tStatic Loss:0.6598\t\n",
      "Val Loss:0.7102\tRecon Loss:1.9544\tTriplet Loss:0.1409\tStatic Loss:0.7547\n",
      "\n",
      "\tTime:56.3451\n",
      "\n",
      "Test Loss:1.0436\tRecon Loss:6.0493\tTriplet Loss:0.5039\tStatic Loss:1.0475\n",
      "\n",
      "\tEpoch:34\tTrain Loss:0.6206\tRecon Loss:2.0235\tTriplet Loss:0.1072\tStatic Loss:0.6579\t\n",
      "Val Loss:0.6943\tRecon Loss:1.9568\tTriplet Loss:0.1458\tStatic Loss:0.7366\n",
      "\n",
      "\tTime:60.7806\n",
      "\n",
      "Test Loss:1.0043\tRecon Loss:5.9866\tTriplet Loss:0.4750\tStatic Loss:1.0075\n",
      "\n",
      "\tEpoch:35\tTrain Loss:0.6175\tRecon Loss:1.9697\tTriplet Loss:0.1106\tStatic Loss:0.6547\t\n",
      "Val Loss:0.7087\tRecon Loss:2.0250\tTriplet Loss:0.1428\tStatic Loss:0.7521\n",
      "\n",
      "\tTime:54.1783\n",
      "\n",
      "Test Loss:1.0410\tRecon Loss:6.3745\tTriplet Loss:0.4763\tStatic Loss:1.0441\n",
      "\n",
      "\tEpoch:36\tTrain Loss:0.6428\tRecon Loss:2.0317\tTriplet Loss:0.1194\tStatic Loss:0.6812\t\n",
      "Val Loss:0.7161\tRecon Loss:1.9842\tTriplet Loss:0.1475\tStatic Loss:0.7603\n",
      "\n",
      "\tTime:59.0672\n",
      "\n",
      "Test Loss:1.0365\tRecon Loss:6.1781\tTriplet Loss:0.4781\tStatic Loss:1.0410\n",
      "\n",
      "\tEpoch:37\tTrain Loss:0.6213\tRecon Loss:1.9962\tTriplet Loss:0.1106\tStatic Loss:0.6586\t\n",
      "Val Loss:0.7236\tRecon Loss:1.9458\tTriplet Loss:0.1640\tStatic Loss:0.7673\n",
      "\n",
      "\tTime:53.3539\n",
      "\n",
      "Test Loss:1.0146\tRecon Loss:6.0522\tTriplet Loss:0.4961\tStatic Loss:1.0161\n",
      "\n",
      "\tEpoch:38\tTrain Loss:0.6181\tRecon Loss:1.9653\tTriplet Loss:0.1072\tStatic Loss:0.6558\t\n",
      "Val Loss:0.7060\tRecon Loss:1.9218\tTriplet Loss:0.1513\tStatic Loss:0.7493\n",
      "\n",
      "\tTime:58.0661\n",
      "\n",
      "Test Loss:1.0060\tRecon Loss:5.9742\tTriplet Loss:0.4928\tStatic Loss:1.0076\n",
      "\n",
      "\tEpoch:39\tTrain Loss:0.6117\tRecon Loss:1.9732\tTriplet Loss:0.1047\tStatic Loss:0.6488\t\n",
      "Val Loss:0.7094\tRecon Loss:1.9195\tTriplet Loss:0.1436\tStatic Loss:0.7539\n",
      "\n",
      "\tTime:55.0370\n",
      "\n",
      "Test Loss:1.0403\tRecon Loss:5.9463\tTriplet Loss:0.4785\tStatic Loss:1.0474\n",
      "\n",
      "\tEpoch:40\tTrain Loss:0.6103\tRecon Loss:1.9970\tTriplet Loss:0.1046\tStatic Loss:0.6470\t\n",
      "Val Loss:0.7219\tRecon Loss:1.9241\tTriplet Loss:0.1540\tStatic Loss:0.7666\n",
      "\n",
      "\tTime:58.0579\n",
      "\n",
      "Test Loss:1.0620\tRecon Loss:5.9539\tTriplet Loss:0.4951\tStatic Loss:1.0698\n",
      "\n",
      "\tEpoch:41\tTrain Loss:0.6097\tRecon Loss:2.1274\tTriplet Loss:0.1117\tStatic Loss:0.6444\t\n",
      "Val Loss:0.7189\tRecon Loss:1.9708\tTriplet Loss:0.1505\tStatic Loss:0.7633\n",
      "\n",
      "\tTime:57.4007\n",
      "\n",
      "Test Loss:1.0716\tRecon Loss:6.1231\tTriplet Loss:0.4705\tStatic Loss:1.0812\n",
      "\n",
      "\tEpoch:42\tTrain Loss:0.6095\tRecon Loss:1.9591\tTriplet Loss:0.1095\tStatic Loss:0.6461\t\n",
      "Val Loss:0.7141\tRecon Loss:2.0881\tTriplet Loss:0.1498\tStatic Loss:0.7568\n",
      "\n",
      "\tTime:56.4133\n",
      "\n",
      "Test Loss:1.0975\tRecon Loss:6.4186\tTriplet Loss:0.5017\tStatic Loss:1.1039\n",
      "\n",
      "\tEpoch:43\tTrain Loss:0.6088\tRecon Loss:2.2490\tTriplet Loss:0.1084\tStatic Loss:0.6425\t\n",
      "Val Loss:0.7053\tRecon Loss:2.0043\tTriplet Loss:0.1626\tStatic Loss:0.7466\n",
      "\n",
      "\tTime:56.0918\n",
      "\n",
      "Test Loss:1.0535\tRecon Loss:6.2378\tTriplet Loss:0.5033\tStatic Loss:1.0567\n",
      "\n",
      "\tEpoch:44\tTrain Loss:0.6046\tRecon Loss:1.9965\tTriplet Loss:0.1110\tStatic Loss:0.6401\t\n",
      "Val Loss:0.7085\tRecon Loss:1.9590\tTriplet Loss:0.1339\tStatic Loss:0.7535\n",
      "\n",
      "\tTime:55.0010\n",
      "\n",
      "Test Loss:1.0849\tRecon Loss:6.0193\tTriplet Loss:0.4699\tStatic Loss:1.0970\n",
      "\n",
      "\tEpoch:45\tTrain Loss:0.6003\tRecon Loss:1.9571\tTriplet Loss:0.1073\tStatic Loss:0.6361\t\n",
      "Val Loss:0.7075\tRecon Loss:1.9385\tTriplet Loss:0.1447\tStatic Loss:0.7515\n",
      "\n",
      "\tTime:57.4659\n",
      "\n",
      "Test Loss:1.0814\tRecon Loss:6.1433\tTriplet Loss:0.4888\tStatic Loss:1.0900\n",
      "\n",
      "\tEpoch:46\tTrain Loss:0.6008\tRecon Loss:1.9615\tTriplet Loss:0.1016\tStatic Loss:0.6371\t\n",
      "Val Loss:0.7148\tRecon Loss:1.9553\tTriplet Loss:0.1526\tStatic Loss:0.7586\n",
      "\n",
      "\tTime:53.3983\n",
      "\n",
      "Test Loss:1.0826\tRecon Loss:6.0884\tTriplet Loss:0.5185\tStatic Loss:1.0890\n",
      "\n",
      "\tEpoch:47\tTrain Loss:0.5965\tRecon Loss:1.9660\tTriplet Loss:0.1063\tStatic Loss:0.6319\t\n",
      "Val Loss:0.7001\tRecon Loss:1.9142\tTriplet Loss:0.1515\tStatic Loss:0.7428\n",
      "\n",
      "\tTime:59.5887\n",
      "\n",
      "Test Loss:1.0491\tRecon Loss:5.9929\tTriplet Loss:0.4911\tStatic Loss:1.0555\n",
      "\n",
      "\tEpoch:48\tTrain Loss:0.5985\tRecon Loss:1.9556\tTriplet Loss:0.1045\tStatic Loss:0.6343\t\n",
      "Val Loss:0.7109\tRecon Loss:1.9172\tTriplet Loss:0.1432\tStatic Loss:0.7556\n",
      "\n",
      "\tTime:51.4971\n",
      "\n",
      "Test Loss:1.0519\tRecon Loss:6.0079\tTriplet Loss:0.4723\tStatic Loss:1.0603\n",
      "\n",
      "\tEpoch:49\tTrain Loss:0.5951\tRecon Loss:1.9959\tTriplet Loss:0.1013\tStatic Loss:0.6304\t\n",
      "Val Loss:0.7256\tRecon Loss:2.6299\tTriplet Loss:0.1519\tStatic Loss:0.7639\n",
      "\n",
      "\tTime:59.4495\n",
      "\n",
      "Test Loss:1.0901\tRecon Loss:8.0222\tTriplet Loss:0.4686\tStatic Loss:1.0830\n",
      "\n",
      "\t\n",
      "Unc Est in Static characteristics:0.0000\tUnc Est in Streamflow, dynamic:0.0000\t\n",
      "\n",
      "\trecon weight:0.1\tstatic weight:10\ttriplet weight:1\tcorr_per:50\tcorr_std:1\tmodel:ATT_NL_3\n",
      "Epoch:0\tTrain Loss:1.0508\tRecon Loss:4.1425\tTriplet Loss:0.4309\tStatic Loss:1.0819\t\n",
      "Val Loss:0.9099\tRecon Loss:3.9818\tTriplet Loss:0.2777\tStatic Loss:0.9423\n",
      "\n",
      "\tTime:57.1015\n",
      "\n",
      "Test Loss:1.3449\tRecon Loss:11.9167\tTriplet Loss:0.8508\tStatic Loss:1.2886\n",
      "\n",
      "\tEpoch:1\tTrain Loss:0.8598\tRecon Loss:3.9828\tTriplet Loss:0.2587\tStatic Loss:0.8887\t\n",
      "Val Loss:0.8683\tRecon Loss:3.9839\tTriplet Loss:0.2331\tStatic Loss:0.9006\n",
      "\n",
      "\tTime:60.2990\n",
      "\n",
      "Test Loss:1.3386\tRecon Loss:11.9332\tTriplet Loss:0.6964\tStatic Loss:1.2969\n",
      "\n",
      "\tEpoch:2\tTrain Loss:0.8092\tRecon Loss:3.9736\tTriplet Loss:0.2153\tStatic Loss:0.8370\t\n",
      "Val Loss:0.8044\tRecon Loss:3.9691\tTriplet Loss:0.1916\tStatic Loss:0.8341\n",
      "\n",
      "\tTime:55.0430\n",
      "\n",
      "Test Loss:1.1572\tRecon Loss:11.8382\tTriplet Loss:0.6271\tStatic Loss:1.1034\n",
      "\n",
      "\tEpoch:3\tTrain Loss:0.7829\tRecon Loss:3.9587\tTriplet Loss:0.2024\tStatic Loss:0.8091\t\n",
      "Val Loss:0.8029\tRecon Loss:3.9629\tTriplet Loss:0.1959\tStatic Loss:0.8320\n",
      "\n",
      "\tTime:59.4365\n",
      "\n",
      "Test Loss:1.1575\tRecon Loss:11.8253\tTriplet Loss:0.5967\tStatic Loss:1.1069\n",
      "\n",
      "\tEpoch:4\tTrain Loss:0.7667\tRecon Loss:3.9480\tTriplet Loss:0.1885\tStatic Loss:0.7927\t\n",
      "Val Loss:0.7855\tRecon Loss:3.9199\tTriplet Loss:0.1912\tStatic Loss:0.8136\n",
      "\n",
      "\tTime:55.3171\n",
      "\n",
      "Test Loss:1.1148\tRecon Loss:11.7061\tTriplet Loss:0.5871\tStatic Loss:1.0617\n",
      "\n",
      "\tEpoch:5\tTrain Loss:0.7519\tRecon Loss:3.8916\tTriplet Loss:0.1649\tStatic Loss:0.7792\t\n",
      "Val Loss:0.7963\tRecon Loss:3.7957\tTriplet Loss:0.1651\tStatic Loss:0.8294\n",
      "\n",
      "\tTime:60.9964\n",
      "\n",
      "Test Loss:1.1759\tRecon Loss:11.4301\tTriplet Loss:0.5182\tStatic Loss:1.1391\n",
      "\n",
      "\tEpoch:6\tTrain Loss:0.7392\tRecon Loss:3.5983\tTriplet Loss:0.1591\tStatic Loss:0.7686\t\n",
      "Val Loss:0.7570\tRecon Loss:3.3211\tTriplet Loss:0.1553\tStatic Loss:0.7915\n",
      "\n",
      "\tTime:53.7520\n",
      "\n",
      "Test Loss:1.0762\tRecon Loss:10.1293\tTriplet Loss:0.5249\tStatic Loss:1.0408\n",
      "\n",
      "\tEpoch:7\tTrain Loss:0.7238\tRecon Loss:2.9479\tTriplet Loss:0.1576\tStatic Loss:0.7582\t\n",
      "Val Loss:0.7479\tRecon Loss:2.7542\tTriplet Loss:0.1668\tStatic Loss:0.7860\n",
      "\n",
      "\tTime:59.7018\n",
      "\n",
      "Test Loss:1.0535\tRecon Loss:8.5365\tTriplet Loss:0.5240\tStatic Loss:1.0316\n",
      "\n",
      "\tEpoch:8\tTrain Loss:0.7138\tRecon Loss:2.4653\tTriplet Loss:0.1500\tStatic Loss:0.7527\t\n",
      "Val Loss:0.7395\tRecon Loss:2.3469\tTriplet Loss:0.1537\tStatic Loss:0.7821\n",
      "\n",
      "\tTime:53.8877\n",
      "\n",
      "Test Loss:1.0169\tRecon Loss:7.2149\tTriplet Loss:0.5322\tStatic Loss:1.0034\n",
      "\n",
      "\tEpoch:9\tTrain Loss:0.7039\tRecon Loss:2.2451\tTriplet Loss:0.1428\tStatic Loss:0.7447\t\n",
      "Val Loss:0.7434\tRecon Loss:2.2312\tTriplet Loss:0.1605\tStatic Loss:0.7868\n",
      "\n",
      "\tTime:60.1779\n",
      "\n",
      "Test Loss:1.0575\tRecon Loss:6.8009\tTriplet Loss:0.5081\tStatic Loss:1.0551\n",
      "\n",
      "\tEpoch:10\tTrain Loss:0.6968\tRecon Loss:2.2307\tTriplet Loss:0.1444\tStatic Loss:0.7367\t\n",
      "Val Loss:0.7315\tRecon Loss:2.2257\tTriplet Loss:0.1595\tStatic Loss:0.7738\n",
      "\n",
      "\tTime:52.1626\n",
      "\n",
      "Test Loss:1.0333\tRecon Loss:6.9321\tTriplet Loss:0.4725\tStatic Loss:1.0304\n",
      "\n",
      "\tEpoch:11\tTrain Loss:0.6890\tRecon Loss:2.1057\tTriplet Loss:0.1400\tStatic Loss:0.7297\t\n",
      "Val Loss:0.7348\tRecon Loss:2.0444\tTriplet Loss:0.1414\tStatic Loss:0.7811\n",
      "\n",
      "\tTime:61.2561\n",
      "\n",
      "Test Loss:1.0562\tRecon Loss:6.3129\tTriplet Loss:0.5089\tStatic Loss:1.0584\n",
      "\n",
      "\tEpoch:12\tTrain Loss:0.6837\tRecon Loss:2.0929\tTriplet Loss:0.1308\tStatic Loss:0.7249\t\n",
      "Val Loss:0.7120\tRecon Loss:2.0802\tTriplet Loss:0.1406\tStatic Loss:0.7555\n",
      "\n",
      "\tTime:52.5808\n",
      "\n",
      "Test Loss:0.9740\tRecon Loss:6.3966\tTriplet Loss:0.4704\tStatic Loss:0.9701\n",
      "\n",
      "\tEpoch:13\tTrain Loss:0.6776\tRecon Loss:2.0508\tTriplet Loss:0.1342\tStatic Loss:0.7182\t\n",
      "Val Loss:0.7039\tRecon Loss:2.0938\tTriplet Loss:0.1540\tStatic Loss:0.7449\n",
      "\n",
      "\tTime:61.6752\n",
      "\n",
      "Test Loss:0.9410\tRecon Loss:6.4902\tTriplet Loss:0.4786\tStatic Loss:0.9317\n",
      "\n",
      "\tEpoch:14\tTrain Loss:0.6713\tRecon Loss:2.0670\tTriplet Loss:0.1402\tStatic Loss:0.7105\t\n",
      "Val Loss:0.7040\tRecon Loss:2.0749\tTriplet Loss:0.1506\tStatic Loss:0.7456\n",
      "\n",
      "\tTime:53.8239\n",
      "\n",
      "Test Loss:0.9584\tRecon Loss:6.5689\tTriplet Loss:0.4485\tStatic Loss:0.9533\n",
      "\n",
      "\tEpoch:15\tTrain Loss:0.6676\tRecon Loss:2.0496\tTriplet Loss:0.1333\tStatic Loss:0.7072\t\n",
      "Val Loss:0.6973\tRecon Loss:2.0295\tTriplet Loss:0.1409\tStatic Loss:0.7396\n",
      "\n",
      "\tTime:61.8323\n",
      "\n",
      "Test Loss:0.9443\tRecon Loss:6.2224\tTriplet Loss:0.4707\tStatic Loss:0.9389\n",
      "\n",
      "\tEpoch:16\tTrain Loss:0.6609\tRecon Loss:2.0473\tTriplet Loss:0.1294\tStatic Loss:0.7001\t\n",
      "Val Loss:0.6984\tRecon Loss:2.0420\tTriplet Loss:0.1364\tStatic Loss:0.7411\n",
      "\n",
      "\tTime:53.8012\n",
      "\n",
      "Test Loss:0.9959\tRecon Loss:6.3137\tTriplet Loss:0.4543\tStatic Loss:0.9968\n",
      "\n",
      "\tEpoch:17\tTrain Loss:0.6644\tRecon Loss:2.0890\tTriplet Loss:0.1306\tStatic Loss:0.7036\t\n",
      "Val Loss:0.7046\tRecon Loss:2.0833\tTriplet Loss:0.1410\tStatic Loss:0.7471\n",
      "\n",
      "\tTime:59.0839\n",
      "\n",
      "Test Loss:1.0145\tRecon Loss:6.3508\tTriplet Loss:0.4846\tStatic Loss:1.0142\n",
      "\n",
      "\tEpoch:18\tTrain Loss:0.6553\tRecon Loss:2.0240\tTriplet Loss:0.1259\tStatic Loss:0.6946\t\n",
      "Val Loss:0.6966\tRecon Loss:2.1799\tTriplet Loss:0.1429\tStatic Loss:0.7371\n",
      "\n",
      "\tTime:58.6325\n",
      "\n",
      "Test Loss:0.9658\tRecon Loss:6.6118\tTriplet Loss:0.4897\tStatic Loss:0.9569\n",
      "\n",
      "\tEpoch:19\tTrain Loss:0.6542\tRecon Loss:2.0782\tTriplet Loss:0.1245\tStatic Loss:0.6929\t\n",
      "Val Loss:0.6967\tRecon Loss:1.9926\tTriplet Loss:0.1361\tStatic Loss:0.7398\n",
      "\n",
      "\tTime:58.4523\n",
      "\n",
      "Test Loss:0.9843\tRecon Loss:6.1870\tTriplet Loss:0.4723\tStatic Loss:0.9835\n",
      "\n",
      "\tEpoch:20\tTrain Loss:0.6495\tRecon Loss:2.0233\tTriplet Loss:0.1258\tStatic Loss:0.6881\t\n",
      "Val Loss:0.6885\tRecon Loss:2.0279\tTriplet Loss:0.1369\tStatic Loss:0.7303\n",
      "\n",
      "\tTime:57.7943\n",
      "\n",
      "Test Loss:0.9647\tRecon Loss:6.1948\tTriplet Loss:0.4597\tStatic Loss:0.9629\n",
      "\n",
      "\tEpoch:21\tTrain Loss:0.6461\tRecon Loss:2.0136\tTriplet Loss:0.1232\tStatic Loss:0.6847\t\n",
      "Val Loss:0.6886\tRecon Loss:2.0232\tTriplet Loss:0.1481\tStatic Loss:0.7293\n",
      "\n",
      "\tTime:57.2164\n",
      "\n",
      "Test Loss:0.9655\tRecon Loss:6.1966\tTriplet Loss:0.4453\tStatic Loss:0.9652\n",
      "\n",
      "\tEpoch:22\tTrain Loss:0.6410\tRecon Loss:2.0218\tTriplet Loss:0.1213\tStatic Loss:0.6791\t\n",
      "Val Loss:0.7026\tRecon Loss:2.0938\tTriplet Loss:0.1377\tStatic Loss:0.7451\n",
      "\n",
      "\tTime:59.2708\n",
      "\n",
      "Test Loss:1.0069\tRecon Loss:6.3661\tTriplet Loss:0.4464\tStatic Loss:1.0093\n",
      "\n",
      "\tEpoch:23\tTrain Loss:0.6398\tRecon Loss:2.0278\tTriplet Loss:0.1188\tStatic Loss:0.6780\t\n",
      "Val Loss:0.7056\tRecon Loss:2.0241\tTriplet Loss:0.1422\tStatic Loss:0.7488\n",
      "\n",
      "\tTime:58.9272\n",
      "\n",
      "Test Loss:1.0475\tRecon Loss:6.1834\tTriplet Loss:0.4659\tStatic Loss:1.0543\n",
      "\n",
      "\tEpoch:24\tTrain Loss:0.6336\tRecon Loss:1.9954\tTriplet Loss:0.1169\tStatic Loss:0.6717\t\n",
      "Val Loss:0.6834\tRecon Loss:2.0513\tTriplet Loss:0.1325\tStatic Loss:0.7248\n",
      "\n",
      "\tTime:56.2730\n",
      "\n",
      "Test Loss:0.9629\tRecon Loss:6.2713\tTriplet Loss:0.4521\tStatic Loss:0.9608\n",
      "\n",
      "\tEpoch:25\tTrain Loss:0.6343\tRecon Loss:2.0233\tTriplet Loss:0.1175\tStatic Loss:0.6721\t\n",
      "Val Loss:0.6811\tRecon Loss:2.0258\tTriplet Loss:0.1349\tStatic Loss:0.7222\n",
      "\n",
      "\tTime:57.3903\n",
      "\n",
      "Test Loss:0.9799\tRecon Loss:6.1549\tTriplet Loss:0.4382\tStatic Loss:0.9823\n",
      "\n",
      "\tEpoch:26\tTrain Loss:0.6438\tRecon Loss:2.0720\tTriplet Loss:0.1263\tStatic Loss:0.6813\t\n",
      "Val Loss:0.7153\tRecon Loss:2.0454\tTriplet Loss:0.1459\tStatic Loss:0.7590\n",
      "\n",
      "\tTime:58.5802\n",
      "\n",
      "Test Loss:0.9963\tRecon Loss:6.2631\tTriplet Loss:0.4491\tStatic Loss:0.9984\n",
      "\n",
      "\tEpoch:27\tTrain Loss:0.6482\tRecon Loss:2.0201\tTriplet Loss:0.1274\tStatic Loss:0.6866\t\n",
      "Val Loss:0.7017\tRecon Loss:1.9971\tTriplet Loss:0.1476\tStatic Loss:0.7441\n",
      "\n",
      "\tTime:52.3223\n",
      "\n",
      "Test Loss:0.9669\tRecon Loss:6.1852\tTriplet Loss:0.4511\tStatic Loss:0.9663\n",
      "\n",
      "\tEpoch:28\tTrain Loss:0.6340\tRecon Loss:2.0081\tTriplet Loss:0.1195\tStatic Loss:0.6717\t\n",
      "Val Loss:0.6905\tRecon Loss:2.0187\tTriplet Loss:0.1317\tStatic Loss:0.7331\n",
      "\n",
      "\tTime:59.9294\n",
      "\n",
      "Test Loss:0.9799\tRecon Loss:6.2179\tTriplet Loss:0.4486\tStatic Loss:0.9806\n",
      "\n",
      "\tEpoch:29\tTrain Loss:0.6376\tRecon Loss:2.0106\tTriplet Loss:0.1184\tStatic Loss:0.6757\t\n",
      "Val Loss:0.6885\tRecon Loss:2.0049\tTriplet Loss:0.1377\tStatic Loss:0.7304\n",
      "\n",
      "\tTime:53.2856\n",
      "\n",
      "Test Loss:0.9346\tRecon Loss:6.1576\tTriplet Loss:0.4261\tStatic Loss:0.9332\n",
      "\n",
      "\tEpoch:30\tTrain Loss:0.6263\tRecon Loss:2.0083\tTriplet Loss:0.1189\tStatic Loss:0.6632\t\n",
      "Val Loss:0.6818\tRecon Loss:1.9660\tTriplet Loss:0.1415\tStatic Loss:0.7230\n",
      "\n",
      "\tTime:58.5520\n",
      "\n",
      "Test Loss:0.9339\tRecon Loss:6.0916\tTriplet Loss:0.4152\tStatic Loss:0.9342\n",
      "\n",
      "\tEpoch:31\tTrain Loss:0.6235\tRecon Loss:1.9871\tTriplet Loss:0.1167\tStatic Loss:0.6605\t\n",
      "Val Loss:0.6772\tRecon Loss:1.9728\tTriplet Loss:0.1394\tStatic Loss:0.7180\n",
      "\n",
      "\tTime:52.3996\n",
      "\n",
      "Test Loss:0.9353\tRecon Loss:6.0999\tTriplet Loss:0.4518\tStatic Loss:0.9320\n",
      "\n",
      "\tEpoch:32\tTrain Loss:0.6196\tRecon Loss:2.0596\tTriplet Loss:0.1130\tStatic Loss:0.6559\t\n",
      "Val Loss:0.6832\tRecon Loss:2.0217\tTriplet Loss:0.1327\tStatic Loss:0.7249\n",
      "\n",
      "\tTime:60.0964\n",
      "\n",
      "Test Loss:0.9902\tRecon Loss:6.1960\tTriplet Loss:0.4149\tStatic Loss:0.9957\n",
      "\n",
      "\tEpoch:33\tTrain Loss:0.6166\tRecon Loss:2.0232\tTriplet Loss:0.1127\tStatic Loss:0.6529\t\n",
      "Val Loss:0.6899\tRecon Loss:1.9917\tTriplet Loss:0.1340\tStatic Loss:0.7324\n",
      "\n",
      "\tTime:54.4514\n",
      "\n",
      "Test Loss:1.0101\tRecon Loss:6.1346\tTriplet Loss:0.4129\tStatic Loss:1.0186\n",
      "\n",
      "\tEpoch:34\tTrain Loss:0.6150\tRecon Loss:1.9898\tTriplet Loss:0.1172\tStatic Loss:0.6511\t\n",
      "Val Loss:0.6953\tRecon Loss:1.9985\tTriplet Loss:0.1423\tStatic Loss:0.7376\n",
      "\n",
      "\tTime:60.8784\n",
      "\n",
      "Test Loss:1.0424\tRecon Loss:6.0984\tTriplet Loss:0.4359\tStatic Loss:1.0524\n",
      "\n",
      "\tEpoch:35\tTrain Loss:0.6134\tRecon Loss:2.0106\tTriplet Loss:0.1158\tStatic Loss:0.6492\t\n",
      "Val Loss:0.6779\tRecon Loss:2.0598\tTriplet Loss:0.1281\tStatic Loss:0.7191\n",
      "\n",
      "\tTime:54.2497\n",
      "\n",
      "Test Loss:0.9760\tRecon Loss:6.3950\tTriplet Loss:0.4182\tStatic Loss:0.9776\n",
      "\n",
      "\tEpoch:36\tTrain Loss:0.6125\tRecon Loss:2.0536\tTriplet Loss:0.1094\tStatic Loss:0.6484\t\n",
      "Val Loss:0.6788\tRecon Loss:2.0090\tTriplet Loss:0.1442\tStatic Loss:0.7189\n",
      "\n",
      "\tTime:61.1585\n",
      "\n",
      "Test Loss:0.9371\tRecon Loss:6.1634\tTriplet Loss:0.4230\tStatic Loss:0.9363\n",
      "\n",
      "\tEpoch:37\tTrain Loss:0.6103\tRecon Loss:2.0088\tTriplet Loss:0.1122\tStatic Loss:0.6462\t\n",
      "Val Loss:0.6775\tRecon Loss:2.0073\tTriplet Loss:0.1291\tStatic Loss:0.7190\n",
      "\n",
      "\tTime:53.5166\n",
      "\n",
      "Test Loss:0.9953\tRecon Loss:6.1021\tTriplet Loss:0.4159\tStatic Loss:1.0021\n",
      "\n",
      "\tEpoch:38\tTrain Loss:0.6078\tRecon Loss:2.0073\tTriplet Loss:0.1172\tStatic Loss:0.6428\t\n",
      "Val Loss:0.6884\tRecon Loss:1.9960\tTriplet Loss:0.1384\tStatic Loss:0.7303\n",
      "\n",
      "\tTime:59.2666\n",
      "\n",
      "Test Loss:1.0167\tRecon Loss:6.1569\tTriplet Loss:0.3897\tStatic Loss:1.0280\n",
      "\n",
      "\tEpoch:39\tTrain Loss:0.6052\tRecon Loss:2.0240\tTriplet Loss:0.1098\tStatic Loss:0.6405\t\n",
      "Val Loss:0.6843\tRecon Loss:2.0050\tTriplet Loss:0.1385\tStatic Loss:0.7257\n",
      "\n",
      "\tTime:55.6879\n",
      "\n",
      "Test Loss:1.0467\tRecon Loss:6.0885\tTriplet Loss:0.3944\tStatic Loss:1.0615\n",
      "\n",
      "\tEpoch:40\tTrain Loss:0.6013\tRecon Loss:1.9998\tTriplet Loss:0.1071\tStatic Loss:0.6368\t\n",
      "Val Loss:0.6816\tRecon Loss:2.0604\tTriplet Loss:0.1275\tStatic Loss:0.7232\n",
      "\n",
      "\tTime:59.8930\n",
      "\n",
      "Test Loss:1.0012\tRecon Loss:6.3732\tTriplet Loss:0.4111\tStatic Loss:1.0065\n",
      "\n",
      "\tEpoch:41\tTrain Loss:0.6024\tRecon Loss:2.0081\tTriplet Loss:0.1064\tStatic Loss:0.6379\t\n",
      "Val Loss:0.6821\tRecon Loss:1.9619\tTriplet Loss:0.1345\tStatic Loss:0.7241\n",
      "\n",
      "\tTime:55.5884\n",
      "\n",
      "Test Loss:1.0253\tRecon Loss:6.0430\tTriplet Loss:0.3991\tStatic Loss:1.0377\n",
      "\n",
      "\tEpoch:42\tTrain Loss:0.5981\tRecon Loss:2.0201\tTriplet Loss:0.1087\tStatic Loss:0.6328\t\n",
      "Val Loss:0.6791\tRecon Loss:2.0161\tTriplet Loss:0.1365\tStatic Loss:0.7200\n",
      "\n",
      "\tTime:59.2018\n",
      "\n",
      "Test Loss:1.0016\tRecon Loss:6.1735\tTriplet Loss:0.4141\tStatic Loss:1.0086\n",
      "\n",
      "\tEpoch:43\tTrain Loss:0.5988\tRecon Loss:1.9913\tTriplet Loss:0.1121\tStatic Loss:0.6335\t\n",
      "Val Loss:0.6779\tRecon Loss:2.0511\tTriplet Loss:0.1302\tStatic Loss:0.7189\n",
      "\n",
      "\tTime:55.7029\n",
      "\n",
      "Test Loss:0.9425\tRecon Loss:6.1671\tTriplet Loss:0.3912\tStatic Loss:0.9454\n",
      "\n",
      "\tEpoch:44\tTrain Loss:0.6029\tRecon Loss:1.9872\tTriplet Loss:0.1154\tStatic Loss:0.6379\t\n",
      "Val Loss:0.6776\tRecon Loss:2.0635\tTriplet Loss:0.1295\tStatic Loss:0.7185\n",
      "\n",
      "\tTime:60.1157\n",
      "\n",
      "Test Loss:0.9487\tRecon Loss:6.2461\tTriplet Loss:0.4273\tStatic Loss:0.9479\n",
      "\n",
      "\tEpoch:45\tTrain Loss:0.5981\tRecon Loss:1.9942\tTriplet Loss:0.1081\tStatic Loss:0.6331\t\n",
      "Val Loss:0.6794\tRecon Loss:2.0486\tTriplet Loss:0.1340\tStatic Loss:0.7202\n",
      "\n",
      "\tTime:55.1552\n",
      "\n",
      "Test Loss:1.0064\tRecon Loss:6.2109\tTriplet Loss:0.4162\tStatic Loss:1.0134\n",
      "\n",
      "\tEpoch:46\tTrain Loss:0.5961\tRecon Loss:1.9998\tTriplet Loss:0.1070\tStatic Loss:0.6310\t\n",
      "Val Loss:0.6797\tRecon Loss:2.0263\tTriplet Loss:0.1365\tStatic Loss:0.7205\n",
      "\n",
      "\tTime:57.9949\n",
      "\n",
      "Test Loss:1.0060\tRecon Loss:6.1257\tTriplet Loss:0.4268\tStatic Loss:1.0128\n",
      "\n",
      "\tEpoch:47\tTrain Loss:0.5924\tRecon Loss:1.9869\tTriplet Loss:0.1017\tStatic Loss:0.6276\t\n",
      "Val Loss:0.6896\tRecon Loss:2.0350\tTriplet Loss:0.1344\tStatic Loss:0.7317\n",
      "\n",
      "\tTime:54.6413\n",
      "\n",
      "Test Loss:1.0362\tRecon Loss:6.2461\tTriplet Loss:0.4176\tStatic Loss:1.0459\n",
      "\n",
      "\tEpoch:48\tTrain Loss:0.5946\tRecon Loss:1.9864\tTriplet Loss:0.1040\tStatic Loss:0.6297\t\n",
      "Val Loss:0.6735\tRecon Loss:2.0408\tTriplet Loss:0.1373\tStatic Loss:0.7135\n",
      "\n",
      "\tTime:57.9279\n",
      "\n",
      "Test Loss:0.9823\tRecon Loss:6.2228\tTriplet Loss:0.4306\tStatic Loss:0.9851\n",
      "\n",
      "\tEpoch:49\tTrain Loss:0.5943\tRecon Loss:2.0304\tTriplet Loss:0.1084\tStatic Loss:0.6285\t\n",
      "Val Loss:0.6790\tRecon Loss:2.1019\tTriplet Loss:0.1453\tStatic Loss:0.7181\n",
      "\n",
      "\tTime:54.6478\n",
      "\n",
      "Test Loss:0.9824\tRecon Loss:6.3152\tTriplet Loss:0.4021\tStatic Loss:0.9871\n",
      "\n",
      "\t\n",
      "Unc Est in Static characteristics:0.0017\tUnc Est in Streamflow, dynamic:0.0010\t\n",
      "\n",
      "\tTrain Data:(531, 39, 365, 33)\tValidation Data:(531, 9, 365, 33)\tTest Data:(531, 19, 365, 33)\n",
      "recon weight:0.1\tstatic weight:10\ttriplet weight:1\tcorr_per:5\tcorr_std:10\tmodel:ATT_NL_0\n",
      "Epoch:0\tTrain Loss:0.6473\tRecon Loss:4.1682\tTriplet Loss:0.3827\tStatic Loss:0.6385\t\n",
      "Val Loss:0.5166\tRecon Loss:3.9864\tTriplet Loss:0.2702\tStatic Loss:0.5066\n",
      "\n",
      "\tTime:59.3197\n",
      "\n",
      "Test Loss:1.3087\tRecon Loss:11.9720\tTriplet Loss:0.8471\tStatic Loss:1.2483\n",
      "\n",
      "\tEpoch:1\tTrain Loss:0.4773\tRecon Loss:3.9820\tTriplet Loss:0.2547\tStatic Loss:0.4645\t\n",
      "Val Loss:0.4826\tRecon Loss:3.9874\tTriplet Loss:0.2373\tStatic Loss:0.4721\n",
      "\n",
      "\tTime:54.2978\n",
      "\n",
      "Test Loss:1.2383\tRecon Loss:11.9150\tTriplet Loss:0.7215\tStatic Loss:1.1832\n",
      "\n",
      "\tEpoch:2\tTrain Loss:0.4432\tRecon Loss:3.9762\tTriplet Loss:0.2162\tStatic Loss:0.4306\t\n",
      "Val Loss:0.4386\tRecon Loss:3.9618\tTriplet Loss:0.2041\tStatic Loss:0.4268\n",
      "\n",
      "\tTime:60.0345\n",
      "\n",
      "Test Loss:1.1220\tRecon Loss:11.8851\tTriplet Loss:0.6574\tStatic Loss:1.0609\n",
      "\n",
      "\tEpoch:3\tTrain Loss:0.4243\tRecon Loss:3.9655\tTriplet Loss:0.1937\tStatic Loss:0.4120\t\n",
      "Val Loss:0.4240\tRecon Loss:3.9595\tTriplet Loss:0.1968\tStatic Loss:0.4114\n",
      "\n",
      "\tTime:54.3341\n",
      "\n",
      "Test Loss:1.0734\tRecon Loss:11.8738\tTriplet Loss:0.5933\tStatic Loss:1.0134\n",
      "\n",
      "\tEpoch:4\tTrain Loss:0.4046\tRecon Loss:3.9304\tTriplet Loss:0.1851\tStatic Loss:0.3912\t\n",
      "Val Loss:0.4161\tRecon Loss:3.8563\tTriplet Loss:0.1758\tStatic Loss:0.4057\n",
      "\n",
      "\tTime:58.2767\n",
      "\n",
      "Test Loss:1.0819\tRecon Loss:11.6172\tTriplet Loss:0.5757\tStatic Loss:1.0272\n",
      "\n",
      "\tEpoch:5\tTrain Loss:0.3941\tRecon Loss:3.7772\tTriplet Loss:0.1748\tStatic Loss:0.3822\t\n",
      "Val Loss:0.4045\tRecon Loss:3.4564\tTriplet Loss:0.1728\tStatic Loss:0.3972\n",
      "\n",
      "\tTime:56.6231\n",
      "\n",
      "Test Loss:1.0495\tRecon Loss:10.6191\tTriplet Loss:0.5576\tStatic Loss:1.0030\n",
      "\n",
      "\tEpoch:6\tTrain Loss:0.3782\tRecon Loss:3.2127\tTriplet Loss:0.1662\tStatic Loss:0.3710\t\n",
      "Val Loss:0.3876\tRecon Loss:2.7648\tTriplet Loss:0.1885\tStatic Loss:0.3838\n",
      "\n",
      "\tTime:60.4169\n",
      "\n",
      "Test Loss:0.9984\tRecon Loss:8.6735\tTriplet Loss:0.5479\tStatic Loss:0.9667\n",
      "\n",
      "\tEpoch:7\tTrain Loss:0.3692\tRecon Loss:2.7743\tTriplet Loss:0.1644\tStatic Loss:0.3656\t\n",
      "Val Loss:0.3786\tRecon Loss:2.4895\tTriplet Loss:0.1736\tStatic Loss:0.3780\n",
      "\n",
      "\tTime:57.4182\n",
      "\n",
      "Test Loss:0.9603\tRecon Loss:7.6756\tTriplet Loss:0.5472\tStatic Loss:0.9345\n",
      "\n",
      "\tEpoch:8\tTrain Loss:0.3605\tRecon Loss:2.6127\tTriplet Loss:0.1590\tStatic Loss:0.3581\t\n",
      "Val Loss:0.3679\tRecon Loss:2.3394\tTriplet Loss:0.1745\tStatic Loss:0.3675\n",
      "\n",
      "\tTime:57.9106\n",
      "\n",
      "Test Loss:0.9216\tRecon Loss:7.1733\tTriplet Loss:0.5257\tStatic Loss:0.8987\n",
      "\n",
      "\tEpoch:9\tTrain Loss:0.3529\tRecon Loss:2.3596\tTriplet Loss:0.1558\tStatic Loss:0.3526\t\n",
      "Val Loss:0.3670\tRecon Loss:2.2306\tTriplet Loss:0.1635\tStatic Loss:0.3687\n",
      "\n",
      "\tTime:59.2511\n",
      "\n",
      "Test Loss:0.9311\tRecon Loss:6.8447\tTriplet Loss:0.5196\tStatic Loss:0.9131\n",
      "\n",
      "\tEpoch:10\tTrain Loss:0.3447\tRecon Loss:2.2164\tTriplet Loss:0.1539\tStatic Loss:0.3451\t\n",
      "Val Loss:0.3626\tRecon Loss:2.0813\tTriplet Loss:0.1636\tStatic Loss:0.3653\n",
      "\n",
      "\tTime:56.7858\n",
      "\n",
      "Test Loss:0.8936\tRecon Loss:6.3898\tTriplet Loss:0.5089\tStatic Loss:0.8771\n",
      "\n",
      "\tEpoch:11\tTrain Loss:0.3450\tRecon Loss:2.2952\tTriplet Loss:0.1529\tStatic Loss:0.3447\t\n",
      "Val Loss:0.3578\tRecon Loss:2.1854\tTriplet Loss:0.1628\tStatic Loss:0.3590\n",
      "\n",
      "\tTime:57.3685\n",
      "\n",
      "Test Loss:0.9137\tRecon Loss:6.8139\tTriplet Loss:0.5259\tStatic Loss:0.8935\n",
      "\n",
      "\tEpoch:12\tTrain Loss:0.3378\tRecon Loss:2.1527\tTriplet Loss:0.1495\tStatic Loss:0.3385\t\n",
      "Val Loss:0.3513\tRecon Loss:2.0092\tTriplet Loss:0.1608\tStatic Loss:0.3538\n",
      "\n",
      "\tTime:57.6645\n",
      "\n",
      "Test Loss:0.9097\tRecon Loss:6.1400\tTriplet Loss:0.4976\tStatic Loss:0.8986\n",
      "\n",
      "\tEpoch:13\tTrain Loss:0.3298\tRecon Loss:2.0300\tTriplet Loss:0.1429\tStatic Loss:0.3315\t\n",
      "Val Loss:0.3490\tRecon Loss:1.9726\tTriplet Loss:0.1579\tStatic Loss:0.3519\n",
      "\n",
      "\tTime:57.1761\n",
      "\n",
      "Test Loss:0.8804\tRecon Loss:6.0636\tTriplet Loss:0.5062\tStatic Loss:0.8660\n",
      "\n",
      "\tEpoch:14\tTrain Loss:0.3254\tRecon Loss:2.0125\tTriplet Loss:0.1336\tStatic Loss:0.3277\t\n",
      "Val Loss:0.3462\tRecon Loss:1.9464\tTriplet Loss:0.1570\tStatic Loss:0.3492\n",
      "\n",
      "\tTime:58.8203\n",
      "\n",
      "Test Loss:0.8811\tRecon Loss:6.0122\tTriplet Loss:0.5134\tStatic Loss:0.8665\n",
      "\n",
      "\tEpoch:15\tTrain Loss:0.3223\tRecon Loss:1.9983\tTriplet Loss:0.1368\tStatic Loss:0.3241\t\n",
      "Val Loss:0.3424\tRecon Loss:1.9380\tTriplet Loss:0.1560\tStatic Loss:0.3451\n",
      "\n",
      "\tTime:58.1428\n",
      "\n",
      "Test Loss:0.8689\tRecon Loss:6.0116\tTriplet Loss:0.5001\tStatic Loss:0.8543\n",
      "\n",
      "\tEpoch:16\tTrain Loss:0.3179\tRecon Loss:2.0181\tTriplet Loss:0.1282\tStatic Loss:0.3198\t\n",
      "Val Loss:0.3418\tRecon Loss:1.9471\tTriplet Loss:0.1525\tStatic Loss:0.3446\n",
      "\n",
      "\tTime:56.4361\n",
      "\n",
      "Test Loss:0.8897\tRecon Loss:5.9782\tTriplet Loss:0.4910\tStatic Loss:0.8787\n",
      "\n",
      "\tEpoch:17\tTrain Loss:0.3191\tRecon Loss:2.1280\tTriplet Loss:0.1314\tStatic Loss:0.3198\t\n",
      "Val Loss:0.3387\tRecon Loss:1.9681\tTriplet Loss:0.1504\tStatic Loss:0.3412\n",
      "\n",
      "\tTime:56.0766\n",
      "\n",
      "Test Loss:0.8621\tRecon Loss:6.0423\tTriplet Loss:0.4551\tStatic Loss:0.8510\n",
      "\n",
      "\tEpoch:18\tTrain Loss:0.3113\tRecon Loss:1.9821\tTriplet Loss:0.1277\tStatic Loss:0.3129\t\n",
      "Val Loss:0.3427\tRecon Loss:1.9676\tTriplet Loss:0.1488\tStatic Loss:0.3458\n",
      "\n",
      "\tTime:56.8696\n",
      "\n",
      "Test Loss:0.8642\tRecon Loss:6.0409\tTriplet Loss:0.4859\tStatic Loss:0.8503\n",
      "\n",
      "\tEpoch:19\tTrain Loss:0.3098\tRecon Loss:2.0075\tTriplet Loss:0.1273\tStatic Loss:0.3111\t\n",
      "Val Loss:0.3385\tRecon Loss:1.9970\tTriplet Loss:0.1496\tStatic Loss:0.3408\n",
      "\n",
      "\tTime:58.2208\n",
      "\n",
      "Test Loss:0.8746\tRecon Loss:6.0926\tTriplet Loss:0.4704\tStatic Loss:0.8629\n",
      "\n",
      "\tEpoch:20\tTrain Loss:0.3052\tRecon Loss:1.9933\tTriplet Loss:0.1253\tStatic Loss:0.3063\t\n",
      "Val Loss:0.3347\tRecon Loss:2.0265\tTriplet Loss:0.1472\tStatic Loss:0.3365\n",
      "\n",
      "\tTime:60.5999\n",
      "\n",
      "Test Loss:0.8572\tRecon Loss:6.3449\tTriplet Loss:0.4745\tStatic Loss:0.8405\n",
      "\n",
      "\tEpoch:21\tTrain Loss:0.3038\tRecon Loss:2.0019\tTriplet Loss:0.1227\tStatic Loss:0.3049\t\n",
      "Val Loss:0.3456\tRecon Loss:1.9966\tTriplet Loss:0.1523\tStatic Loss:0.3485\n",
      "\n",
      "\tTime:57.7685\n",
      "\n",
      "Test Loss:0.9052\tRecon Loss:6.0369\tTriplet Loss:0.4842\tStatic Loss:0.8959\n",
      "\n",
      "\tEpoch:22\tTrain Loss:0.3022\tRecon Loss:2.0473\tTriplet Loss:0.1255\tStatic Loss:0.3024\t\n",
      "Val Loss:0.3379\tRecon Loss:1.9683\tTriplet Loss:0.1400\tStatic Loss:0.3414\n",
      "\n",
      "\tTime:58.0294\n",
      "\n",
      "Test Loss:0.8820\tRecon Loss:5.9924\tTriplet Loss:0.4741\tStatic Loss:0.8717\n",
      "\n",
      "\tEpoch:23\tTrain Loss:0.2995\tRecon Loss:1.9749\tTriplet Loss:0.1206\tStatic Loss:0.3006\t\n",
      "Val Loss:0.3308\tRecon Loss:1.9512\tTriplet Loss:0.1509\tStatic Loss:0.3326\n",
      "\n",
      "\tTime:57.4112\n",
      "\n",
      "Test Loss:0.8576\tRecon Loss:5.9676\tTriplet Loss:0.4599\tStatic Loss:0.8462\n",
      "\n",
      "\tEpoch:24\tTrain Loss:0.2966\tRecon Loss:1.9736\tTriplet Loss:0.1164\tStatic Loss:0.2978\t\n",
      "Val Loss:0.3280\tRecon Loss:1.9180\tTriplet Loss:0.1459\tStatic Loss:0.3303\n",
      "\n",
      "\tTime:60.1037\n",
      "\n",
      "Test Loss:0.8666\tRecon Loss:5.9422\tTriplet Loss:0.4775\tStatic Loss:0.8548\n",
      "\n",
      "\tEpoch:25\tTrain Loss:0.2965\tRecon Loss:2.1475\tTriplet Loss:0.1198\tStatic Loss:0.2957\t\n",
      "Val Loss:0.3344\tRecon Loss:1.9393\tTriplet Loss:0.1460\tStatic Loss:0.3372\n",
      "\n",
      "\tTime:58.5214\n",
      "\n",
      "Test Loss:0.8637\tRecon Loss:5.9884\tTriplet Loss:0.4576\tStatic Loss:0.8530\n",
      "\n",
      "\tEpoch:26\tTrain Loss:0.2917\tRecon Loss:1.9763\tTriplet Loss:0.1179\tStatic Loss:0.2922\t\n",
      "Val Loss:0.3278\tRecon Loss:1.9598\tTriplet Loss:0.1440\tStatic Loss:0.3298\n",
      "\n",
      "\tTime:57.0665\n",
      "\n",
      "Test Loss:0.8566\tRecon Loss:6.1027\tTriplet Loss:0.4355\tStatic Loss:0.8463\n",
      "\n",
      "\tEpoch:27\tTrain Loss:0.2909\tRecon Loss:1.9788\tTriplet Loss:0.1132\tStatic Loss:0.2917\t\n",
      "Val Loss:0.3295\tRecon Loss:1.9647\tTriplet Loss:0.1486\tStatic Loss:0.3312\n",
      "\n",
      "\tTime:57.6355\n",
      "\n",
      "Test Loss:0.8547\tRecon Loss:6.0619\tTriplet Loss:0.4615\tStatic Loss:0.8419\n",
      "\n",
      "\tEpoch:28\tTrain Loss:0.2896\tRecon Loss:2.1366\tTriplet Loss:0.1110\tStatic Loss:0.2889\t\n",
      "Val Loss:0.3258\tRecon Loss:2.0821\tTriplet Loss:0.1422\tStatic Loss:0.3265\n",
      "\n",
      "\tTime:59.0473\n",
      "\n",
      "Test Loss:0.8545\tRecon Loss:6.5852\tTriplet Loss:0.4247\tStatic Loss:0.8401\n",
      "\n",
      "\tEpoch:29\tTrain Loss:0.2878\tRecon Loss:1.9974\tTriplet Loss:0.1162\tStatic Loss:0.2879\t\n",
      "Val Loss:0.3309\tRecon Loss:1.9321\tTriplet Loss:0.1391\tStatic Loss:0.3341\n",
      "\n",
      "\tTime:59.0694\n",
      "\n",
      "Test Loss:0.8476\tRecon Loss:5.9649\tTriplet Loss:0.4509\tStatic Loss:0.8361\n",
      "\n",
      "\tEpoch:30\tTrain Loss:0.2857\tRecon Loss:1.9822\tTriplet Loss:0.1110\tStatic Loss:0.2863\t\n",
      "Val Loss:0.3228\tRecon Loss:1.9314\tTriplet Loss:0.1351\tStatic Loss:0.3255\n",
      "\n",
      "\tTime:53.5119\n",
      "\n",
      "Test Loss:0.8538\tRecon Loss:6.0150\tTriplet Loss:0.4319\tStatic Loss:0.8444\n",
      "\n",
      "\tEpoch:31\tTrain Loss:0.2809\tRecon Loss:1.9713\tTriplet Loss:0.1071\tStatic Loss:0.2814\t\n",
      "Val Loss:0.3198\tRecon Loss:1.9036\tTriplet Loss:0.1354\tStatic Loss:0.3224\n",
      "\n",
      "\tTime:60.1378\n",
      "\n",
      "Test Loss:0.8273\tRecon Loss:5.9054\tTriplet Loss:0.4336\tStatic Loss:0.8159\n",
      "\n",
      "\tEpoch:32\tTrain Loss:0.2810\tRecon Loss:1.9678\tTriplet Loss:0.1058\tStatic Loss:0.2816\t\n",
      "Val Loss:0.3285\tRecon Loss:1.9628\tTriplet Loss:0.1438\tStatic Loss:0.3306\n",
      "\n",
      "\tTime:61.3625\n",
      "\n",
      "Test Loss:0.8607\tRecon Loss:6.0773\tTriplet Loss:0.4399\tStatic Loss:0.8507\n",
      "\n",
      "\tEpoch:33\tTrain Loss:0.2782\tRecon Loss:1.9985\tTriplet Loss:0.1066\tStatic Loss:0.2782\t\n",
      "Val Loss:0.3245\tRecon Loss:1.9355\tTriplet Loss:0.1361\tStatic Loss:0.3272\n",
      "\n",
      "\tTime:60.3850\n",
      "\n",
      "Test Loss:0.8530\tRecon Loss:6.0041\tTriplet Loss:0.4682\tStatic Loss:0.8400\n",
      "\n",
      "\tEpoch:34\tTrain Loss:0.2773\tRecon Loss:1.9548\tTriplet Loss:0.1098\tStatic Loss:0.2773\t\n",
      "Val Loss:0.3205\tRecon Loss:1.9640\tTriplet Loss:0.1387\tStatic Loss:0.3222\n",
      "\n",
      "\tTime:61.6702\n",
      "\n",
      "Test Loss:0.8382\tRecon Loss:6.0508\tTriplet Loss:0.4431\tStatic Loss:0.8255\n",
      "\n",
      "\tEpoch:35\tTrain Loss:0.2774\tRecon Loss:1.9724\tTriplet Loss:0.1086\tStatic Loss:0.2773\t\n",
      "Val Loss:0.3211\tRecon Loss:2.0035\tTriplet Loss:0.1420\tStatic Loss:0.3222\n",
      "\n",
      "\tTime:61.8926\n",
      "\n",
      "Test Loss:0.8662\tRecon Loss:6.0683\tTriplet Loss:0.4649\tStatic Loss:0.8543\n",
      "\n",
      "\tEpoch:36\tTrain Loss:0.2767\tRecon Loss:1.9831\tTriplet Loss:0.1041\tStatic Loss:0.2769\t\n",
      "Val Loss:0.3196\tRecon Loss:1.9491\tTriplet Loss:0.1361\tStatic Loss:0.3216\n",
      "\n",
      "\tTime:60.5674\n",
      "\n",
      "Test Loss:0.8491\tRecon Loss:6.0362\tTriplet Loss:0.4289\tStatic Loss:0.8393\n",
      "\n",
      "\tEpoch:37\tTrain Loss:0.2720\tRecon Loss:1.9674\tTriplet Loss:0.1046\tStatic Loss:0.2718\t\n",
      "Val Loss:0.3177\tRecon Loss:1.9395\tTriplet Loss:0.1462\tStatic Loss:0.3186\n",
      "\n",
      "\tTime:63.3254\n",
      "\n",
      "Test Loss:0.8254\tRecon Loss:6.0174\tTriplet Loss:0.4178\tStatic Loss:0.8142\n",
      "\n",
      "\tEpoch:38\tTrain Loss:0.2726\tRecon Loss:1.9718\tTriplet Loss:0.1029\tStatic Loss:0.2725\t\n",
      "Val Loss:0.3209\tRecon Loss:1.9644\tTriplet Loss:0.1342\tStatic Loss:0.3232\n",
      "\n",
      "\tTime:59.2764\n",
      "\n",
      "Test Loss:0.8726\tRecon Loss:6.1555\tTriplet Loss:0.4608\tStatic Loss:0.8610\n",
      "\n",
      "\tEpoch:39\tTrain Loss:0.2755\tRecon Loss:2.2261\tTriplet Loss:0.1045\tStatic Loss:0.2731\t\n",
      "Val Loss:0.3167\tRecon Loss:1.9986\tTriplet Loss:0.1344\tStatic Loss:0.3181\n",
      "\n",
      "\tTime:59.3780\n",
      "\n",
      "Test Loss:0.8588\tRecon Loss:6.1293\tTriplet Loss:0.4687\tStatic Loss:0.8451\n",
      "\n",
      "\tEpoch:40\tTrain Loss:0.2692\tRecon Loss:1.9586\tTriplet Loss:0.0986\tStatic Loss:0.2693\t\n",
      "Val Loss:0.3263\tRecon Loss:1.9438\tTriplet Loss:0.1510\tStatic Loss:0.3277\n",
      "\n",
      "\tTime:59.8619\n",
      "\n",
      "Test Loss:0.8642\tRecon Loss:6.0083\tTriplet Loss:0.4367\tStatic Loss:0.8555\n",
      "\n",
      "\tEpoch:41\tTrain Loss:0.2691\tRecon Loss:1.9917\tTriplet Loss:0.1028\tStatic Loss:0.2685\t\n",
      "Val Loss:0.3285\tRecon Loss:1.9473\tTriplet Loss:0.1337\tStatic Loss:0.3318\n",
      "\n",
      "\tTime:60.4209\n",
      "\n",
      "Test Loss:0.8605\tRecon Loss:6.0154\tTriplet Loss:0.4139\tStatic Loss:0.8536\n",
      "\n",
      "\tEpoch:42\tTrain Loss:0.2687\tRecon Loss:1.9718\tTriplet Loss:0.1023\tStatic Loss:0.2683\t\n",
      "Val Loss:0.3167\tRecon Loss:1.9089\tTriplet Loss:0.1326\tStatic Loss:0.3191\n",
      "\n",
      "\tTime:57.5334\n",
      "\n",
      "Test Loss:0.8953\tRecon Loss:5.9332\tTriplet Loss:0.4359\tStatic Loss:0.8909\n",
      "\n",
      "\tEpoch:43\tTrain Loss:0.2688\tRecon Loss:1.9587\tTriplet Loss:0.1047\tStatic Loss:0.2683\t\n",
      "Val Loss:0.3275\tRecon Loss:1.9305\tTriplet Loss:0.1429\tStatic Loss:0.3299\n",
      "\n",
      "\tTime:57.4463\n",
      "\n",
      "Test Loss:0.8980\tRecon Loss:5.9956\tTriplet Loss:0.4386\tStatic Loss:0.8930\n",
      "\n",
      "\tEpoch:44\tTrain Loss:0.2649\tRecon Loss:1.9921\tTriplet Loss:0.1004\tStatic Loss:0.2641\t\n",
      "Val Loss:0.3205\tRecon Loss:2.0239\tTriplet Loss:0.1384\tStatic Loss:0.3217\n",
      "\n",
      "\tTime:58.3492\n",
      "\n",
      "Test Loss:0.8599\tRecon Loss:6.3398\tTriplet Loss:0.4130\tStatic Loss:0.8498\n",
      "\n",
      "\tEpoch:45\tTrain Loss:0.2646\tRecon Loss:1.9573\tTriplet Loss:0.0987\tStatic Loss:0.2643\t\n",
      "Val Loss:0.3165\tRecon Loss:1.9163\tTriplet Loss:0.1312\tStatic Loss:0.3191\n",
      "\n",
      "\tTime:57.9465\n",
      "\n",
      "Test Loss:0.8437\tRecon Loss:5.9779\tTriplet Loss:0.4219\tStatic Loss:0.8345\n",
      "\n",
      "\tEpoch:46\tTrain Loss:0.2638\tRecon Loss:1.9803\tTriplet Loss:0.0986\tStatic Loss:0.2632\t\n",
      "Val Loss:0.3129\tRecon Loss:1.9337\tTriplet Loss:0.1300\tStatic Loss:0.3150\n",
      "\n",
      "\tTime:58.0753\n",
      "\n",
      "Test Loss:0.8593\tRecon Loss:6.0612\tTriplet Loss:0.4341\tStatic Loss:0.8498\n",
      "\n",
      "\tEpoch:47\tTrain Loss:0.2627\tRecon Loss:1.9603\tTriplet Loss:0.0991\tStatic Loss:0.2621\t\n",
      "Val Loss:0.3136\tRecon Loss:1.9240\tTriplet Loss:0.1386\tStatic Loss:0.3150\n",
      "\n",
      "\tTime:63.1671\n",
      "\n",
      "Test Loss:0.8519\tRecon Loss:5.9669\tTriplet Loss:0.4296\tStatic Loss:0.8430\n",
      "\n",
      "\tEpoch:48\tTrain Loss:0.2620\tRecon Loss:1.9703\tTriplet Loss:0.0963\tStatic Loss:0.2615\t\n",
      "Val Loss:0.3137\tRecon Loss:1.9185\tTriplet Loss:0.1322\tStatic Loss:0.3158\n",
      "\n",
      "\tTime:46.1275\n",
      "\n",
      "Test Loss:0.8362\tRecon Loss:5.9498\tTriplet Loss:0.4308\tStatic Loss:0.8256\n",
      "\n",
      "\tEpoch:49\tTrain Loss:0.2594\tRecon Loss:1.9623\tTriplet Loss:0.0997\tStatic Loss:0.2583\t\n",
      "Val Loss:0.3155\tRecon Loss:1.9136\tTriplet Loss:0.1356\tStatic Loss:0.3175\n",
      "\n",
      "\tTime:46.0462\n",
      "\n",
      "Test Loss:0.8678\tRecon Loss:5.9763\tTriplet Loss:0.4671\tStatic Loss:0.8567\n",
      "\n",
      "\t\n",
      "Unc Est in Static characteristics:0.0000\tUnc Est in Streamflow, dynamic:0.0000\t\n",
      "\n",
      "\trecon weight:0.1\tstatic weight:10\ttriplet weight:1\tcorr_per:5\tcorr_std:10\tmodel:ATT_NL_3\n",
      "Epoch:0\tTrain Loss:0.6646\tRecon Loss:4.1242\tTriplet Loss:0.4107\tStatic Loss:0.6553\t\n",
      "Val Loss:0.5109\tRecon Loss:3.9749\tTriplet Loss:0.2576\tStatic Loss:0.5016\n",
      "\n",
      "\tTime:45.8161\n",
      "\n",
      "Test Loss:1.3065\tRecon Loss:11.8835\tTriplet Loss:0.7961\tStatic Loss:1.2518\n",
      "\n",
      "\tEpoch:1\tTrain Loss:0.4763\tRecon Loss:3.9779\tTriplet Loss:0.2405\tStatic Loss:0.4649\t\n",
      "Val Loss:0.4517\tRecon Loss:3.9661\tTriplet Loss:0.2136\tStatic Loss:0.4403\n",
      "\n",
      "\tTime:46.7981\n",
      "\n",
      "Test Loss:1.1290\tRecon Loss:11.8591\tTriplet Loss:0.6156\tStatic Loss:1.0730\n",
      "\n",
      "\tEpoch:2\tTrain Loss:0.4363\tRecon Loss:3.9772\tTriplet Loss:0.2044\tStatic Loss:0.4241\t\n",
      "Val Loss:0.4350\tRecon Loss:3.9698\tTriplet Loss:0.1952\tStatic Loss:0.4236\n",
      "\n",
      "\tTime:46.0542\n",
      "\n",
      "Test Loss:1.1155\tRecon Loss:11.8720\tTriplet Loss:0.5695\tStatic Loss:1.0625\n",
      "\n",
      "\tEpoch:3\tTrain Loss:0.4138\tRecon Loss:3.9507\tTriplet Loss:0.1911\tStatic Loss:0.4007\t\n",
      "Val Loss:0.4116\tRecon Loss:3.9387\tTriplet Loss:0.1799\tStatic Loss:0.3995\n",
      "\n",
      "\tTime:44.1897\n",
      "\n",
      "Test Loss:1.0441\tRecon Loss:11.7484\tTriplet Loss:0.5535\tStatic Loss:0.9861\n",
      "\n",
      "\tEpoch:4\tTrain Loss:0.3970\tRecon Loss:3.8090\tTriplet Loss:0.1744\tStatic Loss:0.3851\t\n",
      "Val Loss:0.3959\tRecon Loss:3.7641\tTriplet Loss:0.1805\tStatic Loss:0.3837\n",
      "\n",
      "\tTime:44.3629\n",
      "\n",
      "Test Loss:1.0054\tRecon Loss:11.3552\tTriplet Loss:0.5429\tStatic Loss:0.9482\n",
      "\n",
      "\tEpoch:5\tTrain Loss:0.3831\tRecon Loss:3.4308\tTriplet Loss:0.1644\tStatic Loss:0.3745\t\n",
      "Val Loss:0.3835\tRecon Loss:3.1651\tTriplet Loss:0.1801\tStatic Loss:0.3760\n",
      "\n",
      "\tTime:44.6577\n",
      "\n",
      "Test Loss:0.9699\tRecon Loss:9.5909\tTriplet Loss:0.5014\tStatic Loss:0.9305\n",
      "\n",
      "\tEpoch:6\tTrain Loss:0.3677\tRecon Loss:2.6779\tTriplet Loss:0.1587\tStatic Loss:0.3655\t\n",
      "Val Loss:0.3763\tRecon Loss:2.4702\tTriplet Loss:0.1734\tStatic Loss:0.3756\n",
      "\n",
      "\tTime:46.6624\n",
      "\n",
      "Test Loss:0.9380\tRecon Loss:7.4504\tTriplet Loss:0.4879\tStatic Loss:0.9179\n",
      "\n",
      "\tEpoch:7\tTrain Loss:0.3539\tRecon Loss:2.2850\tTriplet Loss:0.1575\tStatic Loss:0.3542\t\n",
      "Val Loss:0.3802\tRecon Loss:2.1084\tTriplet Loss:0.1668\tStatic Loss:0.3842\n",
      "\n",
      "\tTime:45.3079\n",
      "\n",
      "Test Loss:0.9675\tRecon Loss:6.5165\tTriplet Loss:0.4797\tStatic Loss:0.9608\n",
      "\n",
      "\tEpoch:8\tTrain Loss:0.3435\tRecon Loss:2.0981\tTriplet Loss:0.1457\tStatic Loss:0.3457\t\n",
      "Val Loss:0.3529\tRecon Loss:2.0626\tTriplet Loss:0.1597\tStatic Loss:0.3552\n",
      "\n",
      "\tTime:45.5595\n",
      "\n",
      "Test Loss:0.8897\tRecon Loss:6.3741\tTriplet Loss:0.4610\tStatic Loss:0.8777\n",
      "\n",
      "\tEpoch:9\tTrain Loss:0.3389\tRecon Loss:2.0327\tTriplet Loss:0.1452\tStatic Loss:0.3413\t\n",
      "Val Loss:0.3511\tRecon Loss:1.9732\tTriplet Loss:0.1508\tStatic Loss:0.3549\n",
      "\n",
      "\tTime:44.5412\n",
      "\n",
      "Test Loss:0.9082\tRecon Loss:6.0729\tTriplet Loss:0.4623\tStatic Loss:0.9012\n",
      "\n",
      "\tEpoch:10\tTrain Loss:0.3330\tRecon Loss:2.0884\tTriplet Loss:0.1391\tStatic Loss:0.3349\t\n",
      "Val Loss:0.3452\tRecon Loss:2.0663\tTriplet Loss:0.1477\tStatic Loss:0.3478\n",
      "\n",
      "\tTime:45.6001\n",
      "\n",
      "Test Loss:0.8659\tRecon Loss:6.4256\tTriplet Loss:0.4439\tStatic Loss:0.8525\n",
      "\n",
      "\tEpoch:11\tTrain Loss:0.3269\tRecon Loss:2.0463\tTriplet Loss:0.1386\tStatic Loss:0.3285\t\n",
      "Val Loss:0.3368\tRecon Loss:1.9975\tTriplet Loss:0.1430\tStatic Loss:0.3395\n",
      "\n",
      "\tTime:44.9097\n",
      "\n",
      "Test Loss:0.8446\tRecon Loss:6.0637\tTriplet Loss:0.4496\tStatic Loss:0.8319\n",
      "\n",
      "\tEpoch:12\tTrain Loss:0.3202\tRecon Loss:2.0057\tTriplet Loss:0.1299\tStatic Loss:0.3224\t\n",
      "Val Loss:0.3377\tRecon Loss:1.9366\tTriplet Loss:0.1487\tStatic Loss:0.3406\n",
      "\n",
      "\tTime:44.7101\n",
      "\n",
      "Test Loss:0.8539\tRecon Loss:6.0203\tTriplet Loss:0.4251\tStatic Loss:0.8452\n",
      "\n",
      "\tEpoch:13\tTrain Loss:0.3159\tRecon Loss:2.0030\tTriplet Loss:0.1303\tStatic Loss:0.3176\t\n",
      "Val Loss:0.3441\tRecon Loss:1.9821\tTriplet Loss:0.1484\tStatic Loss:0.3473\n",
      "\n",
      "\tTime:45.6447\n",
      "\n",
      "Test Loss:0.8662\tRecon Loss:6.1269\tTriplet Loss:0.4155\tStatic Loss:0.8587\n",
      "\n",
      "\tEpoch:14\tTrain Loss:0.3136\tRecon Loss:1.9925\tTriplet Loss:0.1300\tStatic Loss:0.3151\t\n",
      "Val Loss:0.3327\tRecon Loss:2.0000\tTriplet Loss:0.1373\tStatic Loss:0.3356\n",
      "\n",
      "\tTime:46.5799\n",
      "\n",
      "Test Loss:0.8375\tRecon Loss:6.1429\tTriplet Loss:0.4139\tStatic Loss:0.8268\n",
      "\n",
      "\tEpoch:15\tTrain Loss:0.3121\tRecon Loss:2.1038\tTriplet Loss:0.1278\tStatic Loss:0.3126\t\n",
      "Val Loss:0.3450\tRecon Loss:2.2389\tTriplet Loss:0.1378\tStatic Loss:0.3467\n",
      "\n",
      "\tTime:46.8648\n",
      "\n",
      "Test Loss:0.8789\tRecon Loss:6.7510\tTriplet Loss:0.4318\tStatic Loss:0.8648\n",
      "\n",
      "\tEpoch:16\tTrain Loss:0.3044\tRecon Loss:2.0928\tTriplet Loss:0.1240\tStatic Loss:0.3046\t\n",
      "Val Loss:0.3323\tRecon Loss:2.1366\tTriplet Loss:0.1335\tStatic Loss:0.3341\n",
      "\n",
      "\tTime:46.6727\n",
      "\n",
      "Test Loss:0.8465\tRecon Loss:6.4865\tTriplet Loss:0.4108\tStatic Loss:0.8337\n",
      "\n",
      "\tEpoch:17\tTrain Loss:0.3016\tRecon Loss:1.9985\tTriplet Loss:0.1191\tStatic Loss:0.3029\t\n",
      "Val Loss:0.3240\tRecon Loss:1.9410\tTriplet Loss:0.1284\tStatic Loss:0.3274\n",
      "\n",
      "\tTime:48.2136\n",
      "\n",
      "Test Loss:0.8307\tRecon Loss:6.0593\tTriplet Loss:0.4274\tStatic Loss:0.8187\n",
      "\n",
      "\tEpoch:18\tTrain Loss:0.3014\tRecon Loss:2.0231\tTriplet Loss:0.1215\tStatic Loss:0.3022\t\n",
      "Val Loss:0.3267\tRecon Loss:1.9446\tTriplet Loss:0.1420\tStatic Loss:0.3289\n",
      "\n",
      "\tTime:48.7638\n",
      "\n",
      "Test Loss:0.8238\tRecon Loss:5.9919\tTriplet Loss:0.4099\tStatic Loss:0.8135\n",
      "\n",
      "\tEpoch:19\tTrain Loss:0.2981\tRecon Loss:2.0087\tTriplet Loss:0.1183\tStatic Loss:0.2990\t\n",
      "Val Loss:0.3307\tRecon Loss:1.9545\tTriplet Loss:0.1238\tStatic Loss:0.3351\n",
      "\n",
      "\tTime:45.8349\n",
      "\n",
      "Test Loss:0.8510\tRecon Loss:6.0571\tTriplet Loss:0.4199\tStatic Loss:0.8420\n",
      "\n",
      "\tEpoch:20\tTrain Loss:0.2951\tRecon Loss:2.0052\tTriplet Loss:0.1143\tStatic Loss:0.2960\t\n",
      "Val Loss:0.3279\tRecon Loss:2.0244\tTriplet Loss:0.1407\tStatic Loss:0.3296\n",
      "\n",
      "\tTime:45.3978\n",
      "\n",
      "Test Loss:0.8315\tRecon Loss:6.1863\tTriplet Loss:0.4015\tStatic Loss:0.8210\n",
      "\n",
      "\tEpoch:21\tTrain Loss:0.2925\tRecon Loss:2.0260\tTriplet Loss:0.1146\tStatic Loss:0.2929\t\n",
      "Val Loss:0.3240\tRecon Loss:1.9398\tTriplet Loss:0.1320\tStatic Loss:0.3271\n",
      "\n",
      "\tTime:44.2431\n",
      "\n",
      "Test Loss:0.8432\tRecon Loss:6.0264\tTriplet Loss:0.4120\tStatic Loss:0.8345\n",
      "\n",
      "\tEpoch:22\tTrain Loss:0.2884\tRecon Loss:2.0163\tTriplet Loss:0.1114\tStatic Loss:0.2889\t\n",
      "Val Loss:0.3239\tRecon Loss:1.9777\tTriplet Loss:0.1283\tStatic Loss:0.3270\n",
      "\n",
      "\tTime:45.5637\n",
      "\n",
      "Test Loss:0.8557\tRecon Loss:6.1414\tTriplet Loss:0.4075\tStatic Loss:0.8477\n",
      "\n",
      "\tEpoch:23\tTrain Loss:0.2879\tRecon Loss:2.0442\tTriplet Loss:0.1104\tStatic Loss:0.2881\t\n",
      "Val Loss:0.3237\tRecon Loss:2.2382\tTriplet Loss:0.1273\tStatic Loss:0.3241\n",
      "\n",
      "\tTime:46.0950\n",
      "\n",
      "Test Loss:0.8529\tRecon Loss:7.0284\tTriplet Loss:0.4123\tStatic Loss:0.8352\n",
      "\n",
      "\tEpoch:24\tTrain Loss:0.2871\tRecon Loss:2.1072\tTriplet Loss:0.1096\tStatic Loss:0.2866\t\n",
      "Val Loss:0.3258\tRecon Loss:1.9512\tTriplet Loss:0.1275\tStatic Loss:0.3294\n",
      "\n",
      "\tTime:45.0969\n",
      "\n",
      "Test Loss:0.8543\tRecon Loss:6.0471\tTriplet Loss:0.4133\tStatic Loss:0.8465\n",
      "\n",
      "\tEpoch:25\tTrain Loss:0.2845\tRecon Loss:1.9742\tTriplet Loss:0.1061\tStatic Loss:0.2854\t\n",
      "Val Loss:0.3171\tRecon Loss:1.9144\tTriplet Loss:0.1259\tStatic Loss:0.3203\n",
      "\n",
      "\tTime:44.5334\n",
      "\n",
      "Test Loss:0.8077\tRecon Loss:5.9170\tTriplet Loss:0.4002\tStatic Loss:0.7974\n",
      "\n",
      "\tEpoch:26\tTrain Loss:0.2925\tRecon Loss:2.0792\tTriplet Loss:0.1112\tStatic Loss:0.2928\t\n",
      "Val Loss:0.3142\tRecon Loss:1.9616\tTriplet Loss:0.1204\tStatic Loss:0.3171\n",
      "\n",
      "\tTime:44.8386\n",
      "\n",
      "Test Loss:0.8285\tRecon Loss:6.0598\tTriplet Loss:0.4007\tStatic Loss:0.8189\n",
      "\n",
      "\tEpoch:27\tTrain Loss:0.2793\tRecon Loss:1.9797\tTriplet Loss:0.1037\tStatic Loss:0.2799\t\n",
      "Val Loss:0.3187\tRecon Loss:1.9367\tTriplet Loss:0.1290\tStatic Loss:0.3215\n",
      "\n",
      "\tTime:46.0818\n",
      "\n",
      "Test Loss:0.8438\tRecon Loss:5.9986\tTriplet Loss:0.3953\tStatic Loss:0.8371\n",
      "\n",
      "\tEpoch:28\tTrain Loss:0.2772\tRecon Loss:1.9759\tTriplet Loss:0.1075\tStatic Loss:0.2772\t\n",
      "Val Loss:0.3129\tRecon Loss:1.9286\tTriplet Loss:0.1147\tStatic Loss:0.3166\n",
      "\n",
      "\tTime:45.1351\n",
      "\n",
      "Test Loss:0.8214\tRecon Loss:5.9796\tTriplet Loss:0.3958\tStatic Loss:0.8123\n",
      "\n",
      "\tEpoch:29\tTrain Loss:0.2756\tRecon Loss:1.9603\tTriplet Loss:0.1047\tStatic Loss:0.2758\t\n",
      "Val Loss:0.3215\tRecon Loss:1.9727\tTriplet Loss:0.1231\tStatic Loss:0.3249\n",
      "\n",
      "\tTime:43.8261\n",
      "\n",
      "Test Loss:0.8354\tRecon Loss:6.1448\tTriplet Loss:0.3936\tStatic Loss:0.8265\n",
      "\n",
      "\tEpoch:30\tTrain Loss:0.2725\tRecon Loss:1.9651\tTriplet Loss:0.1016\tStatic Loss:0.2727\t\n",
      "Val Loss:0.3164\tRecon Loss:2.0461\tTriplet Loss:0.1181\tStatic Loss:0.3189\n",
      "\n",
      "\tTime:45.5849\n",
      "\n",
      "Test Loss:0.8296\tRecon Loss:6.2009\tTriplet Loss:0.3631\tStatic Loss:0.8225\n",
      "\n",
      "\tEpoch:31\tTrain Loss:0.2704\tRecon Loss:1.9572\tTriplet Loss:0.0970\tStatic Loss:0.2708\t\n",
      "Val Loss:0.3141\tRecon Loss:1.9436\tTriplet Loss:0.1205\tStatic Loss:0.3172\n",
      "\n",
      "\tTime:47.4600\n",
      "\n",
      "Test Loss:0.7947\tRecon Loss:6.0337\tTriplet Loss:0.3958\tStatic Loss:0.7822\n",
      "\n",
      "\tEpoch:32\tTrain Loss:0.2757\tRecon Loss:2.0222\tTriplet Loss:0.1049\tStatic Loss:0.2753\t\n",
      "Val Loss:0.3197\tRecon Loss:2.4468\tTriplet Loss:0.1268\tStatic Loss:0.3177\n",
      "\n",
      "\tTime:45.1124\n",
      "\n",
      "Test Loss:0.8172\tRecon Loss:7.2816\tTriplet Loss:0.3733\tStatic Loss:0.7970\n",
      "\n",
      "\tEpoch:33\tTrain Loss:0.2786\tRecon Loss:2.6266\tTriplet Loss:0.0988\tStatic Loss:0.2731\t\n",
      "Val Loss:0.3157\tRecon Loss:2.2795\tTriplet Loss:0.1266\tStatic Loss:0.3149\n",
      "\n",
      "\tTime:45.3459\n",
      "\n",
      "Test Loss:0.8622\tRecon Loss:6.8740\tTriplet Loss:0.3683\tStatic Loss:0.8515\n",
      "\n",
      "\tEpoch:34\tTrain Loss:0.2721\tRecon Loss:2.2676\tTriplet Loss:0.0985\tStatic Loss:0.2695\t\n",
      "Val Loss:0.3190\tRecon Loss:2.3854\tTriplet Loss:0.1176\tStatic Loss:0.3185\n",
      "\n",
      "\tTime:45.6693\n",
      "\n",
      "Test Loss:0.8599\tRecon Loss:7.2541\tTriplet Loss:0.3858\tStatic Loss:0.8434\n",
      "\n",
      "\tEpoch:35\tTrain Loss:0.2677\tRecon Loss:2.1503\tTriplet Loss:0.1006\tStatic Loss:0.2655\t\n",
      "Val Loss:0.3099\tRecon Loss:2.0968\tTriplet Loss:0.1104\tStatic Loss:0.3119\n",
      "\n",
      "\tTime:46.2841\n",
      "\n",
      "Test Loss:0.7966\tRecon Loss:6.3895\tTriplet Loss:0.3606\tStatic Loss:0.7843\n",
      "\n",
      "\tEpoch:36\tTrain Loss:0.2696\tRecon Loss:2.3886\tTriplet Loss:0.0964\tStatic Loss:0.2657\t\n",
      "Val Loss:0.3139\tRecon Loss:2.0990\tTriplet Loss:0.1217\tStatic Loss:0.3153\n",
      "\n",
      "\tTime:49.3613\n",
      "\n",
      "Test Loss:0.8292\tRecon Loss:6.3610\tTriplet Loss:0.3933\tStatic Loss:0.8175\n",
      "\n",
      "\tEpoch:37\tTrain Loss:0.3007\tRecon Loss:2.8349\tTriplet Loss:0.1152\tStatic Loss:0.2939\t\n",
      "Val Loss:0.3234\tRecon Loss:2.8168\tTriplet Loss:0.1288\tStatic Loss:0.3179\n",
      "\n",
      "\tTime:45.6228\n",
      "\n",
      "Test Loss:0.8465\tRecon Loss:8.8276\tTriplet Loss:0.3975\tStatic Loss:0.8116\n",
      "\n",
      "\tEpoch:38\tTrain Loss:0.2826\tRecon Loss:2.5967\tTriplet Loss:0.1017\tStatic Loss:0.2776\t\n",
      "Val Loss:0.3200\tRecon Loss:2.5206\tTriplet Loss:0.1201\tStatic Loss:0.3180\n",
      "\n",
      "\tTime:46.2230\n",
      "\n",
      "Test Loss:0.8557\tRecon Loss:7.6972\tTriplet Loss:0.3992\tStatic Loss:0.8329\n",
      "\n",
      "\tEpoch:39\tTrain Loss:0.2692\tRecon Loss:2.2673\tTriplet Loss:0.0963\tStatic Loss:0.2665\t\n",
      "Val Loss:0.3206\tRecon Loss:2.2438\tTriplet Loss:0.1178\tStatic Loss:0.3216\n",
      "\n",
      "\tTime:47.3977\n",
      "\n",
      "Test Loss:0.8555\tRecon Loss:7.0950\tTriplet Loss:0.3898\tStatic Loss:0.8397\n",
      "\n",
      "\tEpoch:40\tTrain Loss:0.2699\tRecon Loss:2.4247\tTriplet Loss:0.0950\tStatic Loss:0.2659\t\n",
      "Val Loss:0.3069\tRecon Loss:2.0774\tTriplet Loss:0.1294\tStatic Loss:0.3069\n",
      "\n",
      "\tTime:46.5446\n",
      "\n",
      "Test Loss:0.7917\tRecon Loss:6.5136\tTriplet Loss:0.3924\tStatic Loss:0.7744\n",
      "\n",
      "\tEpoch:41\tTrain Loss:0.2622\tRecon Loss:2.0937\tTriplet Loss:0.0947\tStatic Loss:0.2607\t\n",
      "Val Loss:0.3030\tRecon Loss:1.9858\tTriplet Loss:0.1079\tStatic Loss:0.3056\n",
      "\n",
      "\tTime:45.2992\n",
      "\n",
      "Test Loss:0.8112\tRecon Loss:6.1527\tTriplet Loss:0.3795\tStatic Loss:0.8009\n",
      "\n",
      "\tEpoch:42\tTrain Loss:0.2578\tRecon Loss:2.0213\tTriplet Loss:0.0943\tStatic Loss:0.2565\t\n",
      "Val Loss:0.3058\tRecon Loss:1.9492\tTriplet Loss:0.1159\tStatic Loss:0.3084\n",
      "\n",
      "\tTime:45.6923\n",
      "\n",
      "Test Loss:0.7856\tRecon Loss:6.0594\tTriplet Loss:0.3620\tStatic Loss:0.7752\n",
      "\n",
      "\tEpoch:43\tTrain Loss:0.2571\tRecon Loss:1.9980\tTriplet Loss:0.0927\tStatic Loss:0.2561\t\n",
      "Val Loss:0.3072\tRecon Loss:1.9501\tTriplet Loss:0.1125\tStatic Loss:0.3103\n",
      "\n",
      "\tTime:44.9331\n",
      "\n",
      "Test Loss:0.8090\tRecon Loss:6.0245\tTriplet Loss:0.3837\tStatic Loss:0.7994\n",
      "\n",
      "\tEpoch:44\tTrain Loss:0.2570\tRecon Loss:1.9818\tTriplet Loss:0.0932\tStatic Loss:0.2561\t\n",
      "Val Loss:0.3057\tRecon Loss:2.1223\tTriplet Loss:0.1092\tStatic Loss:0.3072\n",
      "\n",
      "\tTime:46.2327\n",
      "\n",
      "Test Loss:0.8223\tRecon Loss:6.5786\tTriplet Loss:0.3881\tStatic Loss:0.8082\n",
      "\n",
      "\tEpoch:45\tTrain Loss:0.2599\tRecon Loss:2.1479\tTriplet Loss:0.0896\tStatic Loss:0.2580\t\n",
      "Val Loss:0.3103\tRecon Loss:2.0177\tTriplet Loss:0.1049\tStatic Loss:0.3138\n",
      "\n",
      "\tTime:46.7464\n",
      "\n",
      "Test Loss:0.8378\tRecon Loss:6.3258\tTriplet Loss:0.3792\tStatic Loss:0.8288\n",
      "\n",
      "\tEpoch:46\tTrain Loss:0.2567\tRecon Loss:1.9886\tTriplet Loss:0.0924\tStatic Loss:0.2559\t\n",
      "Val Loss:0.3072\tRecon Loss:1.9471\tTriplet Loss:0.1168\tStatic Loss:0.3098\n",
      "\n",
      "\tTime:45.2529\n",
      "\n",
      "Test Loss:0.8300\tRecon Loss:6.0252\tTriplet Loss:0.3784\tStatic Loss:0.8233\n",
      "\n",
      "\tEpoch:47\tTrain Loss:0.2550\tRecon Loss:2.0576\tTriplet Loss:0.0932\tStatic Loss:0.2532\t\n",
      "Val Loss:0.3157\tRecon Loss:2.1815\tTriplet Loss:0.1138\tStatic Loss:0.3173\n",
      "\n",
      "\tTime:45.8525\n",
      "\n",
      "Test Loss:0.8507\tRecon Loss:6.8812\tTriplet Loss:0.3617\tStatic Loss:0.8393\n",
      "\n",
      "\tEpoch:48\tTrain Loss:0.2571\tRecon Loss:2.0564\tTriplet Loss:0.0932\tStatic Loss:0.2555\t\n",
      "Val Loss:0.3092\tRecon Loss:1.9681\tTriplet Loss:0.1121\tStatic Loss:0.3123\n",
      "\n",
      "\tTime:45.1815\n",
      "\n",
      "Test Loss:0.8250\tRecon Loss:6.0748\tTriplet Loss:0.3580\tStatic Loss:0.8192\n",
      "\n",
      "\tEpoch:49\tTrain Loss:0.2586\tRecon Loss:2.0387\tTriplet Loss:0.0942\tStatic Loss:0.2572\t\n",
      "Val Loss:0.3048\tRecon Loss:1.9320\tTriplet Loss:0.1161\tStatic Loss:0.3074\n",
      "\n",
      "\tTime:46.3368\n",
      "\n",
      "Test Loss:0.7843\tRecon Loss:6.0144\tTriplet Loss:0.3769\tStatic Loss:0.7728\n",
      "\n",
      "\t\n",
      "Unc Est in Static characteristics:0.0021\tUnc Est in Streamflow, dynamic:0.0007\t\n",
      "\n",
      "\t[50, 1, 'ATT_NL_0', (0.6943428737145884, 8.022231503536826, 0.4686096158172739, 1.082967431921708, 0.0, 0.0)]\n",
      "[50, 1, 'ATT_NL_3', (0.6735479257724903, 6.315154426976254, 0.40209231829564823, 0.9871496307222467, 0.001720233354717493, 0.0010411625262349844)]\n",
      "[5, 10, 'ATT_NL_0', (0.3129037177121198, 5.976257286573711, 0.4670676261088566, 0.8567396472943457, 0.0, 0.0)]\n",
      "[5, 10, 'ATT_NL_3', (0.3029597649971644, 6.014414253987764, 0.3768614199208586, 0.7727765448783573, 0.0021370495669543743, 0.000699154450558126)]\n"
     ]
    }
   ],
   "source": [
    "# different noise, missingness, loss weights\n",
    "models = [\"ATT_NL_0\", \"ATT_NL_3\"] #, \"ATT_NL_4\", \"ATT_NL_5\", \"ATT_NL_6\", \"ATT_NL\" # \"ATT_NL_1\",\n",
    "results = []\n",
    "# corruption_percentage = [ 1, 5, 10, 20, 50]\n",
    "# corruption_stderr = {1:[10],5:[10], 10:[0.1, 0.5, 1, 5], 20:[0.1, 0.5, 1, 5], 50:[0.1, 0.5, 1, 5]}\n",
    "# reconstruction_weight_list = [0, 0.1]\n",
    "# static_weight_list = [0, 10]\n",
    "# triplet_weight_list = [0, 1]\n",
    "\n",
    "corruption_percentage = [ 50, 5]\n",
    "corruption_stderr = {1:[10],5:[10], 10:[0.1, 0.5, 1, 5], 20:[0.1, 0.5, 1, 5], 50:[1]}\n",
    "\n",
    "\n",
    "reconstruction_weight_list = [0.1]\n",
    "static_weight_list = [10]\n",
    "triplet_weight_list = [1]\n",
    "\n",
    "for recon_weight in reconstruction_weight_list:\n",
    "    for static_weight in static_weight_list:\n",
    "        for triplet_weight in triplet_weight_list:\n",
    "            sum_weight = recon_weight+static_weight+triplet_weight\n",
    "            if sum_weight>0:\n",
    "                for corr_per in corruption_percentage:\n",
    "                    for corr_std in corruption_stderr[corr_per]:\n",
    "                        train_data = np.load(os.path.join(DIR,'NUMPY', \"train_data_basin_corrupted_{}_{}.npy\").format(corr_per,corr_std))[:,:,:,:-1]\n",
    "                        validation_data = np.load(os.path.join(DIR,'NUMPY', \"validation_data_basin_corrupted_{}_{}.npy\").format(corr_per,corr_std))[:,:,:,:-1]\n",
    "                        test_data = np.load(os.path.join(DIR,'NUMPY', \"test_data_basin_clean_{}_{}.npy\").format(corr_per,corr_std))[:,:,:,:-1]\n",
    "                        # hidden_train_data = np.load(os.path.join(config.NUMPY_DIR, \"train_hidden_data_basin.npy\"))[:,:,:,:-1]\n",
    "                        print(\"Train Data:{}\\tValidation Data:{}\\tTest Data:{}\".format(train_data.shape, validation_data.shape, test_data.shape))            \n",
    "\n",
    "                        for a_model in models:\n",
    "\n",
    "                            print(\"recon weight:{}\\tstatic weight:{}\\ttriplet weight:{}\\tcorr_per:{}\\tcorr_std:{}\\tmodel:{}\".format(recon_weight, static_weight, triplet_weight, corr_per, corr_std, a_model)) \n",
    "                            model = globals()[a_model](in_channels=len(input_channels), stat_channels=len(static_channels), code_dim=code_dim, device=device)\n",
    "                            model = model.to(device)\n",
    "                            criterion = torch.nn.MSELoss(reduction=\"none\")\n",
    "                            triplet_criterion = torch.nn.TripletMarginLoss(margin=alpha, p=2.0, eps=1e-06, reduction=\"none\")\n",
    "                            # triplet_criterion = torch.nn.TripletMarginWithDistanceLoss(distance_function=torch.nn.PairwiseDistance(p=2.0, eps=1e-06), margin=alpha, reduction=\"none\")\n",
    "                            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "                            results.append([corr_per, corr_std, a_model, run_model(model,train_data, validation_data,test_data, os.path.join(RESULT_DIR, 'corrupt_50_1',a_model+'.pt' )) ])\n",
    "    \n",
    "\n",
    "for i in range(len(results)):\n",
    "    print(results[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:(531, 39, 365, 33)\tValidation Data:(531, 9, 365, 33)\tTest Data:(531, 19, 365, 33)\n",
      "recon weight:0.1\tstatic weight:10\ttriplet weight:1\tcorr_per:1\tcorr_std:10\tmodel:ATT_NL_0\n",
      "Epoch:0\tTrain Loss:0.6438\tRecon Loss:4.2146\tTriplet Loss:0.4526\tStatic Loss:0.6272\t\n",
      "Val Loss:0.4825\tRecon Loss:4.0079\tTriplet Loss:0.2940\tStatic Loss:0.4661\n",
      "\n",
      "\tTime:51.4242\n",
      "\n",
      "Test Loss:1.4219\tRecon Loss:11.9927\tTriplet Loss:0.9341\tStatic Loss:1.3649\n",
      "\n",
      "\tEpoch:1\tTrain Loss:0.4325\tRecon Loss:3.9984\tTriplet Loss:0.2795\tStatic Loss:0.4121\t\n",
      "Val Loss:0.4044\tRecon Loss:3.9739\tTriplet Loss:0.2492\tStatic Loss:0.3843\n",
      "\n",
      "\tTime:52.1167\n",
      "\n",
      "Test Loss:1.1923\tRecon Loss:11.9042\tTriplet Loss:0.7115\tStatic Loss:1.1333\n",
      "\n",
      "\tEpoch:2\tTrain Loss:0.3826\tRecon Loss:3.9779\tTriplet Loss:0.2358\tStatic Loss:0.3613\t\n",
      "Val Loss:0.3776\tRecon Loss:3.9270\tTriplet Loss:0.2156\tStatic Loss:0.3583\n",
      "\n",
      "\tTime:50.9636\n",
      "\n",
      "Test Loss:1.1563\tRecon Loss:11.7502\tTriplet Loss:0.6973\tStatic Loss:1.0963\n",
      "\n",
      "\tEpoch:3\tTrain Loss:0.3610\tRecon Loss:3.9354\tTriplet Loss:0.2176\tStatic Loss:0.3397\t\n",
      "Val Loss:0.3566\tRecon Loss:3.8401\tTriplet Loss:0.1992\tStatic Loss:0.3375\n",
      "\n",
      "\tTime:52.6898\n",
      "\n",
      "Test Loss:1.0895\tRecon Loss:11.4036\tTriplet Loss:0.6340\tStatic Loss:1.0319\n",
      "\n",
      "\tEpoch:4\tTrain Loss:0.3448\tRecon Loss:3.7731\tTriplet Loss:0.1998\tStatic Loss:0.3251\t\n",
      "Val Loss:0.3463\tRecon Loss:3.4632\tTriplet Loss:0.1988\tStatic Loss:0.3299\n",
      "\n",
      "\tTime:55.5011\n",
      "\n",
      "Test Loss:1.0765\tRecon Loss:10.4748\tTriplet Loss:0.6044\tStatic Loss:1.0298\n",
      "\n",
      "\tEpoch:5\tTrain Loss:0.3317\tRecon Loss:3.5426\tTriplet Loss:0.1831\tStatic Loss:0.3144\t\n",
      "Val Loss:0.3323\tRecon Loss:3.4630\tTriplet Loss:0.1828\tStatic Loss:0.3160\n",
      "\n",
      "\tTime:54.8750\n",
      "\n",
      "Test Loss:1.0362\tRecon Loss:10.3863\tTriplet Loss:0.5743\tStatic Loss:0.9889\n",
      "\n",
      "\tEpoch:6\tTrain Loss:0.3167\tRecon Loss:2.9507\tTriplet Loss:0.1705\tStatic Loss:0.3050\t\n",
      "Val Loss:0.3197\tRecon Loss:2.4287\tTriplet Loss:0.1800\tStatic Loss:0.3126\n",
      "\n",
      "\tTime:54.7086\n",
      "\n",
      "Test Loss:0.9532\tRecon Loss:7.3133\tTriplet Loss:0.5864\tStatic Loss:0.9263\n",
      "\n",
      "\tEpoch:7\tTrain Loss:0.3072\tRecon Loss:2.5723\tTriplet Loss:0.1679\tStatic Loss:0.2985\t\n",
      "Val Loss:0.3203\tRecon Loss:2.3035\tTriplet Loss:0.1694\tStatic Loss:0.3155\n",
      "\n",
      "\tTime:53.0936\n",
      "\n",
      "Test Loss:0.9696\tRecon Loss:6.9152\tTriplet Loss:0.5407\tStatic Loss:0.9530\n",
      "\n",
      "\tEpoch:8\tTrain Loss:0.2953\tRecon Loss:2.1866\tTriplet Loss:0.1565\tStatic Loss:0.2903\t\n",
      "Val Loss:0.3217\tRecon Loss:2.0938\tTriplet Loss:0.1720\tStatic Loss:0.3190\n",
      "\n",
      "\tTime:52.2211\n",
      "\n",
      "Test Loss:0.9564\tRecon Loss:6.4120\tTriplet Loss:0.5423\tStatic Loss:0.9433\n",
      "\n",
      "\tEpoch:9\tTrain Loss:0.2928\tRecon Loss:2.2111\tTriplet Loss:0.1596\tStatic Loss:0.2869\t\n",
      "Val Loss:0.3090\tRecon Loss:2.3835\tTriplet Loss:0.1688\tStatic Loss:0.3022\n",
      "\n",
      "\tTime:51.7081\n",
      "\n",
      "Test Loss:0.9649\tRecon Loss:7.1302\tTriplet Loss:0.5576\tStatic Loss:0.9440\n",
      "\n",
      "\tEpoch:10\tTrain Loss:0.2848\tRecon Loss:2.0817\tTriplet Loss:0.1546\tStatic Loss:0.2798\t\n",
      "Val Loss:0.2994\tRecon Loss:2.0220\tTriplet Loss:0.1589\tStatic Loss:0.2962\n",
      "\n",
      "\tTime:51.8382\n",
      "\n",
      "Test Loss:0.9181\tRecon Loss:6.1442\tTriplet Loss:0.5119\tStatic Loss:0.9065\n",
      "\n",
      "\tEpoch:11\tTrain Loss:0.2803\tRecon Loss:2.1133\tTriplet Loss:0.1455\tStatic Loss:0.2754\t\n",
      "Val Loss:0.2980\tRecon Loss:2.0087\tTriplet Loss:0.1636\tStatic Loss:0.2943\n",
      "\n",
      "\tTime:52.6079\n",
      "\n",
      "Test Loss:0.9088\tRecon Loss:6.3811\tTriplet Loss:0.5019\tStatic Loss:0.8948\n",
      "\n",
      "\tEpoch:12\tTrain Loss:0.2752\tRecon Loss:2.0198\tTriplet Loss:0.1456\tStatic Loss:0.2707\t\n",
      "Val Loss:0.2976\tRecon Loss:1.9782\tTriplet Loss:0.1660\tStatic Loss:0.2940\n",
      "\n",
      "\tTime:50.1462\n",
      "\n",
      "Test Loss:0.8837\tRecon Loss:6.1820\tTriplet Loss:0.4873\tStatic Loss:0.8704\n",
      "\n",
      "\tEpoch:13\tTrain Loss:0.2724\tRecon Loss:2.1085\tTriplet Loss:0.1438\tStatic Loss:0.2669\t\n",
      "Val Loss:0.2963\tRecon Loss:1.9674\tTriplet Loss:0.1533\tStatic Loss:0.2939\n",
      "\n",
      "\tTime:50.4981\n",
      "\n",
      "Test Loss:0.9049\tRecon Loss:6.0409\tTriplet Loss:0.5049\tStatic Loss:0.8936\n",
      "\n",
      "\tEpoch:14\tTrain Loss:0.2714\tRecon Loss:2.4759\tTriplet Loss:0.1382\tStatic Loss:0.2627\t\n",
      "Val Loss:0.3073\tRecon Loss:2.3775\tTriplet Loss:0.1538\tStatic Loss:0.3019\n",
      "\n",
      "\tTime:50.2834\n",
      "\n",
      "Test Loss:0.9206\tRecon Loss:7.1281\tTriplet Loss:0.4758\tStatic Loss:0.9030\n",
      "\n",
      "\tEpoch:15\tTrain Loss:0.2655\tRecon Loss:2.0808\tTriplet Loss:0.1415\tStatic Loss:0.2597\t\n",
      "Val Loss:0.2912\tRecon Loss:1.9612\tTriplet Loss:0.1581\tStatic Loss:0.2878\n",
      "\n",
      "\tTime:49.6751\n",
      "\n",
      "Test Loss:0.8761\tRecon Loss:6.0477\tTriplet Loss:0.5154\tStatic Loss:0.8605\n",
      "\n",
      "\tEpoch:16\tTrain Loss:0.2587\tRecon Loss:1.9884\tTriplet Loss:0.1308\tStatic Loss:0.2542\t\n",
      "Val Loss:0.2822\tRecon Loss:1.9514\tTriplet Loss:0.1479\tStatic Loss:0.2790\n",
      "\n",
      "\tTime:51.2361\n",
      "\n",
      "Test Loss:0.8763\tRecon Loss:6.0345\tTriplet Loss:0.4669\tStatic Loss:0.8657\n",
      "\n",
      "\tEpoch:17\tTrain Loss:0.2554\tRecon Loss:1.9916\tTriplet Loss:0.1284\tStatic Loss:0.2507\t\n",
      "Val Loss:0.2965\tRecon Loss:2.0243\tTriplet Loss:0.1491\tStatic Loss:0.2940\n",
      "\n",
      "\tTime:50.7820\n",
      "\n",
      "Test Loss:0.8679\tRecon Loss:6.2879\tTriplet Loss:0.4695\tStatic Loss:0.8535\n",
      "\n",
      "\tEpoch:18\tTrain Loss:0.2563\tRecon Loss:2.0834\tTriplet Loss:0.1293\tStatic Loss:0.2508\t\n",
      "Val Loss:0.2960\tRecon Loss:2.9728\tTriplet Loss:0.1524\tStatic Loss:0.2836\n",
      "\n",
      "\tTime:49.5594\n",
      "\n",
      "Test Loss:0.8963\tRecon Loss:8.8996\tTriplet Loss:0.4842\tStatic Loss:0.8574\n",
      "\n",
      "\tEpoch:19\tTrain Loss:0.2532\tRecon Loss:2.2460\tTriplet Loss:0.1276\tStatic Loss:0.2459\t\n",
      "Val Loss:0.2903\tRecon Loss:1.9626\tTriplet Loss:0.1471\tStatic Loss:0.2879\n",
      "\n",
      "\tTime:48.5900\n",
      "\n",
      "Test Loss:0.9018\tRecon Loss:6.0060\tTriplet Loss:0.4658\tStatic Loss:0.8943\n",
      "\n",
      "\tEpoch:20\tTrain Loss:0.2465\tRecon Loss:1.9976\tTriplet Loss:0.1260\tStatic Loss:0.2411\t\n",
      "Val Loss:0.2802\tRecon Loss:1.9381\tTriplet Loss:0.1620\tStatic Loss:0.2755\n",
      "\n",
      "\tTime:49.2287\n",
      "\n",
      "Test Loss:0.8712\tRecon Loss:5.9466\tTriplet Loss:0.5015\tStatic Loss:0.8575\n",
      "\n",
      "\tEpoch:21\tTrain Loss:0.2477\tRecon Loss:1.9873\tTriplet Loss:0.1250\tStatic Loss:0.2425\t\n",
      "Val Loss:0.2824\tRecon Loss:1.9375\tTriplet Loss:0.1340\tStatic Loss:0.2807\n",
      "\n",
      "\tTime:50.2658\n",
      "\n",
      "Test Loss:0.8781\tRecon Loss:5.9983\tTriplet Loss:0.4455\tStatic Loss:0.8702\n",
      "\n",
      "\tEpoch:22\tTrain Loss:0.2431\tRecon Loss:1.9740\tTriplet Loss:0.1164\tStatic Loss:0.2384\t\n",
      "Val Loss:0.2730\tRecon Loss:1.9489\tTriplet Loss:0.1258\tStatic Loss:0.2710\n",
      "\n",
      "\tTime:50.7843\n",
      "\n",
      "Test Loss:0.8420\tRecon Loss:6.0171\tTriplet Loss:0.4490\tStatic Loss:0.8295\n",
      "\n",
      "\tEpoch:23\tTrain Loss:0.2392\tRecon Loss:1.9786\tTriplet Loss:0.1145\tStatic Loss:0.2343\t\n",
      "Val Loss:0.2757\tRecon Loss:1.9530\tTriplet Loss:0.1471\tStatic Loss:0.2718\n",
      "\n",
      "\tTime:49.9532\n",
      "\n",
      "Test Loss:0.8575\tRecon Loss:5.9532\tTriplet Loss:0.4587\tStatic Loss:0.8465\n",
      "\n",
      "\tEpoch:24\tTrain Loss:0.2377\tRecon Loss:1.9660\tTriplet Loss:0.1188\tStatic Loss:0.2323\t\n",
      "Val Loss:0.2779\tRecon Loss:1.9170\tTriplet Loss:0.1375\tStatic Loss:0.2755\n",
      "\n",
      "\tTime:51.2930\n",
      "\n",
      "Test Loss:0.8834\tRecon Loss:5.9307\tTriplet Loss:0.4791\tStatic Loss:0.8734\n",
      "\n",
      "\tEpoch:25\tTrain Loss:0.2381\tRecon Loss:2.1434\tTriplet Loss:0.1186\tStatic Loss:0.2310\t\n",
      "Val Loss:0.2805\tRecon Loss:2.0636\tTriplet Loss:0.1324\tStatic Loss:0.2775\n",
      "\n",
      "\tTime:51.1866\n",
      "\n",
      "Test Loss:0.8555\tRecon Loss:6.2983\tTriplet Loss:0.4559\tStatic Loss:0.8410\n",
      "\n",
      "\tEpoch:26\tTrain Loss:0.2340\tRecon Loss:1.9872\tTriplet Loss:0.1153\tStatic Loss:0.2283\t\n",
      "Val Loss:0.2783\tRecon Loss:1.9434\tTriplet Loss:0.1426\tStatic Loss:0.2752\n",
      "\n",
      "\tTime:51.8410\n",
      "\n",
      "Test Loss:0.8586\tRecon Loss:6.0114\tTriplet Loss:0.4364\tStatic Loss:0.8493\n",
      "\n",
      "\tEpoch:27\tTrain Loss:0.2325\tRecon Loss:1.9696\tTriplet Loss:0.1139\tStatic Loss:0.2270\t\n",
      "Val Loss:0.2787\tRecon Loss:1.9952\tTriplet Loss:0.1337\tStatic Loss:0.2761\n",
      "\n",
      "\tTime:52.1685\n",
      "\n",
      "Test Loss:0.8466\tRecon Loss:6.1307\tTriplet Loss:0.4499\tStatic Loss:0.8334\n",
      "\n",
      "\tEpoch:28\tTrain Loss:0.2280\tRecon Loss:1.9623\tTriplet Loss:0.1099\tStatic Loss:0.2225\t\n",
      "Val Loss:0.2731\tRecon Loss:1.9280\tTriplet Loss:0.1381\tStatic Loss:0.2701\n",
      "\n",
      "\tTime:51.7059\n",
      "\n",
      "Test Loss:0.8310\tRecon Loss:5.9188\tTriplet Loss:0.4311\tStatic Loss:0.8202\n",
      "\n",
      "\tEpoch:29\tTrain Loss:0.2277\tRecon Loss:1.9791\tTriplet Loss:0.1099\tStatic Loss:0.2219\t\n",
      "Val Loss:0.2663\tRecon Loss:1.9147\tTriplet Loss:0.1344\tStatic Loss:0.2630\n",
      "\n",
      "\tTime:51.5546\n",
      "\n",
      "Test Loss:0.8301\tRecon Loss:5.8895\tTriplet Loss:0.4556\tStatic Loss:0.8170\n",
      "\n",
      "\tEpoch:30\tTrain Loss:0.2265\tRecon Loss:1.9587\tTriplet Loss:0.1084\tStatic Loss:0.2210\t\n",
      "Val Loss:0.2730\tRecon Loss:1.9174\tTriplet Loss:0.1381\tStatic Loss:0.2700\n",
      "\n",
      "\tTime:52.7354\n",
      "\n",
      "Test Loss:0.8276\tRecon Loss:5.8805\tTriplet Loss:0.4319\tStatic Loss:0.8166\n",
      "\n",
      "\tEpoch:31\tTrain Loss:0.2265\tRecon Loss:1.9745\tTriplet Loss:0.1130\tStatic Loss:0.2204\t\n",
      "Val Loss:0.2762\tRecon Loss:1.9213\tTriplet Loss:0.1417\tStatic Loss:0.2732\n",
      "\n",
      "\tTime:54.4331\n",
      "\n",
      "Test Loss:0.8403\tRecon Loss:5.8959\tTriplet Loss:0.4473\tStatic Loss:0.8290\n",
      "\n",
      "\tEpoch:32\tTrain Loss:0.2255\tRecon Loss:1.9520\tTriplet Loss:0.1061\tStatic Loss:0.2202\t\n",
      "Val Loss:0.2703\tRecon Loss:1.9226\tTriplet Loss:0.1372\tStatic Loss:0.2671\n",
      "\n",
      "\tTime:54.0047\n",
      "\n",
      "Test Loss:0.8169\tRecon Loss:5.9082\tTriplet Loss:0.4505\tStatic Loss:0.8027\n",
      "\n",
      "\tEpoch:33\tTrain Loss:0.2218\tRecon Loss:1.9891\tTriplet Loss:0.1074\tStatic Loss:0.2156\t\n",
      "Val Loss:0.2662\tRecon Loss:1.9648\tTriplet Loss:0.1371\tStatic Loss:0.2621\n",
      "\n",
      "\tTime:52.6805\n",
      "\n",
      "Test Loss:0.8152\tRecon Loss:6.0485\tTriplet Loss:0.4101\tStatic Loss:0.8034\n",
      "\n",
      "\tEpoch:34\tTrain Loss:0.2220\tRecon Loss:1.9898\tTriplet Loss:0.1051\tStatic Loss:0.2160\t\n",
      "Val Loss:0.2766\tRecon Loss:1.9144\tTriplet Loss:0.1423\tStatic Loss:0.2736\n",
      "\n",
      "\tTime:52.4868\n",
      "\n",
      "Test Loss:0.8128\tRecon Loss:5.9356\tTriplet Loss:0.4210\tStatic Loss:0.8008\n",
      "\n",
      "\tEpoch:35\tTrain Loss:0.2220\tRecon Loss:1.9621\tTriplet Loss:0.1108\tStatic Loss:0.2158\t\n",
      "Val Loss:0.2670\tRecon Loss:1.9128\tTriplet Loss:0.1229\tStatic Loss:0.2650\n",
      "\n",
      "\tTime:51.3445\n",
      "\n",
      "Test Loss:0.8242\tRecon Loss:5.9242\tTriplet Loss:0.4635\tStatic Loss:0.8093\n",
      "\n",
      "\tEpoch:36\tTrain Loss:0.2176\tRecon Loss:1.9423\tTriplet Loss:0.1044\tStatic Loss:0.2116\t\n",
      "Val Loss:0.2682\tRecon Loss:1.9137\tTriplet Loss:0.1287\tStatic Loss:0.2657\n",
      "\n",
      "\tTime:50.4500\n",
      "\n",
      "Test Loss:0.8106\tRecon Loss:5.8653\tTriplet Loss:0.4504\tStatic Loss:0.7960\n",
      "\n",
      "\tEpoch:37\tTrain Loss:0.2192\tRecon Loss:1.9455\tTriplet Loss:0.1000\tStatic Loss:0.2139\t\n",
      "Val Loss:0.2684\tRecon Loss:1.9251\tTriplet Loss:0.1250\tStatic Loss:0.2661\n",
      "\n",
      "\tTime:49.2227\n",
      "\n",
      "Test Loss:0.8145\tRecon Loss:5.9247\tTriplet Loss:0.4359\tStatic Loss:0.8012\n",
      "\n",
      "\tEpoch:38\tTrain Loss:0.2136\tRecon Loss:1.9438\tTriplet Loss:0.0983\tStatic Loss:0.2079\t\n",
      "Val Loss:0.2699\tRecon Loss:1.9027\tTriplet Loss:0.1368\tStatic Loss:0.2668\n",
      "\n",
      "\tTime:49.3706\n",
      "\n",
      "Test Loss:0.8118\tRecon Loss:5.8725\tTriplet Loss:0.4410\tStatic Loss:0.7983\n",
      "\n",
      "\tEpoch:39\tTrain Loss:0.2151\tRecon Loss:1.9499\tTriplet Loss:0.1025\tStatic Loss:0.2090\t\n",
      "Val Loss:0.2652\tRecon Loss:1.9092\tTriplet Loss:0.1338\tStatic Loss:0.2619\n",
      "\n",
      "\tTime:49.4864\n",
      "\n",
      "Test Loss:0.8247\tRecon Loss:5.9303\tTriplet Loss:0.4393\tStatic Loss:0.8122\n",
      "\n",
      "\tEpoch:40\tTrain Loss:0.2124\tRecon Loss:1.9423\tTriplet Loss:0.1009\tStatic Loss:0.2063\t\n",
      "Val Loss:0.2677\tRecon Loss:1.9183\tTriplet Loss:0.1306\tStatic Loss:0.2649\n",
      "\n",
      "\tTime:49.3711\n",
      "\n",
      "Test Loss:0.8232\tRecon Loss:5.9297\tTriplet Loss:0.4121\tStatic Loss:0.8132\n",
      "\n",
      "\tEpoch:41\tTrain Loss:0.2128\tRecon Loss:1.9982\tTriplet Loss:0.1012\tStatic Loss:0.2061\t\n",
      "Val Loss:0.2865\tRecon Loss:3.6709\tTriplet Loss:0.1323\tStatic Loss:0.2681\n",
      "\n",
      "\tTime:49.4979\n",
      "\n",
      "Test Loss:0.8778\tRecon Loss:11.0495\tTriplet Loss:0.4146\tStatic Loss:0.8224\n",
      "\n",
      "\tEpoch:42\tTrain Loss:0.2272\tRecon Loss:2.6556\tTriplet Loss:0.1083\tStatic Loss:0.2148\t\n",
      "Val Loss:0.2659\tRecon Loss:2.1515\tTriplet Loss:0.1433\tStatic Loss:0.2593\n",
      "\n",
      "\tTime:49.7076\n",
      "\n",
      "Test Loss:0.8162\tRecon Loss:6.5702\tTriplet Loss:0.4126\tStatic Loss:0.7990\n",
      "\n",
      "\tEpoch:43\tTrain Loss:0.2180\tRecon Loss:2.2927\tTriplet Loss:0.1016\tStatic Loss:0.2089\t\n",
      "Val Loss:0.2640\tRecon Loss:2.3201\tTriplet Loss:0.1205\tStatic Loss:0.2578\n",
      "\n",
      "\tTime:51.1202\n",
      "\n",
      "Test Loss:0.8227\tRecon Loss:7.2680\tTriplet Loss:0.4279\tStatic Loss:0.7978\n",
      "\n",
      "\tEpoch:44\tTrain Loss:0.2191\tRecon Loss:2.5252\tTriplet Loss:0.1056\tStatic Loss:0.2074\t\n",
      "Val Loss:0.2674\tRecon Loss:2.5616\tTriplet Loss:0.1234\tStatic Loss:0.2589\n",
      "\n",
      "\tTime:49.9480\n",
      "\n",
      "Test Loss:0.8052\tRecon Loss:7.6638\tTriplet Loss:0.4133\tStatic Loss:0.7758\n",
      "\n",
      "\tEpoch:45\tTrain Loss:0.2120\tRecon Loss:2.2000\tTriplet Loss:0.1030\tStatic Loss:0.2030\t\n",
      "Val Loss:0.2659\tRecon Loss:2.1067\tTriplet Loss:0.1316\tStatic Loss:0.2609\n",
      "\n",
      "\tTime:49.2084\n",
      "\n",
      "Test Loss:0.8243\tRecon Loss:6.3718\tTriplet Loss:0.4121\tStatic Loss:0.8100\n",
      "\n",
      "\tEpoch:46\tTrain Loss:0.2086\tRecon Loss:2.0545\tTriplet Loss:0.1027\tStatic Loss:0.2008\t\n",
      "Val Loss:0.2668\tRecon Loss:1.9617\tTriplet Loss:0.1304\tStatic Loss:0.2635\n",
      "\n",
      "\tTime:49.3621\n",
      "\n",
      "Test Loss:0.8301\tRecon Loss:6.0057\tTriplet Loss:0.4231\tStatic Loss:0.8190\n",
      "\n",
      "\tEpoch:47\tTrain Loss:0.2088\tRecon Loss:1.9832\tTriplet Loss:0.1030\tStatic Loss:0.2017\t\n",
      "Val Loss:0.2642\tRecon Loss:1.9403\tTriplet Loss:0.1384\tStatic Loss:0.2600\n",
      "\n",
      "\tTime:49.3831\n",
      "\n",
      "Test Loss:0.8129\tRecon Loss:5.9974\tTriplet Loss:0.4350\tStatic Loss:0.7988\n",
      "\n",
      "\tEpoch:48\tTrain Loss:0.2068\tRecon Loss:1.9846\tTriplet Loss:0.1010\tStatic Loss:0.1996\t\n",
      "Val Loss:0.2607\tRecon Loss:2.2059\tTriplet Loss:0.1218\tStatic Loss:0.2551\n",
      "\n",
      "\tTime:49.1687\n",
      "\n",
      "Test Loss:0.8080\tRecon Loss:6.6731\tTriplet Loss:0.4151\tStatic Loss:0.7886\n",
      "\n",
      "\tEpoch:49\tTrain Loss:0.2111\tRecon Loss:2.0515\tTriplet Loss:0.1039\tStatic Loss:0.2034\t\n",
      "Val Loss:0.2662\tRecon Loss:1.9267\tTriplet Loss:0.1321\tStatic Loss:0.2630\n",
      "\n",
      "\tTime:50.3838\n",
      "\n",
      "Test Loss:0.8028\tRecon Loss:5.9294\tTriplet Loss:0.3967\tStatic Loss:0.7922\n",
      "\n",
      "\t\n",
      "Unc Est in Static characteristics:0.0000\tUnc Est in Streamflow, dynamic:0.0000\t\n",
      "\n",
      "\trecon weight:0.1\tstatic weight:10\ttriplet weight:1\tcorr_per:1\tcorr_std:10\tmodel:ATT_NL_3\n",
      "Epoch:0\tTrain Loss:0.6010\tRecon Loss:4.1686\tTriplet Loss:0.4140\tStatic Loss:0.5840\t\n",
      "Val Loss:0.4481\tRecon Loss:3.9927\tTriplet Loss:0.2581\tStatic Loss:0.4317\n",
      "\n",
      "\tTime:49.8950\n",
      "\n",
      "Test Loss:1.3179\tRecon Loss:11.9487\tTriplet Loss:0.8076\tStatic Loss:1.2626\n",
      "\n",
      "\tEpoch:1\tTrain Loss:0.4091\tRecon Loss:3.9877\tTriplet Loss:0.2357\tStatic Loss:0.3906\t\n",
      "Val Loss:0.3894\tRecon Loss:3.9698\tTriplet Loss:0.2107\tStatic Loss:0.3715\n",
      "\n",
      "\tTime:50.4350\n",
      "\n",
      "Test Loss:1.1735\tRecon Loss:11.8713\tTriplet Loss:0.6801\tStatic Loss:1.1159\n",
      "\n",
      "\tEpoch:2\tTrain Loss:0.3741\tRecon Loss:3.9726\tTriplet Loss:0.2083\tStatic Loss:0.3547\t\n",
      "Val Loss:0.3656\tRecon Loss:3.9655\tTriplet Loss:0.1836\tStatic Loss:0.3478\n",
      "\n",
      "\tTime:51.6519\n",
      "\n",
      "Test Loss:1.1130\tRecon Loss:11.8729\tTriplet Loss:0.6234\tStatic Loss:1.0543\n",
      "\n",
      "\tEpoch:3\tTrain Loss:0.3573\tRecon Loss:3.9662\tTriplet Loss:0.1918\tStatic Loss:0.3378\t\n",
      "Val Loss:0.3529\tRecon Loss:3.9256\tTriplet Loss:0.1691\tStatic Loss:0.3355\n",
      "\n",
      "\tTime:50.7756\n",
      "\n",
      "Test Loss:1.0707\tRecon Loss:11.7685\tTriplet Loss:0.5925\tStatic Loss:1.0115\n",
      "\n",
      "\tEpoch:4\tTrain Loss:0.3440\tRecon Loss:3.9402\tTriplet Loss:0.1744\tStatic Loss:0.3250\t\n",
      "Val Loss:0.3388\tRecon Loss:3.9169\tTriplet Loss:0.1638\tStatic Loss:0.3206\n",
      "\n",
      "\tTime:49.6444\n",
      "\n",
      "Test Loss:1.0280\tRecon Loss:11.7440\tTriplet Loss:0.5401\tStatic Loss:0.9696\n",
      "\n",
      "\tEpoch:5\tTrain Loss:0.3313\tRecon Loss:3.8376\tTriplet Loss:0.1620\tStatic Loss:0.3132\t\n",
      "Val Loss:0.3289\tRecon Loss:3.6578\tTriplet Loss:0.1510\tStatic Loss:0.3135\n",
      "\n",
      "\tTime:48.7554\n",
      "\n",
      "Test Loss:1.0076\tRecon Loss:10.8697\tTriplet Loss:0.5279\tStatic Loss:0.9570\n",
      "\n",
      "\tEpoch:6\tTrain Loss:0.3178\tRecon Loss:3.4021\tTriplet Loss:0.1570\tStatic Loss:0.3031\t\n",
      "Val Loss:0.3241\tRecon Loss:2.8789\tTriplet Loss:0.1591\tStatic Loss:0.3150\n",
      "\n",
      "\tTime:49.7234\n",
      "\n",
      "Test Loss:0.9598\tRecon Loss:8.7719\tTriplet Loss:0.4968\tStatic Loss:0.9280\n",
      "\n",
      "\tEpoch:7\tTrain Loss:0.3049\tRecon Loss:2.6531\tTriplet Loss:0.1521\tStatic Loss:0.2966\t\n",
      "Val Loss:0.3145\tRecon Loss:2.3827\tTriplet Loss:0.1554\tStatic Loss:0.3097\n",
      "\n",
      "\tTime:49.5003\n",
      "\n",
      "Test Loss:0.9523\tRecon Loss:7.2043\tTriplet Loss:0.5118\tStatic Loss:0.9338\n",
      "\n",
      "\tEpoch:8\tTrain Loss:0.2922\tRecon Loss:2.2792\tTriplet Loss:0.1504\tStatic Loss:0.2865\t\n",
      "Val Loss:0.3062\tRecon Loss:2.1633\tTriplet Loss:0.1590\tStatic Loss:0.3023\n",
      "\n",
      "\tTime:49.8385\n",
      "\n",
      "Test Loss:0.9669\tRecon Loss:6.4419\tTriplet Loss:0.4765\tStatic Loss:0.9612\n",
      "\n",
      "\tEpoch:9\tTrain Loss:0.2833\tRecon Loss:2.0975\tTriplet Loss:0.1379\tStatic Loss:0.2797\t\n",
      "Val Loss:0.2990\tRecon Loss:2.0426\tTriplet Loss:0.1470\tStatic Loss:0.2968\n",
      "\n",
      "\tTime:50.0594\n",
      "\n",
      "Test Loss:0.9420\tRecon Loss:6.1904\tTriplet Loss:0.4719\tStatic Loss:0.9366\n",
      "\n",
      "\tEpoch:10\tTrain Loss:0.2826\tRecon Loss:2.0656\tTriplet Loss:0.1407\tStatic Loss:0.2789\t\n",
      "Val Loss:0.2965\tRecon Loss:2.0428\tTriplet Loss:0.1537\tStatic Loss:0.2934\n",
      "\n",
      "\tTime:50.1663\n",
      "\n",
      "Test Loss:0.9044\tRecon Loss:6.1426\tTriplet Loss:0.4611\tStatic Loss:0.8964\n",
      "\n",
      "\tEpoch:11\tTrain Loss:0.2727\tRecon Loss:2.0203\tTriplet Loss:0.1298\tStatic Loss:0.2695\t\n",
      "Val Loss:0.2955\tRecon Loss:2.0579\tTriplet Loss:0.1400\tStatic Loss:0.2934\n",
      "\n",
      "\tTime:51.0551\n",
      "\n",
      "Test Loss:0.9015\tRecon Loss:6.4063\tTriplet Loss:0.4346\tStatic Loss:0.8931\n",
      "\n",
      "\tEpoch:12\tTrain Loss:0.2702\tRecon Loss:2.1280\tTriplet Loss:0.1342\tStatic Loss:0.2652\t\n",
      "Val Loss:0.3020\tRecon Loss:2.6831\tTriplet Loss:0.1435\tStatic Loss:0.2941\n",
      "\n",
      "\tTime:50.8422\n",
      "\n",
      "Test Loss:0.9161\tRecon Loss:8.2973\tTriplet Loss:0.4362\tStatic Loss:0.8903\n",
      "\n",
      "\tEpoch:13\tTrain Loss:0.2670\tRecon Loss:2.1926\tTriplet Loss:0.1299\tStatic Loss:0.2614\t\n",
      "Val Loss:0.2875\tRecon Loss:1.9722\tTriplet Loss:0.1362\tStatic Loss:0.2857\n",
      "\n",
      "\tTime:50.9239\n",
      "\n",
      "Test Loss:0.8552\tRecon Loss:6.1096\tTriplet Loss:0.4317\tStatic Loss:0.8450\n",
      "\n",
      "\tEpoch:14\tTrain Loss:0.2599\tRecon Loss:2.0021\tTriplet Loss:0.1231\tStatic Loss:0.2562\t\n",
      "Val Loss:0.2842\tRecon Loss:1.9859\tTriplet Loss:0.1483\tStatic Loss:0.2807\n",
      "\n",
      "\tTime:51.2052\n",
      "\n",
      "Test Loss:0.8615\tRecon Loss:6.0917\tTriplet Loss:0.4260\tStatic Loss:0.8527\n",
      "\n",
      "\tEpoch:15\tTrain Loss:0.2575\tRecon Loss:1.9670\tTriplet Loss:0.1277\tStatic Loss:0.2534\t\n",
      "Val Loss:0.2840\tRecon Loss:1.9299\tTriplet Loss:0.1375\tStatic Loss:0.2822\n",
      "\n",
      "\tTime:50.2114\n",
      "\n",
      "Test Loss:0.8708\tRecon Loss:5.9503\tTriplet Loss:0.4416\tStatic Loss:0.8629\n",
      "\n",
      "\tEpoch:16\tTrain Loss:0.2531\tRecon Loss:1.9622\tTriplet Loss:0.1242\tStatic Loss:0.2489\t\n",
      "Val Loss:0.2886\tRecon Loss:1.9225\tTriplet Loss:0.1459\tStatic Loss:0.2866\n",
      "\n",
      "\tTime:50.5921\n",
      "\n",
      "Test Loss:0.8716\tRecon Loss:5.9192\tTriplet Loss:0.4344\tStatic Loss:0.8649\n",
      "\n",
      "\tEpoch:17\tTrain Loss:0.2508\tRecon Loss:1.9895\tTriplet Loss:0.1136\tStatic Loss:0.2471\t\n",
      "Val Loss:0.2853\tRecon Loss:1.9927\tTriplet Loss:0.1356\tStatic Loss:0.2832\n",
      "\n",
      "\tTime:51.1446\n",
      "\n",
      "Test Loss:0.8669\tRecon Loss:6.0481\tTriplet Loss:0.4144\tStatic Loss:0.8603\n",
      "\n",
      "\tEpoch:18\tTrain Loss:0.2484\tRecon Loss:1.9582\tTriplet Loss:0.1179\tStatic Loss:0.2444\t\n",
      "Val Loss:0.2773\tRecon Loss:1.9414\tTriplet Loss:0.1307\tStatic Loss:0.2753\n",
      "\n",
      "\tTime:51.2821\n",
      "\n",
      "Test Loss:0.8716\tRecon Loss:5.9751\tTriplet Loss:0.4272\tStatic Loss:0.8650\n",
      "\n",
      "\tEpoch:19\tTrain Loss:0.2447\tRecon Loss:1.9648\tTriplet Loss:0.1165\tStatic Loss:0.2404\t\n",
      "Val Loss:0.2767\tRecon Loss:1.9495\tTriplet Loss:0.1277\tStatic Loss:0.2748\n",
      "\n",
      "\tTime:53.0559\n",
      "\n",
      "Test Loss:0.8682\tRecon Loss:6.1139\tTriplet Loss:0.3927\tStatic Loss:0.8633\n",
      "\n",
      "\tEpoch:20\tTrain Loss:0.2424\tRecon Loss:1.9514\tTriplet Loss:0.1182\tStatic Loss:0.2377\t\n",
      "Val Loss:0.2769\tRecon Loss:1.8986\tTriplet Loss:0.1307\tStatic Loss:0.2753\n",
      "\n",
      "\tTime:53.2130\n",
      "\n",
      "Test Loss:0.8727\tRecon Loss:5.8962\tTriplet Loss:0.4157\tStatic Loss:0.8682\n",
      "\n",
      "\tEpoch:21\tTrain Loss:0.2393\tRecon Loss:1.9617\tTriplet Loss:0.1165\tStatic Loss:0.2343\t\n",
      "Val Loss:0.2731\tRecon Loss:1.9427\tTriplet Loss:0.1403\tStatic Loss:0.2697\n",
      "\n",
      "\tTime:52.5502\n",
      "\n",
      "Test Loss:0.8689\tRecon Loss:6.0175\tTriplet Loss:0.4383\tStatic Loss:0.8605\n",
      "\n",
      "\tEpoch:22\tTrain Loss:0.2383\tRecon Loss:1.9573\tTriplet Loss:0.1108\tStatic Loss:0.2338\t\n",
      "Val Loss:0.2823\tRecon Loss:1.9190\tTriplet Loss:0.1270\tStatic Loss:0.2815\n",
      "\n",
      "\tTime:52.0705\n",
      "\n",
      "Test Loss:0.8906\tRecon Loss:5.9217\tTriplet Loss:0.4300\tStatic Loss:0.8864\n",
      "\n",
      "\tEpoch:23\tTrain Loss:0.2356\tRecon Loss:1.9397\tTriplet Loss:0.1081\tStatic Loss:0.2313\t\n",
      "Val Loss:0.2666\tRecon Loss:1.8874\tTriplet Loss:0.1342\tStatic Loss:0.2637\n",
      "\n",
      "\tTime:50.9119\n",
      "\n",
      "Test Loss:0.8407\tRecon Loss:5.8518\tTriplet Loss:0.3937\tStatic Loss:0.8353\n",
      "\n",
      "\tEpoch:24\tTrain Loss:0.2327\tRecon Loss:1.9602\tTriplet Loss:0.1084\tStatic Loss:0.2279\t\n",
      "Val Loss:0.2747\tRecon Loss:1.9020\tTriplet Loss:0.1235\tStatic Loss:0.2735\n",
      "\n",
      "\tTime:50.4433\n",
      "\n",
      "Test Loss:0.8608\tRecon Loss:5.9294\tTriplet Loss:0.4050\tStatic Loss:0.8557\n",
      "\n",
      "\tEpoch:25\tTrain Loss:0.2344\tRecon Loss:2.0056\tTriplet Loss:0.1112\tStatic Loss:0.2290\t\n",
      "Val Loss:0.2677\tRecon Loss:1.9134\tTriplet Loss:0.1229\tStatic Loss:0.2658\n",
      "\n",
      "\tTime:50.1195\n",
      "\n",
      "Test Loss:0.8635\tRecon Loss:5.9220\tTriplet Loss:0.4010\tStatic Loss:0.8592\n",
      "\n",
      "\tEpoch:26\tTrain Loss:0.2304\tRecon Loss:1.9374\tTriplet Loss:0.1056\tStatic Loss:0.2259\t\n",
      "Val Loss:0.2744\tRecon Loss:1.8989\tTriplet Loss:0.1265\tStatic Loss:0.2729\n",
      "\n",
      "\tTime:51.3159\n",
      "\n",
      "Test Loss:0.8451\tRecon Loss:5.8991\tTriplet Loss:0.3858\tStatic Loss:0.8405\n",
      "\n",
      "\tEpoch:27\tTrain Loss:0.2306\tRecon Loss:1.9581\tTriplet Loss:0.1056\tStatic Loss:0.2258\t\n",
      "Val Loss:0.2615\tRecon Loss:1.9646\tTriplet Loss:0.1155\tStatic Loss:0.2591\n",
      "\n",
      "\tTime:50.7607\n",
      "\n",
      "Test Loss:0.7973\tRecon Loss:6.0501\tTriplet Loss:0.4065\tStatic Loss:0.7839\n",
      "\n",
      "\tEpoch:28\tTrain Loss:0.2278\tRecon Loss:1.9455\tTriplet Loss:0.1060\tStatic Loss:0.2228\t\n",
      "Val Loss:0.2727\tRecon Loss:1.9098\tTriplet Loss:0.1329\tStatic Loss:0.2703\n",
      "\n",
      "\tTime:50.5994\n",
      "\n",
      "Test Loss:0.8172\tRecon Loss:5.9160\tTriplet Loss:0.4069\tStatic Loss:0.8072\n",
      "\n",
      "\tEpoch:29\tTrain Loss:0.2255\tRecon Loss:1.9471\tTriplet Loss:0.1017\tStatic Loss:0.2207\t\n",
      "Val Loss:0.2686\tRecon Loss:1.9239\tTriplet Loss:0.1253\tStatic Loss:0.2663\n",
      "\n",
      "\tTime:51.1798\n",
      "\n",
      "Test Loss:0.8261\tRecon Loss:5.9113\tTriplet Loss:0.3872\tStatic Loss:0.8192\n",
      "\n",
      "\tEpoch:30\tTrain Loss:0.2223\tRecon Loss:1.9365\tTriplet Loss:0.0945\tStatic Loss:0.2180\t\n",
      "Val Loss:0.2707\tRecon Loss:1.9365\tTriplet Loss:0.1324\tStatic Loss:0.2679\n",
      "\n",
      "\tTime:50.5068\n",
      "\n",
      "Test Loss:0.8206\tRecon Loss:5.9310\tTriplet Loss:0.3910\tStatic Loss:0.8124\n",
      "\n",
      "\tEpoch:31\tTrain Loss:0.2220\tRecon Loss:1.9464\tTriplet Loss:0.1027\tStatic Loss:0.2167\t\n",
      "Val Loss:0.2714\tRecon Loss:1.9095\tTriplet Loss:0.1252\tStatic Loss:0.2696\n",
      "\n",
      "\tTime:51.0118\n",
      "\n",
      "Test Loss:0.8676\tRecon Loss:5.9264\tTriplet Loss:0.3870\tStatic Loss:0.8651\n",
      "\n",
      "\tEpoch:32\tTrain Loss:0.2208\tRecon Loss:1.9422\tTriplet Loss:0.1058\tStatic Loss:0.2150\t\n",
      "Val Loss:0.2660\tRecon Loss:1.9010\tTriplet Loss:0.1164\tStatic Loss:0.2646\n",
      "\n",
      "\tTime:51.3664\n",
      "\n",
      "Test Loss:0.8170\tRecon Loss:5.8901\tTriplet Loss:0.3891\tStatic Loss:0.8090\n",
      "\n",
      "\tEpoch:33\tTrain Loss:0.2195\tRecon Loss:1.9619\tTriplet Loss:0.1001\tStatic Loss:0.2140\t\n",
      "Val Loss:0.2685\tRecon Loss:1.9092\tTriplet Loss:0.1194\tStatic Loss:0.2670\n",
      "\n",
      "\tTime:51.3015\n",
      "\n",
      "Test Loss:0.8105\tRecon Loss:5.9103\tTriplet Loss:0.3808\tStatic Loss:0.8025\n",
      "\n",
      "\tEpoch:34\tTrain Loss:0.2196\tRecon Loss:1.9333\tTriplet Loss:0.0994\tStatic Loss:0.2145\t\n",
      "Val Loss:0.2691\tRecon Loss:1.9046\tTriplet Loss:0.1169\tStatic Loss:0.2680\n",
      "\n",
      "\tTime:50.4772\n",
      "\n",
      "Test Loss:0.8143\tRecon Loss:5.9667\tTriplet Loss:0.3705\tStatic Loss:0.8072\n",
      "\n",
      "\tEpoch:35\tTrain Loss:0.2176\tRecon Loss:1.9460\tTriplet Loss:0.0997\tStatic Loss:0.2121\t\n",
      "Val Loss:0.2612\tRecon Loss:1.8945\tTriplet Loss:0.1176\tStatic Loss:0.2593\n",
      "\n",
      "\tTime:49.7088\n",
      "\n",
      "Test Loss:0.8148\tRecon Loss:5.8703\tTriplet Loss:0.3965\tStatic Loss:0.8061\n",
      "\n",
      "\tEpoch:36\tTrain Loss:0.2155\tRecon Loss:1.9462\tTriplet Loss:0.0982\tStatic Loss:0.2099\t\n",
      "Val Loss:0.2780\tRecon Loss:1.9329\tTriplet Loss:0.1335\tStatic Loss:0.2760\n",
      "\n",
      "\tTime:49.9898\n",
      "\n",
      "Test Loss:0.8564\tRecon Loss:5.9541\tTriplet Loss:0.3836\tStatic Loss:0.8528\n",
      "\n",
      "\tEpoch:37\tTrain Loss:0.2152\tRecon Loss:1.9413\tTriplet Loss:0.0942\tStatic Loss:0.2100\t\n",
      "Val Loss:0.2688\tRecon Loss:1.9205\tTriplet Loss:0.1265\tStatic Loss:0.2666\n",
      "\n",
      "\tTime:49.1054\n",
      "\n",
      "Test Loss:0.8161\tRecon Loss:5.9961\tTriplet Loss:0.3830\tStatic Loss:0.8076\n",
      "\n",
      "\tEpoch:38\tTrain Loss:0.2124\tRecon Loss:1.9386\tTriplet Loss:0.0954\tStatic Loss:0.2069\t\n",
      "Val Loss:0.2700\tRecon Loss:1.9140\tTriplet Loss:0.1250\tStatic Loss:0.2680\n",
      "\n",
      "\tTime:50.1737\n",
      "\n",
      "Test Loss:0.8251\tRecon Loss:5.8940\tTriplet Loss:0.3865\tStatic Loss:0.8182\n",
      "\n",
      "\tEpoch:39\tTrain Loss:0.2156\tRecon Loss:1.9430\tTriplet Loss:0.1011\tStatic Loss:0.2098\t\n",
      "Val Loss:0.2603\tRecon Loss:1.9395\tTriplet Loss:0.1176\tStatic Loss:0.2577\n",
      "\n",
      "\tTime:50.1454\n",
      "\n",
      "Test Loss:0.8058\tRecon Loss:5.9098\tTriplet Loss:0.3545\tStatic Loss:0.7999\n",
      "\n",
      "\tEpoch:40\tTrain Loss:0.2105\tRecon Loss:1.9324\tTriplet Loss:0.0956\tStatic Loss:0.2047\t\n",
      "Val Loss:0.2643\tRecon Loss:1.8960\tTriplet Loss:0.1215\tStatic Loss:0.2623\n",
      "\n",
      "\tTime:51.0025\n",
      "\n",
      "Test Loss:0.8050\tRecon Loss:5.9583\tTriplet Loss:0.3680\tStatic Loss:0.7972\n",
      "\n",
      "\tEpoch:41\tTrain Loss:0.2140\tRecon Loss:1.9454\tTriplet Loss:0.0976\tStatic Loss:0.2083\t\n",
      "Val Loss:0.2618\tRecon Loss:1.9399\tTriplet Loss:0.1153\tStatic Loss:0.2596\n",
      "\n",
      "\tTime:49.7783\n",
      "\n",
      "Test Loss:0.7712\tRecon Loss:6.0568\tTriplet Loss:0.3850\tStatic Loss:0.7570\n",
      "\n",
      "\tEpoch:42\tTrain Loss:0.2104\tRecon Loss:1.9487\tTriplet Loss:0.1007\tStatic Loss:0.2040\t\n",
      "Val Loss:0.2554\tRecon Loss:1.8922\tTriplet Loss:0.1257\tStatic Loss:0.2520\n",
      "\n",
      "\tTime:48.2839\n",
      "\n",
      "Test Loss:0.8034\tRecon Loss:5.9215\tTriplet Loss:0.3638\tStatic Loss:0.7962\n",
      "\n",
      "\tEpoch:43\tTrain Loss:0.2083\tRecon Loss:1.9238\tTriplet Loss:0.0966\tStatic Loss:0.2023\t\n",
      "Val Loss:0.2554\tRecon Loss:1.8897\tTriplet Loss:0.1122\tStatic Loss:0.2534\n",
      "\n",
      "\tTime:48.9210\n",
      "\n",
      "Test Loss:0.7990\tRecon Loss:5.9000\tTriplet Loss:0.3883\tStatic Loss:0.7891\n",
      "\n",
      "\tEpoch:44\tTrain Loss:0.2076\tRecon Loss:1.9486\tTriplet Loss:0.0975\tStatic Loss:0.2012\t\n",
      "Val Loss:0.2621\tRecon Loss:1.8926\tTriplet Loss:0.1263\tStatic Loss:0.2594\n",
      "\n",
      "\tTime:49.3108\n",
      "\n",
      "Test Loss:0.7952\tRecon Loss:5.8542\tTriplet Loss:0.3788\tStatic Loss:0.7862\n",
      "\n",
      "\tEpoch:45\tTrain Loss:0.2087\tRecon Loss:1.9281\tTriplet Loss:0.1000\tStatic Loss:0.2024\t\n",
      "Val Loss:0.2603\tRecon Loss:1.8916\tTriplet Loss:0.1188\tStatic Loss:0.2581\n",
      "\n",
      "\tTime:50.1395\n",
      "\n",
      "Test Loss:0.8022\tRecon Loss:5.8367\tTriplet Loss:0.3784\tStatic Loss:0.7943\n",
      "\n",
      "\tEpoch:46\tTrain Loss:0.2052\tRecon Loss:1.9365\tTriplet Loss:0.0931\tStatic Loss:0.1991\t\n",
      "Val Loss:0.2656\tRecon Loss:1.9165\tTriplet Loss:0.1196\tStatic Loss:0.2637\n",
      "\n",
      "\tTime:49.2741\n",
      "\n",
      "Test Loss:0.8203\tRecon Loss:5.8929\tTriplet Loss:0.3868\tStatic Loss:0.8129\n",
      "\n",
      "\tEpoch:47\tTrain Loss:0.2084\tRecon Loss:1.9440\tTriplet Loss:0.0975\tStatic Loss:0.2021\t\n",
      "Val Loss:0.2641\tRecon Loss:1.9093\tTriplet Loss:0.1219\tStatic Loss:0.2619\n",
      "\n",
      "\tTime:49.1420\n",
      "\n",
      "Test Loss:0.8200\tRecon Loss:5.9083\tTriplet Loss:0.3819\tStatic Loss:0.8130\n",
      "\n",
      "\tEpoch:48\tTrain Loss:0.2050\tRecon Loss:1.9429\tTriplet Loss:0.0926\tStatic Loss:0.1989\t\n",
      "Val Loss:0.2626\tRecon Loss:2.0500\tTriplet Loss:0.1266\tStatic Loss:0.2583\n",
      "\n",
      "\tTime:48.5013\n",
      "\n",
      "Test Loss:0.7826\tRecon Loss:6.0829\tTriplet Loss:0.3856\tStatic Loss:0.7693\n",
      "\n",
      "\tEpoch:49\tTrain Loss:0.2055\tRecon Loss:1.9797\tTriplet Loss:0.0963\tStatic Loss:0.1987\t\n",
      "Val Loss:0.2721\tRecon Loss:1.9146\tTriplet Loss:0.1259\tStatic Loss:0.2703\n",
      "\n",
      "\tTime:49.2711\n",
      "\n",
      "Test Loss:0.8108\tRecon Loss:5.9312\tTriplet Loss:0.4019\tStatic Loss:0.8005\n",
      "\n",
      "\t\n",
      "Unc Est in Static characteristics:0.0017\tUnc Est in Streamflow, dynamic:0.0008\t\n",
      "\n",
      "\t[1, 10, 'ATT_NL_0', (0.26067644192112815, 5.929420276692039, 0.39674147066513177, 0.7921924300883946, 0.0, 0.0)]\n",
      "[1, 10, 'ATT_NL_3', (0.25540364174931135, 5.931188426519695, 0.40193709525230686, 0.8004641877977472, 0.0017002959502860904, 0.0008410392911173403)]\n"
     ]
    }
   ],
   "source": [
    "# different noise, missingness, loss weights\n",
    "models = [\"ATT_NL_0\", \"ATT_NL_3\"] #, \"ATT_NL_4\", \"ATT_NL_5\", \"ATT_NL_6\", \"ATT_NL\" # \"ATT_NL_1\",\n",
    "results = []\n",
    "# corruption_percentage = [ 1, 5, 10, 20, 50]\n",
    "# corruption_stderr = {1:[10],5:[10], 10:[0.1, 0.5, 1, 5], 20:[0.1, 0.5, 1, 5], 50:[0.1, 0.5, 1, 5]}\n",
    "# reconstruction_weight_list = [0, 0.1]\n",
    "# static_weight_list = [0, 10]\n",
    "# triplet_weight_list = [0, 1]\n",
    "\n",
    "corruption_percentage = [ 1 ]\n",
    "corruption_stderr = {1:[10],5:[10], 10:[0.1, 0.5, 1, 5], 20:[0.1, 0.5, 1, 5], 50:[1]}\n",
    "\n",
    "\n",
    "reconstruction_weight_list = [0.1]\n",
    "static_weight_list = [10]\n",
    "triplet_weight_list = [1]\n",
    "\n",
    "for recon_weight in reconstruction_weight_list:\n",
    "    for static_weight in static_weight_list:\n",
    "        for triplet_weight in triplet_weight_list:\n",
    "            sum_weight = recon_weight+static_weight+triplet_weight\n",
    "            if sum_weight>0:\n",
    "                for corr_per in corruption_percentage:\n",
    "                    for corr_std in corruption_stderr[corr_per]:\n",
    "                        train_data = np.load(os.path.join(DIR,'NUMPY', \"train_data_basin_corrupted_{}_{}.npy\").format(corr_per,corr_std))[:,:,:,:-1]\n",
    "                        validation_data = np.load(os.path.join(DIR,'NUMPY', \"validation_data_basin_corrupted_{}_{}.npy\").format(corr_per,corr_std))[:,:,:,:-1]\n",
    "                        test_data = np.load(os.path.join(DIR,'NUMPY', \"test_data_basin_clean_{}_{}.npy\").format(corr_per,corr_std))[:,:,:,:-1]\n",
    "                        # hidden_train_data = np.load(os.path.join(config.NUMPY_DIR, \"train_hidden_data_basin.npy\"))[:,:,:,:-1]\n",
    "                        print(\"Train Data:{}\\tValidation Data:{}\\tTest Data:{}\".format(train_data.shape, validation_data.shape, test_data.shape))            \n",
    "\n",
    "                        for a_model in models:\n",
    "\n",
    "                            print(\"recon weight:{}\\tstatic weight:{}\\ttriplet weight:{}\\tcorr_per:{}\\tcorr_std:{}\\tmodel:{}\".format(recon_weight, static_weight, triplet_weight, corr_per, corr_std, a_model)) \n",
    "                            model = globals()[a_model](in_channels=len(input_channels), stat_channels=len(static_channels), code_dim=code_dim, device=device)\n",
    "                            model = model.to(device)\n",
    "                            criterion = torch.nn.MSELoss(reduction=\"none\")\n",
    "                            triplet_criterion = torch.nn.TripletMarginLoss(margin=alpha, p=2.0, eps=1e-06, reduction=\"none\")\n",
    "                            # triplet_criterion = torch.nn.TripletMarginWithDistanceLoss(distance_function=torch.nn.PairwiseDistance(p=2.0, eps=1e-06), margin=alpha, reduction=\"none\")\n",
    "                            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "                            results.append([corr_per, corr_std, a_model, run_model(model,train_data, validation_data,test_data, os.path.join(RESULT_DIR, 'corrupt_50_1',a_model+'.pt' )) ])\n",
    "    \n",
    "\n",
    "for i in range(len(results)):\n",
    "    print(results[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FORWARD MODEL: STREAMFLOW PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This file is part of the accompanying code to our manuscript:\n",
    "Kratzert, F., Klotz, D., Shalev, G., Klambauer, G., Hochreiter, S., Nearing, G., \"Benchmarking\n",
    "a Catchment-Aware Long Short-Term Memory Network (LSTM) for Large-Scale Hydrological Modeling\".\n",
    "submitted to Hydrol. Earth Syst. Sci. Discussions (2019)\n",
    "You should have received a copy of the Apache-2.0 license along with the code. If not,\n",
    "see <https://opensource.org/licenses/Apache-2.0>\n",
    "\"\"\"\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class EALSTM(nn.Module):\n",
    "    \"\"\"Implementation of the Entity-Aware-LSTM (EA-LSTM)\n",
    "    TODO: Include paper ref and latex equations\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_size_dyn : int\n",
    "        Number of dynamic features, which are those, passed to the LSTM at each time step.\n",
    "    input_size_stat : int\n",
    "        Number of static features, which are those that are used to modulate the input gate.\n",
    "    hidden_size : int\n",
    "        Number of hidden/memory cells.\n",
    "    batch_first : bool, optional\n",
    "        If True, expects the batch inputs to be of shape [batch, seq, features] otherwise, the\n",
    "        shape has to be [seq, batch, features], by default True.\n",
    "    initial_forget_bias : int, optional\n",
    "        Value of the initial forget gate bias, by default 0\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_size_dyn: int,\n",
    "                 input_size_stat: int,\n",
    "                 hidden_size: int,\n",
    "                 batch_first: bool = True,\n",
    "                 initial_forget_bias: int = 0):\n",
    "        super(EALSTM, self).__init__()\n",
    "\n",
    "        self.input_size_dyn = input_size_dyn\n",
    "        self.input_size_stat = input_size_stat\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_first = batch_first\n",
    "        self.initial_forget_bias = initial_forget_bias\n",
    "\n",
    "        # create tensors of learnable parameters\n",
    "        self.weight_ih = nn.Parameter(torch.FloatTensor(input_size_dyn, 3 * hidden_size))\n",
    "        self.weight_hh = nn.Parameter(torch.FloatTensor(hidden_size, 3 * hidden_size))\n",
    "        self.weight_sh = nn.Parameter(torch.FloatTensor(input_size_stat, hidden_size))\n",
    "        self.bias = nn.Parameter(torch.FloatTensor(3 * hidden_size))\n",
    "        self.bias_s = nn.Parameter(torch.FloatTensor(hidden_size))\n",
    "\n",
    "        # initialize parameters\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Initialize all learnable parameters of the LSTM\"\"\"\n",
    "        nn.init.orthogonal_(self.weight_ih.data)\n",
    "        nn.init.orthogonal_(self.weight_sh)\n",
    "\n",
    "        weight_hh_data = torch.eye(self.hidden_size)\n",
    "        weight_hh_data = weight_hh_data.repeat(1, 3)\n",
    "        self.weight_hh.data = weight_hh_data\n",
    "\n",
    "        nn.init.constant_(self.bias.data, val=0)\n",
    "        nn.init.constant_(self.bias_s.data, val=0)\n",
    "\n",
    "        if self.initial_forget_bias != 0:\n",
    "            self.bias.data[:self.hidden_size] = self.initial_forget_bias\n",
    "\n",
    "    def forward(self, x_d: torch.Tensor, x_s: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"[summary]\n",
    "        Parameters\n",
    "        ----------\n",
    "        x_d : torch.Tensor\n",
    "            Tensor, containing a batch of sequences of the dynamic features. Shape has to match\n",
    "            the format specified with batch_first.\n",
    "        x_s : torch.Tensor\n",
    "            Tensor, containing a batch of static features.\n",
    "        Returns\n",
    "        -------\n",
    "        h_n : torch.Tensor\n",
    "            The hidden states of each time step of each sample in the batch.\n",
    "        c_n : torch.Tensor]\n",
    "            The cell states of each time step of each sample in the batch.\n",
    "        \"\"\"\n",
    "        if self.batch_first:\n",
    "            x_d = x_d.transpose(0, 1)\n",
    "\n",
    "        seq_len, batch_size, _ = x_d.size()\n",
    "\n",
    "        h_0 = x_d.data.new(batch_size, self.hidden_size).zero_()\n",
    "        c_0 = x_d.data.new(batch_size, self.hidden_size).zero_()\n",
    "        h_x = (h_0, c_0)\n",
    "\n",
    "        # empty lists to temporally store all intermediate hidden/cell states\n",
    "        h_n, c_n = [], []\n",
    "\n",
    "        # expand bias vectors to batch size\n",
    "        bias_batch = (self.bias.unsqueeze(0).expand(batch_size, *self.bias.size()))\n",
    "\n",
    "        # calculate input gate only once because inputs are static\n",
    "        bias_s_batch = (self.bias_s.unsqueeze(0).expand(batch_size, *self.bias_s.size()))\n",
    "        i = torch.sigmoid(torch.addmm(bias_s_batch, x_s, self.weight_sh))\n",
    "\n",
    "        # perform forward steps over input sequence\n",
    "        for t in range(seq_len):\n",
    "            h_0, c_0 = h_x\n",
    "\n",
    "            # calculate gates\n",
    "            gates = (torch.addmm(bias_batch, h_0, self.weight_hh) +\n",
    "                     torch.mm(x_d[t], self.weight_ih))\n",
    "            f, o, g = gates.chunk(3, 1)\n",
    "\n",
    "            c_1 = torch.sigmoid(f) * c_0 + i * torch.tanh(g)\n",
    "            h_1 = torch.sigmoid(o) * torch.tanh(c_1)\n",
    "\n",
    "            # store intermediate hidden/cell state in list\n",
    "            h_n.append(h_1)\n",
    "            c_n.append(c_1)\n",
    "\n",
    "            h_x = (h_1, c_1)\n",
    "\n",
    "        h_n = torch.stack(h_n, 0)\n",
    "        c_n = torch.stack(c_n, 0)\n",
    "\n",
    "        if self.batch_first:\n",
    "            h_n = h_n.transpose(0, 1)\n",
    "            c_n = c_n.transpose(0, 1)\n",
    "\n",
    "        return h_n, c_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters and data for EALSTM\n",
    "\n",
    "train_data = np.load(os.path.join(DIR, 'NUMPY', \"train_data_basin_ealstm.npy\"))[:,:,:,:-1]#[:-num_hidden,:,:,:-1]\n",
    "validation_data = np.load(os.path.join(DIR, 'NUMPY', \"validation_data_basin_ealstm.npy\"))[:,:,:,:-1]#[:-num_hidden,:,:,:-1]\n",
    "test_data = np.load(os.path.join(DIR, 'NUMPY', \"test_data_basin_ealstm.npy\"))[:,:,:,:-1]#[-num_hidden:,:,:,:-1]\n",
    "# hidden_train_data = np.load(os.path.join(config.NUMPY_DIR, \"train_hidden_data_basin_ealstm.npy\"))[:,:,:,:-1]#[-num_hidden:,:,:,:-1]\n",
    "print(\"Train Data:{}\\tValidation Data:{}\\tTest Data:{}\".format(train_data.shape, validation_data.shape, test_data.shape))\n",
    "feature_names = np.load(os.path.join(DIR, \"RAW_DATA\", \"feature_names.npy\"), allow_pickle=True)\n",
    "print(\"Static features:{}\".format(feature_names[config.static_channels]))\n",
    "print(\"Weather features:{}\".format(feature_names[config.weather_channels]))\n",
    "print(\"SF features:{}\".format(feature_names[config.sf_channels]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANNELS INFO\n",
    "channels = config.channels\n",
    "input_channels = config.weather_channels#+config.sf_channels\n",
    "sf_channels = config.sf_channels\n",
    "static_channels = config.static_channels\n",
    "# TIME SERIES INFO\n",
    "window = config.window\n",
    "\n",
    "# TRAIN INFO\n",
    "device = config.device\n",
    "code_dim = 320#config.code_dim\n",
    "n_clusters = config.n_clusters\n",
    "epochs = 10 #config.epochs\n",
    "batch_size = config.batch_size\n",
    "learning_rate = 3e-4#config.learning_rate\n",
    "alpha = config.alpha\n",
    "recon_weight = 0.1#config.recon_weight\n",
    "static_weight = 10#config.static_weight\n",
    "triplet_weight = 1#config.triplet_weight\n",
    "sum_weight = recon_weight+static_weight+triplet_weight\n",
    "num_layers = 1\n",
    "run=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, stat_channels, code_dim, num_layers,device):\n",
    "        super(LSTM,self).__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.stat_channels = stat_channels\n",
    "        self.code_dim = code_dim\n",
    "        self.device = device\n",
    "        self.num_layers = num_layers\n",
    "        #self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "        #                    num_layers=num_layers, batch_first=True)\n",
    "        self.lstm = EALSTM(in_channels,stat_channels, code_dim, batch_first=True)\n",
    "        self.out = BayesianLinear(code_dim, 1)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "    def forward(self, xd,xs):\n",
    "        batch, seq_len, in_channels = xd.shape\n",
    "       # h = torch.tensor(torch.zeros(num_layers,batch,self.code_dim))\n",
    "        #h = h.to(self.device)\n",
    "        #h = torch.unsqueeze(h,0)\n",
    "        # Propagate input through LSTM\n",
    "        #output,_ = self.lstm(x,h)\n",
    "        output,h = self.lstm(xd,xs)\n",
    "        \n",
    "        out = self.out(output)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = globals()[\"LSTM\"](in_channels=len(input_channels), stat_channels=len(static_channels), code_dim=code_dim,num_layers=num_layers, device=device)\n",
    "model = model.to(device)\n",
    "criterion = torch.nn.MSELoss(reduction=\"none\")\n",
    "triplet_criterion = torch.nn.TripletMarginLoss(margin=alpha, p=2.0, eps=1e-06, reduction=\"none\")\n",
    "# triplet_criterion = torch.nn.TripletMarginWithDistanceLoss(distance_function=torch.nn.PairwiseDistance(p=2.0, eps=1e-06), margin=alpha, reduction=\"none\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Total trainable parameters:{}\".format(pytorch_total_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"{}_{}_{}_{}\".format(\"Only_EALSTM\",num_hidden,run,code_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "validation_loss = []\n",
    "min_val = 10000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    #############################################################\n",
    "    # RUN ON TRAIN DATA\n",
    "    dataset = train_data\n",
    "    total_loss = 0\n",
    "    total_recon_loss = 0\n",
    "    total_triplet_loss = 0\n",
    "    total_static_loss = 0\n",
    "    for year in range(dataset.shape[1]):\n",
    "        data = dataset[:,year]\n",
    "        for batch in range(math.ceil(data.shape[0]/batch_size)):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            batch_data = torch.from_numpy(data[batch*batch_size:(batch+1)*batch_size]).to(device)\n",
    "            \n",
    "            batch_data_input = batch_data[:,:,input_channels]\n",
    "            \n",
    "            batch_data_static = batch_data[:,0,static_channels]\n",
    "\n",
    "            batch_sf_data = batch_data[:,:,sf_channels]\n",
    "            input_data =  batch_data_input\n",
    "            static_data = batch_data_static\n",
    "            reconstruction = model(input_data.to(device),static_data.to(device))\n",
    "\n",
    "#             # Calculate reconstruction loss\n",
    "#             recon_loss = torch.sum(criterion(reconstruction, input_data), axis=2)\n",
    "#             recon_loss = torch.masked_select(recon_loss, (input_data[:,:,-1]!=config.unknown))\n",
    "#             recon_loss = torch.mean(recon_loss)\n",
    "                        # Calculate reconstruction loss\n",
    "            recon_loss = criterion(reconstruction, batch_sf_data)\n",
    "            recon_loss = torch.masked_select(recon_loss, (batch_sf_data!=config.unknown))\n",
    "            recon_loss = torch.mean(recon_loss)\n",
    "            loss = (recon_weight*recon_loss)\n",
    "            total_loss += loss.item()\n",
    "            total_recon_loss += recon_loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    print('Epoch:{}\\tTrain Loss:{:.4f}\\tRecon Loss:{:.4f}\\tTriplet Loss:{:.4f}\\tStatic Loss:{:.4f}'.format(epoch, total_loss/((batch+1)*(year+1)), total_recon_loss/((batch+1)*(year+1)), total_triplet_loss/((batch+1)*(year+1)), total_static_loss/((batch+1)*(year+1))), end=\"\\t\")\n",
    "    train_loss.append(total_loss/((batch+1)*(year+1)))\n",
    "    model.eval()\n",
    "    \n",
    "    #############################################################\n",
    "    # RUN ON VALIDATION DATA\n",
    "    dataset = validation_data\n",
    "    total_loss = 0\n",
    "    total_recon_loss = 0\n",
    "    total_triplet_loss = 0\n",
    "    total_static_loss = 0\n",
    "    for year in range(dataset.shape[1]):\n",
    "        data = dataset[:,year]\n",
    "        for batch in range(math.ceil(data.shape[0]/batch_size)):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            batch_data = torch.from_numpy(data[batch*batch_size:(batch+1)*batch_size]).to(device)\n",
    "            \n",
    "            batch_data_input = batch_data[:,:,input_channels]\n",
    "            \n",
    "            batch_data_static = batch_data[:,0,static_channels]\n",
    "\n",
    "            batch_sf_data = batch_data[:,:,sf_channels]\n",
    "            input_data =  batch_data_input\n",
    "            static_data = batch_data_static\n",
    "            reconstruction = model(input_data.to(device),static_data.to(device))\n",
    "\n",
    "#             # Calculate reconstruction loss\n",
    "#             recon_loss = torch.sum(criterion(reconstruction, input_data), axis=2)\n",
    "#             recon_loss = torch.masked_select(recon_loss, (input_data[:,:,-1]!=config.unknown))\n",
    "#             recon_loss = torch.mean(recon_loss)\n",
    "                        # Calculate reconstruction loss\n",
    "            recon_loss = criterion(reconstruction, batch_sf_data)\n",
    "            recon_loss = torch.masked_select(recon_loss, (batch_sf_data!=config.unknown))\n",
    "            recon_loss = torch.mean(recon_loss)\n",
    "            loss = (recon_weight*recon_loss)\n",
    "            total_loss += loss.item()\n",
    "            total_recon_loss += recon_loss.item()\n",
    "    print('Val Loss:{:.4f}\\tRecon Loss:{:.4f}\\tTriplet Loss:{:.4f}\\tStatic Loss:{:.4f}'.format(total_loss/((batch+1)*(year+1)), total_recon_loss/((batch+1)*(year+1)), total_triplet_loss/((batch+1)*(year+1)), total_static_loss/((batch+1)*(year+1))), end=\"\\t\")\n",
    "    validation_loss.append(total_loss/((batch+1)*(year+1)))\n",
    "    if min_val>validation_loss[-1] and validation_loss[-1]>0:\n",
    "        min_val = validation_loss[-1]\n",
    "        torch.save(model.state_dict(), os.path.join(MODEL_DIR, \"{}.pt\".format(model_name)))    \n",
    "    end = time.time()\n",
    "    print(\"Time:{:.4f}\".format(end-start))\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.xlabel(\"#Epoch\", fontsize=50)\n",
    "plt.plot(train_loss, linewidth=4)\n",
    "plt.plot(validation_loss, linewidth=4)\n",
    "plt.tight_layout(pad=0.0,h_pad=0.0,w_pad=0.0)\n",
    "plt.savefig(os.path.join(RESULT_DIR, \"{}_LOSS.png\".format(model_name)), format = \"png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kgssl",
   "language": "python",
   "name": "kgssl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
